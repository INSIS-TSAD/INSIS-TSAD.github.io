<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>byf 【AAAI-2019】A Deep Neural Network for Unsupervised Anomaly Detection and Diagnosis in Multivariate Time Series Data</title>
    <url>/2021/07/14/BaiYunfei/MSCRED/</url>
    <content><![CDATA[<p><a href="https://imgtu.com/i/Rsvfcq"><img src="https://z3.ax1x.com/2021/07/01/Rsvfcq.png" alt="Rsvfcq.png"></a></p>
<a id="more"></a>
<h1 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h1><p><strong>定义：</strong>多元时间序列中的异常检测和诊断是指<strong>识别特定时间步长的异常状态并查明根本原因。</strong></p>
<p><strong>挑战：</strong>构建多元时序异常检测系统具有挑战性</p>
<p>$\bull$不仅需要捕获每个时间序列中的时间依赖性，还需要对不同时间序列对之间的<strong>相关性</strong>进行编码。</p>
<p>$\bull$系统应具有<strong>抗噪声能力</strong>，并根据不同事件的严重性为操作员提供不同级别的异常评分。</p>
<p><strong>本文解决方案：</strong>提出了一种多尺度卷积循环编码器-解码器 <strong>(MSCRED)</strong>，以在多元时间序列数据中执行异常检测和诊断。</p>
<p>$\bull$构造多尺度（分辨率）<strong>特征矩阵</strong>(signature matrices)来表征不同时间步长中系统状态的多个级别。</p>
<p>$\bull$给定特征矩阵，使用<strong>卷积编码器对传感器间（时间序列）相关性进行编码</strong>，并开发基于注意力的卷积长短期记忆（ConvLSTM）网络来捕获时间模式。</p>
<p>$\bull$基于对传感器间相关性和时间信息进行编码的特征图，<strong>卷积解码器用于重建输入特征矩阵</strong>，并进一步利用<strong>残差特征矩阵</strong>来检测和诊断异常。</p>
<p><strong>实验结果：</strong>基于<strong>合成数据集和真实发电厂数据集</strong>的大量实证研究表明，MSCRED 可以胜过最先进的基线方法。</p>
<h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p>复杂系统在现代制造业和信息服务中无处不在。管理这些系统的一项关键任务是检测<strong>(1)特定时间步长</strong>的异常情况，以便操作员可以采取进一步行动来解决潜在问题。此外，查明根本原因，即<strong>(2)识别导致异常的传感器</strong>（系统组件），可以帮助系统操作员及时进行系统诊断和修复。</p>
<p>在现实世界的应用中，由于现代系统的自动恢复能力和稳健性，由<strong>时间动荡或系统状态切换引起的短期异常可能最终不会导致真正的系统故障</strong>，这是很常见的。因此，如果异常检测算法可以<strong>(3)根据各种事件的严重程度为操作员提供不同级别的异常分数</strong>，那将是很重要的。</p>
<p>为简单起见，本文假定<strong>事件的严重性与这项工作中异常的持续时间成正比</strong>。图 1(a) 说明了多元时间序列数据中的两个异常，即红色虚线圆圈标记的 A1(黄色) 和 A2(黑色)。 A2 的持续时间<strong>(严重性级别)</strong>大于 A1。</p>
<p><a href="https://imgtu.com/i/RsvcNQ"><img src="https://z3.ax1x.com/2021/07/01/RsvcNQ.png" alt="RsvcNQ.png"></a></p>
<p>==先前研究==</p>
<p>为了构建一个可以自动检测和诊断异常的系统，一个主要问题是<strong>历史数据中很少甚至没有异常标签可用，这使得监督算法不可行</strong>。 在过去的几年中，已经开发出了大量无监督的异常检测方法。 最突出的技术包括距离/聚类方法(KNN)、分类方法(OC-SVM)、概率方法、密度估计方法(DAGMM)、时间预测方法(ARMA、基于LSTM的方法)以及最近的深度学习技术。</p>
<p>==缺陷==</p>
<p>尽管存在内在的无监督设置，但由于以下原因，它们中的大多数仍可能无法有效检测异常：</p>
<p><strong>多变量时间序列数据存在时间依赖性。</strong> 由于这个原因，需要使用距离/聚类方法，分类方法和密度估计方法，可能表现不佳，因为它们<strong>无法捕获不同时间步长的时间依赖性。</strong></p>
<p><strong>多元时间序列数据在实际应用中通常包含噪声。</strong> 当噪声变得相对严重时，可能会<strong>影响</strong>时间预测模型的概括能力，以及<strong>增加误报</strong>。根据不同事件的严重程度为运营商提供不同级别的异常评分是有意义的， 现有的根因分析方法，例如(RCA) 对噪声敏感，无法处理这个问题。</p>
<hr>
<p>在本文中，提出了一种多尺度卷积循环编码器-解码器（MSCRED）来共同考虑上述问题。</p>
<p>(1)MSCRED 首先构建多尺度（分辨率）特征矩阵来表示不同时间步长的系统状态的多个级别(系统状态的不同级别用于指示不同异常事件的严重程度)。</p>
<p>(2)给定特征矩阵，使用卷积编码器对传感器间（时间序列）相关模式进行编码，并开发基于注意力的卷积长短期记忆（ConvLSTM）网络来捕获时间模式。</p>
<p>(3)利用对传感器间相关性和时间信息进行编码的特征图，卷积解码器用于重建特征矩阵，并进一步利用残差特征矩阵来检测和诊断异常。</p>
<hr>
<p>==如果 MSCRED 之前从未观察到类似的系统状态，它可能无法很好地重建特征矩阵==</p>
<p>例如，图 1(b) 显示了正常和异常期间的特征矩阵$M<em>{normal}$和$M</em>{abnormal}$。理想情况下，MSCRED 不能很好地重建 $M<em>{abnormal}$，因为训练矩阵（例如，$M</em>{normal}$）与 $M_{abnormal}$不同。</p>
<p><a href="https://imgtu.com/i/RsvcNQ"><img src="https://z3.ax1x.com/2021/07/01/RsvcNQ.png" alt="RsvcNQ.png"></a></p>
<hr>
<p>总而言之，我们工作的<strong>主要贡献</strong>是：</p>
<p>(1)我们将异常检测和诊断问题制定<strong>为三个基本任务</strong>，即==异常检测、根因识别和异常严重程度解释==。 </p>
<p>(2)我们引入了系统特征矩阵的概念，开发了 MSCRED 以通过卷积编码器对传感器间相关性进行编码，将时间模式与基于注意力的 ConvLSTM 网络相结合，并通过卷积解码器重建签名矩阵。 据我们所知，MSCRED 是第一个考虑多元时间序列之间相关性进行异常检测的模型，可以共同解决所有三个任务。==特征抽取、重构、评估==</p>
<p>(3)我们对综合数据集和电厂数据集进行广泛的经验研究。 我们的结果证明了 MSCRED 的性能优于最先进的基线方法。</p>
<hr>
<h1 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h1><p>多变量时间序列数据的无监督异常检测是一项具有挑战性的任务，过去几年已经开发了各种类型的方法。</p>
<p><strong>一种传统类型是距离方法</strong>。KNN,OC-SVM,ARMA,集成方法等。</p>
<p><strong>基于深度学习的无监督异常检测算法</strong>。DAGMM, LSTM等。</p>
<h1 id="MSCRED框架"><a href="#MSCRED框架" class="headerlink" title="MSCRED框架"></a>MSCRED框架</h1><h2 id="问题陈述"><a href="#问题陈述" class="headerlink" title="问题陈述"></a>问题陈述</h2><p>给定长度为T的n个时间序列的历史数据，即$\mathbf{X}=(\mathbf{x}_1,…,\mathbf{x}_n)^T\in \mathbb{R}^{n<em>T}$，假设数据中<em>*不存在异常</em></em>，我们的目标是：</p>
<p>$\bull$检测T之后的异常</p>
<p>$\bull$给出异常的程度</p>
<h2 id="使用特征矩阵表明状态"><a href="#使用特征矩阵表明状态" class="headerlink" title="使用特征矩阵表明状态"></a>使用特征矩阵表明状态</h2><p>先前的研究表明，不同时间序列对之间的相关性对于表征系统状态至关重要。为了表示从$t−w$到 $t$ 的多元时间序列片段中不同时间序列对之间的相关性，基于该时间段内两个时间序列的成对内积构建了一个$n*n$特征矩阵$M^t$。例子如图1(b):</p>
<p><a href="https://imgtu.com/i/RsvcNQ"><img src="https://z3.ax1x.com/2021/07/01/RsvcNQ.png" alt="RsvcNQ.png"></a></p>
<p>具体来说，给定多元时间序列段$X^w$中的两个时间序列==错误==<img src="/Users/baiyunfei/Library/Application Support/typora-user-images/image-20210623150200440.png" alt="image-20210623150200440" style="zoom:50%;" /></p>
<p>和<img src="/Users/baiyunfei/Library/Application Support/typora-user-images/image-20210623150230881.png" alt="image-20210623150230881" style="zoom:50%;" />，它们的相关性$m_{ij}^t\in M^t$计算为：</p>
<p><a href="https://imgtu.com/i/Rsvwct"><img src="https://z3.ax1x.com/2021/07/01/Rsvwct.png" alt="Rsvwct.png"></a></p>
<p>其中$\mathcal{k}=w$，特征矩阵，即$M^t$，不仅可以捕捉两个时间序列之间的<strong>形状相似性和值尺度相关性</strong>，而且对输入<strong>噪声具有鲁棒性</strong>，因为某些时间序列的噪声对特征矩阵的影响很小。</p>
<p>在本文中，两段之间的<strong>间隔设置为10</strong>，此外，为了表征不同尺度的系统状态，我们在每个时间步构建了$s(s = 3) $个不同长度 $(w = 10, 30, 60)$ 的特征矩阵。==异常严重程度解释==</p>
<h2 id="卷积编码器"><a href="#卷积编码器" class="headerlink" title="卷积编码器"></a>卷积编码器</h2><p>采用<strong>全卷积编码器对系统特征矩阵的空间模式进行编码</strong>。具体来说，我们将不同尺度的$M^t$连接为张量$\mathcal{X}^{t,0}\in \mathbb{R}^{n<em>n</em>s}$，然后将其馈送到多个卷积层。假设$\mathcal{X}^{t,l-1}\in \mathbb{R}^{n<em>{l-1}*n</em>{l-1}*d_{l-1}}$表示第$(l-1)$层中的特征图，则第$l$层的输出由下式给出：</p>
<p><a href="https://imgtu.com/i/RDxubF"><img src="https://z3.ax1x.com/2021/07/01/RDxubF.png" alt="RDxubF.png"></a></p>
<p>$f(.)$是激活函数，$W^l\in \mathbb{R}^{k<em>l<em>k_l</em>d</em>{l-1}<em>d_l}$表示大小为$k_l</em>k<em>l*d</em>{l-1}$的卷积核，$b^l\in \mathbb{R}^{d<em>l}$是一个偏置项，$\mathcal{X}^{t,l}\in \mathbb{R}^{n</em>{l}<em>n_{l}</em>d_{l}}$表示第$l$层的输出特征图。</p>
<p>使用缩放指数型线性单元 <strong>(SELU) 作为激活函数和 4 个卷积层</strong>，Conv1-Conv4 具有 32 个大小为 3 × 3 × 3 的内核、64 个大小为3×3×32 的内核、128 个大小为 2×2×64 的内核和 256 个大小为 2×2×128 的内核以及分别为1×1、2×2、2×2 和 2×2 步幅。</p>
<p>图 2(a) 说明了特征矩阵的详细编码过程。</p>
<p><a href="https://imgtu.com/i/RrC1cn"><img src="https://z3.ax1x.com/2021/07/01/RrC1cn.png" alt="RrC1cn.png"></a></p>
<h2 id="基于注意力的ConvLSTM"><a href="#基于注意力的ConvLSTM" class="headerlink" title="基于注意力的ConvLSTM"></a>基于注意力的ConvLSTM</h2><p>卷积编码器生成的空间特征图在时间上取决于之前的时间步长。 </p>
<p>ConvLSTM已被开发用于捕获视频序列中的时间信息，但其性能可能会随着<strong>序列长度的增加而恶化</strong>。 为了解决这个问题，开发了一种基于注意力的 ConvLSTM，它可以跨不同时间步自适应地选择相关的隐藏状态（特征图）。具体来说，给定来自第$l$个卷积层的特征图$\mathcal{X}^{t,l}$和先前的隐藏状态$\mathcal{H}^{t-1,l}\in \mathbb{R}^{n<em>{l}*n</em>{l}*d_{l}}$，当前隐藏状态$\mathcal{H}^{t,l}$更新为$\mathcal{H}^{t,l}=ConvLSTM(\mathcal{X}^{t,l},\mathcal{H}^{t-1,l})$，其中 ConvLSTM单元被表述为：</p>
<p><a href="https://imgtu.com/i/RriyFO"><img src="https://z3.ax1x.com/2021/07/01/RriyFO.png" alt="RriyFO.png"></a></p>
<p>$\circ$代表 Hadamard 积，$\sigma$是 sigmoid 函数，</p>
<p><a href="https://imgtu.com/i/RrApz4"><img src="https://z3.ax1x.com/2021/07/01/RrApz4.png" alt="RrApz4.png"></a></p>
<p>由于最佳实证性能，我们调整步长h(即先前段的数量)并将其设置<strong>为5</strong>。此外，考虑到并非所有先前的步骤都与当前状态$\mathcal{H}^{t,l}$同等相关，我们采用时间注意机制来自适应地选择与当前步骤相关的步骤，并聚合这些信息特征图的表示以形成精炼的输出特征图$\hat{\mathcal{H}}^{t,l}$ ，由下式给出：==归一化==</p>
<p><a href="https://imgtu.com/i/RrZ3wR"><img src="https://z3.ax1x.com/2021/07/01/RrZ3wR.png" alt="RrZ3wR.png"></a></p>
<p>其中 Vec(·) 表示向量,$\mathcal{X}$是重新缩放因子 $(\mathcal{X}=5.0)$。 也就是说，我们将最后一个隐藏状态$\mathcal{H}^{t,l}$作为上下文向量，并通过 softmax 函数测量前面步骤的重要性权重$\alpha_i$。本质上，基于注意力的 ConvLSTM 联合建模特征矩阵的空间模式和每个卷积层的时间信息。图 2(b) 说明了时间建模过程。</p>
<h2 id="卷积解码器"><a href="#卷积解码器" class="headerlink" title="卷积解码器"></a>卷积解码器</h2><p>为了解码上一步获得的特征图并获得重建的特征矩阵，我们设计了一个卷积解码器，其公式如下：</p>
<p><a href="https://imgtu.com/i/RrnkeH"><img src="https://z3.ax1x.com/2021/07/01/RrnkeH.png" alt="RrnkeH.png"></a></p>
<p>$\circledast$表示去卷积操作，$\oplus$代表连接操作，$f(.)$是激活单元，$\hat{W}^l,\hat{b}^l$是第$l$层反卷积层的滤波器核和偏置参数。</p>
<p>具体来说，我们按照相反的顺序将第$l$个 ConvLSTM 层的$\hat{\mathcal{H}}^{t,l}$馈送到反卷积神经网络。输出特征图$\hat{\mathcal{X}}^{t,l-1}$与前一个 ConvLSTM 层的<strong>输出连接</strong>，使解码器过程堆叠。连接后的表示被进一步送入<strong>下一个反卷积层</strong>。最终输出$\hat{\mathcal{X}}^{t,0}$（具有相同大小的输入矩阵）表示重构特征矩阵。</p>
<p>因此，我们使用了 4 个反卷积层：DeConv4-DeConv1 具有 128 个大小为 2×2×256 的内核、64 个大小为 2×2×128 的内核、32 个大小为 3×3×64 的内核和 3个大小为3×3×64的内核 , 以及2×2,2×2,2 × 2, 和1 × 1 步幅。</p>
<p>解码器能够在不同的反卷积和 ConvLSTM 层合并特征图，这可以有效提高异常检测性能，我们将在实验中证明。 图 2(c) 说明了解码过程。</p>
<h2 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h2><p>对于 MSCRED，目标定义为矩阵上的特征误差，即</p>
<p><a href="https://imgtu.com/i/RsvttH"><img src="https://z3.ax1x.com/2021/07/01/RsvttH.png" alt="RsvttH.png"></a></p>
<p>$\mathcal{X}_{:,:,c}^{t,0}\in\mathbb{R}^{n*n}$。我们采用小批量随机梯度下降法和 Adam 优化器来最小化上述损失。 </p>
<p>在足够数量的训练时期后，利用学习到的神经网络参数来推断验证和测试数据的重建特征矩阵。 最后，我们基于残差特征矩阵进行异常检测和诊断。</p>
<h1 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h1><p>在本节中，我们进行了大量实验来回答以下研究问题：</p>
<p>• 异常检测。 在多元时间序列$(RQ1)$中，MSCRED 是否可以胜过基线方法的异常检测？ MSCRED 的每个组件如何影响其性能$(RQ2)$？<br>• 异常诊断。 MSCRED 是否可以有效地执行根因识别$(RQ3)$和异常严重程度（持续时间）解释$(RQ4)$？<br>• 抗噪能力强。 与基线方法相比，MSCRED 是否对输入噪声$(RQ5)$具有更强的鲁棒性？</p>
<h2 id="实验设置"><a href="#实验设置" class="headerlink" title="实验设置"></a>实验设置</h2><h3 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h3><p><a href="https://imgtu.com/i/RsWvo8"><img src="https://z3.ax1x.com/2021/07/01/RsWvo8.png" alt="RsWvo8.png"></a></p>
<p><strong>合成数据集</strong></p>
<p><a href="https://imgtu.com/i/Rshl9g"><img src="https://z3.ax1x.com/2021/07/01/Rshl9g.png" alt="Rshl9g.png"></a></p>
<p>其中$s_{rand}$是 0 或 1 的随机种子。</p>
<p>上面的公式捕获了多元时间序列的三个属性：$(a) $三角函数 (C1) 模拟时间模式；$(b)$ 时间延迟$t_0\in[50,100]$和频率$ω \in[40, 50] (C2) $模拟各种周期循环；$(c)$ 由因子$ λ = 0.3 (C3) $缩放的随机高斯噪声$ \varepsilon\in N(0,1)$模拟各种形状的数据噪声。</p>
<p>此外，如果两个正弦波的频率相似且几乎同相，则它们具有高相关性。 通过随机选择每个时间序列的频率和相位，我们期望一些对具有高相关性，而一些具有低相关性。 我们随机生成 30 个时间序列，每个序列包含 20000 个点。 此外，在测试期间将5个类似冲击波的异常（具有相似的正常数据值范围）随机注入3个随机时间序列（根本原因）中。 每个异常的持续时间属于三个尺度之一，即 30、60、90。</p>
<p><strong>真实的发电厂数据</strong></p>
<p>包含一个由系统操作员识别的异常，我们在测试期间随机注入 4 个额外的异常（类似于我们在合成数据中所做的）以进行评估。</p>
<h3 id="基线"><a href="#基线" class="headerlink" title="基线"></a>基线</h3><p><strong>分类模型：</strong> OC-SVM；<strong>密度估计模型：</strong>DAGMM(能量分数作为异常分数)；</p>
<p><strong>预测模型：</strong> 它对训练数据的时间依赖性进行建模并预测测试数据的值。 我们采用了三种方法：HA、ARMA、LSTM-ED。 异常分数被定义为所有时间序列的平均预测误差。</p>
<p><strong>MSCRED变体：</strong></p>
<p>$CNN_{ConvLSTM}^{ED(4)}:$注意力模块和最后一层ConvLSTM;</p>
<p><strong>$CNN_{ConvLSTM}^{ED(3,4)}:$</strong>注意力模块和第3,4层ConvLSTM;</p>
<p><strong>$CNN_{ConvLSTM}^{ED}:$</strong>无注意力模块；</p>
<p><strong>异常分数：</strong>残差特征矩阵中值大于给定阈值$θ$的数量，$θ $是在不同的数据集上凭经验确定的。</p>
<h3 id="评估方法"><a href="#评估方法" class="headerlink" title="评估方法"></a>评估方法</h3><p>$P，R，F1$</p>
<p>阈值设定(专家建议)：$\tau=\beta·max{s(t)<em>{valid}}$,  $s(t)</em>{valid}$是验证阶段的异常分数，$\beta \in [1,2]$是验证期间最大的F1分数。测试期间的召回和精确度分数是根据此阈值计算的。 </p>
<p>(1)在两个数据集上的实验重复 5 次，并报告平均结果以供比较。</p>
<p>(2)三个通道，使用最小的一个 $(w = 10) $进行以下异常检测和根因识别评估。 还将提供三个通道结果的性能比较，用于异常严重程度的解释。</p>
<h3 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h3><p>异常检测结果$（RQ1、RQ2）$。 表 2 报告了用于异常检测的不同方法的性能，其中最佳分数以粗体突出显示，最佳基线分数以下划线表示。 最后一行报告了 MSCRED 相对于最佳基线方法的改进 (%)。</p>
<p><a href="https://imgtu.com/i/RsblXF"><img src="https://z3.ax1x.com/2021/07/01/RsblXF.png" alt="RsblXF.png"></a></p>
<p><strong>RQ1：与基线的比较</strong></p>
<p>(a)时间预测模型比分类和密度估计模型表现更好，表明两个数据集都具有<strong>时间依赖性</strong>；</p>
<p>(b) LSTM-ED的性能优于 ARMA，表明深度学习模型可以比传统方法捕获数据中<strong>更复杂的关系</strong>； </p>
<p>(c)MSCRED 表现最佳，对最佳基线的改进范围从 13.3% 到 30.0%。因为它可以有效地对多变量时间序列的传感器间相关性和时间依赖性进行建模。</p>
<p>图 3 提供了两个数据集的 MSCRED 和两种最佳基线方法（即 ARMA 和 LSTM-ED）的案例研究。 我们可以观察到 <strong>ARMA 的异常分数不稳定，结果包含很多误报和漏报</strong>。 同时，LSTM-ED 的异常分数比 ARMA 更平滑，但仍<strong>包含一些误报和漏报。</strong> MSCRED 可以检测所有异常，没有任何假阳性和假阴性。</p>
<p>为了证明更令人信服的评估，我们对另一个具有 10 个异常的合成数据进行了实验。MSCRED 的平均召回率和准确率得分（5 次重复实验）为 (0.84, 0.95)，而 LSTM-ED 的值为 (0.64, 0.87)。 此外，我们还对另一个大型电厂数据进行了实验，该数据具有 920 个传感器和 11 个标记异常。 MSCRED 的召回率和准确率得分为 (7/11, 7/13)，而 LSTM-ED 的值为 (5/11, 5/17)。 所有评估结果都表明了我们模型的有效性。</p>
<p><a href="https://imgtu.com/i/RsbIBQ"><img src="https://z3.ax1x.com/2021/07/01/RsbIBQ.png" alt="RsbIBQ.png"></a></p>
<p><strong>RQ2(各个模块的重要性)：与模型变体的比较</strong></p>
<p>在表 2 中，我们还观察到通过<strong>增加</strong> ConvLSTM 层的数量，MSCRED 的性能有所提高。</p>
<p>为了进一步证明<strong>注意力模块的有效性</strong>，图 4 报告了在最后两个 ConvLSTM 层上 5 个先前时间步长上注意力权重的平均分布。 结果是使用<strong>发电厂数据</strong>获得的。 我们分别计算正常时期段和异常时期段的<strong>平均注意力权重分布</strong>。 请注意，在后一种分布中，较旧的时间步长（第 1 步或第 2 步）往往仍处于正常状态，因此与当前时间步长（第 5 步）处于不同的系统状态，其分配的权重低于正常段分布中的权重 . 换句话说，<strong>注意力模块对系统状态变化表现出很高的敏感性，因此有利于异常检测</strong>。</p>
<p><a href="https://imgtu.com/i/Rsqcb4"><img src="https://z3.ax1x.com/2021/07/01/Rsqcb4.png" alt="Rsqcb4.png"></a></p>
<p><strong>RQ3:根因识别结果。</strong></p>
<p>作为异常诊断任务之一，根因识别依赖于良好的异常检测性能。 因此，我们比较了 MSCRED 和最佳基线（即 LSTM-ED）的性能。对于每个异常事件，我们按异常分数对所有时间序列进行排名，并将前 k 个序列确定为根本原因。 图 5 显示了 5 次重复实验中的平均召回率(k = 3)。 MSCRED 在合成数据和发电厂数据中分别以 25.9% 和 32.4% 的幅度优于 LSTM-ED。</p>
<p><a href="https://imgtu.com/i/Rsq526"><img src="https://z3.ax1x.com/2021/07/01/Rsq526.png" alt="Rsq526.png"></a></p>
<p><strong>RQ4：异常严重性（持续时间）解释。</strong> </p>
<p>MSCRED 的特征矩阵包括$s$个通道（在当前实验中$ s = 3$），它们以不同的尺度捕获系统状态。为了解释异常严重程度，我们首先根据三个通道的残差特征矩阵<strong>计算不同的异常分数</strong>，分段大小分别为 $w = 10、30 和 60$，并将它们表示为 MSCRED(S)、MSCRED(M) 和 MSCRED(L)。然后，我们<strong>独立评估</strong>他们在三种类型的异常上的表现。</p>
<p>图6(a)报告了对两个数据集进行 5 次重复实验的<strong>平均召回率分数</strong>。我们可以观察到 MSCRED(S) 能够检测所有类型的异常，而 MSCRED(M) 可以检测中长期异常。相反，MSCRED(L) 只能检测长时间异常。因此，我们可以通过<strong>联合考虑三个异常分数来解释异常严重程度。</strong>如果可以在所有三个通道中检测到异常，则该异常更有可能持续很长时间。否则，可能是短期或中期异常。</p>
<p><a href="https://imgtu.com/i/RsLqyT"><img src="https://z3.ax1x.com/2021/07/01/RsLqyT.png" alt="RsLqyT.png"></a></p>
<p>为了更好地展示 MSCRED 的有效性，图 7 提供了发电厂数据异常诊断的案例研究。在这种情况下，MSCRED(S) 检测到所有 5 个异常，包括 3 个短、1 个中和 1 个持续时间长的异常。 MSCRED(M) 错过了两个短持续时间的异常，而 MSCRED(L) 只检测到长持续时间的异常。此外，注入异常事件的四个残差特征矩阵显示了根本原因识别结果。在这种情况下，我们可以准确地查明超过一半的异常根本原因（红色矩形突出显示的行/列）。</p>
<p><a href="https://imgtu.com/i/RsLLOU"><img src="https://z3.ax1x.com/2021/07/01/RsLLOU.png" alt="RsLLOU.png"></a></p>
<p><strong>RQ5:对噪声的鲁棒性。</strong> </p>
<p>多变量时间序列在实际应用中通常包含噪声，因此异常检测算法对输入噪声的鲁棒性很重要。 为了研究 MSCRED 在异常检测方面的稳健性，我们通过在公式 7 中添加各种噪声因子 λ 在不同的合成数据集中进行实验。图 8 显示了$ λ $对 MSCRED、ARMA 和 LSTM-ED 性能的影响。我们可以观察到，当噪声范围从 0.2 到 0.45 变化时，MSCRED 始终优于 ARMA 和 LSTM-ED。 这表明，与 ARMA 和 LSTM-ED 相比，MSCRED 对输入噪声的鲁棒性更强。</p>
<p><a href="https://imgtu.com/i/RsOnfI"><img src="https://z3.ax1x.com/2021/07/01/RsOnfI.png" alt="RsOnfI.png"></a></p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>在本文中，我们制定了异常检测和诊断问题，并开发了一种创新模型 MSCRED 来解决它。 MSCRED 采用多尺度（分辨率）系统特征矩阵来表征整个系统在不同时间段的状态，并采用深度编码器-解码器框架来生成重建的特征矩阵。 该框架能够对多变量时间序列的传感器间相关性和时间依赖性进行建模。 残差特征矩阵进一步用于检测和诊断异常。 对合成数据集和发电厂数据集的广泛实证研究表明，MSCRED 可以胜过最先进的基线方法。</p>
]]></content>
      <categories>
        <category>byf</category>
      </categories>
      <tags>
        <tag>多变量时间序列</tag>
        <tag>时间序列分类</tag>
      </tags>
  </entry>
  <entry>
    <title>byf 【AAAI-2021】ShapNet</title>
    <url>/2021/03/17/BaiYunfei/ShapeNet(1)/</url>
    <content><![CDATA[<p>关键词：多变量时间序列，时间序列分类</p>
<p>在本文中，我们提出了一个名为ShapeNet的新型模型，该模型将不同长度的小波候选者嵌入到统一的空间中，以进行小波选择。该网络使用聚类三元组损失进行训练，该损失考虑了锚点与多个正（负）样本之间的距离以及正（负）样本之间的距离，这对于收敛非常重要。我们计算有代表性的和多样化的最终小波，而不是直接使用所有小波嵌入进行模型构建，以避免很大一部分非歧视性小波候选。我们已经使用UEA多元时间序列数据集在ShapeNet上进行了具有竞争性的最新技术和基准测试方法的实验。结果表明，ShapeNet的准确性是所有比较方法中最好的。此外，我们通过两个案例研究说明了小波的可解释性。</p>
<a id="more"></a>
<p><strong>1    介绍</strong></p>
<p><strong>MTSC(多元时间序列分类)挑战：</strong></p>
<p>·多元时间序列有多个变量，候选小波可能是大量或异质(一个变量有不同的候选小波)的。</p>
<p>·不同变量的候选小波可能有不同的长度。</p>
<p>·大多数模型是黒盒模型。</p>
<p><strong>贡献：</strong></p>
<p>本文提出了shapeNet方法，<strong>提高了分类的准确性并给了可解释的分类结果。</strong></p>
<p>首先，我们提出了<strong>多长度输入扩张因果卷积神经网络</strong>（Mdc-CNN），该网络增强了<strong>Dc-CNN</strong>，将不同长度和不同变量的小波候选对象嵌入到统一空间中（小波嵌入）。我们<strong>采用了扩展卷积</strong>，这使得序列的接受域指数增大从而能够处理长期依赖性，而不会使模型的复杂性激增。<strong>因果卷积仅用于对当前时间之前的时间序列进行卷积</strong>，以确保将来的值不会影响当前值。</p>
<p>此外，我们提出了一种用于训练<strong>Mdc-CNN的聚类三元组损失函数</strong>，该函数考虑了集群内/集群间度量学习以加速收敛和提高稳定性。</p>
<p>我们的<strong>聚类三元组损失不仅将多个正样本和多个负样本作为输入，而且还计算了它们之间的距离</strong>。相比之下，先前的三元组损失仅涉及一个正样本和一个负样本。我们的损失函数更加健壮，可以更快地确定小波嵌入和收敛（请参见图4）。据我们所知，<strong>本文是第一个使用神经网络发现MTS中小波的方法。</strong></p>
<p><a href="https://imgtu.com/i/6gZJpQ"><img src="https://s3.ax1x.com/2021/03/18/6gZJpQ.png" alt="6gZJpQ.png"></a></p>
<p>其次，我们<strong>避免直接喂入许多小波候选对象</strong>（通过使用Mdc-CNN的嵌入学习进行编码）来建立分类器。 我们首先聚簇小波候选嵌入。 然后，我们提出一个<strong>效用函数</strong>，以选择与大簇的质心接近且与其他聚类质心不同的前k个候选对象，这为我们提供了<strong>具有代表性和多样化的最终小波</strong>。</p>
<p>然后，我们采用<strong>首先正式定义的多元小波变换（MST）</strong>。 具体来说，<strong>给定一个多元时间序列，我们计算其到同一变量的候选小波的距离，以获得MST表示</strong>。</p>
<p>最后，由于有MST表示，我们可以轻松地学习分类模型。 在本文中，<strong>我们采用线性支持向量机</strong>，这使我们能够<strong>可视化不同变量的小波如何分离不同类别的时间序列。</strong></p>
<p>我们在UEA MTS档案库上进行实验。 结果表明，就精度而言，ShapeNet是最新方法中最好的基准。 我们注<strong>意到ShapeNet在30个数据集中的14个数据集中提供了最佳性能</strong>。 我们介绍了<strong>人类动作识别</strong>和<strong>ECG</strong>数据的两种情况，以说明小波如何给出分类的可解释。<br><a href="https://imgtu.com/i/6gZiTK"><img src="https://s3.ax1x.com/2021/03/18/6gZiTK.png" alt="6gZiTK.png"></a></p>
<p><strong>2    相关工作</strong></p>
<p>MTSC的现有方法：基于模型和基于神经网络。</p>
<p><strong>3    ShapeNet</strong></p>
<p>在本节中，我们提出了一个<strong>Shapelet神经网络方法，即ShapeNet</strong>。 具体来说，我们提出了<strong>多长度输入的扩张因果CNN</strong>，<strong>聚类三元组损失函数和多变量小波变换</strong>。</p>
<p><strong>3.1    Mdc-CNN</strong></p>
<p>小波候选者最初是具有不同长度的所有时间序列子序列。 我们使用<strong>离散大小的滑动窗口（图1的圆柱体中显示的数据）来生成候选对象</strong>。 我们的目标是将所有小波候选者从原始空间嵌入到一个新的统一空间中。</p>
<p><strong>3.1.1    设计原理。</strong></p>
<p>首先，<strong>使用扩张的因果卷积神经网络（Dc-CNN）来学习时间序列子序列的新表示</strong>。已有研究证明了扩张因果关系网络对于序列建模任务的有效性。 <strong>扩张的卷积用于修改卷积的接受域</strong>。 <strong>因果卷积的设计使得将来的数据不会影响对过去数据的学习。</strong></p>
<p>其次，<strong>尽管输出的长度可以与输入的长度相同</strong>，但是Dc-CNN无法处理各种长度的输入。 因此，我们<strong>建议引入一个全局最大池化层和一个线性层，它们堆叠在最后一个Dc-CNN层的顶部</strong>，以将所有小波候选者嵌入到统一空间中（图1中的绿色框表示）。 我们称其为多长度输入扩张因果CNN（Mdc-CNN）。</p>
<p> <strong>3.1.2    Mdc-CNN结构。</strong></p>
<p>Mdc-CNN在图2中进一步说明。</p>
<p>图2(a)显示，<strong>编码器具有$i+1$层残差块</strong>，其中$2^i$是扩张因子，并且全局最大池化层和线性层堆叠在<strong>顶部的残差块。</strong> 编码器的输入是各种长度和变量的时间序列子序列，输出是它们的统一表示。 我们称输出<strong>小波候选嵌入</strong>。</p>
<p>图2(b)给出了具有两个相同子块的残差块，以及一个扩张因果卷积块。</p>
<p>图2(c)给出了一个扩张因果卷积示例，其扩张因子$d=2^0,2^1,2^2$。</p>
<p><a href="https://imgtu.com/i/6gVtZ6"><img src="https://s3.ax1x.com/2021/03/18/6gVtZ6.png" alt="6gVtZ6.png"></a></p>
<p><strong>3.2    无监督的表示学习</strong></p>
<p>接下来，我们将说明<strong>如何以无监督的方式训练Mdc-CNN网络</strong>。word2vec的原理假设单词的表示<strong>应满足两个要求：</strong>（i）表示应接近其上下文。以及（ii）它应与那些随机选择的上下文相距较远，因为它们可能与原始单词的上下文不同。</p>
<p>学习/训练（类似于word2vec）的目的是确保相似的时间序列获得相似的表示。</p>
<p><strong>1.</strong>word2vec假设的第二个要求在时间序列中并不总是成立。 例如，Basicmotions数据集中行走类的一个变量如图3所示。我们可以很容易地观察到，波形的某些波峰很远但彼此之间并不遥远。</p>
<p><strong>2.</strong>一批次中仅包含一个正样本来训练网络，在学习小波的表示形式时，这通常是不稳定的。</p>
<p><strong>3.</strong>以前没有考虑过负（正）样本之间的距离。 图4显示了使用原始三元组损失学习小波表示的损失。 可以注意到，<strong>虽然损失略有下降，但它是不稳定的并且几乎不会收敛。</strong></p>
<p><a href="https://imgtu.com/i/6gZOBt"><img src="https://s3.ax1x.com/2021/03/18/6gZOBt.png" alt="6gZOBt.png"></a></p>
<p><a href="https://imgtu.com/i/6gZJpQ"><img src="https://s3.ax1x.com/2021/03/18/6gZJpQ.png" alt="6gZJpQ.png"></a></p>
<p><strong>聚类三元组损失函数</strong>。 在本文中，<strong>我们提出了一个聚类三元组损失函数，该函数以多个正样本和负样本以及正样本（负样本）之间的距离作为输入。</strong> 为简单起见，我们采用两个群集来说明我们的损失函数。 具体来说，训练集$\mathcal{T}$中所有可能的三元组的集合定义如下：</p>
<p><a href="https://imgtu.com/i/6gZEfe"><img src="https://s3.ax1x.com/2021/03/18/6gZEfe.png" alt="6gZEfe.png"></a></p>
<p>其中x是锚定小波候选者，$x^+$和$x^-$分别表示大小为$K^+$和$K^-$的正样本和负样本的集合。</p>
<p>在某些真实的数据集中，三元组的数量很大，并且使用所有三元组进行训练在计算上是禁止的，并且次优。 所以，<strong>本文进行三重采样。</strong></p>
<p>首先，我们将正（负）样本到锚点的归一化距离表示为$D<em>{AP}(D</em>{AN})$，我们具有以下公式：</p>
<p><a href="https://imgtu.com/i/6gZeld"><img src="https://s3.ax1x.com/2021/03/18/6gZeld.png" alt="6gZeld.png"></a></p>
<p>其中，μ是在正样本和负样本之间强制执行的余量。 假设采用平方欧几里德距离。 然后可以如下定义$D<em>{AP}(D</em>{AN})$</p>
<p><a href="https://imgtu.com/i/6gZnOI"><img src="https://s3.ax1x.com/2021/03/18/6gZnOI.png" alt="6gZnOI.png"></a></p>
<p>$f(·)\in \mathcal{R}^z$是Mdc-CNN的嵌入表示形式，$z$是嵌入长度。</p>
<p>除了锚点与正（负）样本之间的距离之外，正（负）样本之间的距离也包括在内，并且应较小（较大）。 所有正（负）样之间的最大距离如下：</p>
<p><a href="https://imgtu.com/i/6gZKmt"><img src="https://s3.ax1x.com/2021/03/18/6gZKmt.png" alt="6gZKmt.png"></a></p>
<p>样本内损失定义如下：</p>
<p><a href="https://imgtu.com/i/6gZM0P"><img src="https://s3.ax1x.com/2021/03/18/6gZM0P.png" alt="6gZM0P.png"></a></p>
<p>将这些放在一起，我们为方程式中的模型建议三元组的聚类三元组损失函数（7），以无监督的方式训练网络。</p>
<p><a href="https://imgtu.com/i/6gZ3tS"><img src="https://s3.ax1x.com/2021/03/18/6gZ3tS.png" alt="6gZ3tS.png"></a></p>
<p><strong>示例1</strong> 图5中说明了等式7。在此示例中说明了我们的聚类三元组损失的两个群集。 三元组损失函数既可以使<strong>锚点与所有正样本之间的距离最小化</strong>，又可以<strong>使所有正样本（负）样本之间的距离最小化</strong>，并且可以使<strong>锚点（正样本）与所有负样本之间的距离最大化</strong>。</p>
<p><a href="https://imgtu.com/i/6gZYlj"><img src="https://s3.ax1x.com/2021/03/18/6gZYlj.png" alt="6gZYlj.png"></a></p>
<p><strong>3.3    多元小波变换</strong></p>
<p>在确定小波候选者的统一表示之后，我们建议<strong>选择高质量和多样化的候选者作为最终的小波</strong>。 最后，我们采用MTS的小波变换过程，然后应用经典分类器解决MTSC问题。</p>
<p><strong>确定最终的小波</strong>。 通过遵循前面的小节，所有候选小波都被嵌入到一个统一的空间中。 它使我们能够简单地采用聚类方法（例如kmeans）来获得小波候选的Y个群集。 <strong>我们提出了一个效用函数（等式8）来对最接近聚类质心的候选进行排序</strong>。 等式8的<strong>第一个组件是候选小波集群的大小</strong>(大型群集意味着它代表许多候选者)。 <strong>第二个组件是候选小波与其他聚类中其他候选小波的距离</strong>(距离大表明候选小波与其他小波有所不同）：</p>
<p><a href="https://imgtu.com/i/6gZ8fg"><img src="https://s3.ax1x.com/2021/03/18/6gZ8fg.png" alt="6gZ8fg.png"></a></p>
<p><strong>根据等式8在所有Y个群集中选择前k个候选对象，并检索原始时间序列子序列作为最终小波，表示为$S_k$</strong>。</p>
<p><strong>多元时间序列转换</strong></p>
<p><strong>定义1    </strong>多元小波变换。 多元小波变换是通过使用一组最终小波$S<em>k$来计算距离将多元时间序列$\mathbb{T}_m$转换为新数据空间（$d</em>{m,1},…,d<em>{m,k}$）的方法，表示为$d</em>{m,j}=dist(T_m ^v,S_j)$，其中$S_j\in S_k,T_m^v \in \mathbb{T}_m$。并且它们的变量相同。</p>
<p><strong>示例2</strong>    图6显示了一个MST示例。最左边的图显示了一个实例，其中包含Basicmotions数据集中的六个变量。 中间有两个小波 S1和S2。 对于MST，我们计算具有相同变量的时间序列子序列之间的距离（例如，第一个变量（顶部的红色时间序列）与S1之间的距离）。 因此，时间序列实例的MST表示是一个向量，如最右部分所示。</p>
<p><a href="https://imgtu.com/i/6gZamq"><img src="https://s3.ax1x.com/2021/03/18/6gZamq.png" alt="6gZamq.png"></a></p>
<p>当所有MTS实例的转换完成时，可以利用某些标准分类器（例如SVM）从转换后的表示中学习分类模型。 在本文中，我们采用具有线性核的SVM，以便可以观察小波的权重进行分类。</p>
<p><strong>4    实验内容</strong></p>
<p><strong>4.1    数据集和参数</strong></p>
<p>测试了MTS数据集的著名基准，即UEA ARCHIVE。</p>
<p>批处理大小，通道数，卷积网络的内核大小以及网络深度分别设置为10、40、3和10。</p>
<p>学习率保持固定在$\eta=0.001$的较低值，而网络训练的时期数为400.等式1中$\mu=0.2$，对于三元损失函数中$\lambda=1$。 等式8中$\beta=0.5$。</p>
<p><strong>4.2    Mdc-CNN的收敛性</strong></p>
<p>我们验证了Mdc-CNN的收敛性(取决于4.1中的参数)。 例如，学习算法在四个数据集上的收敛性如下图所示：</p>
<p><a href="https://imgtu.com/i/6gZw7V"><img src="https://s3.ax1x.com/2021/03/18/6gZw7V.png" alt="6gZw7V.png"></a></p>
<p>随着训练在所有四个数据集上进行，所有损失都非常平滑地收敛。 我们还可以观察到，<strong>损失在开始时迅速收敛，然后稳定下来</strong>。 从其余的数据集中可以观察到类似的趋势。 这验证了我们的集群三元组损失的有效性。</p>
<p><strong>4.3    Baselines</strong></p>
<p>我们将ShapeNet与七种不同的方法进行了比较。</p>
<p><strong>·三个基准：</strong> 三种基准分类器（EDI，DTWI和DT WD）基于欧氏距离（EDI），与维度无关的动态时间规整（DTWI）和与维度有关的动态时间规整（DTWD）。</p>
<p><strong>·MLSTM-FCN：</strong> MLSTM-FCN是一种深度学习框架。</p>
<p><strong>·WEASEL-MUSE：</strong> WEASEL MUSE是基于模式袋的方法，具有统计特征选择，可变的窗口长度和MTSC的SAX。</p>
<p><strong>·负样本（NS）：</strong>该方法在训练其神经网络时应用了多个负样本，然后利用SVM进行最终分类。</p>
<p><strong>·TapNet：</strong>TapNet是一种新颖的MTSC模型，带有注意力原型网络，可以利用传统方法和基于深度学习的方法的优势。</p>
<p><strong>4.4    实验的准确性</strong></p>
<p><strong>与其他方法比较。</strong>基线结果的实验准确度分别来自原始论文。 我们只考虑用于实验的标准化数据集。 表1给出了数据集的总体分类准确度结果。<strong>ShapeNet的准确度结果为10次运行的平均值</strong>，所有数据集的标准偏差均小于0.01。</p>
<p><strong>从表1中可以看出，ShapeNet的总体精度是所有方法中最好的。</strong> 此外，ShapeNet在14个数据集中表现最佳，超过了其他三种基准测试方法。 ShapeNet的总最佳精度几乎是NS，TapNet，WEASEL-MUSE和MLSTM-FCN的两倍，并且显然比其他方法还要好。 </p>
<p><a href="https://imgtu.com/i/6gZyp4"><img src="https://s3.ax1x.com/2021/03/18/6gZyp4.png" alt="6gZyp4.png"></a></p>
<p><strong>弗里德曼检验和威尔科克森符号秩检验。</strong></p>
<p>Friedman检验是一种非参数统计检验，用于检测八种方法在30个数据集中的差异。 我们的统计显着性是p = 0.00，小于α= 0.05。 因此，我们拒绝零假设，所以这八种方法之间存在显着差异。<br>我们注意到ShapeNet在所有比较方法中平均排名第一。 我们进一步针对所有基线进行了Wilcoxon检验，发现所有结果在p &lt;0.05时均具有统计学显着性，除了表1最后一行中的WEASEL-MUSE，NS。</p>
<p><strong>三重抽样与随机抽样。</strong>为了研究三重采样的性能，我们将其与随机三重采样进行比较以训练网络。 由于这里空间的局限性，我们在图8中仅显示了四个MTS数据集的结果，图8显示了最终精度的结果：我们的三元组采样显然是最好的。</p>
<p><a href="https://imgtu.com/i/6gZ61J"><img src="https://s3.ax1x.com/2021/03/18/6gZ61J.png" alt="6gZ61J.png"></a></p>
<p><strong>基于效用与随机选择。</strong>为了研究第3.3节中选择最终形状的效用函数的有效性，我们进行了一项实验，将其与随机选择进行比较。 聚类数为200，k的值为50。随机选择数为50。 它们如图9所示。在其他数据集中也可以找到相同的趋势。 在所有四个数据集中，我们基于效用的方法的准确性明显优于随机选择的方法，这表明它具有发现高质量小波的优越能力。</p>
<p><strong>小波数量的变化。</strong>我们在四个MTS数据集上比较了200个聚类中不同数量的前k个小波对ShapeNet最终精度的影响。</p>
<p>图10显示了通过改变小波数的准确性。 在所有四个数据集中，随小波数量从5增加到50，精确度迅速提高，然后略有下降。 </p>
<p><a href="https://imgtu.com/i/6gZW0x"><img src="https://s3.ax1x.com/2021/03/18/6gZW0x.png" alt="6gZW0x.png"></a></p>
<p><a href="https://imgtu.com/i/6gZf76"><img src="https://s3.ax1x.com/2021/03/18/6gZf76.png" alt="6gZf76.png"></a></p>
<p><strong>4.5    实验的可解释性</strong></p>
<p>我们进一步研究了小波的可解释性，这是基于小波的方法的优势。 我们报告了ShapeNet从两个数据集中生成的两个Shapelet（即k = 2）。 选择这些数据集的原因很简单，因为它们无需太多领域知识即可呈现。</p>
<p><strong>解释Basicmotions的小波</strong></p>
<p>从图11中的Basicmotions数据集（最左侧的图）中发现了两个有趣的小波S1和S2。<strong>S1描述x轴的加速度，S2描述z轴的角速度。</strong> ShapeNet从第一个和第六个变量中选择小波，这表明变量的重要性。 中间的图显示了来自数据集的四个类别的四个多元时间序列。 不同的颜色显示不同的变量。 距离只能在相同变量（在视觉上为相同颜色）的时间序列之间计算。 到两个小波的距离将多元时间序列投影到二维空间中（最右边的图）。 然后，<strong>通过线性分类器对转换后的表示进行分类。 结果表明，S2在区分羽毛球运动与其他运动方面是有效的。 S1可以区分步行和跑步。S1和S2都可以区分站立和其他运动</strong>。</p>
<p>我们注意到，与小数据相比，具有小波的MST表示更易于解释，并且可以观察到一些知识。 例如，站立和羽毛球的S1相似，这很直观。 事实证明，在等待羽毛球比赛时，很多球员都站了起来。</p>
<p><a href="https://imgtu.com/i/6gZIhD"><img src="https://s3.ax1x.com/2021/03/18/6gZIhD.png" alt="6gZIhD.png"></a></p>
<p><strong>解释AtrialFibrillation(心房颤动)的小波</strong></p>
<p>我们以AtrialFibrillation（这是一个带有两个变量的ECG数据集）为例，以显示发现的多元小波的可解释性。 数据集中有三类，<strong>即“持续性房颤”，“至少一分钟自终止性房颤”和“立即终止性房颤”</strong>。 它们分别标记为N，S和T。 从对AtrialFibrillation的简短描述中，我们可以知道这三个类别的终止时间为<strong>T &lt;S &lt;N</strong>。但是，即使以图解形式，原始数据也难以理解。 在图12中，我们的小波S1和S2将所有原始时间序列转换为二维空间。 在MST表示中，读者可以轻松地跟踪每个类别的终止时间。 新空间的大小越大，原始时间序列终止的次数就越多。</p>
<p><a href="https://imgtu.com/i/6gZT9e"><img src="https://s3.ax1x.com/2021/03/18/6gZT9e.png" alt="6gZT9e.png"></a></p>
<p><strong>5    总结</strong></p>
<p>本文提出了一种新颖的用于MTSC的小波神经网络方法ShapeNet。 我们提出了Mdc-CNN，以将各种长度的时间序列子序列学习到统一空间中，并提出了基于聚类（簇）的三元组损失，以无人监督的方式训练网络。 我们采用MST来获得时间序列的MST表示。 转换后，我们使用带有线性核的SVM进行分类。 实验结果表明，ShapeNet的分类准确性优于七个比较方法。 学习算法收敛迅速，效用函数有效。 小波的数量可以设置为50（默认情况下），以实现最高的精度。 小结的可解释性通过两个案例研究得以说明。 至于未来的工作，我们计划研究缺少值的MTS，这对于现实世界的数据集而言具有挑战性。</p>
]]></content>
      <categories>
        <category>byf</category>
      </categories>
      <tags>
        <tag>多变量时间序列</tag>
        <tag>时间序列分类</tag>
      </tags>
  </entry>
  <entry>
    <title>cyf Cellular QoE Prediction for Video Service Based on Causal Structure Learning</title>
    <url>/2021/07/20/ChenYifei/Cellular%20QoE%20Prediction%20for%20Video%20Service%20Based%20on%20Causal%20Structure%20Learning/</url>
    <content><![CDATA[<p><img src="https://s2.loli.net/2022/07/20/xKvXGjfTiHlVwd2.png" alt="image-20220720111309043"></p>
<p>2022年新发表在IEEE Transaction Intelligent Transportation Systems上</p>
<p>作者团队来自北京邮电大学的信息与通讯工程系</p>
<p>随着通信技术的发展和智能设备的普及，蜂窝网络中的用户体验成为人们关注的首要因素。同时，网络运营商面临着两个难题:预测用户实时体验，寻找对用户体验有决定性影响的网络参数。针对这两个问题，我们提出了一种新的用户体验预测方案。蜂窝网络的因果结构学习用于分析从基站收集的众多性能指标(kpi)和关键质量指标(kqi)。通过因果结构学习，可以得到基于kpi与KQI之间关联的有向因果图。这种因果结构可以嵌入到图的注意网络中。其中，选择注意机制进一步强化参数之间的相关性。每个KPI之间以及KPI与KQI之间的相关性用于预测单元级用户体验的未来价值。结果表明，该方法在蜂窝网络数据分析和用户体验预测方面具有良好的性能。</p>
<p>技术路线：算法挖掘因果结构图 $\to$ 因果图作为输入参与图注意力网络 $\to$ 预测用户体验质量(QoE)</p>
<h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>视频领域的主要矛盾之一是==流媒体质量评价的高需求==和==体验质量预测结果[7]的低准确性==之间的矛盾。QoS的具体指标是KPI，通常是蜂窝网络中基站采集的数据。QoE指标和QoS指标不一样。QoE指标通常是平均意见评分(MOS)，由主观和客观两个部分组成。主观部分往往因人而异，没有具体的判断标准。客观部分是KQI。目前对体验质量的研究多集中在主观指标上。虽然MOS和QoE[8]的映射可以很好地判断用户的感知，但在实际的网络优化中，获取每个用户的主观意见显然是不现实的。对于客观部分，KQI的预测常常面临预测精度不高的问题。</p>
<p>当前问题：KPI参数的预测比较成熟预测结果较准确，但是KPI并不能准确估计用户体验，因此KQI的估计逐渐成为研究热点。KQI估计的主要方法是找出KPI和KQI之间的关系，通过KPI的值估计KQI。虽然这种方法对当前的KQI估计准确性较高，但是对其未来值得预测却不好，因为这依赖于==KPI预测算法的稳定性==和==从KPI估计KQI算法的稳定性==。</p>
<p>解决方案：为了保证算法的稳定性，作者主张利用KPI和KQI之间的因果关系构建预测算法。</p>
<p>好处有1.在QoS（各种KPI指标）中找到影响video service的因果关系，用该因果结构取估计用户的体验（KQI）2.无线网络的各种数值型参数中也挖掘出一个因果结构，只使用直接影响用户体验的参数，实现了数据降维。这样得到的1-有向无环因果图和降维了的数据集将会被用到KQI的预测当中。</p>
<p><img src="https://s2.loli.net/2022/07/20/dAVF6T4mtUNksbL.png" alt="image-20220720111433829"></p>
<h1 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h1><h2 id="数据集介绍"><a href="#数据集介绍" class="headerlink" title="数据集介绍"></a>数据集介绍</h2><p><img src="https://s2.loli.net/2022/07/20/kgsybhKRFY4d2J9.png" alt="image-20220720111503413" style="zoom:67%;" /></p>
<p>三个月内一个基站收集到的数据，数据是每一小时记录一次，其统计值是一个小时内的平均值，KPI参数和KQI参数如上表所示；（在实际网络部署中，一个基站通常有两个载波频率。每个频率的资源分别分配给三个cell。）在图2中，目标细胞被标记为绿色，蓝色部分表示相邻相同载频的细胞。棕色部分表示不同的载波频率。不同载频小区的覆盖范围与目标小区的覆盖范围一致。数据收集方面，在空间上，采用目标单元相邻单元的kpi进行分析;从频域角度，采集与目标单元相同位置的不同频段数据;就时间而言，所有kpi都是时间序列数据。我们的分析是基于这三个方面的kpi。</p>
<p><img src="https://s2.loli.net/2022/07/20/cMRaCrlEkLbNdG6.png" alt="image-20220720111637004" style="zoom:50%;" /></p>
<h2 id="因果结构学习"><a href="#因果结构学习" class="headerlink" title="因果结构学习"></a>因果结构学习</h2><p>作者使用了TE（传递熵）来探测KPIs之间和KPI与KQI之间的因果关系。$S=[V_1,V_2,…,V_N]$是包含KPI参数的矩阵，$C=[c_1,c_2,…,c_T]$是包含KQI参数的一个向量，$T$表示时间序列的长度。给定来自$S$的两条时间序列$V_i$和$V_j$，从$V_i$到$V_j$的TE定义为</p>
<p><img src="https://s2.loli.net/2022/07/20/yIlF5kc37dYvUzr.png" alt="image-20220720111705873" style="zoom:50%;" /></p>
<p><img src="https://s2.loli.net/2022/07/20/8GWmwt2Rc59AYUN.png" alt="image-20220720111730430" style="zoom:50%;" /></p>
<p>比值大于1说明有$V_i \to V_j$，小于1则说明不存在（这种度量方法有失偏颇，强行假设$V_i,V_j$一定存在因果联系）；进一步地，根据因果强度构造关于所有参数地一个因果图，如算法1所示，在stage1，具有因果关系的每两个节点根据TE会给予一条有向边。stage2将会进图结构优化，具体地，删除因果链的中间节点，最后保留的因果结构类似于一个树图。在树图中，KQI是根节点，其它叶子节点表示不同的KPIs。</p>
<p><img src="https://s2.loli.net/2022/07/20/yaPlhpKWLEFR4zU.png" alt="image-20220720111801763" style="zoom:50%;" /></p>
<p><img src="https://s2.loli.net/2022/07/20/gU4uCMyJ91ze3XO.png" alt="image-20220720111814717" style="zoom:50%;" /></p>
<h2 id="图注意力网络"><a href="#图注意力网络" class="headerlink" title="图注意力网络"></a>图注意力网络</h2><p>图卷积网络（GCN）是常用的网络模型，它的缺点是根据训练集的图结构整合邻接节点的特征，使得不易在其它图结构上获取好的泛化性能。图注意力网络（GAT）则通过注意力机制聚合邻接节点，实现不同邻点权值的自适应分配，提高了图神经网络模型的表达能力。注意力机制被用于对相邻节点的加权特征进行求和。相邻节点特征的权值完全依赖于节点特征，与图结构无关。在因果结构学习时，我们只获得了因果结构，而KQI的邻接节点的影响则需要通过图神经网络来学习，作者采用GAT模型实现。</p>
<p>具体操作：GAT模型的输入是因果关系结构数据，具体表示为$h={h_1,h_2,…,h_N}$，$h_1$表示C即KQI参数，其余表示结构图中的KPI参数，$h_i\in R^T$，即拥有T个特征，$T$是时间序列长度。这里的注意力系数根据有向图的连边关系采用masked attention，并且只计算节点$i$和它的邻接节点$j$的相关性，引入leakyReLU激活</p>
<p><img src="https://s2.loli.net/2022/07/20/qjuGwrScDyQzmHK.png" alt="image-20220720111950219" style="zoom: 50%;" /></p>
<p>整个嵌入过程如图5所示</p>
<p><img src="https://s2.loli.net/2022/07/20/K45ergY9Whc8LBP.png" alt="image-20220720112008784" style="zoom:50%;" /></p>
<p>模型此外还采用了多头注意力，K个相互独立的注意力机制执行下，最后的输出结果表示如下（||表示拼接）</p>
<p><img src="https://s2.loli.net/2022/07/20/sBLiS3an7de9xH5.png" alt="image-20220720112127963" style="zoom:50%;" /></p>
<p>整个的流程图</p>
<p><img src="https://s2.loli.net/2022/07/20/IV7FOoHZQgumlAS.png" alt="image-20220720112445936"></p>
<h1 id="评价"><a href="#评价" class="headerlink" title="评价"></a>评价</h1><p>从参数降维的层面上，有用的KPI参数得到提炼，如下图的对比</p>
<p><img src="https://s2.loli.net/2022/07/20/U86Kuf14ExpBcbn.png" alt="image-20220720112550395"></p>
<p>验证因果结构学习的作用，比较本网络模型与其它模型的预测能力</p>
<p><img src="https://s2.loli.net/2022/07/20/p6DCj74TbmVLafy.png" alt="image-20220720112617531"></p>
<p>CGAT是本文的模型，GAT和LSTM是baseline，本文模型的RMSE更小。</p>
<p>此外作者还比较了本方法和之前的先预测KPI再估计KQI的模式（KPI预测用GCN或LSTM，KQI估计用SVM，GNB）。本文预测的是连续值，但通常KQI会根据阈值进行离散化，因此连续的预测值将会按照阈值分成两类。下面展示本文方法和之前方法的AUC</p>
<p><img src="https://s2.loli.net/2022/07/20/ahHz3LepDrktK2c.png" alt="image-20220720112639248" style="zoom:50%;" /></p>
<p>结果表明在两种阈值设置下（中位数，更低的分位数）本文的AUC都更大一些。</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>这是一篇特定任务场景下的结合传统因果推断算法的时间序列预测任务的研究论文，将因果算法引入到图神经网络当中，可以降低模型和数据的复杂度，提高模型的解释性，特征与标签之间的因果关系也可能为模型的泛化性能提供鲁棒性。</p>
]]></content>
      <categories>
        <category>cyf</category>
      </categories>
      <tags>
        <tag>因果结构学习 - 时间序列预测 - 图注意力网络</tag>
      </tags>
  </entry>
  <entry>
    <title>cyf Granger Causality Analysis Based on Quantized Minimum Error Entropy Criterion</title>
    <url>/2021/02/24/ChenYifei/Granger%20Causality%20Analysis%20Based%20on%20Quantized%20Minimum%20Error%20Entropy%20Criterion/</url>
    <content><![CDATA[<h1 id="基于量化的最小误差熵准则的格兰杰因果分析"><a href="#基于量化的最小误差熵准则的格兰杰因果分析" class="headerlink" title="基于量化的最小误差熵准则的格兰杰因果分析"></a>基于量化的最小误差熵准则的格兰杰因果分析</h1><p><a href="https://academic.microsoft.com/journal/120629676">2019 IEEE Signal Processing Letters </a>Volume: 26, Issue: 2, pp 347-351 <a href="https://doi.org/10.1109/LSP.2019.2890973"> DOI: 10.1109/LSP.2019.2890973</a></p>
<p> <a href="https://academic.microsoft.com/author/2473510192/publication?paperId=3105268574">Badong Chen</a>1,       <a href="https://academic.microsoft.com/author/2899149957/publication?paperId=3105268574">Rongjin Ma</a> 1,       <a href="https://academic.microsoft.com/author/2886285899/publication?paperId=3105268574">Siyu Yu</a> 1,          <a href="https://academic.microsoft.com/author/2109410961/publication?paperId=3105268574">Shaoyi Du</a> 1,        <a href="https://academic.microsoft.com/author/2679377637/publication?paperId=3105268574">Jing Qin</a> 2</p>
<p>1 <a href="https://academic.microsoft.com/institution/87445476">Xi’an Jiaotong University</a> ,             2 <a href="https://academic.microsoft.com/institution/14243506">Hong Kong Polytechnic University</a></p>
<p>摘要：</p>
<p>基于均方误差标准（MSE) 的线性回归模型（LRM) 被广泛应用于Granger因果分析中。然而，当信号被非高斯噪声污染的情况下，基于MSE的线性回归模型（LRM) 的系数就难以精确的估计，也就从而影响Granger因果分析的准确性。最小误差熵(MEE)标准可以取代MSE标准来解决非高斯噪声环境下的问题，但是它也因为信号过多产生了计算效率上的瓶颈。为了解决前面的这些问题，本文提出了量化的最小误差熵准则（QMEE) ，分别比较了传统的GC和GC—MEE以及GC—QMEE，通过模拟数据集，还有EEG数据集上的实验，表明GC—QMEE在非高斯噪声领域的优势以及QMEE相比MEE大大减少了计算复杂度。</p>
<p>作者对于非高斯噪声的举例：多模的，重尾的，离散的，等等。</p>
<a id="more"></a>
<h4 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h4><p>在信息理论学习（ITL) 中，大量的有监督或无监督的学习算法都与信息论的测量的优化相关，例如熵，互信息以及信息散度等。其中的最小误差熵（MEE) 已经被成功地用在回归，分类，自适应系统训练等领域上。</p>
<p>MEE的基础思想就是利用熵（不确定度）代表假定模型和实验数据对应真实模型的差异。一般常用的均方误差（MSE）只依赖于预测误差的二阶矩，而误差熵则能考虑到更高阶的矩，因此在非高斯分布以及极大的异常点的问题上有更佳的表现。以及已经有一些数值实验证明了MEE的更强的鲁棒性。</p>
<p>本文作者的另一篇文章也就MEE在最简单的情形下优于MSE的结果给出了理论上的数学证明。</p>
<h6 id="具体介绍——"><a href="#具体介绍——" class="headerlink" title="具体介绍——"></a>具体介绍——</h6><p>A.最小误差熵</p>
<p>在ITL（ J. C. Principe, Information theoretic learning: Renyi’s entropy and kernel perspectives. Springer Science and Business Media, 2010.）中，瑞丽（Renyi）熵被用作损失函数，其定义为</p>
<p><img src="C:\Users\acer\AppData\Roaming\Typora\typora-user-images\image-20210220160836459.png" alt="image-20210220160836459"></p>
<p>Renyi熵在$\alpha\rightarrow1$的时候就变成熟知的香农熵。这里$p(e)$表示误差变量$e$的概率密度函数（PDF）。</p>
<p>为了估计$p(e)$，这里使用了Parzen窗方法：</p>
<p><img src="C:\Users\acer\AppData\Roaming\Typora\typora-user-images\image-20210220161635411.png" alt="image-20210220161635411"></p>
<script type="math/tex; mode=display">
这里G_{\sigma}(e,e_i)表示高斯核函数：G_{\sigma}(e,e_i)=\frac{1}{\sqrt{2\pi}\sigma}exp[-\frac{(e-e_i)^2}{2{\sigma}^2}]\</script><p>因为$\alpha$是可变的，在本文中设置$\alpha=2$，就能推导出具体表达式</p>
<p><img src="C:\Users\acer\AppData\Roaming\Typora\typora-user-images\image-20210220162820224.png" alt="image-20210220162820224"></p>
<p>最终上式就是理论上的用于计算的损失函数，这里$N$表示样本点个数，通过两个求和符号可以估计它的计算复杂度是O($N^2$)，这对于庞大的数据集来说不适用。</p>
<p>B.量化方法</p>
<p>提出一种MEE的量化算法，保留它的优点同时减少它的计算复杂度。</p>
<p>量化算法：</p>
<p>输入——误差样本：${e<em>i}</em>{i=1}^N$</p>
<p>输出——量化误差：${Q(e<em>i)}</em>{i=1}^N$以及codebook：${c<em>i}</em>{i=1}^M$</p>
<ol>
<li><p>参数设置：阈值$\epsilon$</p>
</li>
<li><p>初始条件：设置$c_1={e_1}$，这里$c_i$表示第i次迭代时的codebook</p>
</li>
<li><p>for $i=2,3,…,N$  do</p>
<p>​       计算$e<em>i$和$c</em>{i-1}$之间的距离：$dis(e<em>i,c</em>{i-1})=|e<em>i-c</em>{i-1}(j^*)|$</p>
<p>​       这里$j^*=\operatorname{argmin}<em>{}|e_i-c</em>{i-1}(j)|$表示$c_{i-1}$中的第$j$个元素。即距离定义为最小距离</p>
<p>​       if    $dis(e<em>i,c</em>{i-1})\le \epsilon$    then</p>
<p>​              codebook保持不变：$c<em>i=c</em>{i-1}$  并且$Q(e<em>i)=c</em>{i-1}(j^*)$；</p>
<p>​       else    </p>
<p>​              更新codebook：$c<em>i={c</em>{i-1},e_i}$  并且$Q(e_i)=e_i$；</p>
</li>
</ol>
<p>​              end  if</p>
<p>​        end  for</p>
<p>$Q(·)$表示量化算子，最终得到N个误差样本${e<em>i}</em>{i=1}^N$对应的${Q(e<em>i)}</em>{i=1}^N$，和codebook：${c<em>i}</em>{i=1}^M$</p>
<p>量化的误差熵：</p>
<p><img src="C:\Users\acer\AppData\Roaming\Typora\typora-user-images\image-20210220181846008.png" alt="image-20210220181846008"></p>
<p>里面的$M$远小于$N$时，可以看出计算复杂度降低很多。$A_m$表示$c_m$中元素的个数。</p>
<p>这就是最后用于计算的函数。</p>
<p>C.传统granger因果</p>
<p>一种基于线性回归模型的方法，通过比较两个模型的预测能力判断一对时间序列间的关系。</p>
<p><img src="C:\Users\acer\AppData\Roaming\Typora\typora-user-images\image-20210220183303520.png" alt="image-20210220183303520"></p>
<p><img src="C:\Users\acer\AppData\Roaming\Typora\typora-user-images\image-20210220183332611.png" alt="image-20210220183332611"></p>
<p>如果时间序列x的过去值对y的预测有帮助，则认为x对y有Granger因果影响。</p>
<p>直观上即比较$Var(e<em>{21})$和$Var(e</em>{22})$的大小</p>
<p><img src="C:\Users\acer\AppData\Roaming\Typora\typora-user-images\image-20210220183816295.png" alt="image-20210220183816295"></p>
<h4 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h4><p><strong>模拟实验</strong></p>
<p><img src="C:\Users\acer\AppData\Roaming\Typora\typora-user-images\image-20210220184734621.png" alt="image-20210220184734621"></p>
<p>$\varphi_t$服从$[-2,2]$均匀分布，$\psi_t$是噪声分别服从以下四个情况里的分布：</p>
<p><img src="C:\Users\acer\AppData\Roaming\Typora\typora-user-images\image-20210220185220761.png" alt="image-20210220185220761"></p>
<p>结果如下表：</p>
<p><img src="C:\Users\acer\AppData\Roaming\Typora\typora-user-images\image-20210220185542260.png" alt="image-20210220185542260"></p>
<p><img src="C:\Users\acer\AppData\Roaming\Typora\typora-user-images\image-20210220185711137.png" alt="image-20210220185711137"></p>
<p>文章没有深入讨论在高斯噪声下QMEE比MSE优越多少，但是在混合高斯噪声和$\alpha$稳态噪声下QMEE和MEE有更强的鲁棒性。</p>
<p><strong>EEG数据集实验</strong></p>
<p>该数据集由9名受试者使用3个电极（C3，Cz，C4）进行记录</p>
<p>受试者为右撇子，视力正常或矫正视力正常。运动想象任务分为左脑运动想象任务和右脑运动想象任务。</p>
<p><img src="C:\Users\acer\AppData\Roaming\Typora\typora-user-images\image-20210220191919234.png" alt="image-20210220191919234"></p>
<p>t是100次替代数据实验中满足Granger因果指数大于原序列实验的Granger因果指数这一条件的实验的相对频率</p>
<p>t越小说明Granger因果越显著</p>
<p>实验结果展示了右撇子的大脑不对称性对有效连接网络的影响，与之前的研究结果相符。</p>
<h4 id="感想："><a href="#感想：" class="headerlink" title="感想："></a>感想：</h4><p>本文展示了QMEE和MEE准则在非高斯噪声环境下比一般的MSE准则得到的结果更加精确的优势。文章只是提出了线性回归模型上的方案，对于非线性的情况可以使用神经网络进行预测，而且损失函数可以换成QMEE标准下的函数。对于在真实数据集上的神经网络的应用在MSE标准下效果不佳的时候也可以考虑使用QMEE/MEE准则。</p>
]]></content>
      <categories>
        <category>cyf</category>
      </categories>
      <tags>
        <tag>可解释</tag>
      </tags>
  </entry>
  <entry>
    <title>cyf 【ICLR2021】潜在的收敛交叉映射</title>
    <url>/2021/04/18/ChenYifei/%E6%BD%9C%E5%9C%A8%E7%9A%84%E6%94%B6%E6%95%9B%E4%BA%A4%E5%8F%89%E6%98%A0%E5%B0%84/</url>
    <content><![CDATA[<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>一般来说，利用干预是最好的揭示因果机制的方式，因为它能得到一个直观且鲁棒的因果概念。然而，只有当观测数据可获得的时候，我们才有显著的辨明因果依赖性的需求，这些数据必须具有实用性，并且收集成本较低（例如，在还没有介入临床试验之前，必须依靠观察性研究）。然而，与临床试验相比，来自较少控制的环境的真实数据给我们的分析带来了许多挑战。如果不可能进行干预，则无法确定某些因果结构。重要的是，真实数据的主要问题是缺失值。特别是，当收集纵向数据时，所得到的时间序列通常是零星的:采样在时间上是不规律的，并且跨维度导致了在任何给定时间上的一个给定变量的观察值和多个缺失的观察值之间的时间间隔的变化。这一问题普遍存在于各个领域，例如医疗保健，气候科学或者航空航天。</p>
<a id="more"></a>
<p>收敛交叉映射算法(CCM)基于混沌的动态系统理论，尤其是Takens嵌入定理，能够适用于变量不可分离的场景以及弱耦合的系统。然而因为这种方法依赖时间序列的延迟嵌入，所以它对序列的值的缺失高度敏感并且要求时间序列有一定长度且不受干扰。因此这种方法不适用于反复的短的零星的时间序列，而在许多的实际情况中都会出现。为了攻克这个限制，我们提出了学习时间序列间的因果依赖性的方案，那就是在时间序列的潜在过程中证实交叉收敛映射的存在。在零星观测到的时间序列的所有片段上建立一个联合模型，并且命令该模型学习数据的内在的动态系统。我们证明了此方法可以根据短且零星的时间序列中检测到因果关系，而不需要计算延迟嵌入。为了学习系统的相空间的一个连续时间的潜在表征，我们使用GRU-ODE-Bayes(D Brouwer et al., 2019)，它是近来提出的神经ODE模型(2018)的扩展模型。对于因果推断来说，重要的是，模型的过滤特征确保了未来的信息不会泄露到过去，然后我们检验学习到的潜在表征之间的连续映射的存在性，并据此判断因果关系的方向。</p>
<p><img src="https://gitee.com/cyf_1739551672/my_-figure/raw/master/img/20210418223432.png" alt="image-20210410230057988"></p>
<h2 id="相关研究"><a href="#相关研究" class="headerlink" title="相关研究"></a>相关研究</h2><p>收敛交叉映射算法近来的发展</p>
<p>短且零星的时序的因果推断：短的时间序列在实践中十分常见，有许多基于相空间重构的短时序的因果研究方法被提出。交叉映射光滑性(2014)，多空间的收敛交叉映射(2015)。相比之下，在解决不规律采样的基础上，本文的方法通过在所有数据段之间共享的模型来计算含更多信息的相空间表示。而在不完整的时序上推断因果关系的技术已经被提出过，但是它们都基于Granger因果的框架，这使得它们不适用于变量不可分离场景。</p>
<script type="math/tex; mode=display">
\begin{align}
X[t+1]&=X[t]Y[t] \\
X[t+1]&=X[t]+Y[t]
\end{align}</script><h2 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h2><p>我们考虑两个多维度的时间序列$X[t]\in \boldsymbol{R}^{d_X}$，$Y[t]\in \boldsymbol{R}^{d_Y}$，我们要在它们的几个片段上探测这两个时间变量的因果关系。我们假定$X[t],Y[t]$由一个未知动态系统生成。作为一个例子，考虑如下能表示X和Y的动态系统的ODE方程：</p>
<p><img src="C:\Users\acer\AppData\Roaming\Typora\typora-user-images\image-20210411141140752.png" alt="image-20210411141140752"></p>
<p>为了考虑更广泛的场景，我们假设这些时序都是仅仅在有限的区间内观测到的片段。$X[t]$和$Y[t]$各自包括N个的短时间序列$(X^1[t],…,X^N[t])$和$(Y^1[t],…,Y^N[t])$。重点在X和Y的每个部分都是同时观测的。这些时间序列中每一个也是零星的，即不是规律采样的且每次不是所有维度都能观测到。</p>
<h3 id="收敛交叉映射和Takens嵌入定理"><a href="#收敛交叉映射和Takens嵌入定理" class="headerlink" title="收敛交叉映射和Takens嵌入定理"></a>收敛交叉映射和Takens嵌入定理</h3><p>CCM算法是通过验证一个时间序列的相空间里的动态性能否从另一个反应，来探究这两个时间变量间的因果方向。如果X因果影响了Y，那么X是被包含在Y的动态系统中的并且我们有可能从Y的动态系统中获得关于X的动态系统的一个表示。</p>
<p>令$X[t] \in \boldsymbol{R}^{d_X}$对应一个混沌动态系统，这个动态系统有一个计算盒维数为$d_M$的吸引子$\cal{M}$，而吸引子被认为是一个混沌动态系统趋向于向其演化的流形。利用在$\cal{M}$的一个流来对应系统的动力学特性</p>
<script type="math/tex; mode=display">
\phi_{(\cdot)}(\cdot):\boldsymbol{R} \times \cal{M} \to \cal{M} \\
\phi_{\tau}(\cal{M}_{t})=\cal{M}_{t+\tau}</script><p>$\cal{M}<em>t$表示流形上时间指标为t的某个点。这样的流被编码进了系统的ODE中。观测的时间序列$X[t]$由观测函数获得，即$f</em>{obs}(\cdot):X[t]=f_{obs}(\cal{M}_t).$。Takens嵌入定理：一个延迟嵌入$\Phi$，延迟$\tau$以及嵌入维数$k$</p>
<p><img src="C:\Users\acer\AppData\Roaming\Typora\typora-user-images\image-20210411155057665.png" alt="image-20210411155057665"></p>
<p>是吸引子$\cal{M}$的一个拓扑不变意义下的嵌入如果$k&gt;2d_M$，而且$\alpha:\cal{R}^{d_M}\to \cal{R}$是一个二阶可微的观测函数。具体来说，嵌入映射$\Phi$保证原始吸引子流形$\cal{M}$和由延迟嵌入生成的阴影流形$\cal{M}’$之间的微分同胚性。在此假定下，在理论上我们能通过延迟嵌入的表示重构出原始时间序列。</p>
<p>最简单的观测函数$\alpha$是简单地取动态系统观测值中的某一个维度。记$X_i[t]$表示$X[t]$的第i个维度，Takens定理确保由$X’[t]=(X_i[t],…,X_i[t-k\tau])$生成的阴影流形$\cal{M}’$与整个动态系统的原始流形之间是微分同胚的。因此，我们可以在阴影流形上研究子系统之间的耦合关系。</p>
<p>CCM算法首先对系统X和Y进行相空间重构以获得阴影流形$\cal{M}’_X$和$\cal{M}’_Y$。</p>
<p><img src="https://gitee.com/cyf_1739551672/my_-figure/raw/master/img/20210418223551.png" alt="image-20210411161615961"></p>
<p>我们使用皮尔逊相关系数来评价估计结果的好坏。</p>
<p>因为时序的样本长度决定了重构出的阴影流形里轨线的密集程度，长度越长，流形越密集，则近邻点越靠近，从而估计(预测)值越精准，这意味着我们计算出的相关系数随时序长度增加呈现收敛态势。显著的高的相关系数和收敛性是我们判断因果关系的重要依据。</p>
<h3 id="神经ODEs"><a href="#神经ODEs" class="headerlink" title="神经ODEs"></a>神经ODEs</h3><p>许多连续时间的确定性动态系统都能够用常微分方程组(ODEs)描述。但通常来说，不是动态系统的所有维度都能被观测到，这使得一个系统更好地表示形式应该是，（在观测值$X[t]$被生成的条件下）一个在连续的潜在过程$H(t)$上的ODE。例如，当只观测到2维动态系统的一个维度时，我们不能在一个单维度变量上确定一个流$\phi_t(X)$，但我们可以确定一个潜在过程$H(t)$。然后我们有如下的动态系统表述形式：</p>
<p><img src="https://gitee.com/cyf_1739551672/my_-figure/raw/master/img/20210418223604.png" alt="image-20210411163834868"></p>
<p>$\theta$表示ODE的参数，$f_{\theta}(\cdot)$是一个Lipschitz连续函数，$g(\cdot)$是一个连续函数。动态系统的学习在于从过程X的观测值组成的一个有限集合中确定参数$\theta$。神经ODEs(2018)通过一个神经网络实现对这个函数的参数化。</p>
<p><strong>摘自《Neural Ordinary Differential Equations》的内容</strong></p>
<p>诸如残差网络和递归神经网络的解码器和正则化流是通过构成一个隐藏层状态的转换序列来构建复杂的转换</p>
<p><img src="https://gitee.com/cyf_1739551672/my_-figure/raw/master/img/20210418223609.png" alt="image-20210411175033475"></p>
<p>这些迭代更新可以视作连续变换的欧拉离散化。如果我们加入更多的层和更短的时间步，在极限状态，我们参数化了这样的隐藏层单元的连续动态系统通过使用一个由神经网络指定的常微分方程(ODE)：</p>
<p><img src="https://gitee.com/cyf_1739551672/my_-figure/raw/master/img/20210418223614.png" alt="image-20210411175715109"></p>
<p>从输入层$\mathbf{h}(0)$开始，我们能定义输出层$\mathbf{h}(T)$为这个ODE初值问题在某个时间T的解。而这个值可以通过一个黑盒的微分方程求解器进行计算，该求解器可在任何需要的地方估计隐藏层单元的动态系统$f$以确定所需的精度。</p>
<p>这种方式的好处有：</p>
<p>1.存储效率——连续深度模型具有恒定的存储成本 </p>
<p>2.现今的ODE求解技术为逼近误差的增长提供保证，能动态调整其估计策略以达到要求的精度水平</p>
<p>3.当隐藏层的单元的动态系统参数化地变为一个连续的时间函数时，附近层的参数自动捆绑到一起，这将减少了监督学习所需的参数数量</p>
<p>4.变量公式的变化更容易计算。避免了正则化流的单一单元的瓶颈且可以通过极大似然进行直接训练</p>
<p>5.连续定义的动态系统可以自然地合并在任意时刻到达的数据</p>
<h3 id="使用潜在的CCM进行因果推断"><a href="#使用潜在的CCM进行因果推断" class="headerlink" title="使用潜在的CCM进行因果推断"></a>使用潜在的CCM进行因果推断</h3><p>CCM算法的关键步骤是计算时间序列的延迟嵌入：$\Phi(X[t])$和$\Phi(Y[t])$。然而，当数据仅在不规律的区间上零星地被观测到时，对任意的t来说观测到整个延迟样本$X_i[t],X_i[t-\tau],…,X_i[t-k\tau]$的概率几乎为0。$X’[t]=(X_i[t],…,X_i[t-k\tau])$和$Y’[t]$不能被完整观测到（实际上仅有一个维度被观测到）并且不能执行最邻近点的预测。而且，短的时间序列也妨碍我们使用足够的嵌入维数（k）和时间延迟（$\tau$）来计算延迟嵌入。代替计算延迟嵌入，我们利用一个被神经ODE参数化的连续时间的隐藏层过程来学习动态系统，并且使用这种隐藏层的表示作为一个完整的相空间的表示。因此，它不再要求进行延迟嵌入，CCM也不再强调长的，稳定采样的时间序列。下面通过一个图展示这个方法</p>
<p><img src="https://gitee.com/cyf_1739551672/my_-figure/raw/master/img/20210418223622.png" alt="image-20210411205148120"></p>
<p>为推断X[t]和Y[t]之间的因果关系，首先对两个GRU-ODE-Bayes模型进行训练（一种神经ODEs的扩展）。作为一种滤波方法，GRU-ODE-Bayes保证了未来的信息不会向后泄露，这与我们的因果概念——因一定发生在果之前相符合。潜在过程的连续性也是重要的，因为它使得动态系统的吸引子具有更大的范围。事实上，在观测值之间的一个恒定的潜在过程（例如用GRU等经典的循环神经网络获得的过程）会导致较少的独特的潜在过程观测。</p>
<p>同样的模型被用在每个时序的所有片段上，并且经过训练使得预测误差最小化。我们学习观测函数$g$，ODE$f<em>{\theta}$以及连续时间的潜在过程$H(t)$。我们把来自时序X的所有片段上的潜在向量的结果空间写成$\mathcal{H}</em>{X}$。</p>
<p>通过验证在$\mathcal{H}<em>{X}$和$\mathcal{H}</em>{Y}$之间的连续映射的存在性，我们可以做出因果关系的判断。与CCM类似，如果$\mathcal{H}<em>{X}$和$\mathcal{H}</em>{Y}$之间存在一个连续映射的话，我们考虑X是Y的因。实际$\mathcal{H}_{X}$代替了延迟嵌入$\Phi_X$，我们进行因果推断的方式和CCM是相似的。</p>
<p><img src="https://gitee.com/cyf_1739551672/my_-figure/raw/master/img/20210418223629.png" alt="image-20210411211642840"></p>
<p>后续的过程和CCM一样，连续映射的存在性通过相关性来体现。例如，对于$X \to Y$，我们计算实际的$\mathcal{H}_X$和基于$\mathcal{H}_Y$获得的$\mathcal{H}_X$的预测值之间的相关性。</p>
<p>它的代码是公开的： https: //github.com/edebrouwer/latentCCM</p>
<h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><p>对应上面的示意图，本文用了一个物理的系统：双摆系统</p>
<p><img src="https://gitee.com/cyf_1739551672/my_-figure/raw/master/img/20210418223637.png" alt="image-20210411213159189"></p>
<p><img src="https://gitee.com/cyf_1739551672/my_-figure/raw/master/img/20210418223645.png" alt="image-20210411214112681"></p>
<p><img src="https://gitee.com/cyf_1739551672/my_-figure/raw/master/img/20210418223715.png" alt="image-20210411214325246"></p>
<p><img src="https://gitee.com/cyf_1739551672/my_-figure/raw/master/img/20210418223659.png" alt="image-20210414110403624"></p>
<p><img src="https://gitee.com/cyf_1739551672/my_-figure/raw/master/img/20210418223703.png" alt="image-20210414155800140"></p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>神经ODEs是一种能够处理不规律采样的时间序列的深度网络，本文也是使用了它的扩展形式GRU-ODE-Bayes学习潜在过程得到的结果空间$\mathcal{H}$代替了最初的延迟嵌入的相空间，成功处理了短的采样不规律的时序数据的因果探测问题。实际上其它的研究领域也可能存在数据零星的问题，可以考虑使用神经ODEs这种新型的网络。</p>
<h2 id="补充"><a href="#补充" class="headerlink" title="补充"></a>补充</h2><p><strong>《神经ODEs》论文的摘要</strong></p>
<p>我们引入了一种新的深度神经网络模型。我们不用指定一个离散的隐藏层序列，而是使用神经网络参数化隐藏状态的导数。网络的输出使用黑盒的微分方程求解器计算。这些连续深度模型具有恒定的存储成本，根据每个输入调整其评估策略，并可以明确地以数值精度换取速度。我们在连续深度残差网络和连续时间潜在变量模型中证明了这些性质。我们还构造了连续正则化流，这是一个生成模型，可以通过最大似然进行训练，而无需对数据维度进行划分或排序。作为训练，我们展示了如何通过任何ODE求解器进行可伸缩的反向传播，而不需要访问其内部操作。这允许在更大的模型中对ode进行端到端的训练。</p>
]]></content>
      <categories>
        <category>cyf</category>
      </categories>
      <tags>
        <tag>时间序列</tag>
      </tags>
  </entry>
  <entry>
    <title>djx 【ICLR2021】Contrastive Learning with Hard Negative Samples</title>
    <url>/2021/07/14/DengJiaoxue/Contrastive%20Learning%20with%20Hard%20Negative/</url>
    <content><![CDATA[<p>​        作者认为 negative sample 对于表征学习是有很大益处的，对于 negative sample 最主要的挑战就是不能采用现有使用真实相似度信息的负采样策略。因此，本文开发了无监督采样方法来选择 harder negative samples， 并且 user 可以控制 hardness。这种抽样结果的一个极限情况是将每个类紧密地聚在一起，并将不同的类尽可能地分开。该方法提高了跨多模式的下游性能。</p>
<a id="more"></a>
<h4 id="1、Introduction"><a href="#1、Introduction" class="headerlink" title="1、Introduction"></a><strong>1、Introduction</strong></h4><p>对比学习依赖于两个关键因素：正样本对与负样本对的定义，</p>
<p>informative negative ：mapped nearby but should be far apart</p>
<p>好的negative sample：与原始样本标签不同，与原始样本相似</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/image-20210714172640277.png" alt="image-20210714172640277"></p>
<p>动机：寻找更好的negative samples，本文构建了一个可调的采样分布，该分布倾向于描述当前表示（与锚样本）十分相似的负样本对。</p>
<p>挑战：1）无监督条件下无法获得任何真实的相似或不相似信息。2）可调分布需要合适的采样策略。针对挑战1）参考无标签正样本学习，针对挑战2）设计一种抽样技术：需要满足高效、易于实现、不增加计算开销。</p>
<p>理论分析表明，本文提出的方法的最佳表现是将相似的输入归类在紧密的簇中，同时将簇间隔尽可能远。从经验上看，我们的hard negative sampling策略改善了图像、图形和文本数据的下游任务性能，这足以说明我们的negative samples具有更丰富的信息。</p>
<p><strong>贡献</strong>：</p>
<p>1、我们提出了一个关于负样本对的简单分布，用于对比学习，并推导了一种实用的importance sampling 策略。这种策略考虑到了真实不相似信息的缺乏并且计算开销为0。</p>
<p>2、从理论上分析了hard negative客观和最优的表示，理论上说明了hard negative 可以捕获理想状态的泛化性质。</p>
<p>3、经验上观察到本文提出的抽样方法可以提高下游任务性能。</p>
<h4 id="2、对比学习背景"><a href="#2、对比学习背景" class="headerlink" title="2、对比学习背景"></a>2、对比学习背景</h4><p>介绍对比表示学习的背景：</p>
<ul>
<li><p>我们希望学习一个嵌入层：$f:\chi \rightarrow S^{d-1}/t $ ，$S^{d-1}/t $ 是一个半径为$1/t$的超球面，$t$是超参数</p>
<p>假设有一组离散的潜在类$C$表示语义内容，相似样本对$(x,x^{+})$对应相同的潜在类。</p>
<p>对于$c\in C$，定义其分布$\rho(c)$，联合分布 $p_{(x,c)}(x,c)=p(x|c)\rho(c)$ ——条件概率分布变形；</p>
</li>
</ul>
<p>​                                                           边际分布 $ p(x)=\int<em>{c}p</em>{(x,c)}(x,c)dc$  简写为  $p$</p>
<p>​        假设 $supp(p(x))=\chi$ ，意思是$p(x)$的支撑集是全集 $\Leftrightarrow$   $p(x)\neq 0  $   $\forall x\in \chi$</p>
<p>​        为简单起见，假设$p(c)=\tau^{+}$为均匀分布，$\tau^{-}=1-\tau^{+}$     $\tau$是超参数。</p>
<ul>
<li><p>$h:\chi \rightarrow C$ 为输入$x$分配标签的真实潜在假设</p>
<p>如果$h(x)=h(x’)$，我们规定$x$与$x’$来自同一类，定义为 $x \thicksim x’$</p>
<p>定义 $P^{+}<em>{x}(x’)$为标签与$x$相同点的分布 $P^{+}</em>{x}(x’)=P(x’|h(x’)=h(x))$</p>
<p>定义 $P^{-}<em>{x}(x’)$为标签与$x$不同点的分布 $P^{-}</em>{x}(x’)=P(x’|h(x’)\neq h(x))$</p>
</li>
<li><p>NCE：noise-contrastive estimation</p>
<p>对于$\forall x \thicksim p$，NCE融合了正样本$x^{+}$和N个负样本${x^{-}<em>{i}}^{N}</em>{i=1}$，负样本采样自q</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/image-20210714172701989.png" alt="image-20210714172701989"></p>
<p>【q通常被选为边际分布$p(x)$，实际操作中也常用经验近似】</p>
</li>
</ul>
<p>问题：q是否有更好的分布描述负样本？</p>
<h4 id="3、Hard-negative-sample"><a href="#3、Hard-negative-sample" class="headerlink" title="3、Hard negative sample"></a>3、Hard negative sample</h4><p>在本节中，将描述本文的hard negative sampling。我们首先要问，什么是好的negative sample？我们采取以下两条指导原则来回答这个问题:</p>
<p>1、q应当只能抽取真正与锚窗口标签不同的负样本$x_{i}^{-}$</p>
<p>2、最有用的负样本是目前被认为与锚窗口最相似的负样本</p>
<p>简而言之，与锚点有不同标签但嵌入在附近的负样本可能是最有用的，并在训练过程中提供显著的梯度信息。</p>
<ul>
<li>定义负样本分布：$q^{-}_{\beta}$ </li>
</ul>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/image-20210714172736879.png" alt="image-20210714172736879"></p>
<ul>
<li>结合PU-learning的思想，Positive-Unlabeled Learning：</li>
</ul>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/image-20210714172802177.png" alt="image-20210714172802177"></p>
<p> $q<em>{\beta}$ 和 $q^{+}</em>{\beta}$ 都是可得到的分布，通过p得到$q<em>{\beta}$，通过一个保持语义的变换得到$q^{+}</em>{\beta}$。</p>
<hr>
<ul>
<li><p>为获得来自 $q<em>{\beta}$ 和 $ q^{+}</em>{\beta}$的样本，本文采用的是重要抽样法【(importance sampling method)是最有效的蒙特卡罗技巧之一，其主要思想是，它不从给定的概率分布函数中进行抽样，而是对所给定的概率分布进行修改，使得对模拟结果有重要贡献的部分多出现，从而达到提高效率，减少模拟的时间，以及缩减方差的目的】</p>
<p>首先固定（1）式中的Q，并将N趋向于正无穷：</p>
</li>
</ul>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/image-20210714172901804.png" alt="image-20210714172901804"></p>
<p>将选择负样本分布$q^{-}_{\beta}$当作公式中的q，将（2）式代入得到（4）:</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/image-20210714172844973.png" alt="image-20210714172844973"></p>
<p>从4式，可以看到我们只需要近似估计期望$E<em>{x \thicksim q</em>{\beta}}[e^{f^{T}(x)f(x^{-})}]$和$E<em>{v \thicksim q^{+}</em>{\beta}}[e^{f^{T}(x)f(v)}]$。</p>
<p>通过Monte-Carlo Importance sampling技术，可以求得上面两个期望：</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/image-20210714172920914.png" alt="image-20210714172920914"></p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/image-20210714172931852.png" alt="image-20210714172931852"></p>
<h4 id="实验部分"><a href="#实验部分" class="headerlink" title="实验部分"></a>实验部分</h4><p>​        接下来，对我们的hard negative sampling 方法进行了实例评估，在所有的实验中，β都被视为一个超参数(消融实验结果显示在图2)。实验前需要提前确定$\tau^{+}$的值。选择类的先验信息$\tau^{+}$可以通过两种方式进行:1）从数据中估算，要求具有标记数据，2）将其视为超参数。</p>
<h5 id="Image-Representation"><a href="#Image-Representation" class="headerlink" title="Image Representation"></a>Image Representation</h5><p>数据集：STL10，CIFAR100，CIFAR10</p>
<p>baseline：simCLR、Debiased（2020）</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/image-20210714172955351.png" alt="image-20210714172955351"></p>
<h5 id="Graph-Representation"><a href="#Graph-Representation" class="headerlink" title="Graph Representation"></a>Graph Representation</h5><p>数据集：图示中的八个</p>
<p>baseline：InfoGraph 方法（2020）</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/image-20210714173011134.png" alt="image-20210714173011134"></p>
<p>八个cases里面有六个的效果是优于baseline的</p>
<h5 id="Sentence-Representaton"><a href="#Sentence-Representaton" class="headerlink" title="Sentence Representaton"></a>Sentence Representaton</h5><p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/image-20210714173033008.png" alt="image-20210714173033008"></p>
<h5 id="消融实验"><a href="#消融实验" class="headerlink" title="消融实验"></a>消融实验</h5><p>1、$ \beta$  越大越好吗？</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/image-20210714173046987.png" alt="image-20210714173046987"></p>
<p>​        从结果可以看出过大的$\beta$ 反而对结果有负面影响，但是从第二张图的对比中看出，当正样本对采用的是真实信息的时候，结果会$\beta$ 的增加而增加。这个现象是可以在一定程度上解释过大的$\beta$ 为什么会降低准确度：因为，我们实际上是使用一种变换近似估计的$q^{+}_{\beta}$，只能部分纠正与 $ x$ 标签相同的负样本 $x^{-}$，而$\beta$ 的增加意味着学习机制更倾向于$f(x^{-})$ 接近于 $f(x)$，因此会造成更多与 $ x$ 标签相同的负样本 $x^{-}$ 没有被纠正。</p>
<p>2、避免错误负样本是否会改善hard sampling？</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/image-20210714173147439.png" alt="image-20210714173147439"></p>
<h5 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h5><p>​        本文提出了一种 hard negative sampling 方法，并通过实验论证了 hard negative 在对比表示学习中的价值。本文的工作将对比学习与度量学习中的负样本挖掘（negative mining）联系起来，差异在于度量学习中的负挖掘是以成对的相似信息作为核心，而对比学习是无监督的。本文所提的方法有如下优点：1、易于实现 2、不引入额外的计算开销 3、具有理论意义。</p>
]]></content>
      <categories>
        <category>djx</category>
      </categories>
      <tags>
        <tag>自监督</tag>
        <tag>表示学习</tag>
      </tags>
  </entry>
  <entry>
    <title>djx 【IEEE2019】SELF-SUPERVISED REPRESENTATION LEARNING FROM EEG SIGNALS</title>
    <url>/2021/04/09/DengJiaoxue/%E3%80%90IEEE2019%E3%80%91ssl-eeg/</url>
    <content><![CDATA[<p>关键词：EEG；自监督学习；对比学习</p>
<p>有监督学习方法受到数据收集与标记成本的限制，而自监督学习方法作为一个pre-training或者feature learning的方法，在计算机视觉和时间序列分析等领域的前景十分的广阔。本文中，我们提出的自监督模型可用于学习信息性表示（informative representations）。一种成功的方法依赖于预测是否从相同的时间上下文中采样了时间窗口。正如临床相关任务（睡眠评分）和两个脑电图数据集所证明的那样，我们的方法在低数据情况下优于纯监督方法，同时无需获取标签即可捕获重要的生理信息。</p>
<a id="more"></a>
<p>借助SSL，数据的结构可用于将无监督的学习问题转变为有监督的学习问题，称为“前置任务” [3]。<br>在自我监督的前置任务上学习的表示然后可以在监督的下游任务上重用，从而可能大大减少所需的带标签示例的数量。</p>
<p>Hyvérinen从非线性独立组件分析的角度正式对SSL提出了一种general且有理论依据的方法。</p>
<p>该方法中提出SSL任务是通过使用辅助变量u（time index、segment index、history of the data）来构建，以训练对比分类器。此分类器学习预测样本与辅助变量是否配对。</p>
<p>本文提出的自监督方法是为了从无标签的EEG信号中学习端到端的特征。引入了两个时间对比学习任务：relative positioning 和 temporal shuffling。实验中显示这些基于预测时间窗口是否在时间上接近的对比学习任务可用于学习 EEG 功能，这些特征可以捕获数据背后的结构的多个组件。文中证明了这些功能在下游任务中重复使用时的效果优于无监督模型与传统的监督模型。</p>
<h3 id="section2：the-SSL-tasks-and-learning-problems"><a href="#section2：the-SSL-tasks-and-learning-problems" class="headerlink" title="section2：the SSL tasks and learning problems"></a>section2：the SSL tasks and learning problems</h3><p>$S\in R^{M*C}$：输入数据      $M$ ：时间样本数    $C$：通道数</p>
<p>$y\in -1 ,1$ ：二标签</p>
<p>$T$：每个时间窗口的采样点数量</p>
<p>$\tau_{pos}$：positive context的持续时间</p>
<p>$\tau_{neg}$：对应于每个窗口周围的negative context的范围</p>
<h5 id="2-1-pretext—-relative-position"><a href="#2-1-pretext—-relative-position" class="headerlink" title="2.1 pretext—-relative position"></a>2.1 pretext—-relative position</h5><p>假设：相邻的时间窗口对应的标签相同</p>
<p>对时间窗口进行取样，$x_{t}$是锚窗口anchor window</p>
<p>将自定义的$N$个标签对定义为：</p>
<p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/image-20210409201110146.png" alt="image-20210409201110146"></p>
<h5 id="2-2-pretext—-temporal-shuffling"><a href="#2-2-pretext—-temporal-shuffling" class="headerlink" title="2.2 pretext—-temporal shuffling"></a>2.2 pretext—-temporal shuffling</h5><p>从positive context 中取样第三个样本$x<em>{t^{‘’}}$，并用它提供额外的参考点与$x</em>{t^{‘}}$对比。此时标签给予以下定义：</p>
<p>$y_{i}={\begin{array}{rcl}1 &amp; \mbox if &amp; t&lt;t^{‘}<t^{''}\\-1 & \mbox if & t>t^{‘} or t^{‘}&gt;t^{“} \end{array}$</p>
<h5 id="2-3-feature-extractor"><a href="#2-3-feature-extractor" class="headerlink" title="2.3 feature extractor"></a>2.3 feature extractor</h5><p>为了了解端到端如何根据时间窗口的相对位置或顺序来区分时间窗口，我们引入了一个特征提取器：</p>
<p>$h:R^{T*C}\to R^{D}$ 参数$\Theta$ 将窗口$x$映射到其特征空间上。然后使用对比模块聚合每个窗口的特征表示。</p>
<p>对于RP pretext：$g_{RP}:R^{D}*R^{D}\to R^{D}$ </p>
<p>​                            例如通过计算an elementwise absolute difference  </p>
<p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/image-20210409201207638.png" alt="image-20210409201207638" style="zoom: 50%;" /></p>
<p>对于TS pretext：$g_{TS}:R^{D}<em>R^{D}</em>R^{D}\to R^{2D}$  通过合并绝对差异</p>
<p>​                              $g_{TS}(h(x),h(x^{‘},h(x’’))=(abs(h(x)-h(x^{‘})),abs((h(x^{‘})-h(x^{‘’})))\in R^{2D}$</p>
<h5 id="2-4-predict"><a href="#2-4-predict" class="headerlink" title="2.4 predict"></a>2.4 predict</h5><p>一个带有参数$\omega \in R^{D}$ or $\in R^{2D}$和偏差$\omega_{0}$的线性上下文判别模型用于预测相关目标$y$</p>
<p>联合损失函数写为：</p>
<p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/image-20210409201230631.png" alt="image-20210409201230631"></p>
<p>按照$y$使用的惯例，预测目标是<img src="C:\Users\30331\AppData\Roaming\Typora\typora-user-images\image-20210409201246631.png" alt="image-20210409201246631" style="zoom: 50%;" />的符号</p>
<p>RP 和 TS 模型都可分别被视为具有两个或三个子网络的siamese神经网络。</p>
<h3 id="section-3：在睡眠数据上的应用"><a href="#section-3：在睡眠数据上的应用" class="headerlink" title="section 3：在睡眠数据上的应用"></a>section 3：在睡眠数据上的应用</h3><h5 id="3-1-两个睡眠数据集"><a href="#3-1-两个睡眠数据集" class="headerlink" title="3.1 两个睡眠数据集"></a>3.1 两个睡眠数据集</h5><p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/image-20210409201319626.png" alt="image-20210409201319626"></p>
<p>提取30 s的非重叠窗口，在Sleep EDF上生成T = 2000和C = 2的窗口，在MASS上生成C = 3的T = 3840。<br>对窗口进行归一化，以便通道的均值为0，标准差为1。在每个recording中，总共对2000个锚点窗口进行了均匀采样。对于每个锚窗口，采样了三个正样本和三个负样本。</p>
<p>训练集测试集和验证集划分：</p>
<p>Sleep EDF数据集上：验证集——受试者0-19；测试集——受试者20-39；训练集——受试者40-82</p>
<p>​                                     ==分别生成了训练集：512622；验证集：267,630；测试集：342,300对==</p>
<p>MASS 数据集：训练集——1-41；验证集——42-52；测试集——52-62</p>
<p>​                          ==分别生成了训练集：237,882；验证集：52,152；测试集：73,650对==</p>
<h5 id="3-2-模型算法"><a href="#3-2-模型算法" class="headerlink" title="3.2 模型算法"></a>3.2 模型算法</h5><p>对于特征提取器h，采用的是之前提出的架构【S. Chambon, M. N. Galtier, P. J. Arnal, G. Wainrib, and<br>A. Gramfort, “A deep learning architecture for temporal sleep stage classification using multivariate and multimodal time series,” IEEE Trans Neur Syst Rehab Eng, vol. 26, no. 4, pp. 758–769, 2018.  】</p>
<p>输入：$(C,T,1)$</p>
<p>CNN结构：<img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/image-20210409201347481.png" alt="image-20210409201347481"></p>
<p>SleepEDF数据集：k=50，m=13，D=100   可训练参数个数：55545</p>
<p>MASS数据：k=64，m=16，D=100      可训练参数个数：67173</p>
<h5 id="3-3-模型比较"><a href="#3-3-模型比较" class="headerlink" title="3.3 模型比较"></a>3.3 模型比较</h5><p>将经过SSL任务训练的模型与三个神经网络的baseline进行比较：</p>
<p>1）随机初始化</p>
<p>2）卷积自动编码器。自编码器使用特征提取器h作为编码器，四层卷积作为解码器，均方误差作为重建损失。</p>
<p>3）纯监督学习。在特征提取器h中增加softmax层</p>
<p>人工提取了脑电图特征：均值方差、偏度峰度、标准差、（0.5，4，8，13，30，49）Hz之间的频率对数功率带及其所有可能的比率、峰峰值、Hurst指数、近似熵和Hjorth复杂度。致使每个EEG通道有34个特征，将这些特征串联至单个向量组成特征向量。</p>
<p>为解决class之间的不平衡问题，我们使用平衡acc（bal acc）【定义为每个class的平均召回率】来评估下游任务的模型性能。另外，训练时，加权损失也可解决class的不平衡。</p>
<h5 id="3-4-实验"><a href="#3-4-实验" class="headerlink" title="3.4 实验"></a>3.4 实验</h5><p>实验一：分析了不同SSL超参数值下CNN的性能及其对CNN的影响。</p>
<p>实验二：带有有限标签的SSL任务对提高预测性能的作用。</p>
<p>实验三：探究SSL学习到的特征，研究他们的生理相关性。</p>
<h6 id="实验一"><a href="#实验一" class="headerlink" title="实验一"></a>实验一</h6><p>首先评估CNN架构学习SSL任务的能力。使用具有三组超参数$\tau<em>{pos}$和$\tau</em>{neg}$的RP和TS任务，在整个训练集上训练特征提取器h。训练了h后，我们将标记的样本投影到网络各自的特征空间中，然后在每组特征上训练多项式线性logistic回归模型以预测睡眠阶段。</p>
<p>【MASS数据集上，超参数$\tau<em>{pos}$和$\tau</em>{neg}$（in minutes）不同值时，SSL任务和下游分类任务的平衡准确度】</p>
<p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/image-20210409201406945.png" alt="image-20210409201406945"></p>
<p>从结果中可以得到以下：</p>
<p>1）在MASS数据集上，前两组实验（$\tau<em>{pos}$=2，$\tau</em>{neg}$=2和$\tau<em>{pos}$=4，$\tau</em>{neg}$=15）中，SSL任务和下游分类任务的平衡准确度近似。</p>
<p>2）增大超参数$\tau_{pos}$到120后，任务更加困难，SSL任务和分类任务的性能也降低。</p>
<p>最终，决定选择$\tau<em>{pos}$=4，$\tau</em>{neg}$=15，因为相较于第一组可以增加从正context中抽取到的窗口数量</p>
<h6 id="实验二"><a href="#实验二" class="headerlink" title="实验二"></a>实验二</h6><p>用不同的方法对特征提取器h进行训练（AE、RP、TS在无标签数据上及全监督模型在标签数据上）然后提取特征。同时使用随机初始化权重的模型（未经过培训的模型）提取特征。下游分类任务采用逻辑回归。</p>
<p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/image-20210409201423387.png" alt="image-20210409201423387"></p>
<p>在MASS数据集上，SSL的性能要优于纯监督模型，RP要略高于TS，AE和随机初始化模型都较低。SleepEDF数据集上也表现出类似的结果：</p>
<p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/image-20210409201431798.png" alt="image-20210409201431798"></p>
<p>使用自动编码器预制的模型获得了非常低的性能，因为使用均方误差损失的重建任务鼓励模型专注于输入信号的低频率。事实上，这些频率比像EEG这样的生物信号中的高频具有更高的功率。</p>
<h6 id="实验三"><a href="#实验三" class="headerlink" title="实验三"></a>实验三</h6><p>为了进一步探索使用 SSL 学到的功能，我们使用 UMAP [20] 将标记的 Sleep EDF 数据集上获得的 100 维嵌入投影到两个维度。</p>
<p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/image-20210409201503906.png" alt="image-20210409201503906"></p>
<p>上图中可以看出，从使用标签的彩色编码样本来看，groups不仅对应着睡眠阶段，同时按照顺序排列：从图形的右侧开始，向左移动，我们可以绘制一个连续穿过 W、N1、N2 和 N3 的轨迹。R阶段与W和N1重叠。</p>
<p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/image-20210409201512739.png" alt="image-20210409201512739"></p>
<p>此外，在图2-B中，人们可以观察到嵌入编码与年龄相关的信息。年轻受试者的样本占据点云的左外部分，而来自较老受试者的样本则位于U形结构的内侧。这种现象在N1、N2和N3阶段可见，但在W和R阶段不可见，那里看不到明显的老化结构。这可以解释为睡眠主轴的流行，主要特征用于识别随着年龄的增长而变化的N2和N3。</p>
<h3 id="Code"><a href="#Code" class="headerlink" title="Code"></a>Code</h3><h5 id="feature-extractor"><a href="#feature-extractor" class="headerlink" title="feature extractor"></a>feature extractor</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">EEG_FeatureExtractor</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="comment"># based on &quot;A deep learning architecture for temporal sleep stage</span></span><br><span class="line">    <span class="comment"># classification using multivariate and multimodal time series&quot;</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, C, T, k=<span class="number">50</span>, m=<span class="number">13</span>, dropout_prob=<span class="number">0.5</span>, embedding_dim=<span class="number">100</span>, n_spatial_filters=<span class="number">8</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    C: number of EEG channels</span></span><br><span class="line"><span class="string">    T: number of timepoints in a window</span></span><br><span class="line"><span class="string">    k: length of spatial filters (i.e. how much you look in time)  #？空间过滤器的长度</span></span><br><span class="line"><span class="string">    m: maxpool size</span></span><br><span class="line"><span class="string">    n_spatial_filters: number of spatial filters   #空间过滤器的数量</span></span><br><span class="line"><span class="string">    embedding_dim: embedding dimension (D)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># input is (1, C, T) &lt;-- notation (channels, dim1, dim2) is different than paper (dim1, dim2, channels)</span></span><br><span class="line">    <span class="built_in">super</span>().__init__()</span><br><span class="line">    self.depthwise_conv = nn.Conv2d(in_channels=<span class="number">1</span>, out_channels=C, kernel_size=(C,<span class="number">1</span>))</span><br><span class="line">    self.spatial_padding = nn.ReflectionPad2d((<span class="built_in">int</span>(np.floor((k-<span class="number">1</span>)/<span class="number">2</span>)),<span class="built_in">int</span>(np.ceil((k-<span class="number">1</span>)/<span class="number">2</span>)),<span class="number">0</span>,<span class="number">0</span>))</span><br><span class="line">    self.spatialwise_conv1 = nn.Conv2d(in_channels=<span class="number">1</span>, out_channels=n_spatial_filters, kernel_size=(<span class="number">1</span>,k))</span><br><span class="line">    self.spatialwise_conv2 = nn.Conv2d(in_channels=n_spatial_filters, out_channels=n_spatial_filters, kernel_size=(<span class="number">1</span>,k))</span><br><span class="line">    self.relu = nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">    self.maxpool = nn.MaxPool2d(kernel_size=(<span class="number">1</span>,m), stride=(<span class="number">1</span>,m))</span><br><span class="line">    self.dropout = nn.Dropout(p=dropout_prob, inplace=<span class="literal">True</span>)</span><br><span class="line">    self.linear = nn.Linear(n_spatial_filters * C * ((T // m) // m), embedding_dim)</span><br></pre></td></tr></table></figure>
<h6 id="ReflectionPad2d"><a href="#ReflectionPad2d" class="headerlink" title="ReflectionPad2d"></a>ReflectionPad2d</h6><p>对输入数据进行扩边，扩充方法采用镜像填充。ReflectionPad2d(n)相比原来数组每行每列都要增加n</p>
<p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/image-20210409201537136.png" alt="image-20210409201537136"></p>
<h6 id="dropout"><a href="#dropout" class="headerlink" title="dropout"></a>dropout</h6><p>防止过拟合的方法之一，对于神经网络单元，按照一定的概率将其暂时从网络中丢弃。</p>
<p>dropout=0.5时效果最好</p>
<p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/image-20210409201558044.png" alt="image-20210409201558044"></p>
]]></content>
      <categories>
        <category>djx</category>
      </categories>
      <tags>
        <tag>EEG</tag>
        <tag>自监督学习</tag>
      </tags>
  </entry>
  <entry>
    <title>djx ELF-SUPERVISED LEARNING FOR FEW-SHOT IMAGE CLASSIFICATION【ICASSP2021】</title>
    <url>/2022/02/23/DengJiaoxue/SELF-SUPERVISED%20LEARNING%20FOR%20FEW-SHOT%20IMAGE%20CLASSIFICATION%E3%80%90ICASSP2021%E3%80%91/</url>
    <content><![CDATA[<p><img src="https://gitee.com/jiaoxuedeng/markdown/raw/master/img//202202221943711.png" alt="image-20220222194352641"></p>
<h4 id="一、摘要"><a href="#一、摘要" class="headerlink" title="一、摘要"></a>一、<strong>摘要</strong></h4><p>​    小样本图像分类目的是以有限的标注样本进行分类。考虑到标注数据的限制，本文提出在元学习基础上引入自监督学习来训练一个更广义的嵌入网络，通过从数据本身学习到对下游任务更有效的特征，提高特征的鲁棒性及泛化能力。</p>
<p><strong>关键词</strong>：小样本学习（元学习） 自监督学习</p>
<a id="more"></a>
<h4 id="二、相关知识补充"><a href="#二、相关知识补充" class="headerlink" title="二、相关知识补充"></a>二、相关知识补充</h4><h5 id="1、元学习"><a href="#1、元学习" class="headerlink" title="1、元学习"></a>1、元学习</h5><p>元学习即meta-learning，也被称为“<strong>learning to learn</strong>”。</p>
<p>相比于machine learning: machine learning目的是学习一个用于预测的数学模型。而元学习面向的不是学习的结果，而是学习的过程。其学习的不是一个直接用于预测的数学模型，而是学习“如何更快更好地学习一个数学模型”。</p>
<p><img src="https://gitee.com/jiaoxuedeng/markdown/raw/master/img//202202222303226.png" alt="image-20220222230353186" style="zoom: 67%;" /><img src="https://gitee.com/jiaoxuedeng/markdown/raw/master/img//202202222304185.png" alt="image-20220222230411136" style="zoom:50%;" /></p>
<p>1）F是什么？</p>
<p>以传统神经网络为例</p>
<p><img src="https://gitee.com/jiaoxuedeng/markdown/raw/master/img//202202222332840.png" alt="image-20220222233215768" style="zoom:50%;" /></p>
<p>梯度下降算法：设计一个网络架构-&gt;给参数初始化-&gt;读入训练数据批次-&gt;计算梯度-&gt;基于梯度更新参数-&gt;进入下一轮训练-&gt;…</p>
<p>针对梯度下降算法，Meta Learning的最终结果是能够找到一个最佳训练流程，F</p>
<p>2）评价函数 F 的好坏</p>
<p><img src="https://gitee.com/jiaoxuedeng/markdown/raw/master/img//202202222347543.png" alt="image-20220222234724455" style="zoom: 25%;" /><img src="https://gitee.com/jiaoxuedeng/markdown/raw/master/img//202202222348005.png" alt="image-20220222234836913" style="zoom: 50%;" /></p>
<p>​    元学习的训练过程是围绕task展开的，每个task都有训练数据与测试数据。在Task1中，函数F学习到的训练算法是$f^1$，而Task1中的测试集在$f^1$上的测试结果被记作在Task1上的损失$l^1$；在Task2中，函数F学习到的训练算法是$f^2$，而Task1中的测试集在$f^2$上的测试结果被记作在Task1上的损失$l^2$……最终的损失函数是多个任务的总和<img src="https://gitee.com/jiaoxuedeng/markdown/raw/master/img//202202222351401.png" alt="image-20220222235135360" style="zoom:50%;" /></p>
<h5 id="2、自监督学习"><a href="#2、自监督学习" class="headerlink" title="2、自监督学习"></a>2、自监督学习</h5><p>​        两个过程：预训练过程无需任何标注信息，微调部分需要少量标签。</p>
<p>​        自监督学习大致分成两类：生成式与对比式。生成式关键在于前置任务的设计（通过数据增强等方法从数据本身设计出样本与对应的标签）。对比式的关键在于设计正负样本。本文采用的是对比式自监督模型。</p>
<p>​        自监督学习优点：无需标签信息，提高特征泛化能力</p>
<p><img src="https://secure2.wostatic.cn/static/iVnpnPgtnpQi2R2MfpiJU8/image.png?auth_key=1645580363-vRJeLQ7v1ALdVAjkw5AZpA-0-4985c735b4cc984d05c0e17703c6addb&image_process=format,webp" alt="Image" style="zoom: 33%;" /></p>
<h4 id="三、研究背景"><a href="#三、研究背景" class="headerlink" title="三、研究背景"></a>三、研究背景</h4><p>Motivation：在小样本学习中，有标签样本的数量会限制嵌入式网络的规模。规模小的嵌入网络会对结果产生较大的负面影响。嵌入网络的规模成为小样本学习的瓶颈。</p>
<h4 id="四、研究方法"><a href="#四、研究方法" class="headerlink" title="四、研究方法"></a>四、研究方法</h4><p><img src="https://gitee.com/jiaoxuedeng/markdown/raw/master/img//202202230005087.png" alt="image-20220223000515003" style="zoom:50%;" /></p>
<h5 id="1、自监督学习阶段"><a href="#1、自监督学习阶段" class="headerlink" title="1、自监督学习阶段"></a>1、自监督学习阶段</h5><p>自监督模型： Augmented Multiscale Deep InfoMax (AMDIM) </p>
<p>在 AMDIM 中，重新命名 global feature 和 local feature ：</p>
<p>​        将对数据进行编码的特征，称为 global features<br>​        将要预测的特征，称为 local features（也就是网络中间生成的feature map）</p>
<p>通过infoNCE，将最大化互信息转化为最大化互信息的下界。</p>
<p>最大化同一图像的两个视图（xa，xb）的全局特征和局部特征之间的互信息。</p>
<p>即具体来说，最大化$<f_g(xa), f_5(xb)>, <f_g(xa), f_7(xb)>和<f_5(xa), f_5(xb)>$.之间的互信息。</p>
<p>通过NCELoss写成如下形式：</p>
<p><img src="https://gitee.com/jiaoxuedeng/markdown/raw/master/img//202202230042493.png" alt="image-20220223004222464" style="zoom:50%;" /><img src="https://gitee.com/jiaoxuedeng/markdown/raw/master/img//202202230042705.png" alt="image-20220223004238671" style="zoom: 50%;" /></p>
<p>参考文献：Philip Bachman, R Devon Hjelm, and William Buchwalter,“Learning representations by maximizing mutual information across views,”<a href="https://arxiv.org/abs/1906.00910">https://arxiv.org/abs/1906.00910</a></p>
<h5 id="2、元学习阶段"><a href="#2、元学习阶段" class="headerlink" title="2、元学习阶段"></a>2、元学习阶段</h5><p>在本文中，元学习阶段，对所提出的模型进行训练，以学习一个嵌入函数，将来自同一类的所有输入样本映射到描述空间中的平均向量 c 作为每个类的类标识符。对于 $class_k$，它由训练样本的嵌入特征的质心表示，可以得到：</p>
<p><img src="https://gitee.com/jiaoxuedeng/markdown/raw/master/img//202202230059507.png" alt="image-20220223005916480" style="zoom:50%;" /></p>
<p>$f(x_i)$是前一阶段初始化的嵌入函数，$S_k$是训练样本的标签。</p>
<p>作为一种基于度量学习的方法，本文使用欧式距离，并生成给定query set Q 中的query sample q 在所有类上的分布。</p>
<p><img src="https://gitee.com/jiaoxuedeng/markdown/raw/master/img//202202230104112.png" alt="image-20220223010428083" style="zoom:50%;" /></p>
<p>损失函数：</p>
<p><img src="https://gitee.com/jiaoxuedeng/markdown/raw/master/img//202202230108949.png" alt="image-20220223010808924" style="zoom:50%;" /></p>
<h4 id="五、实验结果"><a href="#五、实验结果" class="headerlink" title="五、实验结果"></a>五、实验结果</h4><p>MiniImageNet</p>
<p><img src="https://gitee.com/jiaoxuedeng/markdown/raw/master/img//202202230110578.png" alt="image-20220223011050526" style="zoom:50%;" /></p>
<p>Caltech-UCSD Birds-200-2011 Dataset</p>
<p><img src="https://gitee.com/jiaoxuedeng/markdown/raw/master/img//202202230109491.png" alt="image-20220223010937452" style="zoom:50%;" /></p>
<h4 id="六、总结"><a href="#六、总结" class="headerlink" title="六、总结"></a>六、总结</h4><p>创新点：自监督作为工具应用在元学习方法上，是MAML（元学习典型方法）基础上的改进</p>
<p>优点：实验结果好，解决小样本学习不能使用大规模嵌入网络的问题</p>
<p>不足：有模型堆砌之嫌</p>
<p>分享原因：涉及多个热点方向，多个方向的交叉</p>
]]></content>
      <categories>
        <category>djx</category>
      </categories>
      <tags>
        <tag>自监督</tag>
        <tag>元学习</tag>
      </tags>
  </entry>
  <entry>
    <title>djx SELF-SUPERVISED LEARNING FOR ECG-BASED EMOTION RECOGNITION  基于ECG数据情感识别的自监督模型</title>
    <url>/2021/01/26/DengJiaoxue/ecg_ssl/</url>
    <content><![CDATA[<h5 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h5><p>我们提出了一种使用自我监督学习的基于心电图（ECG）的情绪识别系统。我们提出的体系结构由两个主要网络组成，一个信号转换识别网络和一个情感识别网络。首先，未标记的数据用于成功训练前一个网络，以在自我监督的学习步骤中检测特定的预定信号转换。接下来，将该网络的卷积层的权重转移到情感识别网络，并训练两个密集层以对唤醒和化合价进行分类。我们表明，我们的自我监督方法可帮助模型学习情感识别所需的ECG特征集，其性能与模型的完全监督版本相同或更好。我们提出的方法性能优于使用两个公开可用的数据集SWELL和AMIGOS的基于ECG的最先进的情感识别技术。进一步的分析凸显了我们的自我监督方法的优势，即需要更少的数据来获得可接受的结果。</p>
<a id="more"></a>
<h5 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h5><p>心电图（ECG）已被证明是情绪识别系统的可靠信息来源[1-4]。自动化的xi人机交互系统产生重大影响。 ECG和其他生理信号已在几种情感计算应用中使用。例如，[5]在驾驶任务期间使用ECG，肌电图（EMG）和皮肤电反应（GSR）进行了压力检测。在[6]中，提出了一种用于计算机游戏的动态难度调整机制，通过分析ECG和GSR为个人用户提供量身定制的游戏体验。 [3，7]中提出了一种基于ECG的深度多任务学习框架，用于自适应仿真。目的是根据个人用户的专业水平和认知负担，为其提供个性化的培训体验。  </p>
<p>尽管ECG在情感计算方面具有巨大潜力，但我们经常缺少足够的标记数据来训练深度监督模型。为了解决这个问题，我们提出了一种基于自我监督学习的深度学习解决方案[8]。自我监督学习是一种表示学习方法，其中使用自动生成的标签而不是人工注释的标签来训练模型。</p>
<p>自我监督学习有很多优点。</p>
<p>首先，通过学习更通用的特征而不是特定于任务的特征，使用这种方法学习的特征流形通常对于实例间和实例内变异是不变的[9]。【特征不变性】这些模型可以重用于同一域中的不同任务。此外，自我监督模型实现较高的分类性能时需要较少数量的人工注释标签。</p>
<p>在本文中，我们首次提出了使用多任务自我监督学习的基于ECG的情绪识别。我们使用两个公开可用的数据集，SWELL [10]和AMIGOS [11]。</p>
<p>1、首先，要训练具有自动生成的标签的网络，我们执行6种不同的信号转换任务。</p>
<p>2、将6个变换后的信号与原始信号一起用于以自我监督的方式训练多任务卷积神经网络（CNN）。所提出的CNN体系结构由3个卷积块作为共享层，然后是2个特定于任务的密集层。</p>
<p>3、我们将使用预先训练的模型进行情感分类。为此，我们将预先训练的网络的权重转移到新的网络，并训练一个简单的完全连接的层，并在两个数据集上测试框架。</p>
<p>我们的分析表明，以完全监督的方式进行训练时，与同一个网络相比，我们的自我监督模型更好或更具有竞争力。最后，我们为SWELL和AMIGOS数据集的<!--arousal(即兴奋程度)，valence(即good or bad)-->设置了最新技术。</p>
<h5 id="2-相关工作"><a href="#2-相关工作" class="headerlink" title="2. 相关工作"></a>2. 相关工作</h5><p>pretext task—-generate automatic labels</p>
<p>self-supervised learning helps convolution networks learn high-level features</p>
<p>参考文献12: performed 3D pose estimation using selfsupervised learning </p>
<p>1、used available 2D pose data and performed epipolar geometry to calculate 3D poses in self-supervised manner   </p>
<p>2、the obtained 3D poses were used to train a model to perform 3D pose estimation</p>
<p>  参考文献16：a self-supervised learning method was used for action recognition  </p>
<p>1、using a 3D convolution neural network to predict the order of shuffled video clips  </p>
<p>2、the pre-trained model was fine-tuned using nearest neighbour technique for action recognition.  </p>
<p>描述自监督学习在相关任务中的应用情况</p>
<h5 id="3-方法"><a href="#3-方法" class="headerlink" title="3. 方法"></a>3. 方法</h5><h6 id="Pipeline"><a href="#Pipeline" class="headerlink" title="Pipeline"></a>Pipeline</h6><p><img src="C:\Users\-XY\AppData\Roaming\Typora\typora-user-images\image-20210117224634937.png" alt="image-20210117224634937"></p>
<h6 id="Self-supervised-Learning-自监督学习"><a href="#Self-supervised-Learning-自监督学习" class="headerlink" title="Self-supervised Learning  自监督学习"></a>Self-supervised Learning  自监督学习</h6><p>令$T<em>{P} $ 和$T</em>{d}$ 为前置任务pretext和下游任务downstream。前置任务使用人工生成的伪标签$P<em>{j}$训练，下游任务使用真实标签$y</em>{i}$训练。令$(X<em>{j},P</em>{j})$ 为一组输入元组和伪标签，$j\in[0,N]$ 其中0是初始信号，$0,1,…,N$ 表示进行信号转换的次数。</p>
<p>目的是为了获得一个可以区分下游分类任务的特征流形$F$ 。【<a href="https://blog.csdn.net/weixin_43870329/article/details/107558035】">https://blog.csdn.net/weixin_43870329/article/details/107558035】</a></p>
<p>操作：定义一个模型$\psi<em>{j}$,$F=\gamma(X</em>{j},\theta)$ ，$\theta$ 是可测试参数集，$\psi<em>{j}$是第j个转换任务的预测概率。通过最小化信号转换网络$L</em>{j}$各个损耗的加权平均值找到最佳参数$\theta$ ,其中$L<em>{j}=[P</em>{j}log\psi<em>{j}+(1-P</em>{j})log(1-\psi<em>{j})]$ 总损失表示为$\sum</em>{j=0}^{N}\alpha<em>{j}L</em>{j}$ 其中$\alpha_{j}$ 为第$j$ 个任务的损失系数。</p>
<p>因此，我们可以使用特征流形$F$来执行$T<em>{d}$ 下游任务，因为它包含有关原始信号$X</em>{0}$的有用信息。</p>
<p>操作：1、设置模型$\rho=\zeta(F,\theta’)$ 其中$\theta’$ 为可测试参数集，$\rho$ 为下游任务分类的参数向量。</p>
<p>2、计算最佳$\theta’$ 参数使得交叉熵损失函数最小。交叉熵损失为$\sum<em>{i=1}^{M}y</em>{i}log{\rho_{i}}$,其中M是分类数。</p>
<h6 id="Signal-Transformation-Tasks-信号转换任务"><a href="#Signal-Transformation-Tasks-信号转换任务" class="headerlink" title="Signal Transformation Tasks                              信号转换任务"></a>Signal Transformation Tasks                              信号转换任务</h6><p>在pretext任务中，我们训练自监督网络使网络去学习数据的时空特征与抽象表示。对于开发的信号转换识别网络，执行了以下六种变换：</p>
<p>（1）噪声添加：将随机高斯噪声添加到ECG信号</p>
<p>（2）缩放：ECG信号的幅度缩放20％</p>
<p>（3）负数：ECG信号的幅度乘以-1，导致原始信号发生垂直翻转。</p>
<p>（4）水平翻转：ECG信号沿时间轴水平翻转。按时间轴裁剪信号。</p>
<p>（5）排列：心电图段分为10个子段并随机排列，随机排列它们的时间位置</p>
<p>（6）时间扭曲：ECG信号的随机片段沿x轴拉伸和压缩</p>
<p>将原始信号与变换后的信号堆叠形成输入矩阵，同时，将0,1,…,6变换对应的标签堆叠创建相应的输出向量。</p>
<p>根据经验选择信号转换中的参数，目的是最大程度地提高最终的情绪识别性能。</p>
<h6 id="Network-Architecture-网络架构"><a href="#Network-Architecture-网络架构" class="headerlink" title="Network Architecture                                          网络架构"></a>Network Architecture                                          网络架构</h6><p><strong>信号转换识别网络:</strong>我们的多任务信号转换识别网络包括3个卷积层和两个密集层。卷积层对不同任务是共享的，而密集层是对特定任务的。每个卷积块包括$2*1$ 维具有ReLu激活函数的卷积层，然后是大小为8的最大合并层。在卷积层中，我们通常会增长过滤器的数量，从32到64和128。在每个卷积块之后，内核大小逐渐从32分别减小到16和8。最后，在卷积层的末尾，执行全局最大池化。紧随其后的密集层包括2个具有128个隐藏节点的完全连接层，其后是一个S型层（sigmoid layer）。使用60%的dropout在密集层并且使用$\beta=0.0001$ 的$L2$正则化来克服过拟合。</p>
<p><img src="C:\Users\-XY\AppData\Roaming\Typora\typora-user-images\image-20210118194936442.png" alt="image-20210118194936442"></p>
<p><strong>情绪识别网络</strong>：我们开发了一个简单的情感识别网络，该网络具有与信号转换识别网络相同的卷积层，并具有2个具有64个隐藏节点的密集层，然后是S形层（sigmoid层）。然后，我们将权重从信号转换识别网络的卷积层转移到该网络的卷积层。然后，将ECG信号和情绪标签用作训练此网络的输入和输出。应当注意，从信号变换识别网络的卷积层传递的权重是冻结的，因此不进行重新训练（仅训练密集层）。我们使网络的全连接层保持简单，以便能够评估我们的方法在信号转换任务的自我监督学习方面的性能。</p>
<h5 id="4-实验与结果"><a href="#4-实验与结果" class="headerlink" title="4. 实验与结果"></a>4. 实验与结果</h5><h6 id="数据"><a href="#数据" class="headerlink" title="数据"></a>数据</h6><p>SWELL和AMIGOS数据集</p>
<p>SWELL数据集是从25名参与者那里收集的，目的是了解典型办公环境中不同工作条件下员工的心理压力和情绪属性。这些条件中的每一个都被设计为持续30-45分钟。<a href="http://cs.ru.nl/~skoldijk/SWELL-KW/Dataset.html">http://cs.ru.nl/~skoldijk/SWELL-KW/Dataset.html</a></p>
<p>AMIGOS数据集是从40名参与者中收集的，其中情感视频片段被单独和分组显示给参与者，以引发情感反应。数据集包括两个实验的参与者配置文件（匿名参与者的数据、个性特征和情绪 （PANAS） 配置文件）、参与者评分、外部注释、神经生理记录（EEG、ECG 和 GSR 信号）以及视频录制（正面高清、全身和深度<strong>视频</strong>）：<a href="http://www.eecs.qmul.ac.uk/mmv/datasets/amigos/index.html">http://www.eecs.qmul.ac.uk/mmv/datasets/amigos/index.html</a></p>
<ol>
<li><strong>短视频实验：</strong>在这个实验中，40名志愿者观看了16个电影短片。每个参与者在单独的设置中，并评价每个视频在价值，觉醒，支配地位，熟悉和喜好，并选择的基本情绪（中性，幸福，悲伤，惊喜，恐惧，愤怒和厌恶），他们觉得在视频中。</li>
<li><strong>长视频实验：</strong>在这个实验中，37名前一实验的参与者观看了一组4个长情感视频摘录的电影。17名参与者在单个环境中进行实验，而其他20名参与者在小组设置中进行实验，5组为4人。每个参与者对每个视频的评价是价、觉醒、支配、熟悉和喜好，并选择他们在视频中感受到的基本情绪（中性、幸福、悲伤、惊喜、恐惧、愤怒和厌恶）。</li>
</ol>
<p>两个实验的视频在价量尺度上外部注释，并由 3 个注释器唤醒。</p>
<p>在这两个数据集中，参与者的自我评估情感得分均以1到9的范围来记录arousal和valence。</p>
<p>使用具有自粘电极的MOBI设备（TMSI）[18]以2048 Hz的采样频率记录了SWELL数据集，而使用Shimmer传感器[19]以256 Hz的采样频率收集了AMIGOS。我们对ECG信号执行的预处理非常少。由于以不同的采样率记录了两个数据集，因此首先将SWELL ECG信号下采样到256 Hz。然后，通过应用通带频率为0.8 Hz的高通IIR滤波器，消除两个数据集的ECG基线漂移</p>
<h6 id="模型训练"><a href="#模型训练" class="headerlink" title="模型训练"></a>模型训练</h6><p>ECG信号被分割为10秒的固定窗口大小。每个段用于生成6个变换变量，用于训练信号变换识别网络。我们提出的架构是在Nvidia 2070 Ti GPU上使用TensorFlow实现的。<br>        为了训练这两个网络（信号转换识别和情感识别），使用==Adam优化器==[20]的学习率为0：001，批量为128。信号转换识别网络的训练时间为30个时期，而情感识别网络的训练时间为30个时期。训练了100个纪元，因为达到了不同数目的纪元达到了稳态。与[11，21–23]相似，通过设置等于均值的阈值，将两个数据集的情感属性（输出标签）转换为二进制类别。我们使用==10倍交叉验证来评估我们提出的模型的性能==。</p>
<h6 id="性能与对比"><a href="#性能与对比" class="headerlink" title="性能与对比"></a>性能与对比</h6><p>图2显示在学习信号转换任务时的13个时期，信号转换识别模型达到稳态。</p>
<p><img src="C:\Users\-XY\AppData\Roaming\Typora\typora-user-images\image-20210113221406248.png" alt="image-20210113221406248"></p>
<p>表2和表3展示了我们的自我监督方法进行情感分类的效果。==[参数？？]==</p>
<p><img src="C:\Users\-XY\AppData\Roaming\Typora\typora-user-images\image-20210115232456063.png" alt="image-20210115232456063"></p>
<p>结果表明，对于唤醒和效价分类，我们的模型使用SWELL可以达到96％和95.6％的准确度，而使用AMIGOS可以达到85.1％和84％的准确度。为了进一步评估我们模型的性能，我们仅使用标记的数据集进行训练时，将结果与情感识别网络的完全监督版本进行比较。参见表2和表3。比较表明，自监督方法比完全监督方法具有竞争力或更好，说明了我们方法的有效性。</p>
<p>接下来，我们将我们的结果与先前在这两个数据集上进行的情绪识别工作进行比较。应当指出，使用ECG模态对SWELL数据集进行的先前工作主要集中在压力检测上，而不是对arousal和valence进行分类。在[24]中，该数据集被用于使用支持向量机（SVM）对应力水平进行二进制分类，报告使用ECG和GSR时基线精度为64.1％。同样在[23]中，使用SVM分类器执行压力检测，报告的准确性为86.36％。使用贝叶斯信念网络（BBN）在[22]中执行了类似的任务，报告的准确性为92.6％。虽然在[25]中进行了arousal和valence的估算，但该问题被表述为回归，因此无法与我们的分类方法进行有效比较。结果，我们还对该数据集进行了压力检测，并在自我监督和完全监督的方法分别达到了98.3％和98.4％的精度。表2在同一数据集上<!--比较了我们的自我监督模型和过去的监督工作，表明所提出的模型的执行精度更高。--></p>
<p>对于AMIGOS数据集，基线分类结果在[11]中提供，其中arousal和valence的分类使用高斯朴素贝叶斯分类器进行，两个任务的F1分数分别为54：5％和55：1％。在[21]中，使用CNN进行分类，其arousal和valence的准确度分别为81％和71％。 [26]等其他作品也对AMIGOS进行了情感识别。但是，使用了不同的验证方案。表3展示了我们与先前工作相比的结果，再次显示了自我监督方法在同一数据集上的表现优于先前工作。</p>
<p>接下来，<!--为了评估自我监督方法对充分训练模型所需的标记数据量的影响-->，我们仅使用1％的标记数据来训练自我监督和完全监督的分类方法。我们首先使用整个未标记的数据集来训练使用自动生成的标签（信号转换）的信号转换识别网络。然后，在从自监督网络传递权重后，每类用户每类的标记数据的1％用于训练和测试情感识别网络。接下来，我们还使用相同的1％数据集来训练独立的CNN，而无需进行自我监督。图3显示了在完全监督下的结果。</p>
<p><img src="C:\Users\-XY\AppData\Roaming\Typora\typora-user-images\image-20210115234233360.png" alt="image-20210115234233360"></p>
<h5 id="code"><a href="#code" class="headerlink" title="code"></a>code</h5><p><img src="C:\Users\-XY\Desktop\SSL-ECG\images_ssl_architecture.jpg" alt=""></p>
<ul>
<li><p>implementation: 实现部分</p>
<p> this directory contains all of our source codes.</p>
<ul>
<li>Please create similar directory structure in your working directory:<ul>
<li><em>data_folder</em>: Keep your data in numpy format here.</li>
<li><em>implementation</em>: Keep the <a href="">codes</a> here.</li>
<li><em>summaries</em>: Tensorboard summaries will be saved here.</li>
<li><em>output</em>: Loss and Results will be stored here.</li>
<li><em>models</em>: Self-supervised models will be stored here.</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>load_model: </p>
<p>this directory contains the pretrained self-supervised model and sample codes to use it.  预训练的自监督模型和样本代码</p>
<ul>
<li>The saved pretrained model can be used in order to extract features from raw ECG signals, which can be further used to perform downstream tasks.</li>
<li>特征提取: <a href="">extract_features.py</a>.</li>
<li>为了提取特征，输入的数据形式为 <em>batch_size x window_size</em>. </li>
<li>我们选择 <em>window_size of 10 seconds X 256 Hz = 2560 samples</em>, where 256 Hz refers to the sampling rate. A sample ECG signal is given <a href="">here</a>.</li>
<li>提供 sample code为了保存预训练过的网络的权重 <a href="">save_weights.py</a></li>
</ul>
]]></content>
      <categories>
        <category>djx</category>
      </categories>
      <tags>
        <tag>自监督</tag>
        <tag>表示学习</tag>
        <tag>EEG</tag>
        <tag>睡眠分期</tag>
      </tags>
  </entry>
  <entry>
    <title>gs 【WSDM2021】Time-Series Event Prediction with Evolutionary State Graph</title>
    <url>/2021/04/14/GongSa/WSDM_2021_Time-Series%20Event%20Prediction%20with%20Evolutionary%20State%20Graph(1)/</url>
    <content><![CDATA[<p><strong>关键词</strong>：时间序列预测，进化状态图，图网络</p>
<h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h3><p>为了对时序数据中未来事件做到精确且可解释的预测，需要捕获具有代表性的模式(state)。以前的研究都主要关注对模式的表示和识别，忽视了变化中的过渡关系。</p>
<p>本文使用一种演化状态图，节点表示模式，边表示演化关系。</p>
<p>提出了<code>Evolutionary State Graph Network(EvoNet)</code>，对进化状态图进行编码，以便准确和可解释的时间序列事件预测，<code>EvoNet</code>对节点与节点和图级别传播（segment 2 segment）进行建模，同时捕获节点与图随时间交互的信息。</p>
<p>基于5个真实世界数据集的实验结果表明，与11个基线相比，我们的方法不仅取得了明显的改进，而且为解释事件预测的结果提供了更多的见解。</p>
<a id="more"></a>
<h3 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h3><p>时间序列数据中未来事件(如异常)的预测一直是时间数据挖掘的重要任务。</p>
<h4 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h4><ol>
<li>一个常见的方法是<strong>使用隐空间状态的模型</strong>，像HMM、RNN和RNN的变体等，使用一系列潜在表示对时序数据进行编码，但这个编码是个黑盒操作，并不能直接捕获一些具有实际物理意义的典型模式，比如通过健身追踪设备观察对的步行或跑步。</li>
</ol>
<ul>
<li>对噪声敏感</li>
<li>可解释性差</li>
<li>出现问题时很难调试</li>
</ul>
<ol>
<li>另外的工作：对时间序列进行离散化并寻找其底层状态，采用序列<strong>聚类</strong>、<strong>字典</strong>(例如SAX)等方法和<strong>shapelets</strong>。</li>
</ol>
<ul>
<li>有效处理噪声和提供更好的可解释性</li>
<li>只找到这些状态，并没有关注状态之间的关系的潜在影响</li>
</ul>
<ol>
<li><p><strong>图结构(graph structures)</strong>模型，<code>GCN-LSTM</code> 、 <code>Time2Graph</code> 。</p>
<p><code>GCN-LSTM</code> 需要一个显示的图作为输入，这个一般很难从时间序列数据直接得到</p>
<p><code>Time2Graph</code> 使用shapelets发现states和relations，但是图在全局是一个静态的，在实际中，这个图是随时间变化的。</p>
</li>
</ol>
<p>时序往往受到不同的状态的共同影响，特别是状态关系的变化的影响。</p>
<blockquote>
<p>:one: 在健康追踪设备的连续观察中，在高强度跑步后停止运动可能会导致昏厥事件，而如果一个人在慢跑后停止运动，监测数据看起来是正常的</p>
<p>:two:从网上购物记录来看，从电子产品到化妆品的突然兴趣转变可能比从化妆品到时尚的平稳转变更令人怀疑</p>
</blockquote>
<p><a href="https://imgtu.com/i/ccItf0"><img src="https://z3.ax1x.com/2021/04/14/ccItf0.png" alt="ccItf0.png"></a></p>
<p>方法：基于潜在的状态对时间序列进行建模，为了从原始时间序列数据中保留更多的信息，我们将每个时间序列段建模为属于多个具有不同权值的状态，并利用有向图来建模相邻段之间的状态之间的过渡关系。</p>
<blockquote>
<p>1)时间序列演化可以转化为不同层次的图动态</p>
<p>2)当事件发生时，时间序列波动可以表示为图结构的迁移，特别是连接某些状态的一些边的动态</p>
</blockquote>
<h4 id="贡献"><a href="#贡献" class="headerlink" title="贡献"></a>贡献</h4><ul>
<li>通过对实际数据的分析，我们发现状态间的时变关系对于时间序列事件的预测很重要</li>
<li>我们提出了演化状态图来捕捉状态之间的动态关系，并基于进演化状态图开发<code>EvoNet</code>来提高事件预测的性能</li>
<li>我们在5个数据集上进行了大量的实验，以证明我们的方法可以做出更准确的预测，并为解释它们提供更多的见解</li>
</ul>
<h3 id="背景及问题定义"><a href="#背景及问题定义" class="headerlink" title="背景及问题定义"></a>背景及问题定义</h3><h4 id="时间序列事件预测"><a href="#时间序列事件预测" class="headerlink" title="时间序列事件预测"></a>时间序列事件预测</h4><p><a href="https://imgtu.com/i/ccId6U"><img src="https://z3.ax1x.com/2021/04/14/ccId6U.png" alt="ccId6U.png"></a></p>
<p>$\tau$：滑窗大小（表示某种物理意义，比如24h）</p>
<p>$d$：dimension</p>
<p><a href="https://imgtu.com/i/ccIalT"><img src="https://z3.ax1x.com/2021/04/14/ccIalT.png" alt="ccIalT.png"></a></p>
<h4 id="状态-State"><a href="#状态-State" class="headerlink" title="状态 State"></a>状态 State</h4><p>状态集合（典型模式片段集合）：$\Theta _v\in R^{\tau \times d}$</p>
<p>提取方式：Symbolic Aggregate Approximation, Bag of Patterns, Shapelets, sequence clustering</p>
<h4 id="Segment-to-state-representation"><a href="#Segment-to-state-representation" class="headerlink" title="Segment-to-state representation"></a>Segment-to-state representation</h4><p><a href="https://imgtu.com/i/ccIUpV"><img src="https://z3.ax1x.com/2021/04/14/ccIUpV.png" alt="ccIUpV.png"></a></p>
<h3 id="EvoNet框架"><a href="#EvoNet框架" class="headerlink" title="EvoNet框架"></a><code>EvoNet</code>框架</h3><h4 id="Evolutionary-State-Graph-演化状态图"><a href="#Evolutionary-State-Graph-演化状态图" class="headerlink" title="Evolutionary State Graph  演化状态图"></a>Evolutionary State Graph  演化状态图</h4><p>图结构：$G<em>{(t)} = {V, E^{(t)}, M^{(t)}}$表示从$X</em>{t-1}$到$X_{t }$的状态</p>
<p><a href="https://imgtu.com/i/ccIBm4"><img src="https://z3.ax1x.com/2021/04/14/ccIBm4.png" alt="ccIBm4.png"></a></p>
<p><a href="https://imgtu.com/i/ccIr79"><img src="https://z3.ax1x.com/2021/04/14/ccIr79.png" alt="ccIr79.png"></a></p>
<p><a href="https://imgtu.com/i/ccID0J"><img src="https://z3.ax1x.com/2021/04/14/ccID0J.png" alt="ccID0J.png"></a></p>
<ul>
<li>异常时刻时图会更加稠密</li>
<li>异常时节点对应的的in-degree会增加</li>
</ul>
<h4 id="Evolutionary-State-Graph-Network-演化状态图网络"><a href="#Evolutionary-State-Graph-Network-演化状态图网络" class="headerlink" title="Evolutionary State Graph Network  演化状态图网络"></a>Evolutionary State Graph Network  演化状态图网络</h4><p>网络利用状态演化图来捕获一下两种信息：</p>
<p><strong>局部结构影响</strong>：状态与状态之间局部变化的影响（例子：跑步）</p>
<p><strong>时间影响</strong>：先前状态的转换将影响当前观测数据</p>
<blockquote>
<p>例如，(高强度跑步→慢跑)→···→停止运动)和(慢跑→慢跑→···→停止运动)会产生不同的健身效果。</p>
</blockquote>
<p>在演化状态中的表现：</p>
<ul>
<li>局部结构影响-&gt;图中的每个节点之间的局部成对关系 ——&gt;local information aggregation</li>
<li>时间影响-&gt;不同图上的演化 ——&gt;temporal graph propagation</li>
</ul>
<p><a href="https://imgtu.com/i/ccI6t1"><img src="https://imgtu.com/i/ccIcfx" alt="ccIcfx.png](https://z3.ax1x.com/2021/04/14/ccIcfx.png)"></a></p>
<h5 id="Local-information-aggregation"><a href="#Local-information-aggregation" class="headerlink" title="Local information aggregation"></a><strong>Local information aggregation</strong></h5><p><a href="https://imgtu.com/i/ccIykR"><img src="https://z3.ax1x.com/2021/04/14/ccIykR.png" alt="ccIykR.png"></a></p>
<p><a href="https://imgtu.com/i/ccI2p6"><img src="https://z3.ax1x.com/2021/04/14/ccI2p6.png" alt="ccI2p6.png"></a></p>
<h5 id="Temporal-graph-propagation"><a href="#Temporal-graph-propagation" class="headerlink" title="Temporal graph propagation"></a>Temporal graph propagation</h5><p><a href="https://imgtu.com/i/ccIq9P"><img src="https://z3.ax1x.com/2021/04/14/ccIq9P.png" alt="ccIq9P.png"></a></p>
<p><a href="https://imgtu.com/i/ccIR1K"><img src="https://z3.ax1x.com/2021/04/14/ccIR1K.png" alt="ccIR1K.png"></a></p>
<p><a href="https://imgtu.com/i/ccIW6O"><img src="https://z3.ax1x.com/2021/04/14/ccIW6O.png" alt="ccIW6O.png"></a></p>
<p><a href="https://imgtu.com/i/ccIfXD"><img src="https://z3.ax1x.com/2021/04/14/ccIfXD.png" alt="ccIfXD.png"></a></p>
<h5 id="End-to-End-Model-Learning-端到端的模型学习"><a href="#End-to-End-Model-Learning-端到端的模型学习" class="headerlink" title="End-to-End Model Learning  端到端的模型学习"></a>End-to-End Model Learning  端到端的模型学习</h5><p><a href="https://imgtu.com/i/ccI4ne"><img src="https://z3.ax1x.com/2021/04/14/ccI4ne.png" alt="ccI4ne.png"></a></p>
<p><strong>训练一个分类器</strong>（<code>NN</code> or <code>XGBoost</code>）</p>
<p><a href="https://imgtu.com/i/ccI50H"><img src="https://z3.ax1x.com/2021/04/14/ccI50H.png" alt="ccI50H.png"></a></p>
<blockquote>
<p>where Yˆ𝑡+1 ∈ {0, 1} is the ground truth that indicating whether a future event will occur.   </p>
</blockquote>
<h3 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h3><h4 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h4><p><a href="https://imgtu.com/i/ccII7d"><img src="https://imgtu.com/i/ccITAA" alt="ccITAA.png](https://z3.ax1x.com/2021/04/14/ccITAA.png)"></a></p>
<ul>
<li><strong>DJIA 30 Stock Time Series (DJIA30)</strong>  ：三种交易价格和一个交易数字；目标是基于最近50周的数据预测下一周是否有异常的价格波动</li>
<li><strong>Web Traffic Time Series Forecasting (WebTraffic)  </strong>：目标是根据12月的数据预测未来一个月是否出现快速增长</li>
<li><strong>Information Networks Supervision (NetFlow)  </strong>：由中国电信提供。小时粒度；流入与流出（两维）；15天预测两天；</li>
<li><strong>Watt-hour Meter Clock Error (ClockErr)  </strong>：由中国国家电网提供。每个读数记录电能表的偏差时间和延迟时间；当偏差时间超过120时，表示仪表异常；我们的目标是根据过去12个月的记录预测下个月的异常情况；</li>
<li><strong>Abnormal Server Response (AbServe)  </strong>:本数据集由阿里巴巴云提供。每个系列记录不同指标的详细读数(例如:CPU、磁盘、内存等)。当服务器无法响应时，日志将记录异常。我们的目标是根据前一小时的记录预测未来五分钟内的异常情况。</li>
</ul>
<h4 id="BaseLine"><a href="#BaseLine" class="headerlink" title="BaseLine"></a>BaseLine</h4><ul>
<li><p><strong>基于特征的模型</strong></p>
<p>Bag of Patterns (BoP), Vector Space Model using SAX (SAX-VSM) and Fast Shapelet (FS)  </p>
<blockquote>
<p>这些方法捕获不同的状态表示，这些状态表示作为事件预测的特征</p>
</blockquote>
</li>
<li><p><strong>序列模型</strong></p>
<ul>
<li><p>switching-time-series model (S-HMM)   ：建模状态序列的马尔可夫依赖</p>
</li>
<li><p>multiscale recurrent neural network (MRNN)   ：以$X_t \oplus Y_t$作为输入，学习隐空间表示来做预测</p>
</li>
<li><p>hierarchical recurrent neural network (HRNN)   ：学习更多$X_t $和$ Y_t$的相关性</p>
</li>
</ul>
</li>
<li><p><strong>基于图的模型</strong></p>
<ul>
<li><p>gated graph neural network (GGNN)  ：使用one-hot对$h_0$进行初始化，局部信息传递使用GGNN，节点级传播是用GRU</p>
</li>
<li><p>GCN-LSTM ：使用$\Theta$对$h_0$进行初始化，局部信息传递使用GCN，节点级传播是用LSTM</p>
</li>
<li><p>EvolveGCN ：将RNN和GCN结合起来的多层动态图神经网络，关注的节点级的传播</p>
</li>
<li><p>ST-MGCN  ：时空多图卷积网络，使用$ Y_t$作为传播的上下文信息，它直接将上下文信息融合到节点级表示中，而不是学习图级表示并对节点-图交互进行建模</p>
</li>
<li><p>Time2Graph  ：将不同时间的图形聚合成静态图，并进行DeepWalk来学习图形的表示，然后作为事件预测的特征</p>
</li>
</ul>
</li>
<li><p><strong><code>EvoNet</code>变体</strong></p>
<p><code>EvoNet w/o G</code>：不使用演化状态图，使用状态序列直接建模（LSTM）</p>
<p><code>EvoNet w/o A</code>：不使用时间注意力机制</p>
</li>
</ul>
<p><a href="https://imgtu.com/i/ccIOc8"><img src="https://z3.ax1x.com/2021/04/14/ccIOc8.png" alt="ccIOc8.png"></a></p>
<p><code>Q1</code>: How does <code>EvoNet</code> perform on the time-series prediction task, compared with other baselines from the state-of-the-art?  </p>
<p><code>Q2</code>: How does the proposed <code>EvoBlock</code> effectively bridge the graph-level and node-level information over time?</p>
<p><code>Q3</code>: How do different configurations, e.g., state number, segmentation length, implementation of state recognition and message passing, influence the performance?  </p>
<p><a href="https://imgtu.com/i/ccIHht"><img src="https://z3.ax1x.com/2021/04/14/ccIHht.png" alt="ccIHht.png"></a></p>
<h4 id="Case-Study"><a href="#Case-Study" class="headerlink" title="Case Study"></a>Case Study</h4><p><a href="https://imgtu.com/i/ccI7tI"><img src="https://z3.ax1x.com/2021/04/14/ccI7tI.png" alt="ccI7tI.png"></a></p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>本文研究状态之间的关系如何反映时间数据的演化问题。我们提出了一种新的表示方法——演化状态图，来表示时间序列状态之间的时变关系。为了捕获这些有效的模式用于下游任务，我们进一步提出了基于<code>GNN</code>的<code>EvoNet</code>模型来进行动态图建模。为了验证<code>EvoNet</code>的有效性，我们在五个真实世界的数据集上进行了大量的实验。实验结果表明，我们的模型明显优于11种最先进的基准测试方法。在此基础上，我们可以发现状态之间的一些有意义的关系，使我们能够理解时间数据。</p>
]]></content>
      <categories>
        <category>djx</category>
      </categories>
      <tags>
        <tag>EEG</tag>
        <tag>自监督学习</tag>
      </tags>
  </entry>
  <entry>
    <title>gs CTF:Anomaly Detection in High Dimensional Time Series with Coarse to Fine Model Transfer</title>
    <url>/2021/02/24/GongSa/aa/</url>
    <content><![CDATA[<p><a href="https://imgtu.com/i/yObyUH"><img src="https://s3.ax1x.com/2021/02/24/yObyUH.png" alt="yObyUH.png"></a></p>
<p>[INFOCOM2021]</p>
<h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>本文提出了一个基于粗到细模型迁移的<code>CTF</code>框架，以实现可扩展和准确的数据中心规模的异常检测。CTF预先训练一个粗粒度模型，使用该模型提取每台机器的特征并计算其分布，根据分布对机器进行聚类，并进行模型迁移以对每个类簇模型进行微调以获得较高的精度。文中还对聚类算法、距离度量等设计进行了证明，以达到最佳的精度，并在生产数据上进行实验，验证了其可扩展性和准确性。</p>
<p>关键字：异常检测，高维，时间序列，大规模</p>
<a id="more"></a>
<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>背景：大规模数据中心的异常检测监控</p>
<h3 id="挑战"><a href="#挑战" class="headerlink" title="挑战"></a>挑战</h3><h4 id="1-基于深度学习的算法面临的挑战：维度爆炸"><a href="#1-基于深度学习的算法面临的挑战：维度爆炸" class="headerlink" title="1 基于深度学习的算法面临的挑战：维度爆炸"></a>1 基于深度学习的算法面临的挑战：<strong>维度爆炸</strong></h4><ul>
<li>机器数量</li>
<li>检测指标数量（KPI）</li>
<li>时间粒度细（30s）</li>
</ul>
<p>对于每个机器构建一个模型，能够确保精确度，但是不能保证效率</p>
<p>因此提出，先对机器进行<strong>聚类</strong>，对每一类的机器使用一个模型。</p>
<h4 id="2-引出另一个挑战：直接对机器的高维KPI进行聚类，会由于高维引起的维度灾难，带来计算效率低的问题"><a href="#2-引出另一个挑战：直接对机器的高维KPI进行聚类，会由于高维引起的维度灾难，带来计算效率低的问题" class="headerlink" title="2 引出另一个挑战：直接对机器的高维KPI进行聚类，会由于高维引起的维度灾难，带来计算效率低的问题"></a>2 引出另一个挑战：直接对机器的高维KPI进行聚类，会由于高维引起的维度灾难，带来计算效率低的问题</h4><p>因此提出，对高维KPI做一个降维表示</p>
<h3 id="进一步构建框架的挑战"><a href="#进一步构建框架的挑战" class="headerlink" title="进一步构建框架的挑战"></a>进一步构建框架的挑战</h3><h4 id="1-RNN-VAE模型的训练和聚类之间存在依赖关系"><a href="#1-RNN-VAE模型的训练和聚类之间存在依赖关系" class="headerlink" title="1 RNN-VAE模型的训练和聚类之间存在依赖关系"></a>1 RNN-VAE模型的训练和聚类之间存在依赖关系</h4><p>要聚类的前提是有训练好的模型获得低维潜在表示，但训练一个RNN-VAE模型只用没聚类的高维时间序列数据很难准确且高效</p>
<p><strong>解决办法：</strong>提出一个 coarse-to-fine model transfer framework </p>
<h4 id="2-time-domain-：-潜在表示仍然是高维时间序列"><a href="#2-time-domain-：-潜在表示仍然是高维时间序列" class="headerlink" title="2 time domain ： 潜在表示仍然是高维时间序列"></a>2 time domain ： 潜在表示仍然是高维时间序列</h4><p>这样对聚类很不友好</p>
<p><strong>解决办法：</strong>将时间序列转换成分布，这既提高了效率，也提高了准确性</p>
<h4 id="3-要对模型迁移策略、聚类算法、距离度量进行选择"><a href="#3-要对模型迁移策略、聚类算法、距离度量进行选择" class="headerlink" title="3 要对模型迁移策略、聚类算法、距离度量进行选择"></a>3 要对模型迁移策略、聚类算法、距离度量进行选择</h4><h3 id="框架：CTF"><a href="#框架：CTF" class="headerlink" title="框架：CTF"></a>框架：CTF</h3><p>离线训练分为四步：</p>
<ul>
<li>采样部分数据训练粗粒度模型</li>
<li>使用粗粒度模型将每台机器的多变量时序转化为低维潜在表示</li>
<li>基于潜在表示的分布对机器进行聚类</li>
<li>对每个聚类的机器fine-tune模型</li>
</ul>
<p>我们的评估表明，当CTF使用OmniAnomaly算法，CTF可以将模型训练时间从两个月左右减少到4.40小时（6台计算服务器，一个数据中心10万台机器），F1score-0.830（loss0.012）</p>
<h3 id="贡献"><a href="#贡献" class="headerlink" title="贡献"></a>贡献</h3><ul>
<li><p>我们提出了一个基于coarse-to-fine model transfer  的框架，该框架可以在机器、KPI和时间域上具有高维的庞大操作数据集上执行异常检测。其核心技术如下：</p>
<ul>
<li>第一次综合了模型训练和机器聚类，并对两者进行了加速；</li>
<li>第一次利用潜在表示的分布进行聚类，加速了对距离的计算；</li>
<li>第一次对RNN-VAE模型应用微调策略，验证其在准确性和效率方面的好处；</li>
</ul>
</li>
<li><p>在全球顶级互联网公司的大规模数据集上使用最先进的异常检测算法对CTF进行了实现和评估，展示了CTF在实际基础设施中的有效性和可扩展性。</p>
</li>
<li>开源了多变量时间序列的<a href="https://github.com/NetManAIOps/label-tool">标记工具</a>和<a href="https://github.com/NetManAIOps/CTF data">标记的数据集</a></li>
</ul>
<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><h3 id="问题陈述"><a href="#问题陈述" class="headerlink" title="问题陈述"></a>问题陈述</h3><p><a href="https://imgtu.com/i/yOb65d"><img src="https://s3.ax1x.com/2021/02/24/yOb65d.png" alt="yOb65d.png"></a></p>
<p><a href="https://imgtu.com/i/yObDbD"><img src="https://s3.ax1x.com/2021/02/24/yObDbD.png" alt="yObDbD.png"></a></p>
<p><a href="https://imgtu.com/i/yObBDO"><img src="https://s3.ax1x.com/2021/02/24/yObBDO.png" alt="yObBDO.png"></a></p>
<p><a href="https://imgtu.com/i/yObsVe"><img src="https://s3.ax1x.com/2021/02/24/yObsVe.png" alt="yObsVe.png"></a></p>
<p><a href="https://imgtu.com/i/yObR2t"><img src="https://s3.ax1x.com/2021/02/24/yObR2t.png" alt="yObR2t.png"></a></p>
<p><strong>动机：</strong>我们观察到基于RNN-VAE的算法可以利用VAE的典型结构将每个高维KPI向量(L)压缩为低维潜在表示(C)。</p>
<p><strong>挑战</strong></p>
<ul>
<li><strong>聚类与模型训练之间的相互依赖性</strong></li>
</ul>
<blockquote>
<p>解决：（1）先采样部分数据，对粗粒度模型进行预训练；（2）使用粗粒度模型将每台机器的MTS转换为潜在表示；（3）利用潜在表示的分布将机器分类成K个簇；（4）将粗粒度模型迁移到每个类簇，并对每个类簇的细粒度模型进行微调；</p>
<p>聚类算法：Hierarchical Agglomerative Clustering.  （HAC）</p>
<p>优点：</p>
<ol>
<li>不需要初始参数（聚类数和距离阈值等）</li>
<li>它对距离测量算法不敏感，因为它是基于距离的排序而不是值进行聚类</li>
<li>不同层次之间的关系是明显的，便于我们可视化聚类结果</li>
</ol>
</blockquote>
<ul>
<li><strong>The high dimension of the time domain</strong>  </li>
</ul>
<blockquote>
<p>解决：对潜在表示序列进行抽样，得到分布，并在聚类中利用分布进行距离计算。</p>
<p>距离度量：Wasserstein distance  </p>
<p><a href="https://imgtu.com/i/yObgPA"><img src="https://s3.ax1x.com/2021/02/24/yObgPA.png" alt="yObgPA.png"></a></p>
<p>在两个分布之间的重叠较少或没有重叠时特别有用</p>
</blockquote>
<ul>
<li><strong>神经网络训练方法的选择</strong></li>
</ul>
<blockquote>
<p>在新数据集中训练旧模型的所有神经网络层，<strong>在新数据集中训练旧模型的部分层(即微调)</strong></p>
<p>微调dense layers</p>
</blockquote>
<h2 id="设计"><a href="#设计" class="headerlink" title="设计"></a>设计</h2><h3 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h3><ul>
<li>缺失值填充（previously observed value）</li>
<li>Data normalization  </li>
</ul>
<p><a href="https://imgtu.com/i/yOb28I"><img src="https://s3.ax1x.com/2021/02/24/yOb28I.png" alt="yOb28I.png"></a></p>
<h3 id="离线模型训练"><a href="#离线模型训练" class="headerlink" title="离线模型训练"></a>离线模型训练</h3><p>1）预训练粗粒度模型</p>
<p>2）特征提取</p>
<blockquote>
<p>抽取部分KPI进行降维表示，学习分布</p>
</blockquote>
<p>3）机器聚类</p>
<blockquote>
<p>子集上进行聚类中心计算</p>
</blockquote>
<p>4）模型迁移</p>
<blockquote>
<p>冻结RNN层</p>
<p>The reason is that RNN layers are shallow and deterministic, and thus, they extract general time-series features in the coarse-grained model, which could contribute to the model generalization  </p>
</blockquote>
<h2 id="在线检测"><a href="#在线检测" class="headerlink" title="在线检测"></a>在线检测</h2><p><strong>异常分数：</strong>重构概率（KPI接近normal行为的概率）</p>
<p><strong>阈值选择：</strong>Peaks-Over-Threshold (POT)  </p>
<blockquote>
<p>1）POT对整个群体中某一低分位数以下的样本记性过滤，用Generalized Pareto Distribution (GPD) 拟合，获得GPD函数；</p>
<p><a href="https://imgtu.com/i/yObOx0"><img src="https://s3.ax1x.com/2021/02/24/yObOx0.png" alt="yObOx0.png"></a></p>
<p>2）利用函数和整个群体中的一个异常分位（q）数来确定阈值</p>
<p>优点：①没对整个总体分布进行假设 ②低分位数和q ③实际效率高</p>
</blockquote>
<h2 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h2><p><a href="https://imgtu.com/i/yObWxP"><img src="https://s3.ax1x.com/2021/02/24/yObWxP.png" alt="yObWxP.png"></a></p>
<p><a href="https://imgtu.com/i/yOb5qS"><img src="https://s3.ax1x.com/2021/02/24/yOb5qS.png" alt="yOb5qS.png"></a></p>
<p><strong>功能</strong></p>
<ol>
<li>加载、可视化、拖动、放大/缩小时间序列，使用户可以概览整个序列的形状，并定位某个片段的细节</li>
<li>可以折叠和展开几个KPI维度，为用户提供更好的视图</li>
<li>对异常进行标记或取消。用户可以选择间隔的开始和结束，并将其保存为异常</li>
<li>实时收集并更新异常间隔(如计数、百分比)的统计信息。</li>
</ol>
<h2 id="评估"><a href="#评估" class="headerlink" title="评估"></a>评估</h2><h3 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h3><ul>
<li>533机器实体</li>
<li>每个机器49条KPI</li>
<li>采样间隔30s</li>
<li>13天数据（from April 18th to April 30th）</li>
</ul>
<h3 id="参数"><a href="#参数" class="headerlink" title="参数"></a>参数</h3><p>预训练采样实体数：100</p>
<p>预训练采样KPI数：每个实体的10%</p>
<p>聚类数：5</p>
<p>低分位数：0.01， 0.02， 0.03</p>
<p>q：$10^{-5}$</p>
<h3 id="性能"><a href="#性能" class="headerlink" title="性能"></a>性能</h3><p><a href="https://imgtu.com/i/yObhKf"><img src="https://s3.ax1x.com/2021/02/24/yObhKf.png" alt="yObhKf.png"></a></p>
<p><a href="https://imgtu.com/i/yOb4r8"><img src="https://s3.ax1x.com/2021/02/24/yOb4r8.png" alt="yOb4r8.png"></a></p>
<p><a href="https://imgtu.com/i/yOboVg"><img src="https://s3.ax1x.com/2021/02/24/yOboVg.png" alt="yOboVg.png"></a></p>
<blockquote>
<p>we tune alerting policy cross-time: at least N consecutive anomalous points will be considered as anomalies (e.g., N = 5 in our scenario).  </p>
</blockquote>
<p><a href="https://imgtu.com/i/yObTaQ"><img src="https://s3.ax1x.com/2021/02/24/yObTaQ.png" alt="yObTaQ.png"></a></p>
<p><a href="https://imgtu.com/i/yOb75j"><img src="https://s3.ax1x.com/2021/02/24/yOb75j.png" alt="yOb75j.png"></a></p>
<blockquote>
<p>特征表示</p>
</blockquote>
<p><a href="https://imgtu.com/i/yObbPs"><img src="https://s3.ax1x.com/2021/02/24/yObbPs.png" alt="yObbPs.png"></a></p>
<p><a href="https://imgtu.com/i/yObqGn"><img src="https://s3.ax1x.com/2021/02/24/yObqGn.png" alt="yObqGn.png"></a></p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本文提出了一个基于粗到细模型迁移的<code>CTF</code>框架，以实现可扩展和准确的数据中心规模的异常检测，离线模型训练分四步进行，每一步的设计提高精度且提高性能，更是公开了数据集和开源了标签工具。另外，该框架可以扩展到大规模时序预测或分类。</p>
]]></content>
      <categories>
        <category>gs</category>
      </categories>
      <tags>
        <tag>多变量时间序列</tag>
        <tag>异常检测</tag>
        <tag>大规模异常检测</tag>
      </tags>
  </entry>
  <entry>
    <title>gs A Deep Neural Network for Unsupervised Anomaly Detection and Diagnosis in Multivariate Time Series Data</title>
    <url>/2021/01/16/GongSa/gs_AAAI_2020_A%20Deep%20Neural%20Network%20for%20Unsupervised%20Anomaly%20Detection%20and%20Diagnosis%20in%20Multivariate%20Time%20Series%20Data/</url>
    <content><![CDATA[<blockquote>
<p>Zhang C, Song D, Chen Y, et al. A deep neural network for unsupervised anomaly detection and diagnosis in multivariate time series data[C]//Proceedings of the AAAI Conference on Artificial Intelligence. 2019, 33: 1409-1416.</p>
</blockquote>
<h3 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a>背景介绍</h3><p>目前，多变量时间序列数据在各种现实系统中越来越受到重视，如发电厂等。</p>
<p>多变量时间序列异常检测与诊断是指在一定的时间步长中<strong>识别异常状态</strong>，找出<strong>异常的根本原因</strong>。</p>
<p>然而，建立这样一个系统是具有挑战性的：</p>
<ul>
<li>需要捕获每个时间序列中的时间依赖性</li>
<li>需要对不同时间序列对之间的相互关系进行编码</li>
<li>该系统应该对噪声具有鲁棒性</li>
<li>根据不同事件的严重程度为操作员提供不同级别的异常评分</li>
<li>需要面对标签稀缺的问题</li>
</ul>
<p>尽管已经开发了大量的非监督异常检测算法，但其中很少有能够共同应对这些挑战的。</p>
<a id="more"></a> 
<p><a href="https://imgchr.com/i/sJykuV"><img src="https://s3.ax1x.com/2021/01/12/sJykuV.png" alt="sJykuV.png"></a></p>
<h4 id="相关工作非监督的方法效果较差的原因"><a href="#相关工作非监督的方法效果较差的原因" class="headerlink" title="相关工作非监督的方法效果较差的原因"></a>相关工作非监督的方法效果较差的原因</h4><ul>
<li><strong>多元时间序列数据存在时间相关性。</strong>基于距离/聚类的方法<code>kNN</code>，基于分类的方法<code>OC-SVM</code>,基于密度的方法<code>DAGMM</code>（深度自编码高斯混合模型），都不能捕获跨不同时间步长的时间依赖性</li>
<li><strong>多变量时间序列数据在实际应用中往往含有噪声。</strong>噪声可能会影响时间预测模型的泛化能力，如自回归移动平均（<code>ARMA</code>）和<code>LSTM Encoder-Decoder</code> ，使得结果假阳性增多</li>
<li><strong>在实际应用中，根据不同事件的严重程度，为操作人员提供不同程度的异常评分是很有意义的。</strong></li>
</ul>
<h4 id="本文贡献"><a href="#本文贡献" class="headerlink" title="本文贡献"></a>本文贡献</h4><ul>
<li><strong>异常检测与诊断是异常检测与诊断的三大基本任务。</strong>异常检测、根本原因识别和异常严重程度(持续时间)解释。不像以前的研究是独立地解决每个问题，我们是共同地解决这些问题的。</li>
<li><strong>提出了系统特征矩阵的概念，并利用卷积编码器对时序间的相关关系进行编码，将时间序列与基于注意力机制的卷积<code>LSTM</code>网络相结合，利用卷积解码器重构特征矩阵。</strong><code>MSCRED</code>是第一个考虑多变量时间序列相关性的异常检测模型，可以联合解决这三个任务。</li>
<li><strong>我们对合成数据集和发电厂数据集进行了广泛的实证研究。</strong>我们的结果表明<code>MSCRED</code>优于最先进的基线方法。</li>
</ul>
<h3 id="MSCRED框架"><a href="#MSCRED框架" class="headerlink" title="MSCRED框架"></a><code>MSCRED</code>框架</h3><p><a href="https://imgchr.com/i/sJyij0"><img src="https://s3.ax1x.com/2021/01/12/sJyij0.png" alt="sJyij0.png"></a></p>
<h4 id="特征矩阵"><a href="#特征矩阵" class="headerlink" title="特征矩阵"></a>特征矩阵</h4><p>特征矩阵：$M^t$</p>
<p>两个时序段：$x_i^w=(x_i^w-t,x_i^w-t+1,…,x_i^w)$</p>
<p>​                    $x_j^w=(x_j^w-t,x_j^w-t+1,…,x_j^w)$</p>
<p>特征矩阵的每一项：<script type="math/tex">m_{ij}^t=\frac{\sum_{\delta=0}^w x_i^{t-\delta}x_j^{t-\delta} }{\kappa}</script></p>
<p>窗口大小：$w=10,30,60$</p>
<p>段滑窗：$10$</p>
<blockquote>
<p>该方法不仅能捕获两个时间序列之间的形状相似性和值尺度相关性，而且对输入噪声具有很强的鲁棒性，因为特定时间序列的波动对特征矩阵的影响很小</p>
</blockquote>
<h4 id="卷积编码器"><a href="#卷积编码器" class="headerlink" title="卷积编码器"></a>卷积编码器</h4><p><a href="https://imgchr.com/i/sJy99s"><img src="https://s3.ax1x.com/2021/01/12/sJy99s.png" alt="sJy99s.png"></a></p>
<p>输入：$\chi^{t,0}\in R^{n\times n\times s}$</p>
<p>输出：$\chi^{t,l}=f(W^{l}*\chi^{t,l-1}+b^l)$ 激活函数： Scaled Exponential Linear Unit</p>
<p><code>Conv1-Conv4</code>：$3\times 3 \times 3$ 的32核，$3\times 3 \times 32$ 的64核，$2\times 2 \times 64$ 的128核，$2\times 2 \times 128$ 的256核；步长：$1\times 1$, $2\times 2$, $2\times 2$, $2\times 2$</p>
<h4 id="基于注意力机制的ConvLSTM"><a href="#基于注意力机制的ConvLSTM" class="headerlink" title="基于注意力机制的ConvLSTM"></a>基于注意力机制的<code>ConvLSTM</code></h4><p><a href="https://imgchr.com/i/sJyShj"><img src="https://s3.ax1x.com/2021/01/12/sJyShj.png" alt="sJyShj.png"></a></p>
<p><a href="https://imgchr.com/i/sJszNQ"><img src="https://s3.ax1x.com/2021/01/12/sJszNQ.png" alt="sJszNQ.png"></a></p>
<p><a href="https://imgchr.com/i/sJyPcq"><img src="https://s3.ax1x.com/2021/01/12/sJyPcq.png" alt="sJyPcq.png"></a></p>
<h4 id="卷积解码器"><a href="#卷积解码器" class="headerlink" title="卷积解码器"></a>卷积解码器</h4><p><a href="https://imgchr.com/i/sJyABT"><img src="https://s3.ax1x.com/2021/01/12/sJyABT.png" alt="sJyABT.png"></a></p>
<p><a href="https://imgchr.com/i/sJyZEF"><img src="https://s3.ax1x.com/2021/01/12/sJyZEF.png" alt="sJyZEF.png"></a></p>
<p><code>DeConv1-DeConv4</code>：$3\times 3 \times 3$ 的32核，$3\times 3 \times 32$ 的64核，$2\times 2 \times 64$ 的128核，$2\times 2 \times 128$ 的256核；步长：$1\times 1$, $2\times 2$, $2\times 2$, $2\times 2$</p>
<h4 id="Loss-Function"><a href="#Loss-Function" class="headerlink" title="Loss Function"></a>Loss Function</h4><p><a href="https://imgchr.com/i/sJyEHU"><img src="https://s3.ax1x.com/2021/01/12/sJyEHU.png" alt="sJyEHU.png"></a></p>
<h3 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h3><h4 id="回答的问题"><a href="#回答的问题" class="headerlink" title="回答的问题"></a>回答的问题</h4><p><code>RQ1</code> <code>MSCRED</code>在多变量时间序列异常检测方面是否优于基线方法?</p>
<p><code>RQ2</code> <code>MSCRED</code>的每个组件都怎样影响其性能？</p>
<p><code>RQ3</code> <code>MSCRED</code>是否能做到异常跟因检测？</p>
<p><code>RQ4</code> <code>MSCRED</code>能否对异常严重性做有效的解释？</p>
<p><code>RQ5</code> <code>MSCRED</code>是否能对输入噪音具有鲁棒性？</p>
<h4 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h4><p><strong>Synthetic data</strong></p>
<p><a href="https://imgchr.com/i/sJyeN4"><img src="https://s3.ax1x.com/2021/01/12/sJyeN4.png" alt="sJyeN4.png"></a></p>
<p><strong>Power plant data</strong></p>
<p><a href="https://imgchr.com/i/sJz6df"><img src="https://s3.ax1x.com/2021/01/12/sJz6df.png" alt="sJz6df.png"></a></p>
<p>合成数据中生成的5个异常持续时间属于1-3种尺度（30,60,90）</p>
<p>电厂数据中一个是实际异常，4个是随机植入的</p>
<h4 id="Baseline-methods"><a href="#Baseline-methods" class="headerlink" title="Baseline methods"></a>Baseline methods</h4><p><strong>分类模型：</strong><code>OC-SVM</code></p>
<p><strong>密度估计模型：</strong><code>DAGMM</code>（深度自编码高斯混合模型）</p>
<p><strong>预测模型：</strong><code>HA</code>(History Average) <code>ARMA</code> <code>LSTM-ED</code></p>
<p><strong><code>MSCRED</code>变体:</strong></p>
<p>​    （1）去除注意力模块和最开始的三个<code>ConvLSTM</code> </p>
<p>​    （2）去除注意力模块和最开始的两个<code>ConvLSTM</code> </p>
<p>​    （3）去除注意力模块</p>
<h4 id="评价指标"><a href="#评价指标" class="headerlink" title="评价指标"></a>评价指标</h4><p><strong><code>Precision</code>, <code>Recall</code>, <code>F1-Score</code></strong></p>
<h4 id="性能评估"><a href="#性能评估" class="headerlink" title="性能评估"></a>性能评估</h4><h5 id="RQ1-MSCRED在多变量时间序列异常检测方面是否优于基线方法"><a href="#RQ1-MSCRED在多变量时间序列异常检测方面是否优于基线方法" class="headerlink" title="RQ1 MSCRED在多变量时间序列异常检测方面是否优于基线方法?"></a><code>RQ1</code> <code>MSCRED</code>在多变量时间序列异常检测方面是否优于基线方法?</h5><p><a href="https://imgchr.com/i/sJxUvn"><img src="https://s3.ax1x.com/2021/01/12/sJxUvn.png" alt="sJxUvn.png"></a></p>
<ul>
<li>时间预测模型要比分类和基于密度的模型效果好一些</li>
<li><code>LSTM-ED</code>比<code>ARMA</code>效果好，深度学习模型可以捕获时间信息</li>
<li><code>MSCRED</code>表现最好</li>
</ul>
<p><a href="https://imgchr.com/i/sJxfDx"><img src="https://s3.ax1x.com/2021/01/12/sJxfDx.png" alt="sJxfDx.png"></a></p>
<h5 id="RQ2-MSCRED的每个组件都怎样影响其性能？"><a href="#RQ2-MSCRED的每个组件都怎样影响其性能？" class="headerlink" title="RQ2 MSCRED的每个组件都怎样影响其性能？"></a><code>RQ2</code> <code>MSCRED</code>的每个组件都怎样影响其性能？</h5><p><a href="https://imgchr.com/i/sJxwD0"><img src="https://s3.ax1x.com/2021/01/12/sJxwD0.png" alt="sJxwD0.png"></a></p>
<p><a href="https://imgchr.com/i/sJxduq"><img src="https://s3.ax1x.com/2021/01/12/sJxduq.png" alt="sJxduq.png"></a></p>
<h5 id="RQ3-MSCRED是否能做到异常跟因检测？"><a href="#RQ3-MSCRED是否能做到异常跟因检测？" class="headerlink" title="RQ3 MSCRED是否能做到异常跟因检测？"></a><code>RQ3</code> <code>MSCRED</code>是否能做到异常跟因检测？</h5><p><a href="https://imgchr.com/i/sJx8US"><img src="https://s3.ax1x.com/2021/01/12/sJx8US.png" alt="sJx8US.png"></a></p>
<blockquote>
<p>top-k 方式判定异常跟因 图5 k=3</p>
</blockquote>
<h5 id="RQ4-MSCRED能否对异常严重性做有效的解释？"><a href="#RQ4-MSCRED能否对异常严重性做有效的解释？" class="headerlink" title="RQ4 MSCRED能否对异常严重性做有效的解释？"></a><code>RQ4</code> <code>MSCRED</code>能否对异常严重性做有效的解释？</h5><p><a href="https://imgchr.com/i/sJx0bV"><img src="https://s3.ax1x.com/2021/01/12/sJx0bV.png" alt="sJx0bV.png"></a></p>
<p><a href="https://imgchr.com/i/sJxWK1"><img src="https://s3.ax1x.com/2021/01/12/sJxWK1.png" alt="sJxWK1.png"></a></p>
<h5 id="RQ5-MSCRED是否能对输入噪音具有鲁棒性？"><a href="#RQ5-MSCRED是否能对输入噪音具有鲁棒性？" class="headerlink" title="RQ5 MSCRED是否能对输入噪音具有鲁棒性？"></a><code>RQ5</code> <code>MSCRED</code>是否能对输入噪音具有鲁棒性？</h5><p><a href="https://imgchr.com/i/sJx6C4"><img src="https://s3.ax1x.com/2021/01/12/sJx6C4.png" alt="sJx6C4.png"></a></p>
<blockquote>
<p>噪声的控制在于$\lambda$的取值</p>
<p><a href="https://imgchr.com/i/sJyeN4"><img src="https://s3.ax1x.com/2021/01/12/sJyeN4.png" alt="sJyeN4.png"></a></p>
</blockquote>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>本文综合异常检测和诊断提出了一个创新的模型<code>MSCRED</code>，该模型可以采用不同尺度（解析度）对系统状态（多元时间序列）构造特征矩阵来描述不同时间段里整个系统状态，采用基于注意力机制的深度编码器解码器来重构特征矩阵，最终判定异常的方式是使用重构误差。</p>
]]></content>
      <categories>
        <category>gs</category>
      </categories>
      <tags>
        <tag>多变量时间序列</tag>
        <tag>异常检测</tag>
        <tag>生成式模型</tag>
      </tags>
  </entry>
  <entry>
    <title>gs Diagnosing Root Causes of Intermittent Slow Queries in Large-Scale Cloud Databases</title>
    <url>/2021/01/16/GongSa/gs_VLDB_2020_Diagnosing%20Root%20Causes%20of%20Intermittent%20Slow%20Queries%20in%20Large-Scale%20Cloud%20Databases/</url>
    <content><![CDATA[<blockquote>
<p>Proc. VLDB Endow. 13(8): 1176-1189 (2020)</p>
<p><a href="https://imgchr.com/i/sJBXBF"><img src="https://s3.ax1x.com/2021/01/12/sJBXBF.png" alt="sJBXBF.png"></a></p>
</blockquote>
<h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h3><p>随着云数据库市场的不断增长，检测和消除慢速查询对服务稳定性至关重要。以前的研究集中在优化由于内部原因(例如，编写得不好的sql)而导致的缓慢查询。</p>
<p>在这项工作中，我们发现了一组不同的慢速查询，与其他慢速查询相比，这些查询对数据库用户的危害可能更大。我们将这种查询命名为<strong>间歇性慢速查询(iSQs)</strong>，因为它们通常是由外部的间歇性性能问题造成的(例如，在数据库或机器级别)。诊断iSQs的根本原因是一项艰巨但非常有价值的任务。</p>
<p>本文提出<strong>iSQUAD（Intermittent Slow QUery Anomaly Diagnoser）</strong>，一个可以诊断iSQs的根本原因的框架，它对人工干预的需求比较松。</p>
<a id="more"></a> 
<p>面临的挑战：<strong>通用性、标签开销和可解释性</strong>。因此设计了四个组件：</p>
<ul>
<li>异常提取</li>
<li>依赖清理</li>
<li>面向类型的模式集成聚类(TOPIC)</li>
<li>贝叶斯实例模型（Bayesian Case Model）</li>
</ul>
<p><strong>组成：</strong></p>
<ul>
<li>阶段一：离线聚类+解释</li>
<li>阶段二：在线跟因诊断+更新</li>
</ul>
<p><strong>数据集：</strong>阿里巴巴OLTP数据库的真实数据集</p>
<h3 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h3><p>云数据库正在不断地发展，数据库中的服务中断或性能故障可能会导致严重的效率损失和品牌损失。因此，数据库总是处于不断的监控之中，检测和消除慢速查询对于服务的稳定性至关重要。</p>
<p>大多数数据库系统，如MySQL、Oracle、SQL Server，会自动记录完成时间超过用户限制阈值的查询的详细信息。一些缓慢的查询是由<u>内部原因</u>造成的，比如复杂性、缺乏索引和SQL语句编写得很差，这些可以被自动分析和优化。</p>
<p><strong>间歇性慢速查询(iSQs)：</strong>这些慢速查询是由<u>外部的</u>间歇性性能问题(例如，在数据库或机器级别)导致的。</p>
<blockquote>
<p><strong>造成损失严重，手动诊断费事费力</strong></p>
<p>通常，iSQs是云数据库中性能问题甚至故障的主要症状。由于iSQs是断断续续的，服务开发人员和客户希望它们能够正常响应，而突然增加的延迟会产生巨大的影响。例如，在浏览网页时，iSQ可能导致网页加载延迟。据报道，亚马逊每0.1秒的加载延迟就会损失1%的销售额，而谷歌搜索结果每0.5秒的加载延迟就会导致的流量下降20%。我们获得了阿里巴巴OLTP数据库的数据库管理员在一年内注意到的几个性能问题记录:当一个性能问题发生时，一系列的isq持续几分钟。事实上，手动诊断iSQs的根本原因需要几十分钟，这既费时又容易出错。</p>
</blockquote>
<p>本文的工作目标：尽可能的减少人工干预来进行于数据库中iSQ的跟因诊断。以下是观察到的异常症状和跟因的一些记录：</p>
<ul>
<li><strong>数据库管理员需要扫描数百个关键性能指标来查找性能问题症状。</strong></li>
</ul>
<p><a href="https://imgchr.com/i/sJBqXT"><img src="https://s3.ax1x.com/2021/01/12/sJBqXT.png" alt="sJBqXT.png"  /></a></p>
<ul>
<li><p><strong>性能问题异常主要包括不同的kpi模式。</strong>我们总结了三组对称的KPI模式，即，<strong>突起突降，水平漂移（向上或向下），缺失</strong>。单纯基于检测KPI异常与否，我们无法准确诊断iSQs的根本原因。</p>
</li>
<li><p><strong>一个异常KPI通常伴随着另一个或多个异常KPI。</strong></p>
</li>
<li><p><strong>类似的异常与相同的根因相关。</strong>在每个根本原因类别中，性能问题的KPI症状彼此相似。</p>
</li>
</ul>
<p>提出<strong>iSQUAD（Intermittent Slow QUery Anomaly Diagnoser）</strong>，其中，我们采用异常提取和依赖清理来代替传统的异常检测方法，以解决异常多样性的挑战。为了减少标记开销，提出了面向类型的模式集成聚类(TOPIC)，将具有相同根源的iSQ聚类在一起，同时考虑KPI和异常类型。在聚类可解释性方面，利用贝叶斯实例模型为每个聚类提取基于实例的表示，便于DBAs研究。</p>
<p><strong>组成：</strong></p>
<ul>
<li><p>阶段一：离线聚类+解释</p>
<p>获得聚类和跟因，用于在线阶段的诊断。数据库管理员只需要对每个聚类标记一次，除非在线阶段出现了新的类。</p>
</li>
<li><p>阶段二：在线跟因诊断+更新</p>
</li>
</ul>
<p><strong>工作主要贡献：</strong></p>
<ul>
<li><p>基于云数据库中iSQs速度慢的问题，并设计了一个名为<strong>iSQUAD的可伸缩框架</strong>，该框架可以为iSQs提供准确而有效的根因诊断。它采用了机器学习技术，克服了在通用性、标识开销和可交互性等方面的挑战。</p>
</li>
<li><p><strong>异常提取</strong>：使用KPIs的异常提取来代替异常检测来区分异常类型。</p>
</li>
<li><p><strong>聚类</strong>：提出了一种新的聚类算法TOPIC来减少标记开销。</p>
</li>
<li><p>最先通过<strong>贝叶斯实例模型</strong>在数据库领域中应用和改进基于实例的推理，并将实例子空间表示推给DBAs用于标记。</p>
</li>
<li><p>我们对iSQUAD的评估进行了大量的实验，证明了我们的方法获得了平均F1-score 80.4%，较前一种技术提高了49.2%。此外，已经在真实的云数据库服务中部署了iSQUAD的原型。iSQUAD可以帮助DBAs在80分钟内找到数百个iSQs的全部10个根因，这比传统的逐例诊断快大约30倍。</p>
</li>
</ul>
<h3 id="背景与动机"><a href="#背景与动机" class="headerlink" title="背景与动机"></a>背景与动机</h3><h4 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h4><h5 id="阿里巴巴OLTP数据库"><a href="#阿里巴巴OLTP数据库" class="headerlink" title="阿里巴巴OLTP数据库"></a>阿里巴巴OLTP数据库</h5><p>支持的服务有淘宝、天猫、钉钉和菜鸟等。这个数据库包含了跨越几十个地理区域的十万个实际运行的实体，配备有一个度量系统用于收集日志和KPIs。</p>
<h5 id="Intermittent-Slow-Queries-iSQs"><a href="#Intermittent-Slow-Queries-iSQs" class="headerlink" title="Intermittent Slow Queries (iSQs)"></a>Intermittent Slow Queries (iSQs)</h5><p><strong>查询时间</strong>：SQL查询被提交给数据库和其结果被数据库返回之间的时间。</p>
<p><strong>iSQ：</strong>第$t$ 个SQL语句 $Q_t$，执行时间$X_t$,当$X_t&gt;z$且$P(X_i&gt;z)&lt;\epsilon$,其中$1&lt;=t,i&lt;=T$，z是一个iSQ的阈值。对于阿里数据库管理员设置：$z=1s,\epsilon=0.01,T=10^4$</p>
<p><a href="https://imgchr.com/i/sJBbcV"><img src="https://s3.ax1x.com/2021/01/12/sJBbcV.png" alt="sJBbcV.png"></a></p>
<blockquote>
<p>图（a） 每条语句查询时间的概率分布，iSQs的占比0.0028</p>
<p>图（b） 每条语句查询时间的概率分布，每条SQL语句都比较慢</p>
</blockquote>
<p>在慢速查询中，其他类型的慢速查询主要是由任务的复杂性造成的，通常是非交互和可容忍的(约占79%)，这些慢速查询可以通过添加索引或重写SQL语句等方式来进行优化。</p>
<p>iSQs只占1%，但其影响非常大，比例很小，但是每天都会是成千上万的，处理优化这些异常有利于调高用户体验。</p>
<h4 id="观察"><a href="#观察" class="headerlink" title="观察"></a>观察</h4><p>由于当出现性能问题时，许多正常的在线服务查询会受到影响，速度会比平时慢得多，所以，理解iSQs的根本原因对于缓解慢速查询很重要。</p>
<ul>
<li><p><strong>（需要多变量）KPIs对于定位iSQs的根本原因非常重要。</strong>单独的KPI不能捕获所有类型的问题，不同类型的KPI才能掌握跟踪整个系统的状态。</p>
</li>
<li><p><strong>（以前的工作并没有关注异常类型，仅关注<u>是否异常</u>）应该注意kpi的异常类型。</strong></p>
<p>​    突起突降、水平漂移（向上或向下）、无效（缺失或为0）</p>
</li>
</ul>
<p><a href="https://imgchr.com/i/sJBH10"><img src="https://s3.ax1x.com/2021/01/12/sJBH10.png" alt="sJBH10.png"></a></p>
<p><a href="https://imgchr.com/i/sJBOnU"><img src="https://s3.ax1x.com/2021/01/12/sJBOnU.png" alt="sJBOnU.png"></a></p>
<blockquote>
<p>异常类型与异常跟因有关</p>
<p>case1 实例1进行数据库备份，两个实例共享IO</p>
<p>case2 只有一个物理机器，发生总体工作负载增加（闪购时间）</p>
</blockquote>
<ul>
<li><p><strong>（序列之间的相关性、依赖性）KPIs间异常是高度相关的，</strong>其关系可能是单向，也可能双向。</p>
</li>
<li><p><strong>类似的KPI模式与相同的根本原因相关。</strong></p>
<blockquote>
<p>例：DBAs将异常跟因分为了10类，每种跟因中，有些KPI异常是相似的，可以相互替换，比如 sql-update和sql-delete引起的负载异常。</p>
</blockquote>
</li>
</ul>
<p><a href="https://imgchr.com/i/sJBxAJ"><img src="https://s3.ax1x.com/2021/01/12/sJBxAJ.png" alt="sJBxAJ.png"></a></p>
<h4 id="挑战"><a href="#挑战" class="headerlink" title="挑战"></a>挑战</h4><ul>
<li>异常类型多样性</li>
</ul>
<blockquote>
<p>之前的方法的局限性：目前的异常研究普遍忽略和过度概括了异常类型。这样的检测方法可能会在(监控数据)预处理阶段错误地检测出大量信息，从而降低(监控)数据集的质量。</p>
</blockquote>
<ul>
<li>标签开销大：专家工作量大、过程复杂</li>
</ul>
<blockquote>
<p>之前的方法的局限性：有复现跟因的方法——实际情况不允许；<u>自定义数据负载进行统计也是不现实的</u>（？）</p>
</blockquote>
<ul>
<li>可解释的模型：模型的准确性和它对人类的可解释性之间存在不可避免的权衡。</li>
</ul>
<blockquote>
<p>之前的方法的局限性：决策树，依赖于开始时提供精确的信息，因为即使是输入中的细微差别也可能导致大的树修改，此外，决策树还可能产生“分析瘫痪”的问题，即向决策者提供的信息过多，而不是关键要素。</p>
</blockquote>
<h3 id="概览"><a href="#概览" class="headerlink" title="概览"></a>概览</h3><p>模型框架：<strong>iSQUAD (Intermittent Slow QUery Anomaly Diagnoser)</strong></p>
<p><a href="https://imgchr.com/i/sJDShR"><img src="https://s3.ax1x.com/2021/01/12/sJDShR.png" alt="sJDShR.png"></a></p>
<ul>
<li><p>离线阶段：对iSQs进行聚类，让专家更容易的识别标记跟因。</p>
<p>异常提取—异常KPIs离散化—依赖清理—聚类—Bayesian Case Model（一个典型的iSQ和它的基本KPI矩阵作为特征空间）</p>
</li>
<li><p>在线阶段：输入iSQ和其对应的KPIs—异常提取—异常KPIs离散化—依赖清理—查询匹配一个跟因类—给DBAs展示解释异常（若未匹配，则分配到一个新类）</p>
</li>
</ul>
<h3 id="iSQUAD细节设计"><a href="#iSQUAD细节设计" class="headerlink" title="iSQUAD细节设计"></a>iSQUAD细节设计</h3><h4 id="离线阶段：异常提取"><a href="#离线阶段：异常提取" class="headerlink" title="离线阶段：异常提取"></a>离线阶段：异常提取</h4><p><a href="https://imgchr.com/i/sJBzN9"><img src="https://s3.ax1x.com/2021/01/12/sJBzN9.png" alt="sJBzN9.png"></a></p>
<p><a href="https://imgchr.com/i/sJBH10"><img src="https://s3.ax1x.com/2021/01/12/sJBH10.png" alt="sJBH10.png"></a></p>
<ul>
<li><p>峰值：Robust Threshold（中位数和中位数绝对偏差值）（假设是柯西分布），时间间隔1h，阈值根据经验。</p>
</li>
<li><p>水平漂移：分成两个窗口，检验两个窗口分布是否相似，如果通过T-Test（一种用于测试两组平均差异的推断统计量）发现存在明显差异，则确定发生水平飘移。窗口30分钟，t值根据经验。</p>
</li>
</ul>
<h4 id="离线阶段：依赖清理"><a href="#离线阶段：依赖清理" class="headerlink" title="离线阶段：依赖清理"></a>离线阶段：依赖清理</h4><p>目的：确保KPIs之间相互独立，这样就没有相关性或者过度表示。</p>
<p><strong>相关指数（阈值）</strong>：</p>
<p><a href="https://imgchr.com/i/sJD991"><img src="https://s3.ax1x.com/2021/01/12/sJD991.png" alt="sJD991.png"></a></p>
<blockquote>
<p>例子：CPU（实体和物理机器）</p>
</blockquote>
<h4 id="离线阶段：面向类型的模式集成聚类（Type-Oriented-Pattern-Integration-Clustering，TOPIC）"><a href="#离线阶段：面向类型的模式集成聚类（Type-Oriented-Pattern-Integration-Clustering，TOPIC）" class="headerlink" title="离线阶段：面向类型的模式集成聚类（Type-Oriented Pattern Integration Clustering，TOPIC）"></a>离线阶段：面向类型的模式集成聚类（Type-Oriented Pattern Integration Clustering，TOPIC）</h4><blockquote>
<p>pattern：一个iSQ的封装的KPI特定组合</p>
</blockquote>
<p><a href="https://imgchr.com/i/sJDABD"><img src="https://s3.ax1x.com/2021/01/12/sJDABD.png" alt="sJDABD.png"></a></p>
<p>两个iSQs之间的相似度：<a href="https://imgchr.com/i/sJDC1x"><img src="https://s3.ax1x.com/2021/01/12/sJDC1x.png" alt="sJDC1x.png"></a>t是KPI类型数目，T是总KPI类型数目</p>
<p><a href="https://imgchr.com/i/sJDijK"><img src="https://s3.ax1x.com/2021/01/12/sJDijK.png" alt="sJDijK.png"></a></p>
<p><a href="https://imgchr.com/i/sJDZAH"><img src="https://s3.ax1x.com/2021/01/12/sJDZAH.png" alt="sJDZAH.png"></a></p>
<h4 id="离线阶段：Bayesian-Case-Model-贝叶斯实例模型"><a href="#离线阶段：Bayesian-Case-Model-贝叶斯实例模型" class="headerlink" title="离线阶段：Bayesian Case Model 贝叶斯实例模型"></a>离线阶段：Bayesian Case Model 贝叶斯实例模型</h4><p>作用：从每个聚类中提取有用的和有启发性的信息，为DBAs打标签提供便利</p>
<p>前提：离散化 标签（聚类的结果）</p>
<h4 id="在线阶段：跟因检测和更新"><a href="#在线阶段：跟因检测和更新" class="headerlink" title="在线阶段：跟因检测和更新"></a>在线阶段：跟因检测和更新</h4><p>匹配：相似度最高的一个模式</p>
<p>更新：匹配失败后，交给DBAs处理</p>
<h3 id="评估"><a href="#评估" class="headerlink" title="评估"></a>评估</h3><h4 id="设置"><a href="#设置" class="headerlink" title="设置"></a>设置</h4><p><strong>iSQs数据集</strong> 阿里OLTP数据集（随机的，一个任意一天的数据集 两个 周数据集）（一个实体上的每个时间戳只选一个iSQ）</p>
<p><strong>KPIs数据集</strong> 发生在iSQ前后一小时的数据，粒度5秒</p>
<p><strong>人工标记标记 （DBAs）</strong></p>
<ul>
<li>三个数据集上随机选取319个iSQs标记跟因 </li>
</ul>
<h4 id="评估分数"><a href="#评估分数" class="headerlink" title="评估分数"></a>评估分数</h4><ul>
<li>F1-Score</li>
<li>Weighted Average F1-score</li>
<li>Clustering Accuracy </li>
<li>Normalized Mutual Information （归一化互信息）</li>
</ul>
<h4 id="iSQUAD的准确性和效率"><a href="#iSQUAD的准确性和效率" class="headerlink" title="iSQUAD的准确性和效率"></a>iSQUAD的准确性和效率</h4><blockquote>
<p>设置：对174个iSQs进行聚类，得到10个聚类，对剩下145进行测试</p>
</blockquote>
<p><a href="https://imgchr.com/i/sJDPc6"><img src="https://s3.ax1x.com/2021/01/12/sJDPc6.png" alt="sJDPc6.png"></a></p>
<p><a href="https://imgchr.com/i/sJDknO"><img src="https://s3.ax1x.com/2021/01/12/sJDknO.png" alt="sJDknO.png"></a></p>
<blockquote>
<p>iSQUAD在四个方面优于DBSherlock</p>
<p>1）DBSherlock需要用户自定义或自动生成KPI的异常和正常间隔。其旨在解释异常间隔，而非时间戳</p>
<p>2）DBSherlock根据<strong>平均值</strong>的差异是否超过一个阈值来区分两个部分，iSQUAD具有利用不同波动的异常提取功能</p>
<p>3）DBSherlock不能消除KPIs之间的依赖关系</p>
<p>4）DBSherlock利用因果模型提供纯文本解释不同，忽略了一部分异常类型和模式；iSQUAD使用了贝叶斯实例模型，以向DBAs显示可理解的实例子空间表示。</p>
</blockquote>
<h4 id="异常提取的性能"><a href="#异常提取的性能" class="headerlink" title="异常提取的性能"></a>异常提取的性能</h4><p><a href="https://imgchr.com/i/sJDeNd"><img src="https://s3.ax1x.com/2021/01/12/sJDeNd.png" alt="sJDeNd.png"></a></p>
<blockquote>
<p>时间计算：执行一个iSQ</p>
<p>性能优的原因：包容性和通用性</p>
</blockquote>
<h4 id="依赖清理精度"><a href="#依赖清理精度" class="headerlink" title="依赖清理精度"></a>依赖清理精度</h4><p><a href="https://imgchr.com/i/sJDu9I"><img src="https://s3.ax1x.com/2021/01/12/sJDu9I.png" alt="sJDu9I.png"></a></p>
<h4 id="TOPIC评估"><a href="#TOPIC评估" class="headerlink" title="TOPIC评估"></a>TOPIC评估</h4><p><a href="https://imgchr.com/i/sJD1u8"><img src="https://s3.ax1x.com/2021/01/12/sJD1u8.png" alt="sJD1u8.png"></a></p>
<blockquote>
<p>层次聚类容易产生离群值效应，新模式的iSQ会被归类为离群值，而非新的一类。层次聚类需要预先设定聚类中心的个数。</p>
<p>K-means集群也需要预先限定的集群数量。此外，它高度依赖于初始iSQ模式，因此不稳定。</p>
<p>DBSCAN产生的集群是严重倾斜和分散</p>
</blockquote>
<h4 id="BCM评估"><a href="#BCM评估" class="headerlink" title="BCM评估"></a>BCM评估</h4><p><strong>BCM的影响：</strong>使用了iSQUAD后，减少了DBAs需要考虑的KPIs数量。减少诊断时间，是以前的30倍。</p>
<p><strong>可视化平台：</strong>将贝叶斯实例模型嵌入可视化平台中，该可视化平台可以显示iSQ类的实例子空间表示及其跟因。在DBA选择iSQ类之后，该平台会立即显示相应的KPI，并输出这个iSQ类的根因。</p>
<p><strong>用户研究</strong></p>
<p><a href="https://imgchr.com/i/sJDK3t"><img src="https://s3.ax1x.com/2021/01/12/sJDK3t.png" alt="sJDK3t.png"></a></p>
<h3 id="案例及讨论"><a href="#案例及讨论" class="headerlink" title="案例及讨论"></a>案例及讨论</h3><p><a href="https://imgchr.com/i/sJDMgP"><img src="https://s3.ax1x.com/2021/01/12/sJDMgP.png" alt="sJDMgP.png"></a></p>
<blockquote>
<p>人工：18min</p>
<p>框架：40s</p>
</blockquote>
<p><strong>多跟因</strong>：1）挖掘更深层次的原因 2）多跟因的发生概率很小</p>
<p><strong>iSQUAD的普遍性</strong> 很多场景适用</p>
<p><strong>对不同原因的操作</strong></p>
<p>（1）Scaling(#1，#2，#3，#5，#6)：增大资源</p>
<p>（2）Limiting (#4, #8)：限制速率</p>
<p>（3）Optimizing (#7, #9, #10)</p>
<p><a href="https://imgchr.com/i/sJDQjf"><img src="https://s3.ax1x.com/2021/01/12/sJDQjf.png" alt="sJDQjf.png"></a></p>
<h3 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h3><ul>
<li><p>Slow Query Analysis</p>
<p>自动化索引修改、机器学习算法调优数据库参数、深度学习提升查询</p>
</li>
<li><p>Anomaly Extraction</p>
<p>二分类（即异常、正常）的异常检测方法：</p>
<blockquote>
<p>Opprentice</p>
<p>dSPOT </p>
<p>iSST </p>
<p>雅虎的EGADS</p>
<p>推特的S-H-ESD </p>
<p>Netflix的RPCA</p>
</blockquote>
</li>
<li><p>Clustering Algorithm</p>
</li>
<li><p>Root Cause Diagnosis</p>
</li>
</ul>
<h3 id="未来工作"><a href="#未来工作" class="headerlink" title="未来工作"></a>未来工作</h3><p>作为未来的工作，我们的目标是在iSQUAD的基础上开发一个更通用的、更有能力的框架，自动化故障诊断和系统恢复。</p>
]]></content>
      <categories>
        <category>gs</category>
      </categories>
      <tags>
        <tag>时间序列</tag>
        <tag>根因诊断</tag>
      </tags>
  </entry>
  <entry>
    <title>hgh Adversarial Graph Representation Adaptation for Cross-Domain Facial Expression Recognition</title>
    <url>/2021/01/04/HuGanghui/Adversarial%20Graph%20Representation%20Adaptation%20for%20Cross-Domain%20Facial%20Expression%20Recognition/</url>
    <content><![CDATA[<h2 id="ACM-MM-2020"><a href="#ACM-MM-2020" class="headerlink" title="ACM MM 2020"></a>ACM MM 2020</h2><h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>由于主观的标注过程和不同的采集条件，不同的表情识别数据集之间难免存在数据不一致和偏差。最近的研究求助于学习领域不变特性的对抗机制来减轻领域转移。</p>
<p>这些研究大多侧重于整体特征的适应，而忽略了更容易跨不同数据集转移的局部特征</p>
<p>局部有限元具有更详细、更有辨别力的内容，因此结合局部特征可以实现细粒度的适应</p>
<p>在这项工作中，我们提出了一种新的对抗图表示适应(AGRA)框架，该框架将图表示传播与对抗学习统一起来，用于跨域全局-局部特征的协同适应</p>
<a id="more"></a> 
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><h3 id="数据集的差异"><a href="#数据集的差异" class="headerlink" title="数据集的差异"></a>数据集的差异</h3><ul>
<li>因为人类对面部表情的理解随着他们的经验和生活文化的不同，他们的标注不可避免地是主观的，导致在不同的数据集中明显的领域变化。</li>
<li>不同数据集的人脸图像通常是在不同的环境(如实验室控制或野外)和不同种族的人类中采集的，这进一步扩大了域偏移</li>
</ul>
<h3 id="领域自适应"><a href="#领域自适应" class="headerlink" title="领域自适应"></a>领域自适应</h3><ul>
<li>为了减轻领域漂移，最近的研究引入了对抗学习机制，旨在学习领域不变特征</li>
</ul>
<h3 id="当前研究缺陷"><a href="#当前研究缺陷" class="headerlink" title="当前研究缺陷"></a>当前研究缺陷</h3><ul>
<li><p>侧重于提取整体特征进行域自适应，忽略了从两个方面对跨域FER有利的局部特征</p>
<ul>
<li>局部区域具有更易于跨不同数据集迁移的判别特征。例如，唇角-拉皮动作对快乐表情具有区分性，对不同数据集的样本具有相似性</li>
<li>局部区域对整体特征编码的细节性和互补性更强。对每个域内和不同域内的整体局部特征的相关性进行模化，可以使适应过程更细粒度，从而促进跨域迁移</li>
</ul>
</li>
</ul>
<h3 id="本文工作"><a href="#本文工作" class="headerlink" title="本文工作"></a>本文工作</h3><ul>
<li><p>我们证明了在每个域内以及跨源和目标域的全局局部特征的相关性可以用结构化的图来明确表示，并且它们的相互作用和适应性可以通过图中的自适应信息支持来捕获</p>
</li>
<li><p>开发了一种新的对抗图表示适应(AGRA)框架，该框架将图表示传播与对抗学习机制集成在一起，以实现跨域整体-局部特征的相互作用和协同适应</p>
</li>
<li><p>具体来说，我们首先根据面部地标提取几个有鉴别性的局部区域(如眼睛、鼻子、嘴角等)，并分别构建两个图将整体图像与各个域内以及不同域之间的局部区域进行关联。</p>
<ul>
<li><p>图节点初始化</p>
<ul>
<li>给定一个域的输入图像，提取整体图像和局部区域的特征，初始化该域的相应节点</li>
<li>其他域的节点由相应的每类可学习的统计特征分布初始化</li>
</ul>
</li>
<li><p>图卷积网络</p>
<ul>
<li>我们引入两个堆叠图卷积网络，在每个域内传播节点消息，探索全域与局部特征的交互作用，以及跨两个不同域实现全域与局部特征的协同适应</li>
</ul>
</li>
<li><p>通过这种方法，可以逐步缓解源域和目标域之间整体局部特征的漂移，实现学习判别特征和领域不变特征的学习，便于跨域FER。</p>
<p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/Figure1.png" alt="Figure1"></p>
</li>
<li><p>作图仅使用整体特征进行领域自适应，右图为AGRA框架，能够较好地将来自不同领域、属于同一类别的样本的特征聚集在一起，在提高领域不变特征识别能力的同时，能够较好地学习领域不变特征</p>
</li>
</ul>
</li>
</ul>
<ul>
<li><p>贡献</p>
<ul>
<li>我们提出将图表示传播与对抗学习机制整合在一起，以实现跨不同领域的整体-局部特征协同适应</li>
<li>们开发了一种类感知的两阶段更新机制，迭代地学习每个域的统计特征分布，用于图节点初始化。它在减少领域漂移方面起着关键作用，有助于学习领域不变特征</li>
</ul>
</li>
</ul>
<h2 id="Related-Work"><a href="#Related-Work" class="headerlink" title="Related Work"></a>Related Work</h2><h3 id="本文所提出的框架也与一些工作有关，这些工作使图神经网络适应视觉交互学习和推理这些工作建议以图形的形式明确地建模标签依赖关系，并采用图形来指导特征交互学习。"><a href="#本文所提出的框架也与一些工作有关，这些工作使图神经网络适应视觉交互学习和推理这些工作建议以图形的形式明确地建模标签依赖关系，并采用图形来指导特征交互学习。" class="headerlink" title="本文所提出的框架也与一些工作有关，这些工作使图神经网络适应视觉交互学习和推理这些工作建议以图形的形式明确地建模标签依赖关系，并采用图形来指导特征交互学习。"></a>本文所提出的框架也与一些工作有关，这些工作使图神经网络适应视觉交互学习和推理这些工作建议以图形的形式明确地建模标签依赖关系，并采用图形来指导特征交互学习。</h3><h3 id="受这些工作的启发，我们进一步扩展了图，以建模域内和跨域的全局局部特征交互，从而实现细粒度的特征适应。"><a href="#受这些工作的启发，我们进一步扩展了图，以建模域内和跨域的全局局部特征交互，从而实现细粒度的特征适应。" class="headerlink" title="受这些工作的启发，我们进一步扩展了图，以建模域内和跨域的全局局部特征交互，从而实现细粒度的特征适应。"></a>受这些工作的启发，我们进一步扩展了图，以建模域内和跨域的全局局部特征交互，从而实现细粒度的特征适应。</h3><h2 id="AGRA-FRAMEWORK"><a href="#AGRA-FRAMEWORK" class="headerlink" title="AGRA FRAMEWORK"></a>AGRA FRAMEWORK</h2><h3 id="DANN的基本模型框架"><a href="#DANN的基本模型框架" class="headerlink" title="DANN的基本模型框架"></a>DANN的基本模型框架</h3><p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/image-20210106113921758.png" alt="image-20210106113921758"></p>
<h3 id="AGRA的基本模型框架"><a href="#AGRA的基本模型框架" class="headerlink" title="AGRA的基本模型框架"></a>AGRA的基本模型框架</h3><p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/image-20210106113940321.png" alt="image-20210106113940321"></p>
<ul>
<li>首先构建一个图来关联每个域内的整体和局部区域，以及另一个图来关联不同域内的这些区域。然后，我们学习每个域的分类统计分布，并从输入图像中提取整体-局部特征来初始化对应的图节点</li>
<li>最后，引入了两种堆叠图卷积网络来支撑每个域内的整体-局部特征，以探讨它们之间的相互作用以及跨不同域的整体-局部特征协同适应</li>
<li>一旦两个图被构建，消息传播将通过域内图来探索与每个域的全域-局部耦合，并通过域间图来实现全域-局部特征的协同适应</li>
</ul>
<h3 id="Stack-graph-convolution-networks"><a href="#Stack-graph-convolution-networks" class="headerlink" title="Stack graph convolution networks"></a>Stack graph convolution networks</h3><ul>
<li>我们使用两个堆叠的GCN，其中一个GCN通过域内图传播消息，以探索每个域内的整体-局部特征交互作用，另一个GCN通过域间GCN传输消息，以实现整体-局部特征的协同适应。</li>
<li><p>具体细节</p>
<ul>
<li>首先使用原始源域图像来初始化域内图的每个节点，然后，利用目标域内所有类别簇的特征分布计算这个样本的距离，得到距离最小的簇c。然后，对目标域的每个节点进行特征分布初始化</li>
<li>然后对初始特征进行重新排列，得到特征矩阵</li>
<li>然后,我们对输入特征矩阵进行图卷积运算，迭代地传播和更新节点特征</li>
<li>通过叠加域内图的卷积层，充分挖掘域内图内的节点信息，得到特征矩阵Hintra。</li>
<li><p>然后利用该特征矩阵初始化域间图的节点，并通过图卷积运算迭代更新节点特征</p>
</li>
<li><p>同理，将图的卷积运算按Linter次数进行重复，得到最终的特征矩阵H。我们将源域节点的特征串接为最终特征，输入分类器预测表达式标签和域鉴别器来估计其域</p>
</li>
</ul>
</li>
</ul>
<h2 id="EXPERIMENTS"><a href="#EXPERIMENTS" class="headerlink" title="EXPERIMENTS"></a>EXPERIMENTS</h2><h3 id="baseline对比实验"><a href="#baseline对比实验" class="headerlink" title="baseline对比实验"></a>baseline对比实验</h3><p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/image-20210106113959177.png" alt="image-20210106113959177"></p>
<h3 id="消融实验"><a href="#消融实验" class="headerlink" title="消融实验"></a>消融实验</h3><ul>
<li><p>消融实验：局部特征以及GCN的作用</p>
<p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/image-20210106114024370.png" alt="image-20210106114024370"></p>
</li>
</ul>
<ul>
<li><p>消融实验：域内图、域间图以及双层迭代GCN的作用</p>
<p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/image-20210106114044295.png" alt="image-20210106114044295"></p>
</li>
</ul>
<ul>
<li><p>消融实验：邻接矩阵的不同定义方式</p>
<p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/image-20210106114103032.png" alt="image-20210106114103032"></p>
</li>
</ul>
<ul>
<li>通过手工定义连接，初始化域内图和域间图的两个相邻矩阵，为消息传播的正则化提供了先验指导，换为随机或者全一之后的效果下降。</li>
<li>为了调整邻接矩阵以更好地引导消息传播，在训练过程中还对邻接矩阵进行了联合微调。在这一部分中，我们通过固定先验矩阵训练来验证它的有效性。在表5中展示了结果。平均正确率从66.13%降至56.01%。这表明，联合调整邻接矩阵可以学习数据集指定的矩阵，这对促进跨域FER至关重要。</li>
</ul>
]]></content>
      <categories>
        <category>hgh</category>
      </categories>
      <tags>
        <tag>迁移学习</tag>
      </tags>
  </entry>
  <entry>
    <title>hgh 【ISSRE-2019】Unsupervised Detection of Microservice Trace Anomalies through Service-Level Deep Bayesian Networks</title>
    <url>/2021/03/10/HuGanghui/Unsupervised%20Detection%20of%20Microservice%20Trace%20Anomalies%20through%20Service-Level%20Deep%20Bayesian%20Networks/</url>
    <content><![CDATA[<p>关键词：微服务； 异常检测； 根因分析</p>
<h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><h3 id="本文旨在解决微服务调用跟踪异常"><a href="#本文旨在解决微服务调用跟踪异常" class="headerlink" title="本文旨在解决微服务调用跟踪异常"></a>本文旨在解决微服务调用跟踪异常</h3><ul>
<li><p>挑战</p>
<ul>
<li>底层微服务数量众多</li>
<li>它们之间的调用关系复杂</li>
<li>响应时间和调用路径之间的相互依赖性</li>
</ul>
</li>
<li><p>TraceAnomaly 核心理念</p>
<ul>
<li><p>在定期的离线训练中，使用机器学习来自动学习轨迹的整体正常模式</p>
<ul>
<li>新颖的痕迹表示和设计的深度贝叶斯网络后验流</li>
</ul>
</li>
<li><p>在线异常检测中，一个带有小异常分数(根据学习到的正态模式计算)的新轨迹被认为是异常</p>
</li>
</ul>
</li>
<li><p>效果</p>
<ul>
<li>某公司已在18个在线服务上部署了TraceAnomaly</li>
<li><p>详细评估四大在线服务包含数百个microservices和实验包含41 microservices</p>
<ul>
<li>表明TraceAnomaly的查全率和查准率都高于0.97,优于现有的方法(硬编码规则)19.6%和7.1%</li>
<li>和其他七个基线平均57.0%和41.6%。</li>
</ul>
</li>
</ul>
</li>
</ul>
<a id="more"></a>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><h3 id="具有相同uuid的所有消息构成一个微服务调用跟踪"><a href="#具有相同uuid的所有消息构成一个微服务调用跟踪" class="headerlink" title="具有相同uuid的所有消息构成一个微服务调用跟踪"></a>具有相同uuid的所有消息构成一个微服务调用跟踪</h3><p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/Fig7.png" alt="Figure1"></p>
<h3 id="解决挑战"><a href="#解决挑战" class="headerlink" title="解决挑战"></a>解决挑战</h3><ul>
<li><p>以一种可解释的方式统一跟踪的响应时间和调用路径，用于异常检测</p>
<ul>
<li>由于不同的调用路径会导致不同的响应时间，因此对响应时间的建模需要一定需要考虑调用路径</li>
<li>由于调用的频繁程度，对于每个单个的path的响应时间进行单独的时序异常检测也是不现实的</li>
<li>并且当异常路径被检测到，需要快速的定位到根因，因此需要这种统一表示的方式有一定的可解释性</li>
<li><p>核心思想</p>
<ul>
<li>将每个服务的trace作为一个训练样本，并使用机器学习来捕捉服务跟踪的整体模式。因此，每个服务都有一个模型</li>
<li>将调用路径和响应时间构建成一个向量 STV（service trace verctor），然后交给深度学习算法</li>
<li>通过STV，也可以很轻松的帮助后续的根因的确定</li>
</ul>
</li>
</ul>
</li>
<li><p>设计一个精确的、健壮的、无监督的学习体系结构，以捕获复杂的痕迹模式的特征，并有合理的训练开销</p>
<ul>
<li>正如挑战1中所描述的，微服务的响应时间与它本身和它的调用路径有关。因此需要在它们的调用路径上有条件地学习数百个响应时间分布。</li>
<li>有了这样的复杂性，就需要一个大容量的模型，并且标签难以获得，就必须使用无监督算法</li>
<li><p>符合上述条件的就是深度贝叶斯网络</p>
<ul>
<li>同时希望模型对超参数不敏感。应对这一挑战的核心思想是应用后验流（posterior flow），它可以使用非线性映射来增加贝叶斯网络中潜在变量的复杂性，允许模型以稳健、准确和无监督的方式捕捉复杂模式。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="贡献点"><a href="#贡献点" class="headerlink" title="贡献点"></a>贡献点</h3><ul>
<li><p>提出STV</p>
<p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/Fig7.png" alt="Fig4"></p>
<ul>
<li>相信除了本文提出的算法外，STV还可以作为其他基于ml的跟踪异常检测和定位算法的跟踪表示。</li>
<li>第一种被实际部署应用的基于机器学习的trace异常检测方法</li>
<li>提出一种基于STV根源定位算法，该算法成功地对来自4个大型服务的所有73个异常跟踪进行了正确的根源定位，其定位精度比3个基线的测试结果高出55%。</li>
</ul>
</li>
</ul>
<h2 id="TRACEANOMALY-OVERVIEW-SERVICE-TRACE-VECTOR-CONSTRUCTION-AND-LOCALIZATION-ALGORITHM"><a href="#TRACEANOMALY-OVERVIEW-SERVICE-TRACE-VECTOR-CONSTRUCTION-AND-LOCALIZATION-ALGORITHM" class="headerlink" title="TRACEANOMALY OVERVIEW, SERVICE TRACE VECTOR CONSTRUCTION AND LOCALIZATION ALGORITHM"></a>TRACEANOMALY OVERVIEW, SERVICE TRACE VECTOR CONSTRUCTION AND LOCALIZATION ALGORITHM</h2><h3 id="异常检测"><a href="#异常检测" class="headerlink" title="异常检测"></a>异常检测</h3><p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/Fig7.png" alt="Fig3"></p>
<ul>
<li><p>VAE + Posterior Flow</p>
<p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/Fig7.png" alt="Fig8"></p>
<ul>
<li><p>一个标准化流作用在一个简单分布上，经过 k个可逆的函数变换后得到一个复杂的分布，基于流的生成模型即用 pk(zk)来模拟训练数据的分布</p>
<p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/Fig7.png" alt="Flow"></p>
</li>
<li><p>进而得到训练数据在这个分布下的似然，然后按着最大似然准则对标准流进行优化</p>
</li>
</ul>
</li>
<li><p>使用KDE而不是简单阈值来判断某个样本是否是异常</p>
<ul>
<li>设定p-value的显著性水平为0.001，一个常用的值</li>
</ul>
</li>
</ul>
<h3 id="根因定位"><a href="#根因定位" class="headerlink" title="根因定位"></a>根因定位</h3><p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/Fig7.png" alt="Fig7"></p>
<ul>
<li>3-sigma原则</li>
</ul>
<h2 id="IMPLEMENTATION-AND-DEPLOYMENT"><a href="#IMPLEMENTATION-AND-DEPLOYMENT" class="headerlink" title="IMPLEMENTATION AND DEPLOYMENT"></a>IMPLEMENTATION AND DEPLOYMENT</h2><p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/Fig8.png" alt="Fig9"></p>
<h2 id="Evaluation"><a href="#Evaluation" class="headerlink" title="Evaluation"></a>Evaluation</h2><p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/Fig7.png" alt="Fig8"></p>
<p>TraceAnomaly和Multimodal LSTM无法区分异常类型(响应时间异常或调用路径异常)，因此无法计算响应时间异常和调用路径异常的精度。实际上，异常跟踪通常包含响应时间异常和调用路径异常。它在试验台的区别只是为了评价的目的。</p>
]]></content>
      <categories>
        <category>hgh</category>
      </categories>
      <tags>
        <tag>异常检测</tag>
        <tag>微服务</tag>
        <tag>根因分析</tag>
      </tags>
  </entry>
  <entry>
    <title>hgh 关于时序异常检测-动态基线原型系统的提升点的思考</title>
    <url>/2021/03/04/HuGanghui/%E5%85%B3%E4%BA%8E%E6%97%B6%E5%BA%8F%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B-%E5%8A%A8%E6%80%81%E5%9F%BA%E7%BA%BF%E5%8E%9F%E5%9E%8B%E7%B3%BB%E7%BB%9F%E7%9A%84%E6%8F%90%E5%8D%87%E7%82%B9%E7%9A%84%E6%80%9D%E8%80%83(1)/</url>
    <content><![CDATA[<h2 id="关于时序异常检测-动态基线原型系统的提升点的思考"><a href="#关于时序异常检测-动态基线原型系统的提升点的思考" class="headerlink" title="关于时序异常检测-动态基线原型系统的提升点的思考"></a>关于时序异常检测-动态基线原型系统的提升点的思考</h2><a id="more"></a>
<h3 id="关于动态基线原型系统实时处理的思考"><a href="#关于动态基线原型系统实时处理的思考" class="headerlink" title="关于动态基线原型系统实时处理的思考"></a>关于动态基线原型系统实时处理的思考</h3><p>实时处理的逻辑是来一个点，处理一个点，目前动态基线使用的是STL/EMD分解+3Sigma/四分数来进行异常检测，并且当前的运行逻辑是类似批处理的概念，前端传入一个文件，包含一批数据，然后对这一批数据进行分解+异常检测。</p>
<p>但如果使用改为流处理（实时处理）在异常检测方面的问题都不是很大，因为目前的3Sigma以及四分位数都已经使用上了流式的算法，一个是流式的均值计算，一个是流式的中位数（以及第一、三四分位数的计算）。</p>
<p>因此，主要的关键问题就在于时序分解的实时化处理，当然，目前有一个非常简单的实现方式便是：</p>
<p>当来一个点，结合之前的若干的点，比如1-2千个点，重新进行一下时序分解，来获取当前点的残差项，季节项以及趋势项，然后进行后续的异常检测，这里会存在稍微多一些的重复分解计算的工作。同时，工程上，可以有一个专门的缓存数组，来动态更新需要重复利用的那1-2千个点。</p>
<h3 id="关于动态基线原型系统的判断时序数据是否有周期性的判定算法的调研"><a href="#关于动态基线原型系统的判断时序数据是否有周期性的判定算法的调研" class="headerlink" title="关于动态基线原型系统的判断时序数据是否有周期性的判定算法的调研"></a>关于动态基线原型系统的判断时序数据是否有周期性的判定算法的调研</h3><p>目前的动态基线原型系统是缺少对时序数据是否具有周期性的判定算法的，就不管是否真的具备周期性，都直接给ACF来获取该时序的周期，然后使用时序分解来进行分解。其实应该要有一个判定算法的。</p>
<p>不过说起来，本身航信提供的数据大多都是tps-average之类的有周期性的数据，这么想的话，确实也不完全需要周期性判断算法。</p>
<p><a href="https://zhuanlan.zhihu.com/p/266766105">AIOps在美团的探索与实践——故障发现篇</a>这篇博客里有提到美团关于如何进行时序分类的，详见其中的<strong>3.2 时序数据自动分类</strong>，同时，这里还有提到<strong>3.3 周期型指标异常检测</strong>，使用了类似学徒系统的有监督算法，当然也会有各种各样的问题，因此在<strong>3.3.5 特殊场景优化</strong>有专门的特殊的优化方式。</p>
<h3 id="关于工业界目前前沿落地的其他时序异常检测算法"><a href="#关于工业界目前前沿落地的其他时序异常检测算法" class="headerlink" title="关于工业界目前前沿落地的其他时序异常检测算法"></a>关于工业界目前前沿落地的其他时序异常检测算法</h3><ul>
<li><p>美团</p>
<ul>
<li><a href="https://zhuanlan.zhihu.com/p/266766105">AIOps在美团的探索与实践——故障发现篇</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MjM5NjQ5MTI5OA==&amp;mid=2651749742&amp;idx=1&amp;sn=b6bcf56ab7f11e765bdd4384e462bd0e&amp;chksm=bd12a4238a652d35668eb3b77023244fe17e2fd0759337723653eb3a38bdd0888039a6c5174d&amp;scene=21#wechat_redirect">数据库智能运维探索与实践</a></li>
</ul>
</li>
<li><p>阿里云</p>
<ul>
<li><a href="https://help.aliyun.com/document_detail/93024.html?spm=a2c4g.11186623.6.873.25c5455fvPBuwl">日志服务机器学习功能</a></li>
<li><a href="https://developer.aliyun.com/article/670718">SLS机器学习最佳实战：时序异常检测和报警</a></li>
<li><a href="https://help.aliyun.com/document_detail/172130.html?spm=a2c4g.11186623.2.10.4e9a31e8sflG5L">流式统计算法异常检测</a></li>
<li><a href="https://help.aliyun.com/document_detail/172132.html?spm=a2c4g.11186623.2.10.16365bb9e0ovgD">流式图算法异常检测</a></li>
<li><a href="https://petecheng.github.io">https://petecheng.github.io</a> 一个浙大的同学，时序人公众号的作者，主要做的也是时序异常检测</li>
</ul>
</li>
</ul>
]]></content>
      <categories>
        <category>hgh</category>
      </categories>
      <tags>
        <tag>时间序列</tag>
        <tag>异常检测</tag>
      </tags>
  </entry>
  <entry>
    <title>hgh A时间序列异常检测论文阅读汇总</title>
    <url>/2021/03/04/HuGanghui/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E6%B1%87%E6%80%BB(1)/</url>
    <content><![CDATA[<h2 id="时间序列异常检测论文阅读汇总"><a href="#时间序列异常检测论文阅读汇总" class="headerlink" title="时间序列异常检测论文阅读汇总"></a>时间序列异常检测论文阅读汇总</h2><a id="more"></a>
<h3 id="《Time-Series-Anomaly-Detection-Service-at-Microsoft》SR方法-KDD-2019-微软"><a href="#《Time-Series-Anomaly-Detection-Service-at-Microsoft》SR方法-KDD-2019-微软" class="headerlink" title="《Time-Series Anomaly Detection Service at Microsoft》SR方法 KDD 2019 微软"></a>《Time-Series Anomaly Detection Service at Microsoft》SR方法 KDD 2019 微软</h3><p><a href="/Users/hgh/Downloads/my_file/insis实验室/航信项目/时间序列异常检测项目/异常检测——论文/2019最新的论文/Time-Series Anomaly Detection Service at Microsof.pdf">论文地址</a></p>
<p><a href="https://github.com/microsoft/anomalydetector">开源代码</a></p>
<p>文章中有提到Holt winters以及Spot算法（极值理论）的利弊，称<a href="https://baike.baidu.com/item/Holt-Winters%20方法/24137738?fr=aladdin">Holt winters</a>对非季节性/周期性的时序的效果不好，</p>
<p>Spot则相反，对于季节性/周期性的时序效果不行。言下之意就是SR在三者上的效果都是非常好的，更加通用。</p>
<p>其中设计时序分类，关于<a href="https://baike.baidu.com/item/非平稳序列/10449553">非平稳序列的定义</a></p>
<p>同时文章提到工业界需要的异常检测算法需要满足：无监督、准确、高效、通用。（不过，可能有些企业可以也愿意打标签使用有监督的算法😂，比如美团？）</p>
<p>提到两个无监督算法Luminol [1] and DONUT [23]说问题在于要么需要大量时间要么对参数敏感（不过这个应该指训练吧，如果是训练的话，时间倒还好，但是这里很可能是因为需要部署到海量的时序上，因此训练时间过长也是不可接受的，那这样其实可以看看最新的裴丹团队的异常检测模型迁移的文章-<a href="https://netman.aiops.org/wp-content/uploads/2021/02/paper-INFOCOM21-cfp.pdf"><strong>CTF: Anomaly Detection in High-Dimensional Time Series with Coarse-to-Fine Model Transfer</strong></a>）</p>
<p>这篇文章提到SR+CNN，因为SR处理后的时序的异常就非常明显了，因此相当于给CNN提供了一个伪标签，没有使用任何真实标签，保持了算法的无监督的特点。</p>
<p>在具体实现细节方面，SR提供了比较详细的说明，以及如何应对实时化的改进，应该相当于需要实时的进行FFT（<a href="https://www.zhihu.com/search?type=content&amp;q=快速傅立叶变换">关于FFT相关介绍博客</a>），提到了填充点的操作，可能有参考价值。</p>
<p>对于开源代码方面，在之前论文的基础上，后续又有了一项<a href="https://github.com/microsoft/anomalydetector/tree/master/aml_component">更新</a>，主要是添加了一个有上下界限的模式，然后这个东西好像是为了给Azure Machine Learning designer使用的。<strong>不过之前我们也思考过一个问题就是如何给SR添加上下界限，这个确实值得看看源码的实现。</strong></p>
<h3 id="《RobustSTL-A-Robust-Seasonal-Trend-Decomposition-Algorithm-for-Long-Time-Series》AAAI-2019-阿里达摩院"><a href="#《RobustSTL-A-Robust-Seasonal-Trend-Decomposition-Algorithm-for-Long-Time-Series》AAAI-2019-阿里达摩院" class="headerlink" title="《RobustSTL: A Robust Seasonal-Trend Decomposition Algorithm for Long Time Series》AAAI 2019 阿里达摩院"></a>《RobustSTL: A Robust Seasonal-Trend Decomposition Algorithm for Long Time Series》AAAI 2019 阿里达摩院</h3><p><a href="/Users/hgh/Downloads/my_file/insis实验室/航信项目/时间序列异常检测项目/异常检测——论文/动态基线-阿里达摩院跟进/RobustSTL- A Robust Seasonal-Trend Decomposition Algorithm for Long Time Series.pdf">论文地址</a></p>
<p><a href="https://github.com/LeeDoYup/RobustSTL">非官方复现代码</a></p>
<p>这片文章介绍了一个改进版本的STL算法，不过我发现突然发现，作为异常检测，我只需要将残差项剥离出来即可，不需要周期项和趋势项的分离，因此这个想通了的话，我一直思考的如何进行STL的Online版本也就相对好实现了。不过好像也没有我想的那么简单啦，再看RobustSTL如果后续操作真的都对残差项没影响了，也不太可能。</p>
<p>参考IBM的实时分解算法：<a href="https://community.ibm.com/community/user/cloudpakfordata/viewdocument/real-time-decomposition-of-time-ser?CommunityKey=c0c16ff2-10ef-4b50-ae4c-57d769937235&amp;tab=librarydocuments">Real-Time Decomposition of Time Series</a> </p>
<p><a href="https://community.ibm.com/community/user/cloudpakfordata/viewdocument/detecting-anomalies-in-seasonal-dat?CommunityKey=c0c16ff2-10ef-4b50-ae4c-57d769937235&amp;tab=librarydocuments">Detecting Anomalies in Seasonal Data</a></p>
<p>其实都谈不上实时，真的分解的时候的延时还是很大的</p>
<p>搜索过程中遇到几篇Stream Time Series的论文</p>
<ul>
<li><p><a href="https://arxiv.org/pdf/1911.05376.pdf">Real-Time Anomaly Detection for Advanced Manufacturing:<br>Improving on Twitter’s State of the Art</a> 20年6月的，还比较新</p>
</li>
<li><p><a href="https://milets19.github.io/papers/milets19_paper_6.pdf">Online FDR Controlled Anomaly Detection for Streaming Time<br>Series</a></p>
</li>
<li><p><a href="https://www.mdpi.com/1424-8220/20/8/2344/htm">Automatic Anomaly Detection on In-Production Manufacturing Machines Using Statistical Learning Methods</a></p>
</li>
<li><p><a href="http://cs230.stanford.edu/projects_spring_2020/reports/38856976.pdf">CS230 Project Report Cloud Anomaly Detection</a></p>
</li>
<li><p><a href="https://www.sciencedirect.com/science/article/pii/S0925231217309864">Unsupervised real-time anomaly detection for streaming data</a></p>
</li>
</ul>
]]></content>
      <categories>
        <category>hgh</category>
      </categories>
      <tags>
        <tag>时间序列</tag>
        <tag>异常检测</tag>
      </tags>
  </entry>
  <entry>
    <title>jzh A 3D Convolutional Neural Network for Emotion Recognition based on EEG Signals</title>
    <url>/2021/01/06/JiaoZehui/A%203D%20Convolutional%20Neural%20Network%20for%20Emotion%20Recognition%20based%20on%20EEG%20Signals/</url>
    <content><![CDATA[<h2 id="信息"><a href="#信息" class="headerlink" title="信息"></a>信息</h2><p><strong>期刊: </strong> IJCNN</p>
<p><strong>作者:</strong>  <img src="https://jzh-markdown-pics.oss-cn-beijing.aliyuncs.com/img/image-20201006202616766.png" alt="image-20201006202616766"></p>
<h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>传统的机器学习方法使用手工提取特征和精心设计的分类器，然而提取特征局限于我们的专业领域知识。</p>
<p>我们提出了一种三维卷积神经网络模型来自动提取脑电信号的时空特征，通过预处理信号和对电极拓扑结构的重定位，在DEAP数据集二分类任务上实现了96.61%、96.43%的ACC，四分类上实现了93.53%的ACC，在AMIGOS实现了97.52%、96.96%和95.86%ACC。</p>
<a id="more"></a> 
<h2 id="关键词"><a href="#关键词" class="headerlink" title="关键词"></a>关键词</h2><p><strong>Emotion Recognition, Electroencephalography(EEG), 3D Convolutional Neural Network (3D CNN), Spatiotemporal Features, Deep Learning</strong></p>
<h2 id="介绍及相关工作"><a href="#介绍及相关工作" class="headerlink" title="介绍及相关工作"></a>介绍及相关工作</h2><p>基于生理信号尤其是脑电图信号的识别方法已经成为研究热点，因为与面部表情或语音等其他信号相比，这些信号能够表征人的内在情绪状态，无法进行主观控制。</p>
<p>传统的机器学习方法提取特征主要有</p>
<ol>
<li><strong>时域特征</strong>。事件相关电位ERP，信号统计(功率，均值，标准差，一阶差分，二阶差分)，高阶统计量(HOC)。</li>
<li><strong>频域特征</strong>。功率谱密度(PSD)，高阶谱(HOS)。</li>
<li><strong>时频特征</strong>。希尔伯特黄谱(HHS)，幅度平方相关估计(MSCE)。</li>
</ol>
<p>深度学习方法中，2D卷积常规方法忽略了脑电信号的空间特征，因此提出了时空特征提取方法。</p>
<h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><h3 id="DEAP"><a href="#DEAP" class="headerlink" title="DEAP"></a>DEAP</h3><p>DEAP是一个开放的数据集，供研究人员验证他们的模型。该数据集包含<strong>32个通道的脑电信号和8个通道的其余生理信号</strong>，这些信号是在<strong>32名参与者观看40个视频</strong>(每个视频时长1分钟)时采集的。<strong>每次试验包含63s信号</strong>，<strong>前3s是baseline信号</strong>。当参与者没有受到刺激时，记录baseline信号。看完一分钟的视频后，参与者对<strong>valence、arousal、liking和dominance</strong>自我评估进行评分，评分范围从1到9。</p>
<p>已经提供了预处理版本:数据从512赫兹下采样到128赫兹，并且应用了4.0-45.0赫兹的带通频率滤波器。DEAP的脑电数据大小为32(participants)x40(videos)x32(channels)x8064(signals)，8064信号包含384个baseline信号。</p>
<h3 id="AMIGOS"><a href="#AMIGOS" class="headerlink" title="AMIGOS"></a>AMIGOS</h3><p>AMIGOS 是一个新开放的数据集。该数据集包含<strong>14导脑电信号和3导其余生理信号</strong>，采集于40名参与者观看20个视频(16个短视频 + 4个长视频)。每次试验首先包含5s的baseline信号，其他信号的长度取决于视频的持续时间。观看视频后，参与者还对<strong>valence、arousal、liking和dominance</strong>进行了1到9级的自我评估。</p>
<p>已经提供了预处理版本:数据被下采样到128赫兹，并应用了4.0-45.0赫兹的带通频率滤波器。</p>
<h2 id="研究过程"><a href="#研究过程" class="headerlink" title="研究过程"></a>研究过程</h2><h3 id="预处理"><a href="#预处理" class="headerlink" title="预处理"></a>预处理</h3><p>Yang报告说，在情绪识别任务中，预处理方法可以将识别准确率提高大约32%。</p>
<p>预处理方法包括:</p>
<ol>
<li>从所有<strong>通道C</strong>中提取<strong>baseline信号</strong>，并将其切割成固定长度L的N段，得到N段C×L矩阵</li>
<li>用分段数据计算baseline信号的<strong>均值</strong>，得到baseline信号均值矩阵</li>
<li>去除baseline信号，并且<strong>减去均值</strong>后进行切割，得到预处理后的信号。</li>
<li><img src="https://jzh-markdown-pics.oss-cn-beijing.aliyuncs.com/img/image-20201006205022755.png" alt="image-20201006205022755">因为我们要利用空间位置，所以我们自己做了一个图。把32导转换到9*9的矩阵中去。我们转换的时候使用了标准化。</li>
</ol>
<h3 id="3D卷积结构"><a href="#3D卷积结构" class="headerlink" title="3D卷积结构"></a>3D卷积结构</h3><p><img src="https://jzh-markdown-pics.oss-cn-beijing.aliyuncs.com/img/image-20201006205211100.png" alt="image-20201006205211100"></p>
<p>卷积结构如上，只有两个卷积层，每次卷积层跟着池化。</p>
<p>输入为（9，9，128）。前两维是空间位置图，最后一维是时间采样点的数量，也就是Hz。</p>
<p>卷积核的数量为32和64，大小为（3，3，4），卷积使用零填充，激活函数是relu。</p>
<p>池化层为（1，1，2）。</p>
<p>全连接层后跟着dropout，为0.5。</p>
<p>学习率为0.001。</p>
<p>batchsize为240。</p>
<p>验证方法是十倍交叉验证。</p>
<h2 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h2><h3 id="DEAP数据集结果"><a href="#DEAP数据集结果" class="headerlink" title="DEAP数据集结果"></a>DEAP数据集结果</h3><p>一次实验数据是(32×8064)，把baseline信号(32×384)切割成3段(3×32×128)，因为长3s，得到均值(1×32×128)。</p>
<p>将没有baseline信号的脑电信号分割成60段(60×32×128)，然后减去baseline信号的均值，得到预处理后的信号(60×32×128)。</p>
<p>对于每个时间采样点，将32路脑电信号映射成一个9x9矩阵。最终数据集是(76800×9×9×128)。76800是32个人看40个视频，每个视频1分钟。</p>
<p><img src="https://jzh-markdown-pics.oss-cn-beijing.aliyuncs.com/img/image-20201006211150102.png" alt="image-20201006211150102" style="zoom:50%;" /></p>
<p><img src="https://jzh-markdown-pics.oss-cn-beijing.aliyuncs.com/img/image-20201006211158851.png" alt="image-20201006211158851" style="zoom:50%;" /></p>
<p><img src="https://jzh-markdown-pics.oss-cn-beijing.aliyuncs.com/img/image-20201006211447565.png" alt="image-20201006211447565" style="zoom:50%;" /></p>
<p><img src="https://jzh-markdown-pics.oss-cn-beijing.aliyuncs.com/img/image-20201006211447565.png" style="zoom:50%;" /></p>
<h3 id="AMIGOS数据集结果"><a href="#AMIGOS数据集结果" class="headerlink" title="AMIGOS数据集结果"></a>AMIGOS数据集结果</h3><p>同上，最终有45474个样本。</p>
<p><img src="https://jzh-markdown-pics.oss-cn-beijing.aliyuncs.com/img/image-20201006211247669.png" alt="image-20201006211247669" style="zoom:50%;" /></p>
<p><img src="https://jzh-markdown-pics.oss-cn-beijing.aliyuncs.com/img/image-20201006211310792.png" alt="image-20201006211310792" style="zoom:50%;" /></p>
<h4 id=""><a href="#" class="headerlink" title=""></a><img src="https://jzh-markdown-pics.oss-cn-beijing.aliyuncs.com/img/image-20201006211518043.png" alt="image-20201006211518043"></h4><p><img src="https://jzh-markdown-pics.oss-cn-beijing.aliyuncs.com/img/image-20201006154305924.png" alt="image-20201006154305924"></p>
<h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>本文提出了一种简单有效的基于脑电信号的三维卷积神经网络模型，该模型可用于不同的任务和数据集。</p>
<p>缺点是，相比之下，深度学习方法往往被视为一个黑箱系统，我们将努力改进模型的可解释性，找出情感识别中的重要因素。</p>
]]></content>
      <categories>
        <category>jzh</category>
      </categories>
      <tags>
        <tag>EEG</tag>
        <tag>迁移学习</tag>
      </tags>
  </entry>
  <entry>
    <title>jzh A Hierarchical Bidirectional GRU Model With Attention for EEG-Based Emotion Classification</title>
    <url>/2021/01/06/JiaoZehui/A%20Hierarchical%20Bidirectional%20GRU%20Model%20With%20Attention%20for%20EEG-Based%20Emotion%20Classification/</url>
    <content><![CDATA[<h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>本文提出了一种层次结构双向门控递归单元(GRU)网络，用于从连续的脑电信号中进行情感分类。Attention用于EEG的samples和epochs两个级别上。</p>
<p>我们在DEAP数据集上进行了跨受试者情感分类实验，以评估模型的性能。实验结果表明，在valence和arousal维度上，我们的1-s EEG序列分别比最佳deep baseline LSTM模型好4.2%和4.6%，比最佳shallow baseline模型好11.7%和12%。</p>
<a id="more"></a> 
<h2 id="信息"><a href="#信息" class="headerlink" title="信息"></a>信息</h2><p><strong>期刊: </strong>IEEE ACCESS 2019</p>
<p><strong>作者:</strong>  <img src="https://jzh-markdown-pics.oss-cn-beijing.aliyuncs.com/img/image-20201005212230396.png" alt="image-20201005212230396"></p>
<h2 id="关键词"><a href="#关键词" class="headerlink" title="关键词"></a>关键词</h2><p><strong>Hierarchical, bidirectional GRU, attention, EEG, emotion classification</strong></p>
<h2 id="介绍及相关工作"><a href="#介绍及相关工作" class="headerlink" title="介绍及相关工作"></a>介绍及相关工作</h2><p>由于脑电信号具有高度的时间依赖性、非平稳性和易受噪声干扰等特点，因此很难分辨和提取出脑电信号序列中情感相关性较高的关键时间点或片段。</p>
<p>假设EEG信号是平稳的，则 <strong>Dynamic Statistical Parametric Maps (DSPM), Minimum Norm Estimation<br>(NME), Phase Shift and Vector Modulation </strong> 可以使用。滑动窗口问题在某种程度上解决了数据的非平稳性，但是它的统计效率是很低的。</p>
<p>目前，CNN、RNN和LSTM已逐渐应用于脑电信号的建模，但研究仍处于起步阶段。</p>
<p>这些方法在一定程度上提高了脑电情感分类的性能，但很少有模型考虑到<strong>脑电epoch和sample</strong>对序列情感类别的有不同的重要性。</p>
<p>此外，目前的研究主要集中在依赖受试者的脑电数据的情感分类上，而非<strong>独立于受试者</strong>的脑电数据。我们不打算为每个用户单独训练一个模型，而是通过微调来预测用户的情感状态。</p>
<p>我们提出了一种具有注意机制的分层双向门控递归单元(GRU)网络，称为H-ATT-BGRU。</p>
<h2 id="研究过程"><a href="#研究过程" class="headerlink" title="研究过程"></a>研究过程</h2><h3 id="双向GRU编码器"><a href="#双向GRU编码器" class="headerlink" title="双向GRU编码器"></a>双向GRU编码器</h3><p>GRU模型比标准的LSTM模型更简单、更快。特别是在训练大数据时，与标准LSTM模型相比，性能差异小，可以节省大量时间。对于许多序列建模任务来说，了解未来和过去的序列是有益的。然而，标准GRU网络按时间顺序处理序列，它们忽略了上下文。</p>
<p><img src="https://jzh-markdown-pics.oss-cn-beijing.aliyuncs.com/img/image-20201006140501283.png" alt="image-20201006140501283"></p>
<h3 id="层次的Attention结构"><a href="#层次的Attention结构" class="headerlink" title="层次的Attention结构"></a>层次的Attention结构</h3><p>为了应用好我们的模型，我们把样本分成epoch，每个epoch有多个sample。</p>
<h4 id="sample-encoder"><a href="#sample-encoder" class="headerlink" title="sample encoder"></a>sample encoder</h4><p>我们首先将sample进行编码，使用的是双向GRU。</p>
<h4 id="sample-attention"><a href="#sample-attention" class="headerlink" title="sample attention"></a>sample attention</h4><p><img src="https://jzh-markdown-pics.oss-cn-beijing.aliyuncs.com/img/image-20201006145907433.png" alt="image-20201006145907433"></p>
<script type="math/tex; mode=display">
\begin{aligned} u_{j t} &=\tanh \left(W_{s} h_{j t}+b_{s}\right) \\ \alpha_{j t} &=\frac{\exp \left(u_{j t}^{T} u_{s}\right)}{\sum_{t} \exp \left(u_{j t}^{T} u_{s}\right)} \\ e_{j} &=\sum_{t} \alpha_{j t} h_{j t} \end{aligned}</script><p>$u_{s}$随机初始化，并在过程中进行调整。</p>
<h4 id="epoch-encoder"><a href="#epoch-encoder" class="headerlink" title="epoch encoder"></a>epoch encoder</h4><p><img src="https://jzh-markdown-pics.oss-cn-beijing.aliyuncs.com/img/image-20201006150436115.png" alt="image-20201006150436115"></p>
<h4 id="epoch-decoder"><a href="#epoch-decoder" class="headerlink" title="epoch decoder"></a>epoch decoder</h4><p><img src="https://jzh-markdown-pics.oss-cn-beijing.aliyuncs.com/img/image-20201006150443547.png" alt="image-20201006150443547"></p>
<h4 id="sequence-classification"><a href="#sequence-classification" class="headerlink" title="sequence classification"></a>sequence classification</h4><p>结果输出</p>
<script type="math/tex; mode=display">
p=\operatorname{softmax}\left(W_{c} v+b_{c}\right)</script><p>损失函数</p>
<script type="math/tex; mode=display">
\mathrm{E} \Theta=-\frac{1}{N} \sum_{n=1}^{N} Y_{n} \log \left(\tilde{Y}_{n}\left(X_{n}, \theta\right)\right)+\frac{\lambda}{2}|| \theta||_{2}^{2}</script><h3 id="模型结构"><a href="#模型结构" class="headerlink" title="模型结构"></a>模型结构</h3><p><img src="https://jzh-markdown-pics.oss-cn-beijing.aliyuncs.com/img/image-20201006151353306.png" alt="image-20201006151353306" style="zoom:67%;" /></p>
<h2 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h2><h3 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h3><p>伦敦玛丽皇后大学的研究人员开发了DEAP数据集，这是一个大型的开源数据集，包含多种带有情绪评估的生理信号。该数据集记录了32名受试者在观看40个1分钟的具有不同情绪倾向的音乐视频时的脑电图、心电图、肌电图和其他生物电信号。然后，受试者的情绪用从1到9对看视频的感受进行衡量，包括valence，arousal，liking，dominance，familiarity。评级值从小到大表示各指数由负到正或由弱到强。这40个刺激视频由20个valence/arousal视频和20个valence/arousal视频组成。</p>
<h3 id="数据处理"><a href="#数据处理" class="headerlink" title="数据处理"></a>数据处理</h3><ol>
<li>32导EEG被下采样到128赫兹。使用4-47Hz的带通滤波器来消除噪音。使用盲源分离取均值到参考值，并且去除了EOG伪影。</li>
<li>预处理后的脑电信号总长度为63-s，包括看视频的60-s和看前的3-s。然后，我们从观看视频的60秒脑电图信号(7680次读数)中去除3秒基本信号的平均值，并对跨通道数据进行归一化。</li>
<li>每个受试者数据为 40(trials)×60(epochs)×128 (samples)×32(channels)，大于5的标为1，小于等于5的标为0。</li>
<li>其余划分方式<img src="https://jzh-markdown-pics.oss-cn-beijing.aliyuncs.com/img/image-20201006153106754.png" alt="image-20201006153106754"></li>
</ol>
<h4 id="实验设置"><a href="#实验设置" class="headerlink" title="实验设置"></a>实验设置</h4><p>batchsize为60，学习率为0.05。</p>
<p>数据则选择25%为训练集，GRU隐藏单元个数为64，双向拼接为128。</p>
<h3 id="Baseline"><a href="#Baseline" class="headerlink" title="Baseline"></a>Baseline</h3><h4 id="shallow-baseline"><a href="#shallow-baseline" class="headerlink" title="shallow baseline"></a>shallow baseline</h4><p>我们使用AR和PSD来提取特征值，送入BT和SVM中进行分类。</p>
<h4 id="deep-baseline"><a href="#deep-baseline" class="headerlink" title="deep baseline"></a>deep baseline</h4><p>CNN</p>
<p><img src="https://jzh-markdown-pics.oss-cn-beijing.aliyuncs.com/img/image-20201006153551794.png" alt="image-20201006153551794"></p>
<p>LSTM</p>
<p><img src="https://jzh-markdown-pics.oss-cn-beijing.aliyuncs.com/img/image-20201006153607719.png" alt="image-20201006153607719"></p>
<h3 id="实验效果"><a href="#实验效果" class="headerlink" title="实验效果"></a>实验效果</h3><p><img src="https://jzh-markdown-pics.oss-cn-beijing.aliyuncs.com/img/image-20201006154225760.png" alt="image-20201006154225760"></p>
<p><img src="https://jzh-markdown-pics.oss-cn-beijing.aliyuncs.com/img/image-20201006154247800.png" alt="image-20201006154247800"></p>
<p><img src="https://jzh-markdown-pics.oss-cn-beijing.aliyuncs.com/img/image-20201006154305924.png" alt="image-20201006154305924"></p>
<p><img src="https://jzh-markdown-pics.oss-cn-beijing.aliyuncs.com/img/image-20201006154317371.png" alt="image-20201006154317371"></p>
<h4 id="Attention-权重"><a href="#Attention-权重" class="headerlink" title="Attention 权重"></a>Attention 权重</h4><p><img src="https://jzh-markdown-pics.oss-cn-beijing.aliyuncs.com/img/image-20201006155249282.png" alt="image-20201006155249282"></p>
<h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>本文提出了一种具有注意机制的分层双向GRU模型(H-A TT-BGRU)，用于学习脑电序列特征并对其进行跨受试者情感分类。随着脑电序列epoch长度的增加，我们的模型表现出比其他baseline模型更好的分类性能，表明该模型能够有效降低长期脑电序列非平稳性的影响，提高基于脑电的情感分类的准确性和鲁棒性。该模型将应用于未来开发鲁棒的情感脑机接口的应用。</p>
]]></content>
      <categories>
        <category>jzh</category>
      </categories>
      <tags>
        <tag>EEG</tag>
        <tag>迁移学习</tag>
      </tags>
  </entry>
  <entry>
    <title>jzh 【INFORMATION SCIENCES-2020】Attention guided for partial domain adaptation</title>
    <url>/2021/03/03/JiaoZehui/Attention%20guided%20for%20partial%20domain%20adaptation(1)/</url>
    <content><![CDATA[<p><strong>作者：</strong> Changchun Zhang , Qingjie Zhao </p>
<p>a Beijing Laboratory of Intelligent Information Technology, School of Computer Science, Beijing Institute of Technology, Beijing 100081, China</p>
<h2 id="关键词"><a href="#关键词" class="headerlink" title="关键词"></a>关键词</h2><p><strong>Partial Domain Adaptation</strong> <strong>Attention Mechanism</strong> <strong>Adversarial Networks</strong></p>
<h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>如何有效地从目标域的未标记样本中提取特征表示对于无监督的域自适应是至关重要的，特别是对于部分域自适应，其中源标签空间是目标标签空间的一个超空间，因为它有助于减少由于域偏移或域偏差而导致的较大性能差距。</p>
<p>我们提出了一种基于对抗学习的局部域自适应方法和多自注意网络（MSAN）。与现有的大部分局部域自适应方法只关注高层次特征不同，MSAN主要是利用<strong>标记源数据从未标记目标数据中提取有效的高层次上下文特征和低层次结构特征</strong>。具体地说，我们提出了多重自注意网络，这是一种通过逐步增强特征来学习更细粒度和可转移特征的一般方法，这样可以相对减少域转移，从而提高模型的泛化能力。在Office-31和Office-Home数据集上的综合实验表明，该方法显著改进了表示部分域自适应方法，为各种部分转移任务提供了最新的结果。</p>
<a id="more"></a>
<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>虽然深度神经网络基于其丰富的特征表示能力，极大地提高了各种机器学习问题和应用的性能，但其训练过程在很大程度上依赖于大量的标记样本，为各种应用程序任务手动标注大量此类数据是非常必要，成本往往非常昂贵。</p>
<p>因此，如何有效地降低机器学习中数据标注的巨大成本仍然是一个有待解决的问题。领域自适应方法[]是一种研究得很好的策略，通过传递知识来解决这个问题，它使用一个有标记的训练数据集来改进没有标记信息的测试数据集。然而，这种有前途的领域适应范式在将类别分类器转移到目标任务方面提出了重大挑战.</p>
<p>虽然深度神经网络基于其丰富的特征表示能力，极大地提高了各种机器学习问题应用的性能，但其训练过程在很大程度上依赖于大量的标记样本，所以各种应用程序任务手动注释大量此类数据是非常必要的在现实生活中，成本往往非常昂贵。因此，如何有效地降低机器学习中数据标注的巨大成本仍然是一个有待解决的问题。领域自适应方法[是一种研究得很好的策略，通过传递知识来解决这个问题，它使用一个有标记的训练数据集来改进没有标记信息的测试数据集。然而，这种有前途的领域适应任务在将类别分类器转移到目标任务方面提出了重大挑战。</p>
<p>在统计学习中，大多数现有的域自适应方法通常假设训练和测试样本共享一致的类标签，但是遵循不同的分布，即无监督域自适应，将从源样本训练的分类器应用到目标样本。最近的研究表明，深层神经网络能够解开潜在数据集变化的解释因素，因此学习更多的域不变表示可以极大地提高域自适应的能力。沿着这条路线，这些基于特征的方法遵循的思想是将矩匹配、对抗网络和批量标准化统计嵌入深度模型，以学习领域可转移特征。</p>
<p>尽管这些深域自适应方法通过减少特征分布差异来桥接源域和目标域，但假设不同的两个域共享相同的标签空间。然而，在现实世界的应用中，期望源域与目标域具有相同的类别标签通常是不现实的。<br>因此，本文重点研究了一种更为实际的场景，即源域标签空间包含目标域标签空间，即<strong>部分域自适应</strong>（PDA）。此外，通常假设源域具有足够的多样性和规模，其标签空间包括目标域的标签空间。因此，将源域和目标域的整体匹配方法应用于部分域自适应算法并不是一种有效的方法。</p>
<p>最常见的部分域自适应方法执行特征学习和标签预测，将输入图像域映射到深层特征，然后对异常源类样本降低样本权重，以减少两个不同域之间的差异，最后生成预测的标签，如图1所示。例如，Cao等人提出了部分对抗域适应（PADA）和选择性对抗网络（SAN），另一个相关工作是IWAN方法。三种方法通过在对抗性学习网络中训练的区分两个域的域识别器中对每个样本进行加权来解决部分域自适应问题。另外，最新的工作是ETN方法，它通过进一步揭示可转移量词的鉴别器结构，提高了上述三种方法的权重质量。这些局部域自适应方法只关注<strong>高层次的特征，而忽略了挖掘低层次的特征</strong>来指导深域自适应模型生成细粒度的特征表示。</p>
<p><img src="https://jzh-markdown-pics.oss-cn-beijing.aliyuncs.com/img/image-20210227202256124.png" alt="image-20210227202256124"></p>
<p><img src="https://jzh-markdown-pics.oss-cn-beijing.aliyuncs.com/img/image-20210227203703520.png" alt="image-20210227203703520"></p>
<ul>
<li>提出了一种新的基于注意力引导的局部域自适应神经网络，以渐进的特征增强方式学习细粒度特征，提高模型的泛化能力。</li>
<li>通过报告分类精度和注意后目标类数量变化的分类精度曲线，我们展示了我们的注意机制如何鼓励框架学习更精确的领域可转移表示。</li>
<li>通过对Office-Home和Office-31数据集的大量实验，证明所提出方法的结果超过了现有的最新结果。</li>
</ul>
<h2 id="研究过程"><a href="#研究过程" class="headerlink" title="研究过程"></a>研究过程</h2><h3 id="部分域适应"><a href="#部分域适应" class="headerlink" title="部分域适应"></a>部分域适应</h3><p>尽管标准域自适应技术已经取得了长足的进步，但如何有效地进行部分域自适应仍然是一个理论和实践上的未知数。因为它仍然需要一个普通的假设，即标签空间在源域和目标域中是相同的。在部分域自适应场景中，模型从一个具有丰富标签的大域转移到一个没有标签信息的小目标域，违反了这一假设。根据文献研究，目前已有四篇关于部分领域适应问题的研究进展。</p>
<p>选择性对抗网络使用基于对抗学习的多个域鉴别器，引入加权机制，过滤掉属于离群点标签空间的源数据的相关部分。部分对抗域自适应是选择性对抗网络的一个改进版本，它只采用一个单域鉴别器来实现可转移特征的提取，并进一步引入类权重向量来量化每个源域类别的贡献。这些权重向量直接应用于源样本训练的分类器和源样本上的域鉴别器。重要性加权对抗网（IWAN）基于对抗学习方式，采用两个领域分类器对源实例进行加权，在离群点标签空间中选出源实例。另一个重要的工作是ETN方法，它学习如何适应相关样本，减少离群样本，用于训练标签分类器和域鉴别器。此外，它使用辅助域鉴别器和辅助标记预测来获得一个判别加权方案来量化源样本的可转移性。<strong>上述方法只利用上一卷积层的高层次特征表示，而忽略了低层次的结构特征和细粒度特征信息，这或多或少会降低模型在目标域上的性能</strong>。</p>
<h3 id="自注意力"><a href="#自注意力" class="headerlink" title="自注意力"></a>自注意力</h3><p>最近，自我注意机制在一系列任务中取得了显著进展。研究人员提出了SCA-CNN网络，该网络在CNN图像字幕框架中融合了空间和通道注意。据报道，多层注意网络在图像分割、图像覆盖、图像分类等方面都取得了很好的效果。尽管它在各种计算机视觉和机器学习中取得了成功，但自我注意在领域适应中从未被探索过。我们的工作将非局部自我注意机制嵌入到深度部分域自适应模型中，通过逐步增强特征的方式来学习细粒度特征以提高模型性能的可行性和有效性。</p>
<h3 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h3><p>我们的方法包含一个带有多个自我注意模块的共享特征提取器F、一个域鉴别器D和一个标签分类器G。我们的网络工作框架如图3。首先，自我注意模块能够提高可转移特征表征的能力，抑制不必要的特征表征。第二，提出了一种新的网络，称为多重自注意网络（MSAN），它与基本网络一起强调从低级结构特征到高级上下文特征的意义特征。此外，底层结构特征可以引导以渐进的特征增强方式学习更细粒度的高层上下文特征。</p>
<p><img src="https://jzh-markdown-pics.oss-cn-beijing.aliyuncs.com/img/image-20210303115414985.png" alt="image-20210303115414985"></p>
<h4 id="Multiple-self-attention-networks"><a href="#Multiple-self-attention-networks" class="headerlink" title="Multiple self-attention networks"></a>Multiple self-attention networks</h4><script type="math/tex; mode=display">
m_{j i}=\frac{\exp \left(\mathrm{X} 1_{i} \cdot \mathrm{X} 2_{j}\right)}{\sum_{i=1}^{N} \exp \left(\mathrm{X} 1_{i} \cdot \mathrm{X} 2_{j}\right)}
\\\mathrm{X}_{j}^{\prime}=\mu \sum_{i=1}^{N}\left(m_{j i} \mathrm{X} 3_{i}\right)+\mathrm{X}_{j}</script><p><img src="https://jzh-markdown-pics.oss-cn-beijing.aliyuncs.com/img/1665919-20190424155202293-128757257.png" alt="img" style="zoom: 50%;" /></p>
<h4 id="SAN"><a href="#SAN" class="headerlink" title="SAN"></a>SAN</h4><p><img src="https://jzh-markdown-pics.oss-cn-beijing.aliyuncs.com/img/20190416200902443.png" alt="img"></p>
<p><img src="https://jzh-markdown-pics.oss-cn-beijing.aliyuncs.com/img/20201112115255.png" alt="image-20201112115253734"></p>
<h2 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h2><p><img src="https://jzh-markdown-pics.oss-cn-beijing.aliyuncs.com/img/image-20210303125341967.png" alt="image-20210303125341967"></p>
<p><img src="https://jzh-markdown-pics.oss-cn-beijing.aliyuncs.com/img/image-20210303125427627.png" alt="image-20210303125427627"></p>
<p><img src="https://jzh-markdown-pics.oss-cn-beijing.aliyuncs.com/img/image-20210303125514872.png" alt="image-20210303125514872"></p>
<p>基于ResNet-50的Office-31和Office-Home数据集的部分域适配结果如表1和表2所示。我们还比较了Office-31数据集和VGG-16数据集上的不同方法，结果如表3所示。<br>我们的模型在平均准确率方面优于所有其他方法，表明我们的方法在不同数据集上适用于不同的基网络。具体来说，结果揭示了几个观察结果。</p>
<p>（1） 我们的方法显著提高了域对抗网络的性能，并取得了最新的成果。</p>
<p>（2） 我们的方法还提高了PADA和SAN的（平均）分类精度。由于SAN是一种更先进的方法，导致提升空间相对较小，因此我们对PADA的推广更为明显。这证明了MSAN在训练过程中有效地学习更多领域可转移特征表示的有效性。</p>
<p>（3） 如表1、表2和表3所示，多重自我注意网络成功地减少了两个不同领域的领域偏差。这意味着多个自注意网络能够有效地从底层结构特征和高层上下文特征中提取特征，并与基本网络一起实现部分域自适应任务。</p>
<p>（4）通过基于VGG-16主干的训练，多个自我关注网络提高了Office-31数据集上PADA和SAN的性能。这表明，多个自注意网络也有利于基于不同基础网络的局部域适应任务，是一种通用的方法，可以很容易地插入到任何域适应网络。</p>
<p><img src="https://jzh-markdown-pics.oss-cn-beijing.aliyuncs.com/img/image-20210303125709083.png" alt="image-20210303125709083"></p>
<h2 id="讨论"><a href="#讨论" class="headerlink" title="讨论"></a>讨论</h2><p>在这项工作中，我们研究了如何学习更多的可转移的特征表示，这些特征表示来自高级上下文特征和低级结构特征，用于部分域自适应。以往的研究主要集中在高层次的上下文特征上，我们发现低层次的结构特征可以引导学高层次上下文特征。因此，引入的自我注意部分域自适应方法学习更多的域可转移特征表示，从而减轻由于离群源类引起的负迁移。在Office-31和Office-Home数据集上的综合实验表明，我们的模型能够产生显著的性能增益。</p>
]]></content>
      <categories>
        <category>jzh</category>
      </categories>
      <tags>
        <tag>迁移学习</tag>
      </tags>
  </entry>
  <entry>
    <title>jzh Deep Transfer Learning for Single-Channel Automatic Sleep Staging with Channel Mismatch</title>
    <url>/2021/01/06/JiaoZehui/Deep%20Transfer%20Learning%20for%20Single-Channel%20Automatic%20Sleep%20Staging%20with%20Channel%20Mismatch/</url>
    <content><![CDATA[<h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>​    许多睡眠研究都面临数据不足的问题，无法充分利用深层神经网络，因为不同的实验室使用不同的记录设置，因此需要在相当小的数据库上训练算法，然而，由于通道不匹配，大型的数据库不能直接进行数据补偿。本文提出了一种<strong>深度转移学习方法来克服通道不匹配问题</strong>，并将知识从一个大的数据集转移到一个小的队列中来研究单通道输入下的自动睡眠分期。我们采用最先进的SeqSleepNet并在源域（即大数据集）中训练网络。然后，在目标域（即小群体）中对预训练网络进行微调，完成知识转移。我们研究了源域和目标域之间存在轻微和严重通道不匹配的两种迁移学习场景。我们还研究微调完全或部分预训练的网络是否会影响目标域上睡眠分段的性能。<br>​    本研究以蒙特利尔睡眠研究档案馆（MASS）的200名受试者为源域，以20名受试者组成的Sleep-EDF扩展数据库作为目标域，我们的实验结果表明，所提出的深度转移学习方法在睡眠分期方面有显著的改善。此外，这些结果也揭示了微调预训练网络的特征学习部分以绕过信道失配问题的必要性。</p>
<a id="more"></a> 
<h2 id="文献信息"><a href="#文献信息" class="headerlink" title="文献信息"></a>文献信息</h2><p><strong>会议：</strong> 2019 27th European Signal Processing Conference (EUSIPCO)</p>
<p><strong>作者：</strong> </p>
<p>Huy Phan , Oliver Y. Chen, Philipp Koch, Alfred Mertins, and Maarten De Vos </p>
<p><em>University of Kent, United Kingdom</em></p>
<p><em>University of Oxford, United Kingdom</em></p>
<h2 id="关键词"><a href="#关键词" class="headerlink" title="关键词"></a>关键词</h2><p><strong>Automatic sleep staging, deep learning, transfer learning, SeqSleepNet</strong></p>
<h2 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a>背景介绍</h2><h3 id="深度学习的缺陷"><a href="#深度学习的缺陷" class="headerlink" title="深度学习的缺陷"></a>深度学习的缺陷</h3><p>深度学习已经成功地应用于许多领域，并受到睡眠研究界的广泛关注。深度学习具有自动表示学习理解大数据集的能力，显著提高了自动睡眠分期的性能，准确率达到睡眠专家手动评分的水平。</p>
<p>然而，这种专家水平的表现只有在研究群体规模较大时才能获得，即数百到数千名受试者。原因是深层神经网络通常需要大量的数据来训练。在实践中，许多睡眠研究都有一个小群体，比如几十个研究对象，有时甚至更少，尤其是那些与睡眠障碍相关的研究或探索新的通道位置。</p>
<p>当不同的研究使用不同的通道布局或可能探索新的电极放置时，会出现通道失配问题。此外，当研究调查一种特殊的睡眠异常时，这种情况也会发生，当模型只在健康志愿者身上进行训练时，可能会获得较差的表现。</p>
<h3 id="我们的工作"><a href="#我们的工作" class="headerlink" title="我们的工作"></a>我们的工作</h3><p>我们提出了一种转移学习的方法来解决信道失配问题，使得从一个大数据库中有效地转移知识，从而在更小的数据集中利用深度神经网络来研究单通道睡眠分期。</p>
<p>本研究以蒙特利尔睡眠研究档案馆（MASS）数据库为源域，以20名受试者为目标域的Sleep-EDF扩展数据库。SeqSleepNet是一种序列到序列的模型，它被用作基本模型。</p>
<p>首先用源域数据训练网络，然后用目标域数据对网络进行微调。研究了两种情况：（1）源域为EEG信道，目标域为另一个EEG信道时，信道轻微不匹配的同态转移学习；（2）源域为EEG信道，目标域为EOG信道时，信道严重不匹配的跨模态转移学习。此外，我们研究了不同的微调策略，以深入了解不同通道失配条件下的深度转移学习。</p>
<h3 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h3><p>本研究以MASS为源域。这个数据集包括200名年龄在18至76岁之间的受试者的整晚记录（97名男性和103名女性）。睡眠专家根据AASM标准（SS1和SS3子集）或R&amp;K标准（SS2、SS4和SS5子集）对记录的每个时期进行手动注释。</p>
<p>我们转化为W,N1,N2,N3,REM。将20秒的epoch扩展为30秒的epoch。我们采用C4-A1脑电通道（C4-A1）作为源域数据。最初采样频率为256Hz的信号被降采样至100Hz。</p>
<p><img src="https://jzh-markdown-pics.oss-cn-beijing.aliyuncs.com/img/c5aebd1a996439c636198b015fde00b4c739f487.png@1320w_460h.webp" alt="img"></p>
<p>我们采用SLEEP-EDF数据集中的（SC）子集作为目标域。它由20名年龄在25-34岁之间的受试者组成。采样频率为100Hz，每个受试者都可以获得随后两个白天和夜晚的PSG记录，只有一个受试者（受试者13）是一个晚上的数据。睡眠专家根据R&amp;K标准对每30秒的记录进行手动标记，分为八类{W，N1，N2，N3，N4，REM，MOVEMENT，UNKNOWN}。与之前的工作相似，N3和N4级合并为单个N3级。排除运动和未知类别。在同一通道和跨通道转移学习实验中，我们研究了Fpz-Cz-EEG通道和EOG通道。根据以前论文的建议，只包括了录音的床上部分（从熄灯时间到开灯时间）。</p>
<h2 id="本文方法"><a href="#本文方法" class="headerlink" title="本文方法"></a>本文方法</h2><h3 id="模型结构"><a href="#模型结构" class="headerlink" title="模型结构"></a>模型结构</h3><p><img src="https://jzh-markdown-pics.oss-cn-beijing.aliyuncs.com/img/image-20201211114218708.png" alt="image-20201211114218708"></p>
<h3 id="图卷积"><a href="#图卷积" class="headerlink" title="图卷积"></a>图卷积</h3><script type="math/tex; mode=display">
\mathbf{Z}=\hat{\mathbf{D}}^{-\frac{1}{2}} \hat{\mathbf{A}} \hat{\mathbf{D}}^{-\frac{1}{2}} \mathbf{X}^{T} \mathbf{W}</script><h3 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h3><script type="math/tex; mode=display">
\begin{aligned} \mathcal{L}\left(\mathcal{X}_{S}, \mathcal{Y}_{S}, \mathcal{X}_{T}\right) &=\mathcal{L}_{C}\left(\mathcal{X}_{S}, \mathcal{Y}_{S}\right)+\lambda \mathcal{L}_{D A}\left(\mathcal{X}_{S}, \mathcal{X}_{T}\right) +\gamma \mathcal{L}_{C A}\left(\mathcal{X}_{S}, \mathcal{Y}_{S}, \mathcal{X}_{T}\right)+\eta \mathcal{L}_{T} \end{aligned}</script><p>​    Xs和Xt是源域和目标域提取的特征是由以下过程得到，X为CNN提取的样本特征，我们认为这是图信号，即图中每个节点的特征。图的邻接矩阵由DSA网络提取Xsc，然后乘以其转置矩阵得到邻接矩阵A。这样我们就有了A和X，可以进行图卷积。</p>
<script type="math/tex; mode=display">
\mathbf{X}=C N N\left(\mathbf{X}_{b a t c h}\right)
\\\mathbf{X_{sc}}=D S A\left(\mathbf{X}_{b a t c h}\right)
\\\hat{\mathbf{A}}=\mathbf{X}_{s c} \mathbf{X}_{s c}^{T}</script><h4 id="分类损失"><a href="#分类损失" class="headerlink" title="分类损失"></a>分类损失</h4><p>​        交叉熵损失</p>
<script type="math/tex; mode=display">
\mathcal{L}_{C}\left(\mathcal{X}_{S}, \mathcal{Y}_{S}\right)=\mathbb{E}_{(x, y) \sim D_{S}}[J(f(x), y)]</script><h4 id="域对齐损失"><a href="#域对齐损失" class="headerlink" title="域对齐损失"></a>域对齐损失</h4><script type="math/tex; mode=display">
\begin{aligned} \mathcal{L}_{D A}\left(\mathcal{X}_{S}, \mathcal{X}_{T}\right) &=\mathbb{E}_{x \in D_{S}}[\log (1-D(G(x)))] +\mathbb{E}_{x \in D_{T}}[\log (D(G(x)))] \end{aligned}</script><h4 id="structure-aware-对齐损失"><a href="#structure-aware-对齐损失" class="headerlink" title="structure-aware 对齐损失"></a>structure-aware 对齐损失</h4><p>​        利用triplet loss来约束DSA结构。</p>
<script type="math/tex; mode=display">
\mathcal{L}_{T}=\max \left(\left\|\mathbf{X}_{s c_{a}}-\mathbf{X}_{s c_{p}}\right\|^{2}-\left\|\mathbf{X}_{s c_{a}}-\mathbf{X}_{s c_{n}}\right\|^{2}+\alpha_{T}, 0\right)</script><p>​        由于CNN的源特征和目标特征在训练初期具有区域区分性，同时构造图可能会影响网络训练的稳定性。因此，源图和目标图被单独构造并输入到参数共享的gcn中以学习表示。</p>
<h4 id="类质心对齐损失"><a href="#类质心对齐损失" class="headerlink" title="类质心对齐损失"></a>类质心对齐损失</h4><script type="math/tex; mode=display">
\mathcal{L}_{C A}\left(\mathcal{X}_{S}, \mathcal{Y}_{S}, \mathcal{X}_{T}, \mathcal{Y}_{T}\right)=\sum_{k=1}^{K} \phi\left(\mathcal{C}_{S}^{k}, \mathcal{C}_{T}^{k}\right)</script><p>​        距离度量函数选择的是欧氏距离。</p>
<h2 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h2><h3 id="数据集-1"><a href="#数据集-1" class="headerlink" title="数据集"></a>数据集</h3><p><strong>Office-31</strong> 来自三个不同域的31个类中的4110个图像，三个域分别是亚马逊A、网络摄像头W和单反相机D。</p>
<p><strong>ImageCrep-DA</strong> 是ImageCrep 2014域适应挑战赛的基准数据集，它包含以下三个公共数据集12个常见类别。每个数据集被视为一个域：Caltrch-256（C）、ImageNet ILSVRC 2012（I）和Pascal VOC 2012（P）。每个类别有50个图像，每个域有600个图像。</p>
<p><strong>Office Home</strong> 包含4个域，每个域有65个类别，都是日常用品。具体而言，Art（Ar）是对象图像的艺术描绘，Clipart（Cl）表示剪贴画的图片集合，Product（Pr）显示背景清晰的物品图像。</p>
<h3 id="实验设置"><a href="#实验设置" class="headerlink" title="实验设置"></a>实验设置</h3><p>我们使用0.9动量的随机梯度下降，学习速率按µp=µ0*(1+α·p)^β退火，其中µ0=0.01，α=10，β=0.75。我们将微调层的学习速率设置为学习率的0.1倍。<br>我们将每个域的batchs size设置为128。域对抗性系数损失0.1。</p>
<h3 id="Office-31"><a href="#Office-31" class="headerlink" title="Office-31"></a>Office-31</h3><p><img src="https://jzh-markdown-pics.oss-cn-beijing.aliyuncs.com/img/image-20201207221738570.png" alt="image-20201207221738570"></p>
<h3 id="ImageCLEF-DA"><a href="#ImageCLEF-DA" class="headerlink" title="ImageCLEF-DA"></a>ImageCLEF-DA</h3><p><img src="https://jzh-markdown-pics.oss-cn-beijing.aliyuncs.com/img/image-20201207221838366.png" alt="image-20201207221838366"></p>
<h3 id="Office-home"><a href="#Office-home" class="headerlink" title="Office-home"></a>Office-home</h3><p><img src="https://jzh-markdown-pics.oss-cn-beijing.aliyuncs.com/img/image-20201207221903561.png" alt="image-20201207221903561"></p>
<h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>在本文中，我们提出了一种新的方法，在统一的深层网络中联合使用数据结构、域标签和类标签信息，以实现无监督域自适应。</p>
<p>为了实现源域和目标域分布的鲁棒匹配，我们设计了三种有效的对齐机制，包括结构感知对齐、域对齐和类质心对齐。</p>
<p>这三种对齐机制可以相互增强和互补，以学习目标任务的领域不变性和区分性表示。在标准域自适应数据集上的实验验证了该模型的有效性。</p>
]]></content>
      <categories>
        <category>jzh</category>
      </categories>
      <tags>
        <tag>EEG</tag>
        <tag>迁移学习</tag>
      </tags>
  </entry>
  <entry>
    <title>jzh Emotion Recognition using Multimodal Residual LSTM Network</title>
    <url>/2021/01/06/JiaoZehui/Emotion%20Recognition%20using%20Multimodal%20Residual%20LSTM%20Network/</url>
    <content><![CDATA[<h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>使用脑电图(EEG)和其他生理信号的传统LSTM网络捕获时间信息的方法对<strong>多模态情绪识别</strong>非常有用。然而，使用更深的LSTM网络的多模态和深层次时间特征学习之间的依赖性仍有待研究。</p>
<p>我们提出了一种用于情感识别的多模态残差LSTM网络。MMResLSTM网络共享每个LSTM层中模态的权重，以学习脑电图和其他生理信号之间的相关性。</p>
<p>使用公开可用的DEAP数据集进行评估。实验结果表明，该网络的arousal分类准确率为92.87%，valence为92.30%</p>
<a id="more"></a> 
<h2 id="信息"><a href="#信息" class="headerlink" title="信息"></a>信息</h2><p><strong>会议: </strong>ACM International Conference on Multimedia </p>
<p><strong>作者:</strong>  <img src="https://jzh-markdown-pics.oss-cn-beijing.aliyuncs.com/img/image-20201004104931374.png" alt="image-20201004104931374"></p>
<h2 id="关键词"><a href="#关键词" class="headerlink" title="关键词"></a>关键词</h2><p><strong>Multimodal emotion recognition; long-short-term memory network; electroencephalography</strong></p>
<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>受深度神经网络在许多识别分类任务中的巨大成功的启发，已经提出了几种深度学习架构来改善脑电图(EEG)信号和其他生理信号的多模态情感分类的效果，包括<strong>自编码器、卷积神经网络(CNN)和递归神经网络(RNN)</strong></p>
<p>各种研究表明，因为考虑时间信息，RNN时间特征提取模块的效果较好。然而，多模态之间的<strong>时间相关性信息</strong>，以及使用更深层次的神经网络的<strong>深层时间特征学习</strong>，还有待研究。</p>
<p>尽管不同设备从不同位置收集<strong>多种模态</strong>的信号有不同的反射延迟，但是它们却共同反映了相同情绪在随时间变化。因此多模态的信息还是很重要的。</p>
<p>随着残差学习的使用和神经元层的归一化，DNN可以更高效地收敛，从而优化训练的时间成本。类似于残差学习，我们假设具有<strong>残差连接的深层神经网络</strong>可以学习更复杂的高级情感识别特征，因此优于其他神经网络架构。</p>
<h2 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h2><p>我们有六种常用的情绪识别数据集：DEAP (2012), MAHNOB-HCI (2012), SEED (2015), HR-EEG4EMO (2017), DREAMER (2018), SEED-IV(2019)。</p>
<p>在典型的时间序列信号中，常规的脑电信号特征包括<strong>时域、频域和时频域特征</strong>，可以使用SVM、MLP、经验模式分解等方法提取特征。深度学习出现后，端到端的方式更为常用，即利用网络自动提取特征。</p>
<p>虽然DEAP数据集有四个情感标签:arousal, valence, dominance, liking，但并不是所有的标签都用于相关研究。大多数关于DEAP数据集的研究已经将情绪识别问题视为两个独立的二分类任务。</p>
<p>在新的研究中，情绪识别已经使用各种模态，如面部表情，声音，脑电图，瞳孔直径(EEG)，眼电描记术(EOG) 。</p>
<h2 id="研究过程"><a href="#研究过程" class="headerlink" title="研究过程"></a>研究过程</h2><h3 id="多模态LSTM"><a href="#多模态LSTM" class="headerlink" title="多模态LSTM"></a>多模态LSTM</h3><p>传统上，为了使用脑电图和其他生理信号实现多模态情感识别，多模态架构或者为不同的模态<strong>建立并行的LSTM</strong>，或者直接<strong>拼接多模态数据</strong>以产生更大的输入。</p>
<p>第一种方法包含用于不同模态的并行LSTM，对于训练是更有效的，因为每个LSTM具有相似属性的输入；它也更易于解释，因为来自不同模态的信息是分开存储的。然而，这种体系结构没有为多模态之间的相关性学习做准备，因为各模态之间是完全独立的。</p>
<p>第二种方法尽管网络可以自由地同时访问多个模态的信息，但是交叉的模态相关性并没有被明确地学习。在LSTM，模态内关系和模态间关系没有区别。同时，这种方法更容易过拟合。</p>
<p>下图为多模态LSTM：</p>
<p><img src="https://jzh-markdown-pics.oss-cn-beijing.aliyuncs.com/img/image-20201004152911263.png" alt="image-20201004152911263"></p>
<p>$W<em>{h *}$ 是共享的，因为它更能学到时域的特性。通过$W</em>{h *}$ ，多模态LSTM可以在学习过程中起到交互的作用。time steps也被共享。</p>
<h3 id="残差网络"><a href="#残差网络" class="headerlink" title="残差网络"></a>残差网络</h3><h3 id="层归一化"><a href="#层归一化" class="headerlink" title="层归一化"></a>层归一化</h3><p>层归一化是通过归一化神经元的活动来减少深层神经元的训练时间。这对于RNNs中的隐藏态是有效的。</p>
<script type="math/tex; mode=display">
\begin{aligned} \mu_{t} &=\frac{1}{H} \sum_{i=1}^{H}\left(h_{t}\right)_{i} \\ \delta_{t} &=\sqrt{\frac{1}{H} \sum_{i=1}^{H}\left(\left(h_{t}\right)_{i}-\mu_{t}\right)^{2}} \\ y_{t} &=f\left(\frac{g}{\delta_{t}} \odot\left(h_{t}-\mu_{t}\right)+b\right) \end{aligned}</script><p>LN中这组参数叫做增益（gain） <img src="https://www.zhihu.com/equation?tex=g" alt="[公式]"> 和偏置（bias） <img src="https://www.zhihu.com/equation?tex=b" alt="[公式]"> ，是可以学习的。</p>
<p><img src="https://jzh-markdown-pics.oss-cn-beijing.aliyuncs.com/img/v2-c039daa05cd9d5c3936c4513422690b0_1440w.jpg" alt="img"></p>
<p>图1为LN，图二是BN。</p>
<h3 id="模型结构"><a href="#模型结构" class="headerlink" title="模型结构"></a>模型结构</h3><p><img src="https://jzh-markdown-pics.oss-cn-beijing.aliyuncs.com/img/image-20201004161602843.png" alt="image-20201004161602843" style="zoom:50%;" /></p>
<h2 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h2><h3 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h3><p>我们使用DEAP数据集评估了模型的性能。DEAP数据集包含EEG和周边生理信号(PPS)，其中包括EOG和EMG数据。在这个数据集中，32名受试者观看了40个刺激情绪的视频片段。每个视频都是一分钟长。</p>
<p>我们的模型是为了每个受试者单独训练和测试的，因此使我们的方法依赖于受试者。</p>
<ol>
<li>根据我们对以往任务的研究的回顾，缺乏独立于受试者的研究。依赖受试者的方法能够进行更多的比较。</li>
<li>独立于受试者的方法可能会引起个人隐私问题，因为它需要收集私人脑电图数据和建立一个大型情绪数据库。</li>
</ol>
<h3 id="数据处理"><a href="#数据处理" class="headerlink" title="数据处理"></a>数据处理</h3><ol>
<li>原始脑电信号和PPS被下采样到128赫兹。对于脑电信号，去除了EOG伪影。</li>
<li>使用4.0-45.0Hz的带通频率滤波器。</li>
<li>EEG信号被平均到公共参考。</li>
</ol>
<h3 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h3><p><img src="https://jzh-markdown-pics.oss-cn-beijing.aliyuncs.com/img/image-20201004163128402.png" alt="image-20201004163128402"></p>
<p><img src="https://jzh-markdown-pics.oss-cn-beijing.aliyuncs.com/img/image-20201004165251317.png" alt="image-20201004165251317"></p>
<p>图为LSTM和残差LSTM以及多模态的LSTM对比。<img src="https://jzh-markdown-pics.oss-cn-beijing.aliyuncs.com/img/image-20201004165314035.png" alt="image-20201004165314035"></p>
<p>图为LSTM对于每个个体的表现。</p>
<p><img src="https://jzh-markdown-pics.oss-cn-beijing.aliyuncs.com/img/image-20201004165338427.png" alt="image-20201004165338427"></p>
<p>图为MM-ResLSTM和其他方法的对比。</p>
<h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>在本研究中，我们提出了多模态深度LSTM网络，通过残差学习和权值共享来增强效果。该网络以端到端的方式运行，以隐含地提取高级时间特征。在DEAP数据集上的实验表明，所提出的方法分别以92.87%和92.30%的准确率对arousal和valence进行分类，从而优于现有的方法。</p>
]]></content>
      <categories>
        <category>jzh</category>
      </categories>
      <tags>
        <tag>EEG</tag>
      </tags>
  </entry>
  <entry>
    <title>jzh mproving EEG-Based Emotion Classification Using Conditional Transfer Learning</title>
    <url>/2021/01/06/JiaoZehui/Improving%20EEG-Based%20Emotion%20Classification%20Using%20Conditional%20Transfer%20Learning/</url>
    <content><![CDATA[<h1 id="Improving-EEG-Based-Emotion-Classification-Using-Conditional-Transfer-Learning"><a href="#Improving-EEG-Based-Emotion-Classification-Using-Conditional-Transfer-Learning" class="headerlink" title="Improving EEG-Based Emotion Classification Using Conditional Transfer Learning"></a>Improving EEG-Based Emotion Classification Using Conditional Transfer Learning</h1><p>[TOC]</p>
<h2 id="信息"><a href="#信息" class="headerlink" title="信息"></a>信息</h2><p><strong>期刊：</strong> Frontiers in Human Neuroscience, 2017</p>
<p><strong>作者：</strong> Yuan-Pin Lin, National Sun Yat-sen University; Tzyy-Ping Jung, University of California, San Diego</p>
<h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>近年来，迁移学习在脑电信号挖掘领域受到越来越多的关注。然而，盲目的迁移学习也会导致负迁移现象。</p>
<p>本研究提出了一个条件迁移(cTL)框架，以促进每个个体的正迁移。通过对26的个体进行实验，相比仅仅利用自身的数据，在valence分类上提升了15%，在arousal分类上提升了26%。</p>
<p>简单来讲，cTL设置了一个阈值，如果准确率不高，则可以考虑迁移学习(利用其他相似个体的数据)，否则没必要进行迁移学习。</p>
<a id="more"></a> 
<h2 id="关键词"><a href="#关键词" class="headerlink" title="关键词"></a>关键词</h2><p><strong>EEG，emotion，transfer learning，classification</strong></p>
<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p><strong>现状：</strong> 为个体开发一个适应的模型效果应该是比较好的，但是因为缺乏数据，已经成为一个瓶颈问题。</p>
<ul>
<li><p>一个直接的方案是基于受试者群体的数据开发一个独立于受试者的分类模型，而不是为每个个体构建一个依赖于受试者的模型。如果个体之间的类分布在某种程度上是相似的，那应该有不错的效果。但是实际情况往往不满足这些情况，所以广义的分类器有时无法取得优秀的结果。</p>
<blockquote>
<p>Zhu J , Zheng W , Lu B . Cross-subject and Cross-gender Emotion Classification from EEG[J]. 2015.</p>
</blockquote>
</li>
<li><p>另一个方案允许个体选择性地使模型适应来自其他受试者的数据或信息，从而可以在某种程度上减轻个体差异的影响。</p>
<blockquote>
<p>TCA: Zheng W L , Zhang Y Q , Zhu J Y , et al. Transfer components between subjects for EEG-based emotion recognition[C]// International Conference on Affective Computing &amp; Intelligent Interaction. IEEE, 2015.</p>
<p>KPCA: Zheng W L, Lu B L. Personalizing EEG-based affective models with transfer learning[C]//Proceedings of the Twenty-Fifth International Joint Conference on Artificial Intelligence. 2016: 2732-2738.</p>
<p>TPT: Sangineto E, Zen G, Ricci E, et al. We are not all equal: Personalizing models for facial expression analysis with transductive parameter transfer[C]//Proceedings of the 22nd ACM international conference on Multimedia. 2014: 357-366.</p>
</blockquote>
</li>
</ul>
<h2 id="研究过程"><a href="#研究过程" class="headerlink" title="研究过程"></a>研究过程</h2><h3 id="假设-通过实验验证"><a href="#假设-通过实验验证" class="headerlink" title="假设(通过实验验证)"></a>假设(通过实验验证)</h3><ol>
<li>本研究假设TL框架可以显著改善那些参与度低的受试者的分类器。</li>
<li>本研究进一步假设由TL获得的分类性能的提高应该与目标域和源域中包含的受试者的相似程度正相关。</li>
</ol>
<h3 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h3><p>Oscar soundtrack EEG dataset ，数据集由从26名健康受试者收集的30通道脑电图信号组成。音乐使用了16个30s音乐节选，并试图按照二维valence-arousal情绪模型归纳出四种情绪类别。</p>
<p>本文中因为类别分类不平衡，将四分类问题改为两个二分类问题。</p>
<h3 id="处理EEG信号"><a href="#处理EEG信号" class="headerlink" title="处理EEG信号"></a>处理EEG信号</h3><ol>
<li>通过短时傅里叶变换+50%覆盖的汉明窗，通过1-50Hz的巴特沃斯滤波器获得了五个频带。</li>
<li>通过DLAT对12导的五个频带进行处理，生成了60维特征，然后除以前5s的平均能量值，使用gain<br>model-based calibration method，使用z-transformed对特征进行归一化。</li>
<li>使用ReliefF方法对特征空间进行选择，没有选择DLAT的全部空间。</li>
<li>使用高斯朴素贝叶斯分类器进行分类。</li>
</ol>
<h3 id="迁移学习"><a href="#迁移学习" class="headerlink" title="迁移学习"></a>迁移学习</h3><p><strong>领域 (Domain)</strong>: 是进行学习的主体。领域主要由两部分构成： 数据和生成这些数据的概率分布。通常我们用花体 D 来表示一个 domain，用大写斜体 P 来表示一个概率分布。</p>
<p>特别地，因为涉及到迁移，所以对应于两个基本的领域： <strong>源领域 (Source Domain) 和目标领域 (Target Domain)</strong>。源领域就是有知识、有大量数据标注的领域，是我们要迁移的对象；目标领域就是我们最终要赋予知识、赋予标注的对象。知识从源领域传递到目标领域，就完成了迁移 。</p>
<h3 id="条件迁移学习框架"><a href="#条件迁移学习框架" class="headerlink" title="条件迁移学习框架"></a>条件迁移学习框架</h3><p><strong>when：</strong> 当由他们自己的数据训练，仅实现低于chance-level的准确性(即两类分类问题中的50%)。</p>
<p><strong>how：</strong> 本研究基于其ReliefF排序的情感相关特征空间来表征主体间的相似性。相似性被定义为皮尔逊相关系数的值。即相关系数值越大，受试者越相似。</p>
<p><strong>what：</strong> 本研究将所选样本集和相似样本集的数据连接在一起，开发一个更一般化但信息量更大的特征空间。</p>
<p><img src="https://jzh-markdown-pics.oss-cn-beijing.aliyuncs.com/img/image-20200929164105930.png" alt="image-20200929164105930"></p>
<p>​    <strong>条件迁移学习框架前提：</strong> 数据集共26人，25人看成源领域，1人看作目标领域。每个人数据由16次实验组成，实验中采用LTO方法，即每次利用15次实验数据去预测另一次实验的数据。</p>
<ol>
<li>计算源域和目标域的相似性，便于后续利用。</li>
<li>选择O个最相似的人，和当前受试者的15次实验组成新的数据集，即O*16 + 15。</li>
<li>为了在分类器建模过程中消除类别不平衡问题的影响，该步骤在500次重复的训练中随机选择类别平衡样本，试图产生最优但公平的训练模型。每次重复应用5倍交叉验证并且添加一个特征，即一次添加一个具有高ReliefF分数的特征。</li>
<li>使用朴素高斯贝叶斯分类器进行重新分类。</li>
</ol>
<h2 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h2><p><img src="https://jzh-markdown-pics.oss-cn-beijing.aliyuncs.com/img/image-20200929165903471.png" alt="image-20200929165903471"></p>
<p>图2：纵轴为acc，横轴为目标域index。左边是valence，右边是arousal，灰色线是50%acc，也就是瞎蒙的水平。蓝色代表自身预测就比较好的，红色代表自身预测比较差的，数字代表第几位受试者。</p>
<p><img src="https://jzh-markdown-pics.oss-cn-beijing.aliyuncs.com/img/image-20200929170235650.png" alt="image-20200929170235650"></p>
<p>图3：横轴是添加源域的人数，也就是说使用迁移学习方法，我们决定引入源域多少人(1-25)。纵轴是效果，有提升也有下降。第一行是valence，第二行是arousal。第一列是添加的相似人数，第二列是添加的不相似人数。红色线代表原始数据效果不好使用迁移学习的变化，蓝色线代表原始数据效果好的使用迁移学习变化。灰色线是目标域所有的数据使用迁移学习后的结果。三角代表得出的最高点或者最低点。</p>
<p>首先可以看出，本身效果就不错的实验，添加了其他人的数据，结果都会变差。这也证明了条件迁移的必要性。同时，添加相似的数据效果是比添加不相似的效果更好，但是二者最终趋于统一。</p>
<p><img src="https://jzh-markdown-pics.oss-cn-beijing.aliyuncs.com/img/image-20200929171453556.png" alt="image-20200929171453556"></p>
<p>图4：该图是通过上图的添加人数得出的新结果，valence为18人，arousal为12人。横轴为不相似性，即离得越远越不相似。纵轴为acc的变化率。灰色直线为线性回归线，三角形和原形均表示正迁移，叉号和加号均表示负迁移。红色代表添加相关数据，蓝色代表添加不相关数据。图中数字为受试者编号。第一列为原本结果优秀的人，第二列为原本结果比较差的人。</p>
<p>从图中可以看到，蓝色普遍靠右，很容易理解，因为不相似性肯定更大。同时右侧结果普遍提升比较大，也证明了迁移学习对原本效果比较差的有较大提升。</p>
<p><img src="https://jzh-markdown-pics.oss-cn-beijing.aliyuncs.com/img/image-20200929172435547.png" alt="image-20200929172435547"></p>
<p>图5：图为4种方法的对比，default即最原始的方法，rTL则是将所有的数据都进行迁移学习，cTL则是当结果低于50%的时候进行迁移学习，oTL比较鸡贼，先迁移学习，如果发生了正迁移则采用，否则不适用迁移学习。<em>和*</em>是两个实验的假设检验。</p>
<h2 id="讨论"><a href="#讨论" class="headerlink" title="讨论"></a>讨论</h2><h3 id="正迁移的时机"><a href="#正迁移的时机" class="headerlink" title="正迁移的时机"></a>正迁移的时机</h3><p>因此，本研究的动机是提出有条件的迁移学习，假设迁移学习将使结果表现较低的受试者受益，而不是那些表现相对较好的受试者。本研究直观地采用了高于或低于机会水平(即50%)的默认标准来推断是否进行迁移。</p>
<h3 id="正迁移的相似性数据和不相似性数据"><a href="#正迁移的相似性数据和不相似性数据" class="headerlink" title="正迁移的相似性数据和不相似性数据"></a>正迁移的相似性数据和不相似性数据</h3><p>迁移学习的分类模型通过利用5-10个相似受试者获得了立即的改进，但是将所有可用的受试者集合在一起并不能绝对保证在使用相似或不相似源域受试者的情况下最大程度地提高性能。</p>
<p>这项研究将这一问题设为将来单独的研究，通过添加更多的受试者数据寻找规律。</p>
]]></content>
      <categories>
        <category>jzh</category>
      </categories>
      <tags>
        <tag>EEG</tag>
        <tag>迁移学习</tag>
      </tags>
  </entry>
  <entry>
    <title>jzh 【AAAI2021】Plug-and-Play Domain Adaptation for Cross-Subject EEG-based Emotion Recognition</title>
    <url>/2021/04/06/JiaoZehui/Plug-and-Play%20Domain%20Adaptation%20for%20Cross-Subject%20EEG-based%20Emotion%20Recognition(1)/</url>
    <content><![CDATA[<p>关键词：迁移学习；EEG</p>
<h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>由于脑电信号的跨受试者的变异性，情感脑机接口面对人类情感解码时受到了很大的阻碍。现有的方法通常需要收集每一个新对象的大量脑电数据，耗时很大而且用户体验糟糕。为了解决这个问题，我们将脑电表示分为特定于<strong>每个受试者的私人成分和对所有受试者都通用的共同情感成分</strong>。根据这一表示部分，我们提出了一种即插即用域自适应方法来处理受试者的可变性。</p>
<p>在训练阶段，由一个<strong>共享编码器</strong>和一个<strong>私有编码器</strong>分别捕获对象不变的情感表征和源对象的私有成分。在此基础上，我们构建了一个基于<strong>共享部分的情感分类器</strong>，并结合这两个部分构建了<strong>受试者分类器</strong>。在校准阶段，该模型只需要少量来自目标受试者的未标记脑电数据来对其私有成分进行建模。因此，除了共享情感分类器外，我们还有另一条管道通过私有成分的相似性来使用源域的知识。在测试阶段，我们将共享情感分类器的预测结果与通过相似性权重调制后的个体分类器的预测结果相结合。在SEED数据集上的实验结果表明，该模型在保持识别准确率的同时，大大缩短了校准时间，使情感解码更具普遍性和实用性。</p>
<a id="more"></a>
<p><strong>作者：</strong> <strong>Li-Ming Zhao,</strong> <strong>Xu Yan,</strong>  <strong>Bao-Liang Lu</strong></p>
<p>Department of Computer Science and Engineering, Shanghai Jiao Tong University, Shanghai, China, 200240</p>
<p>Department of Linguistics, University of Washington, Seattle, WA, USA, 98195</p>
<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>新兴的情感计算旨在检测、记录、处理和回应人们的情感状态。它在日常生活中的许多应用领域都有着广阔的前景，从医疗、智能教育和娱乐等特定场景到脑-机接口（BCIs）等一般情感敏感系统，其中情感识别是首要步骤和里程碑。近年来，基于脑电信号的情感识别以其信息的充分性引起了研究者的极大兴趣。然而，由于受试者之间的<strong>结构和功能变异性</strong>，如精神状态、电极阻抗、头部形状等，EEG数据高度依赖于受试者。图1说明了情绪EEG数据的受试者间变异性，这给构建实用的基于脑电信号的情感模型带来了很大的挑战。这阻碍了情感计算的大规模发展和应用。</p>
<p><img src="https://jzh-markdown-pics.oss-cn-beijing.aliyuncs.com/img/image-20210311101228568.png" alt="image-20210311101228568"></p>
<p>上述阻碍促使许多研究者开发了实用的情感识别算法。<strong>传统的方法</strong>是从新受试者中采集大量数据，对其进行标记，并在测试阶段前使用它们定制分类器参数。不幸的是，这种需求耗时，导致用户体验差，这使得模型的实用性降低。另一种方法是使用<strong>迁移学习方法</strong>来处理个体差异。根据目标域的数据是否用于模型训练阶段，将迁移学习大致分为域适应（DA）和域通用化（DG）。在情感识别的实际应用中，由于使用了所有目标数据，DA效率低下，DG不依赖目标对象的任何信息，因此可能会受到其泛化能力的影响。</p>
<p>与DA和DG的极端相反，在实时识别开始之前引入短期校准阶段是可以接受的，也是必要的。图1主观地展示了算法性能和用户体验之间的权衡困境。然而，现有的研究表明，如果训练数据的数量比特征向量的维数小，模型很可能会崩溃。因此，用有限的目标训练数据来获得良好的DA结果是一个挑战。</p>
<p>针对上述问题，我们提出了一种<strong>即插即用的域自适应方法</strong>，该方法可以在不牺牲识别准确率的前提下，利用少量未标记的目标数据进行校正。我们假设将脑电表示分为对所有子对象具有<strong>普遍性的共享情感成分</strong>和对每个受试者具有<strong>特定性的私有成分</strong>。我们使用LSTM和损失函数来分离私有成分，并在此过程中产生对情感识别更有意义的表征。然而，我们相信，只用共享情感空间中的单一分类器对于从未见过的新受试者仍然具有有限的能力。因此，我们还为现有的源域建立了一系列独立的分类标准，目的是为新的受试者提供参考。通过重构少量的校准数据，我们可以快速构建新的被试的私有编码器，同时训练出共享的编码器和解码器。因此，目标主体可以通过私有成分的相似性从源个体分类器中借用知识，并与共享分类器一起加强情感预测。脑电传感器建立后，私有成分是引起个体间变异的主要原因，在一个集合内保持不变，这是缩短校准时间的关键。此外，我们希望利用注意机制自动学习与情绪识别最相关的关键脑电通道和频带。</p>
<h2 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h2><p>迁移学习的出现引起了广泛的关注，并迅速成为解决脑机接口受试者间差异的重要方法。</p>
<p>迁移学习有两个主要的分支可以帮助减少主题不变性。一种是领域适应（DA）。DA方法通过最小化源域和目标域之间的域偏移来提高目标数据的准确性，这表明在训练阶段，我们必须从目标域获取数据。</p>
<ul>
<li>TPT</li>
<li>DANNs</li>
<li>DSN</li>
</ul>
<p>无论数据如何实现知识迁移，所有的方法都需要所有的目标信息，这适用于离线数据集的转移，但在实时BCI应用中是无法达到的。</p>
<p>这种隐含的不足促使研究者转向域泛化（DG）寻求帮助。DG方法可以通过利用多个源对象的域差异来提取域不变特征，而无需从目标对象获取任何数据。</p>
<ul>
<li>DICA</li>
<li>SCA</li>
<li>DResNet</li>
</ul>
<p>虽然DG方法似乎更可能贴合实际，但仍有一些问题值得思考。DG方法对目标数据无需求的限制是否最适合实时应用方案？虽然长期校准会导致用户体验差，但通过短期校准仍然可以收集很少的目标数据，以快速适应目标主体。</p>
<ul>
<li>STM</li>
</ul>
<p>Li et al.（2019）利用样式转换映射（STM）方法，在支持少量标记目标数据的情况下减少域差异。他们在三种情绪识别任务的校准阶段使用了三组总共10分钟左右的标记脑电数据。Li等人已经取得了很好的效果，但是10分钟的校准时间在实际应用中仍然很长。此外，STM要求标记数据覆盖所有类别，这意味着随着情感类别的扩展，校准时间将进一步增加。</p>
<p>影响脑电域适应时间的一个关键点是脑电信号含有过多的信息。我们的大脑在情绪方面表现出偏侧化，一些区域和频带比其他具有不同情绪的区域和频带更能提供信息。也已经证实了神经信号与不同情绪之间存在相关性。此外，在情绪识别任务中，有人还根据训练好的深层信念网络所赋予的权重来分配关键通道和频带。相比之下attention机制为解决这一问题提供了新的可能性。</p>
<h2 id="研究过程"><a href="#研究过程" class="headerlink" title="研究过程"></a>研究过程</h2><h3 id="综述"><a href="#综述" class="headerlink" title="综述"></a>综述</h3><p>我们提出了一种新的即插即用域适配（PPDA）方法。PPDA的框架如图2所示。整个结构可分为<strong>训练阶段、校准阶段和测试阶段</strong>。</p>
<ul>
<li>训练阶段，首先采用基于注意池的方法来利用脑电信号关键通道和频带的空间信息。然后，采用基于长-短记忆的编解码方案来提取特征。我们提出了一个<strong>共享编码器</strong>Es和<strong>n个私有编码器</strong>Ep，分别捕获受试者不变的情感表征和私有成分。通过使用编码器的输出，我们进一步构建了一个<strong>共享分类器</strong>Cs和<strong>n个分类器</strong>Cp来同时识别情感。在这个阶段，只采用<strong>有标签源数据</strong>来训练模型。</li>
<li>在校准阶段，我们使用新受试者的起始数据，借助经过训练的Es和解码器Ds对新对象的<strong>私有部分编码器</strong>进行建模，我们称之为校准阶段。</li>
<li>在测试阶段，我们不仅可以像领域泛化方法那样使用共享分类器的流水线，还可以通过与私有源组件的相似度从私有分类器中获取知识。最后采用分类器融合策略对两种识别结果进行融合。</li>
</ul>
<p><img src="https://jzh-markdown-pics.oss-cn-beijing.aliyuncs.com/img/image-20210311103426076.png" alt="image-20210311103426076" style="zoom:200%;" /></p>
<h3 id="自注意力"><a href="#自注意力" class="headerlink" title="自注意力"></a>自注意力</h3><script type="math/tex; mode=display">
\alpha_{t}=\operatorname{softmax}\left(W_{a} x_{t}+b_{a}\right)\\\widetilde{x}_{t}=\alpha_{t} \cdot x_{t}</script><p>我们尝试引入注意机制，让模型自动探索情绪识别的关键通道和波段。</p>
<h3 id="LSTM编码"><a href="#LSTM编码" class="headerlink" title="LSTM编码"></a>LSTM编码</h3><p>我们设计了两种编码器分别提取脑电信号的共享情感成分和私有成分。这两个组件串联之后，一个共享解码器被应用于重构输入特征。</p>
<p><img src="https://jzh-markdown-pics.oss-cn-beijing.aliyuncs.com/img/image-20210311111320712.png" alt="image-20210311111320712" style="zoom:50%;" /></p>
<h3 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h3><script type="math/tex; mode=display">
\mathcal{L}=\mathcal{L}_{\mathrm{c}_{-} \mathrm{s}}+\alpha \mathcal{L}_{\mathrm{c}_{-} \mathrm{p}}+\beta \mathcal{L}_{\mathrm{recon}}+\gamma \mathcal{L}_{\mathrm{difference}}+\delta \mathcal{L}_{\mathrm{similarity}}</script><script type="math/tex; mode=display">
\mathcal{L}_{\mathrm{recon}}=\frac{1}{k}\left\|\tilde{X}-\widetilde{X}^{\prime}\right\|_{2}^{2}</script><script type="math/tex; mode=display">
\mathcal{L}_{\text {difference }}=\frac{1}{n} \sum_{j=1}^{n}\left\|\mathbf{H}_{s}^{j}{ }^{\top} \mathbf{H}_{p}^{j}\right\|_{F}^{2}</script><script type="math/tex; mode=display">
\mathcal{L}_{\text {similarity }}=\sum_{i} d_{i} \log \left(\hat{d}_{i}\right)</script><h3 id="校准和测试"><a href="#校准和测试" class="headerlink" title="校准和测试"></a>校准和测试</h3><p>由于脑电图数据是按时间顺序记录的，所以我们只能从一开始就把数据作为校准数据。<br>首先对专用target编码器Etp的参数进行随机初始化，并利用校准数据，利用损失函数对其进行<strong>重构</strong>损失和<strong>difference</strong>的优化。我们认为，一旦任务完成，共享编码器Es就足够广义，并能够提取出主题不变的情感成分，Ds将很好地用于数据重建。</p>
<p>在测试阶段，一旦收集到一个目标序列xt，我们就同时从每个源域中随机选择长度相同的数据，我们的模型的性能由两条管道保证。像大多数领域泛化方法一样，使用经过训练的共享分类器来保证泛化能力为。对于另一个管道，我们计算源域和测试数据之间的余弦相似度ws以利用私有信息。权重越高，表示分布与目标数据越相似，因此对相应分类器的信任度越高。然后，我们通过权重向量和Cp1∼n的结果向量的点积得到预测y。最终结果是在这两个标签通过分类器融合策略整合后确定的。</p>
<h2 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h2><h3 id="数据集和实验设置"><a href="#数据集和实验设置" class="headerlink" title="数据集和实验设置"></a>数据集和实验设置</h3><p>我们在SEED上验证了我们的PPDA模型的性能，SEED是一个用于情感识别的公共情感EEG数据集。本研究选取了15个经过严格筛选的中国电影片段，在快乐、悲伤和中性三种情绪中提取出期望的目标情绪。15名受试者（8名女性，平均23.27，标准差2.37）在不同的时间参加了三次实验。在实验过程中，受试者被鼓励沉浸在视频中以激发相应的情绪。利用ESI神经扫描系统，利用国际10-20系统，在电影观看过程中记录了62个通道的脑电信号。预处理的数据被下采样到200 Hz，并用0-75 Hz的带通进行滤波。在不重叠的1秒时间窗口内，从5个频带（即δ：1-3Hz，θ：4-7Hz，α：8-13 Hz，β：14-30 Hz，γ：31-50 Hz）的频率。因此，在一个实验中，总共有3394个样本，每个受试者有310个特征，用62个通道乘以5个波段计算。</p>
<p>为了与最新的结果进行比较，我们的评估细节保持一致。具体来说，每个受试者只进行一次实验，就可以用LOSO来研究跨受试者效果。在每次迭代中，我们选择一个主题作为目标域，另外14个主题作为现有的源域。<br>需要注意的是，尽管我们在校准阶段没有使用标记的emotion数据，但SEED中的所有3394个样本点都被标记。因此，在校准阶段，将第一个T秒数据作为校准数据。</p>
<p>LSTM的层数、隐藏大小和时间步长分别固定为2、64和15。情感分类器和领域分类器都是单元为64的单层全连通网络。校准时间T设置为45s。</p>
<h3 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h3><p><img src="https://jzh-markdown-pics.oss-cn-beijing.aliyuncs.com/img/image-20210311113915167.png" alt="image-20210311113915167" style="zoom:50%;" /></p>
<p><img src="https://jzh-markdown-pics.oss-cn-beijing.aliyuncs.com/img/image-20210311113957392.png" alt="image-20210311113957392"></p>
<p>一旦添加了校准过程，模型的性能将如预期的那样显著提高，这强调了校准的重要性。一般来说，模型的性能会随着校准时间的延长而提高。然而，随着校准时间的延长，我们并没有看到显著的增长。这种差异主要是由于脑电信号的独特性质，正如我们在一开始所讨论的。实际上，脑电图数据对外部因素（如电极阻抗和头部形状）以及内部变量（如精神状态）非常敏感。尽管很容易受到影响，但在一次实验中，由于这些因素在一定时期内是相对稳定的，因此其构成基本保持不变。换言之，我们可以在几乎没有校准数据的情况下很好地对目标主体的私有组件进行建模，并使用它来提高整体性能。由于只有很少的数据提供了我们所需要的足够的信息，模型的性能不会随着校准数据的增加而提高。</p>
<h3 id="LSTM"><a href="#LSTM" class="headerlink" title="LSTM"></a>LSTM</h3><p><img src="https://jzh-markdown-pics.oss-cn-beijing.aliyuncs.com/img/image-20210311114308563.png" alt="image-20210311114308563" style="zoom:50%;" /></p>
<p>为了证明该结构正常工作，我们从每个受试者中随机抽取50个脑电图样本，通过散点图（如图5（a）所示）用t-SNE对其进行可视化。图5（b）展示了共享编码器和私有编码器的输出。</p>
<h3 id="注意力"><a href="#注意力" class="headerlink" title="注意力"></a>注意力</h3><p><img src="https://jzh-markdown-pics.oss-cn-beijing.aliyuncs.com/img/image-20210311114541755.png" alt="image-20210311114541755" style="zoom:50%;" /></p>
<p><img src="https://jzh-markdown-pics.oss-cn-beijing.aliyuncs.com/img/image-20210311114525114.png" alt="image-20210311114525114" style="zoom:50%;" /></p>
<p>如图所示。在图中，很明显，β和γ波段比其他三个波段活跃得多。此外，颜色深度的分布甚至揭示了用它来识别情感的可行性。例如，在β波段，当快乐情绪被激发时，蓝色会更深。在中性和悲伤的感觉中，伽玛带也是如此。在图6（b）中，我们绘制了反映关键通道分布的地形脑电图图。大脑区域越暗，这个区域的通道就越重要。外侧颞叶FT7、FT8、T7和T8通道密集触发。我们的发现与现有的基于EEG的情绪识别关键波段和通道的观察结果一致。</p>
<h2 id="讨论"><a href="#讨论" class="headerlink" title="讨论"></a>讨论</h2><p>本文设计了一种基于脑电的跨受试者情绪识别即插即用域自适应方法自动识别，旨在让每个人都能在保持识别准确性的同时，无需等待即可立即使用。它在一分钟内成功地缩短了校准时间，准确率超过86.7%，与最先进的域自适应性能相当。这种技术可以用来增强用户体验，使基于EEG的情感计算应用更加实用。此外，注意机制所覆盖的通道和频带为可穿戴式脑电设备和实时情绪识别的发展提供了线索。我们未来的工作将集中在各种实际环境下的实时测试，以观察其实用性。</p>
]]></content>
      <categories>
        <category>jzh</category>
      </categories>
      <tags>
        <tag>EEG</tag>
        <tag>迁移学习</tag>
      </tags>
  </entry>
  <entry>
    <title>jzh【IEEE2021】SparseDGCNN:Recognizing emotion from Multichannel EEG Signals</title>
    <url>/2021/04/06/JiaoZehui/SparseDGCNN%20Recognizing%20Emotion%20from%20Multichannel%20EEG%20Signals(1)/</url>
    <content><![CDATA[<p>关键词：图神经网络；EEG</p>
<h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>基于脑电信号的情感识别在情感计算中受到了广泛的关注。近年来，提出了一种新的动态图卷积神经网络（DGCNN）模型，该模型同时优化了网络参数和表征脑电记录设备中每对电极之间函数关系强度的加权图G。本文提出了一种<strong>稀疏的DGCNN模型</strong>，该模型通过对G进行稀疏约束来修正DGCNN，提高了情感识别的性能。我们的工作基于一个<strong>重要的观察</strong>：断层扫描研究表明，脑电图电极采集的不同脑区可能与大脑的不同功能有关，电极之间的功能关系可能是<strong>高度局部化和稀疏的</strong>。然而，在图G中引入稀疏性约束，使得稀疏DGCNN的损失函数在某些奇点处不可微。为了保证稀疏DGCNN的训练过程收敛，我们采用了前向后向切分的方法。为了评价稀疏DGCNN的性能，我们将其与四种有代表性的识别方法（SVM、DBN、GELM和DGCNN）进行了比较。除了比较不同的识别方法外，我们的实验还比较了不同的特征和谱带，包括从四个有代表性的脑电数据集（SEED、DEAP、DREAMER和CMEED）中提取的时频域脑电特征（DE、PSD、DASM、RASM、ASM和DCAU）。<br>结果表明：</p>
<ul>
<li>稀疏DGCNN的识别准确率始终优于典型方法，且具有良好的可扩展性；</li>
<li>γ波段的DE、PSD和ASM特征表达了最具区分性的情感信息，分离特征和频带的融合可以提高识别性能。</li>
</ul>
<a id="more"></a>
<h2 id="信息"><a href="#信息" class="headerlink" title="信息"></a>信息</h2><p><strong>期刊：</strong> IEEE TRANSACTIONS ON AFFECTIVE COMPUTING 2021</p>
<p><strong>作者：</strong>Guanhua Zhang, Minjing Yu, Yong-Jin Liu<em>,</em> Guozhen Zhao, Dan Zhang, Wenming Zheng</p>
<p>清华大学、天津大学、东南大学、中科院心理所</p>
<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>运动是一种与特定生理活动模式相关的人类体验，它可以通过一种灵活的适应机制来表征。从行为或生理信号中识别人类的情感状态在情感计算和人机交互中起着重要的作用。与行为信号（如面部表情、声调、手势和身体姿势）相比，生理信号是自发的，很难隐藏，因此为情感识别提供了一种直接而全面的手段。</p>
<p>人体产生各种生理信号，包括<strong>脑电活动（脑电图或EEG）、心率变化（心电图或ECG）、肌电流（肌电图或EMG）、呼吸频率（capno gram）、皮肤电导和皮肤电反应等</strong>。近年来，随着新型无线耳机（如Emotiv）的普及，以及便携、经济、易用、实用性强、物理限制小等特点，脑电信号在各种生理信号中备受关注</p>
<p>为了训练和评估一个基于脑电信号的情感识别系统，需要具有真值标签的数据集。在这些数据集中，为了正确标记脑电图信号，标准化的情绪刺激（例如视觉或听觉刺激）被用来激发目标情绪。一些早期的数据集包括英语单词和文本的情感规范[8]、国际情感数字化语音系统[9]、国际情感图片系统[10]和日内瓦情感图片数据库[11]。最近提出的数据集扩展了传统的材料（如文字、文本、图片和声音），将视觉和听觉刺激结合起来，通常采用电影剪辑或音乐视频的形式[3]、[12]、[13]。与静态照片和幻灯片相比，这些组合刺激的存在可以更好地捕捉现实生活中的情感体验[14]。在本文中，我们选取了四个有代表性的公开数据集，即<strong>DEAP[4]、SEED[15]、DREAMER[16]和CMEED</strong>[3]、[17]、[18]，来评估我们提出的情绪识别方法：在所有这些数据集中，通过从观看标准化的音乐视频或电影片段中激发目标情绪来收集和标记脑电信号。</p>
<p>两种不同的模型可以用来描述脑电数据中的情绪：<strong>离散模型和多维模型</strong>。</p>
<ul>
<li>离散模型将情感空间表示为有限数量的基本情感。例如，Ekman[19]提出了六种普遍的情绪（喜悦、悲伤、惊讶、恐惧、愤怒和厌恶），Plutchik[20]提出了八种离散的情绪，增加了两种（好奇和接受）。</li>
<li>作为一个二维或三维空间，例如，三个维度valence, arousal and dominance被广泛使用。valence是指内在的吸引力/优点（正valence）或厌恶/缺点（负valence）。arousal 反映了一个人情绪的心理警觉水平和生理活动的强度。dominance地位是指一个人的状态，即控制或被控制。现在，最常用的模型是Circumplex Model of Affect，它只使用了valence, arousal[6]，[21]</li>
</ul>
<h2 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h2><p>脑电信号的情感识别依赖于鉴别脑电特征。脑电信号是离散时间序列，存在与认知过程密切相关的<strong>空间、频谱和时间脑电特征</strong>[22]。在时间域，一些广泛应用的<strong>统计信息</strong>，如倾向性、分形维数和高阶交叉等，可以作为脑电特征[23]、[24]。在频域中，EEG信号被分解成<strong>几个频率范围</strong>，每个频率范围在某些脑活动中都是突出的，例如δ带（1-3Hz）、θ带（4-7Hz）、α带（8-13Hz）、β带（14-30Hz）和γ带（&gt;30Hz）[25]。从每个频带中，可以提取一些广泛应用的特征，包括功率谱密度（PSD）特征、差分熵（DE）特征、差分因果性（DCAU）、不对称性（ASM）、差分不对称性（DASM）和有理不对称性（RASM）等特征[2]、[4]、[15]、[26]。<strong>与时域特征相比，基于频率的特征更适合于情感识别。</strong>一些神经科学研究表明，情绪相关的神经信息主要存在于较高的频带[27]、[28]、[29]，但时域特征使用所有频带的信息。</p>
<p>脑电图是通过头皮上的电极测量大脑电场，它通常有足够的密度（&gt;30个电极）来绘制地形图。<br>到目前为止，研究不同脑电通道/电极之间关系的功能特征在文献中很少被考虑。最近，Li等人[30]提出了一个通用的神经网络模型来学习左右半球的区别性情感特征。但他们的工作并没有调查渠道之间的关系。Song等人[31]建立了一个表示多个脑电通道之间连接的加权图G，并提出了一个动态图卷积神经网络（DGCNN）模型来自动学习G中的一组最优权值。图G中的每个节点对应于一个脑电通道，并由标量（针对单个特征）或一个向量表示向量（用于融合特征），然后将脑电数据视为图信号，即定义在不规则图G上的信号。通过学习G中每一条边上定义的一组最优权值，节点间的连接强度可以作为一个函数特征来确定。为了分析图形信号，需要对图形进行信号处理的技术（特别是谱图滤波或图形卷积技术）[32]，我们在第2.1节中简要总结了这些技术。</p>
<p>为了处理不规则图结构上的信号，如社交网络和大脑连接体中的信号，图CNN（GCNN）首先在[33]中提出，它基于域的层次聚类或图的拉普拉斯谱。通过引入用于图卷积的快速局部化谱滤波器[35]，进一步改进了GCNN[34]。GCNN的一些其他变体包括[36]，[37]。Song等人[31]将GCNN引入到使用多通道EEG的情绪识别中，并提出了一个DGCNN模型。DGCNN考虑不规则图上的边权值，并自动学习一组最优权值。这些权值为揭示脑电通道间的内在联系提供了一种有效的方法：在脑电图形信号中，第i个和第j个电极之间的权值越大，这两个节点的相关性就越强。我们在第2.2节中简要总结了DGCNN。</p>
<p>本文的工作是基于一个重要的观察：DGCNN以无约束的方式优化图G的权值，而断层扫描显示，脑电电极所采集的不同脑区可能与不同的脑功能有关，因此权值（代表电极间的功能关系）可能是高度局部化和稀疏的。本文通过在图表示G中引入一个新的稀疏约束来改进DGCNN，提出了一个稀疏约束极小化问题的解决方案，以保证网络模型的收敛性。</p>
<p>我们称我们的方法为稀疏DGCNN。实验结果表明，与现有的情绪识别方法相比，稀疏DGCNN基于DEAP[4]、SEED[15]、DREAMER[16]和CMEED[3]四个数据集提取的不同时频域脑电特征，均取得了较好的性能，平均提高了8.88%的准确率。我们的研究结果还表明，γ波段的DE、PSD和ASM特征传达了最重要的辨别性情感信息，这与以往的研究结果一致。</p>
<h2 id="研究过程"><a href="#研究过程" class="headerlink" title="研究过程"></a>研究过程</h2><h3 id="Spectral-graph-theory"><a href="#Spectral-graph-theory" class="headerlink" title="Spectral graph theory"></a>Spectral graph theory</h3><p>我们感兴趣的是分析定义在无向加权图G={V，W}上的多通道脑电信号。V={v1，v2，···，vn}是顶点集，其中每个顶点vi对应一个电极，n是脑电图记录设备中的电极数。n×n矩阵W是G的邻接矩阵，其条目wij≥0度量vi和vj之间函数关系的强度。DGCNN[31]从训练集中自动学习最优邻接矩阵W。</p>
<p>谱图论将经典的信号处理技术推广到图谱域，在处理图上的信号时引入了不规则的图结构。在特殊图论中起中心作用的图G的拉普拉斯矩阵L被定义为L=D-W，其中D是一个n×n对角矩阵，$D<em>{i i}=\sum</em>{j=1}^{n} w_{i j}$。图G的傅里叶基U可以表示为正交矩阵，由拉普拉斯矩阵$L=U \Lambda U^{T}$的奇异值分解得到，其中∧=diag（[λ1，λ2，···，λn]）是对角矩阵。当图的傅里叶变换及其逆可以表示为ˆx=UT x和x=Uˆx时，图卷积算子在图的谱域中定义为</p>
<script type="math/tex; mode=display">
x * y=U\left[\left(U^{T} x\right) \odot\left(U^{T} y\right)\right]</script><p>滤波函数g可以设计成对角矩阵。</p>
<script type="math/tex; mode=display">
y=g(L) x=g\left(U \Lambda U^{T}\right) x=U g(\Lambda) U^{T} x</script><p>上述滤波器设计可以解释为滤波信号y等于信号x和Ug（λ）的图形卷积：</p>
<script type="math/tex; mode=display">
\begin{aligned} y &=g(L) x=U g(\Lambda) U^{T} x=[U g(\Lambda)] \odot\left(U^{T} x\right) \\ &=U\left\{U^{T}[U g(\Lambda)]\right\} \odot\left(U^{T} x\right)=x *[U g(\Lambda)] \end{aligned}</script><h3 id="DGCNN"><a href="#DGCNN" class="headerlink" title="DGCNN"></a>DGCNN</h3><p>DGCNN的输入是一个图信号G={V，W}，其中W是相邻矩阵，其条目wij≥0度量每对（vi，vj），i，j∈{1，2，·····，n}之间函数关系的强度，每个顶点处的信号vi∈V是从相应电极提取的脑电特征f。在[31]中，测试了五个频段（δ、θ、α、β和γ波段）的PSD、DE、DASM、RASM和DCAU特征。</p>
<p>DGCNN模型由图滤波层、卷积层、ReLu激活层和全连接层组成。</p>
<p><img src="https://jzh-markdown-pics.oss-cn-beijing.aliyuncs.com/img/image-20210318125158268.png" alt="image-20210318125158268"></p>
<p>图形滤波层将不规则图形信号传输到频域。然而，式（2）中滤波函数g的对角线形式没有局部化，因此其计算非常耗时。DGCNN使用Defferrard等人[34]提出的多项式滤波器，其近似于切比雪夫展开式。</p>
<script type="math/tex; mode=display">
g(\Lambda)=\sum_{k=0}^{K-1} \theta_{k}^{\prime} \Lambda^{k} \simeq \sum_{k=0}^{K-1} \theta_{k} T_{k}(\widetilde{\Lambda})</script><p>与传统的CNN类似，卷积层可能检测到频域中的特定模式。然后应用ReLu激活函数[41]来实现非线性映射能力。ReLu激活层的输出是非负的。最后一个完全连接的层使用softmax函数来预测所需的类标签信息。</p>
<p>除了像GCNN一样优化网络参数[34]，DGCNN在训练过程中同时学习一个最优的邻接矩阵W。为了实现这一目标，DGCNN使用以下损失函数并计算其对网络参数和矩阵W的偏导数：</p>
<script type="math/tex; mode=display">
\operatorname{Loss}=\psi\left(l, l^{p}\right)+\alpha\|\Theta\|_{2}</script><h3 id="THE-SPARSE-DGCNN-MODEL"><a href="#THE-SPARSE-DGCNN-MODEL" class="headerlink" title="THE SPARSE DGCNN MODEL"></a>THE SPARSE DGCNN MODEL</h3><p>迄今为止，大多数基于EEG的情绪识别研究都利用了个别电极的EEG特征（如[3]、[6]）。在这些方法中，基本假设是每个个体的情绪体验都与一组限定的皮层和皮层下的大脑区域相关，不同的大脑区域参与不同的情绪，构成了认知的基础。</p>
<p>网络神经科学的最新进展正在改变我们对人类情感的理解。简单地说，网络神经科学家强调神经连接的重要性，而不是神经反应，因为它能更好地描述影响人类认知功能的神经机制[42]。由于情感与感知、认知、动机和行动紧密相连，从神经生理角度来看，基于网络的观点是合理的，最近受到越来越多的关注[43]。</p>
<p>随着神经科学的发展，情感计算领域的研究人员开始探索基于网络的情感识别特征。然而，DGCNN模型以无约束的方式优化相邻矩阵W，没有充分利用人类神经网络的神经生理特性。我们的关键观察是W具有很高的包含n×n个变量的能力，我们可以通过加入一些特定的先验知识来减少方差。本文所考虑的先验知识是矩阵W的稀疏性：由于W表示每对（vi，vj），vi，vj∈V之间函数关系的强度，因此W中的非零项wij应尽可能稀疏。</p>
<p>上述W的稀疏假设得到了一些神经科学研究的支持。从层析成像可知，不同的脑区可能与不同的脑功能有关。如图2所示，头皮电极位置根据不同的大脑区域进行标记：额叶（F）、中央叶（C）、颞叶（T）、后叶（P）和枕叶（O）。一些大脑功能可能只激活受限的大脑区域；例如，情绪处理器可能位于T3和T4[44]。因此，条目wij之间的函数关系可能是高度局部化的，因此矩阵W应该是非常稀疏的。此外，大脑网络通常表现出一系列用于有效信息处理的复杂特性，包括集线器（高度互联的节点）、小世界拓扑（具有稀疏远程连接的密集局部聚类）等[45]。因此，这些神经科学发现要求在基于图的机器学习算法中实现稀疏性。事实上，稀疏性已经被认为是实现可靠和高性能脑电处理算法的一个重要因素（例如，[46]）。</p>
<p><img src="https://jzh-markdown-pics.oss-cn-beijing.aliyuncs.com/img/image-20210318130022988.png" alt="image-20210318130022988"></p>
<p>为了对矩阵W施加稀疏性，我们期望W中的非零项应该尽可能少。为了实现这一目标，在稀疏编码研究中，我们可以使用L1或L0矩阵范数。在我们的研究中，我们选择L1矩阵范数由于其凸性，并制定以下正则化项。</p>
<script type="math/tex; mode=display">
\mathcal{L}(\Theta, W)=\psi\left(l, l^{p}\right)+\alpha\|\Theta\|_{2}+\lambda\|W\|_{1}</script><p>其中λ是稀疏约束的权重。预测标签lp取决于输入图形信号、动态调整矩阵W和网络参数；因此，它是一个函数lp（Θ，W）。</p>
<script type="math/tex; mode=display">
\frac{\partial \mathcal{L}}{\partial W}=\frac{\partial \psi\left(l, l^{p}\right)}{\partial W}+\lambda \frac{\partial\|W\|_{1}}{\partial W}</script><p>这一项有可能不可微。我们可以应用<strong>次梯度法</strong>[47]。然而，次梯度法的迭代在不可微的点上变得很少，在不可微点上通常可能是真最小值。此外，次梯度法有时不能保证精确的稀疏解[48]。在稀疏DGCNN中，我们使用了前向后分裂方法[49]，它可以有效地解决不可微和有约束的优化问题，如最小化等式（8）中的目标函数。具体步骤如下。稀疏DGCNN在每个迭代中有两个步骤。</p>
<ul>
<li>第一步与DGCNN相同，使用式（6）中的损失函数进行反向传播：$W^{i+\frac{1}{2}}=W^{i}-\tau_{i} \frac{\partial L o s s}{\partial W^{i}}$</li>
<li>在第二步中，我们计算了一个新的矩阵Wi+1，它在两个目标之间找到了一个很好的折衷：（1）紧靠$W^{i+\frac{1}{2}}$；（2）用||W||1实现稀疏表示：<script type="math/tex">W^{i+1}=\arg \min _{W}\left\{\left\|W-W^{i+\frac{1}{2}}\right\|_{F}^{2}+\tau_{i+\frac{1}{2}} \lambda\|W\|_{1}\right\}</script></li>
</ul>
<p>在上述目标函数中，稀疏编码被描述为由矩阵数据邻近项组成的最小化问题，由Frobenius范数表示</p>
<script type="math/tex; mode=display">
\left\|W^{\prime}\right\|_{F}=\sqrt{\sum_{i=1}^{n} \sum_{j=1}^{n} w_{i j}^{\prime 2}}=\sqrt{\operatorname{trace}\left(W^{\prime T} W^{\prime}\right)}</script><h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><p>为了评价稀疏DGCNN的性能，我们将其与四种具有代表性的算法进行了比较，包括两种经典的机器学习方法，即支持向量机（SVM）和图正则化极值学习方法（GELM），以及两种深层神经网络模型，即深层信念网络（DBN）和原始DGCNN。</p>
<p>支持向量机利用核函数将输入数据转化为一个特征空间，在该特征空间中找到一个超平面，将数据最好地分割成两个距离最大的类。</p>
<p>支持向量机是最流行的传统机器学习方法之一，在[51]中被用来研究脑电信号的频带。</p>
<p>Peng等人[52]提出了GELM，它构建了一个节点为样本的图。GELM对基本ELM进行了图正则化，使得同一类样本的输出是相似的。</p>
<p>请注意，GELM中的图形没有描述多通道连接。GELM被用于情感识别，与SVM分类器相比取得了更好的性能[51]。</p>
<p>DBN使用一堆受限的Boltzmann机器，其最后一层是分类器。</p>
<p>综上所述，对于SVM、DBN和GELM，将数据嵌入到序列和矩阵中，即将一个时间单元中所有通道的脑电特征串联成一个序列，然后将所有时间单元组成一个矩阵。对于DGCNN和稀疏DGCNN，脑电数据被嵌入到一个不规则的图结构中，即图的每个节点都是来自一个通道的脑电数据，而节点之间的连接则代表通道之间的连接。</p>
<h3 id="实验设置"><a href="#实验设置" class="headerlink" title="实验设置"></a>实验设置</h3><p>两个策略：</p>
<ul>
<li><p>一种是不使用一个片段的交叉验证，用于受试者依赖性评价。也就是说，对于观看m个视频片段的每个受试者，我们使用m-1片段为他/她训练一个模型，并在1个片段上进行测试。最后的结果是所有测试的平均值，每个片段用于一个测试。</p>
</li>
<li><p>另一种方案是将一名受试者排除在交叉验证之外，进行独立于受试者的评估。也就是说，一个受试者的数据被用作测试集，而其他受试者的数据被用作训练集。同样，最终结果是所有测试的平均值，每个受试者的数据用于一次测试。</p>
</li>
</ul>
<p>两个情绪识别任务:</p>
<ul>
<li>SEED具有正、负、中性价情绪，而DEAP、DREAMER和CMEED具有正、负性价情绪和高、低唤醒情绪。因此，我们在本文中确定了正性与负性valence以及高与低arousal情绪。</li>
</ul>
<p>六个基本特征和融合：</p>
<ul>
<li>从θ、α、β和γ波段提取DE、PSD、DASM、RASM、ASM和DCAU作为数据源。进一步研究了提高分类精度的特征融合方法。我们首先融合一个特征的不同波段，并将所有波段的特征作为输入数据，例如所有波段的DE。</li>
</ul>
<p><img src="https://jzh-markdown-pics.oss-cn-beijing.aliyuncs.com/img/image-20210318132754001.png" alt="image-20210318132754001"></p>
<h3 id="SEED"><a href="#SEED" class="headerlink" title="SEED"></a>SEED</h3><p>种子数据集[15]收集了15名受试者（7名男性和8名女性，平均年龄=23.27，SD=2.37）的脑电图数据。这些脑电图数据是由中国情感电影剪辑形式的视听刺激所激发的。在参与者观看15个4分钟的电影片段时，他们的脑电图数据由62个通道的ESI神经系统记录，采样率为1000Hz。随后，将脑电图数据采样至200 Hz，并手动检查以消除EOG和EMG ARI事实。对于每个受试者，在三个时间顺序不连贯的会话中捕获脑电图记录，每个会话重复相同的实验。因为SEED是四个数据集中唯一包含三个重复会话的会话，以确保评估的一致性，因此在我们的实验中，<strong>我们只对每个受试者使用第一个session</strong>，因为第一个会话反映的情感比后面两个会话更可靠。</p>
<p>另外，SEED不包含唤醒信息，因此我们只认识到SEED上的积极和消极情绪。在0.3～50Hz之间的带通滤波器预处理后，提取了5个特征（DE、PSD、DASM、RASM和DCAU），在四个波段上提取1s窗口θ带（4-7Hz）、α波段（8-13Hz）、β带（14-30Hz）和γ带（&gt;30Hz）。</p>
<p><img src="https://jzh-markdown-pics.oss-cn-beijing.aliyuncs.com/img/image-20210318133018359.png" alt="image-20210318133018359"></p>
<h3 id="DEAP"><a href="#DEAP" class="headerlink" title="DEAP"></a>DEAP</h3><p>DEAP数据集[4]收集了32名受试者（16名女性和16名男性，平均年龄为26.9岁，年龄范围为19-37岁）的脑电图和外周信号。在Biosemi-ActiveTwo系统中，采用32个电极，以512hz的采样率采集了40个1min长的音乐视频，记录了脑电数据。脑电图数据随后被下采样到128Hz，并去除了EOG伪影。数据以普通参考为基础，分割成1分钟长的片段。删除了3秒长的试验前基准。</p>
<p>根据自我评估人体模型（SAM），对每一部电影和相关的EEG信号进行高/低唤醒、价维度的标记。如前所述，我们对正/负价和高/低唤醒维度进行了二元分类。由于DEAP提供的预处理数据在4.0-45.0Hz波段进行滤波（即去除δ波段），我们在其他4个波段提取了6个窗口为2s的特征，即θ（4-8hz）、α（8-12hz）、β（12-30Hz）和γ（&gt;30Hz）。</p>
<p><img src="https://jzh-markdown-pics.oss-cn-beijing.aliyuncs.com/img/image-20210318133819566.png" alt="image-20210318133819566"></p>
<p><img src="https://jzh-markdown-pics.oss-cn-beijing.aliyuncs.com/img/image-20210318133829741.png" alt="image-20210318133829741"></p>
<h3 id="DREAMER"><a href="#DREAMER" class="headerlink" title="DREAMER"></a>DREAMER</h3><p>DREAMER数据集[16]收集了23名受试者（14名男性和9名女性，平均年龄=26.6，标准差=2.7）的脑电图和心电图数据。脑电图数据是在观看18段英语情感电影片段（长度在65到393秒之间，平均199秒）的过程中获得的，并由Emotiv-EPOC系统使用16个通道中的14个（左2个为参考）以128hz的采样率记录。我们遵循[16]中的预处理方法去除脑电数据中的伪影，只保留每个片段的最后60秒，并在四个波段使用重叠1s的2s窗口进一步处理脑电数据，与其他三个波段一致：θ波段（4-8Hz）、α波段（8-13Hz）、β波段（13-30Hz）和γ波段（&gt;30Hz）。对每个频带，计算PSD特征。</p>
<p>脑电数据显示了9种情绪类型（娱乐、兴奋、快乐、平静、愤怒、厌恶、恐惧、悲伤和惊讶）。这些情绪类型进一步被分为价/唤醒等级量表，并按照[16]中相同的阈值策略，将问题转化为二值分类问题。</p>
<h3 id="CMEED"><a href="#CMEED" class="headerlink" title="CMEED"></a>CMEED</h3><p>CMEED数据集[3]收集了37名受试者（17名男性和20名女性，平均年龄=23.95，SD=1.56）的脑电图数据。在观看16个胶片剪辑（长度在61至134秒）期间，脑电图数据被神经症患者quik-cap2记录，使用32个电极中的30个（左2个为参考），采样率为1024Hz。利用MATLAB中的EEGLAB工具箱，对1-45hz滤波器进行滤波预处理，并进行独立分量分析。利用1s重叠的2s窗口，从θ波段（4-7Hz）、α波段（8-13Hz）、β波段（14-30Hz）、γ波段（&gt;30Hz）四个波段提取PSD特征，与做梦者和DEAP相似，我们还根据评分将情绪分为正/负价和高/低唤醒。</p>
<h3 id="Cross-corpus-Evaluation"><a href="#Cross-corpus-Evaluation" class="headerlink" title="Cross-corpus Evaluation"></a>Cross-corpus Evaluation</h3><p><img src="https://jzh-markdown-pics.oss-cn-beijing.aliyuncs.com/img/image-20210318134942423.png" alt="image-20210318134942423"></p>
<h2 id="讨论"><a href="#讨论" class="headerlink" title="讨论"></a>讨论</h2><p><img src="https://jzh-markdown-pics.oss-cn-beijing.aliyuncs.com/img/image-20210318135035457.png" alt="image-20210318135035457"></p>
<p>在未来的工作中，我们计划研究注意机制的作用，并在适当的水平上进一步引导我们的稀疏约束。第二，稀疏DGCNN遵循原始DGCNN[31]使用非负条目来建模邻接矩阵W，因为ReLu激活层的输出是非负的。在未来的研究中，考虑负相关值是一个有趣的问题，因为在情绪面孔处理中可能发现负相关。第三，DEAP、DREAMER和CMEED的数据集使用自我报告标签，SEED使用电影剪辑类别作为标签。这两种类型的标签分别对应于感觉到的和感知到的情绪（例如，[72]）。我们的CNN可以处理这两种类型的标签。在今后的工作中，通过研究这两种标签类型的差异，有可能提高识别精度。</p>
]]></content>
      <categories>
        <category>jzh</category>
      </categories>
      <tags>
        <tag>EEG</tag>
        <tag>图神经网络</tag>
      </tags>
  </entry>
  <entry>
    <title>jzh Transfer Learning for EEG-Based Brain-Computer Interfaces:A Review of Progress Made Since 2016</title>
    <url>/2021/01/06/JiaoZehui/Transfer%20Learning%20for%20EEG-Based%20Brain-Computer%20Interfaces%20A%20Review%20of%20Progress%20Made%20Since%202016/</url>
    <content><![CDATA[<h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>脑机接口(BCI)使用户能够直接使用脑信号与计算机交流。</p>
<p>最常见的模式是<strong>非侵入性BCI</strong>，使用的是脑电图，它对噪声和伪影较为敏感，并且受试者之间和受试者内部的信号也是非平稳的。因此很难用基于脑电图的BCI系统建立通用模式的识别模型，该模型对于不同的受试者、不同的会话、不同的设备和任务是最优的。</p>
<p>一般情况下，会通过收集受试者的一部分数据来进行校准和微调，这既耗时又对用户不友好。<strong>迁移学习</strong>的出现就是为了减少校准微调的工作量，它利用<strong>相似或相关</strong>的受试者/会话/设备/任务的数据来促进对新受试者/会话/设备/任务的学习。</p>
<p>本文回顾了自2016年有关EEG的BCI期刊论文，其中有六种范式和应用</p>
<ol>
<li>motor imagery</li>
<li>event-related potentials </li>
<li>steady-state visual evoked potentials</li>
<li>affective BCIs</li>
<li>regression problems</li>
<li>adversarial attacks</li>
</ol>
<p>我们回顾这些话题，给出一些观察结果和结论</p>
<a id="more"></a> 
<h2 id="文献信息"><a href="#文献信息" class="headerlink" title="文献信息"></a>文献信息</h2><p><strong>期刊：</strong> IEEE Transactions on Cognitive and Developmental Systems</p>
<p><strong>作者：</strong> </p>
<ol>
<li>Dongrui Wu, Senior Member，IEEE，Huazhong University of Science and Technology</li>
<li>Yifan Xu, Student Member，IEEE，Huazhong University of Science and Technology</li>
<li>Bao-Liang Lu，Senior Member，IEEE，Shanghai Jiao Tong University</li>
</ol>
<h2 id="关键词"><a href="#关键词" class="headerlink" title="关键词"></a>关键词</h2><p><strong>Brain-computer interfaces, EEG, transfer learning, domain adaptation, affective BCI, adversarial attacks</strong></p>
<h2 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a>背景介绍</h2><h3 id="BCI"><a href="#BCI" class="headerlink" title="BCI"></a>BCI</h3><p>BCI这个术语在1973年被提出，最初为残疾人提出，但是现在的应用范围早已扩展。</p>
<p>BCI被分为三种类型：</p>
<ol>
<li>非侵入性BCI，主要采集的信号是<strong>脑电图EEG</strong>和<strong>功能性近红外光谱fNIRS</strong></li>
<li>侵入性BCI，需要手术植入传感器或者电极，收集大脑的尖峰信号和局部场电位。</li>
<li>半侵入性BCI，传感器植入在大脑外部，颅骨的内部。</li>
</ol>
<p>本文主要介绍的还是非侵入性BCI，尤其是EEG，因为它安全、低成本、方便。</p>
<h3 id="BCI系统流程"><a href="#BCI系统流程" class="headerlink" title="BCI系统流程"></a>BCI系统流程</h3><p><img src="https://jzh-markdown-pics.oss-cn-beijing.aliyuncs.com/img/image-20201008171654892.png" alt="image-20201008171654892" style="zoom:67%;" /></p>
<p>上图流程：</p>
<ol>
<li>信号采集：从头皮收集脑电信号，早期使用有线连接或者凝胶来增强导电性，目前无线连接和干式电极越来越受欢迎。</li>
<li>信号处理：包括<strong>时间滤波和空间滤波</strong>。前者主要是为了减少干扰，例如伪影、直流漂移、眨眼。后者通过结合不同的导，增加信号的信噪比。空间滤波器主要有公共空间模式，独立成分分析，盲源分离，xDAWN等。</li>
<li>特征提取：时域、频域、时频、黎曼空间或者功能性大脑连接（functional brain connectivity）。</li>
<li>模式识别：分类或者回归</li>
<li>控制器：输出命令或者改变行动。</li>
</ol>
<h3 id="存在的问题和破解方法"><a href="#存在的问题和破解方法" class="headerlink" title="存在的问题和破解方法"></a>存在的问题和破解方法</h3><ol>
<li>脑电图信号很弱，容易受到干扰和噪声的污染。</li>
<li>脑电图信号对于同一受试者来说是不稳定的，并且在不同的受试者和会话之间是不同的。</li>
</ol>
<p>一般情况下，会通过收集受试者的一部分数据来进行校准和微调。因此，减少这种对特定受试者的校准对于基于EEG的BCI的市场成功至关重要。</p>
<p>迁移学习和主动学习已经开始着手解决这问题，其中迁移学习更有前途，因为它利用了相似的信息。除此以外，迁移学习还能和其它技术结合。</p>
<h3 id="BCI经典范例"><a href="#BCI经典范例" class="headerlink" title="BCI经典范例"></a>BCI经典范例</h3><ol>
<li><strong>motor imagery</strong>，由于不同的MI影响大脑的不同区域，BCI可以从脑电图中解码出来，映射到特定的运动。</li>
<li><strong>event-related potentials</strong>，事件相关电位是一种特殊的脑诱发电位，通过有意地赋予刺激以特殊的心理意义，利用多个或多样的刺激所引起的脑的电位。最常用的是P300。</li>
<li><strong>steady-state visual evoked potentials</strong>，脑电图在特定频率下以与视觉刺激相同(或数倍)的频率振荡，通常在3.5至75赫兹之间。</li>
</ol>
<p><strong>基于情感的BCI</strong>，也叫作aBCI，已经成为了一种新兴领域。</p>
<p><strong>BCI的回归问题</strong>，例如驾驶员的睡意估计，用户反映时间估计。</p>
<p><strong>BCI的对抗攻击</strong>，故意设计的微小扰动被添加到脑电图试验中，来欺骗机器模型。</p>
<h3 id="迁移学习定义"><a href="#迁移学习定义" class="headerlink" title="迁移学习定义"></a>迁移学习定义</h3><script type="math/tex; mode=display">
\mathcal{D}=\{\mathcal{X}, P(X)\}, \text { where } X \in \mathcal{X}\\\mathcal{T}=\{\mathcal{Y},f(X)\}</script><p>公式1，我们得到了$\mathcal{D<em>{s}}$和 $\mathcal{D</em>{t}}$，<strong>源域和目标域不同</strong>，因为他们的特征空间不同或者概率分布不同。</p>
<p>公式2，我们得到了标签空间和预测函数，也有了任务$\mathcal{T<em>{s}}$和$\mathcal{T</em>{t}}$，<strong>源域任务和目标域任务不同</strong>，因为标签空间不同或者条件概率不同。</p>
<p>给定源域$\mathcal{D}<em>{s}=\left{\left(X</em>{s}^{i}, y<em>{s}^{i}\right)\right}</em>{i=1}^{N}$，目标域 $\mathcal{D}<em>{t}$$\left{\left(X</em>{t}^{i}, y<em>{t}^{i}\right)\right}</em>{i=1}^{N<em>{l}}$，$\left{X</em>{t}^{i}\right}<em>{i=N</em>{l}+1}^{N<em>{l}+N</em>{u}}$，$N<em>{l}、N</em>{u}$分别是有标签的和无标签的，去学习$f: X<em>{t} \mapsto y</em>{t}$，使得在 $\mathcal{D}_{t}$上有较低的误差。当然了，因为是迁移学习，所以至少有源域和目标域不同或者源域任务和目标域任务不同。</p>
<h4 id="迁移学习分类"><a href="#迁移学习分类" class="headerlink" title="迁移学习分类"></a>迁移学习分类</h4><h4 id="迁移学习分类-1"><a href="#迁移学习分类-1" class="headerlink" title="迁移学习分类"></a>迁移学习分类</h4><ol>
<li>inductive transfer learning，也叫归纳迁移学习，推导迁移学习。此时，$N_{l}&gt;0$，我们根据源域数据的情况进行进一步分类。</li>
</ol>
<ul>
<li>源域数据有标注，此时迁移学习类似多任务学习，区别在于我们只关注目标任务，多任务学习则是同时关注源任务和目标任务。</li>
<li>源域数据没有标注，此时迁移学习类似自我学习。</li>
</ul>
<ol>
<li>transductive transfer learning，也叫转导迁移学习或者直推式迁移学习。当$N_{l}=0$时，也就是我们没有目标域的标签。协变量偏移和域自适应是其中的两种情况。</li>
</ol>
<ul>
<li><p>域自适应：定义类似迁移学习，但是我们假设</p>
<script type="math/tex; mode=display">
\mathcal{X}_{s}=\mathcal{X}_{t} \text { and } \mathcal{Y}_{s}=\mathcal{Y}_{t}\\  P_{s}(X) \neq P_{t}(X) \text { and/or } P_{s}(y \mid X) \neq P_{t}(y \mid X)</script></li>
<li><p>协变量偏移：定义类似迁移学习，但是我们假设</p>
</li>
</ul>
<script type="math/tex; mode=display">
\mathcal{X}_{s}=\mathcal{X}_{t} \text { and } \mathcal{Y}_{s}=\mathcal{Y}_{t} \text { and }P_{s}(X) = P_{t}(X) \\ P_{s}(y \mid X) \neq P_{t}(y \mid X)</script><ol>
<li><p>unsupervised transfer learning，也叫无监督迁移学习。源域和目标域都没有标注。无监督迁移学习专注于解决目标域中的无监督学习问题，如聚类、降维、密度估计。</p>
<p><img src="https://jzh-markdown-pics.oss-cn-beijing.aliyuncs.com/img/20190612220640186.png" alt="在这里插入图片描述"></p>
</li>
</ol>
<h3 id="BCI的迁移学习场景"><a href="#BCI的迁移学习场景" class="headerlink" title="BCI的迁移学习场景"></a>BCI的迁移学习场景</h3><ol>
<li>Cross-subject TL，跨受试者迁移学习。通常，我们的任务和EEG的设备是一致的。</li>
<li>Cross-session TL，跨会话迁移学习。通常，我们的受试者、任务和EEG的设备是一致的。</li>
<li>Cross-device TL，跨设备迁移学习。通常，我们的任务和EEG的设备是一致的。</li>
<li>Cross-task TL，跨任务迁移学习。例如，来自左右手的运动想象的数据用于校准脚和舌运动想象。通常，受试者和EEG设备是一致的的。</li>
</ol>
<p>1和2本质上是相同的，3和4因为更困难，所以研究更少。</p>
<h2 id="迁移学习在BCI的应用"><a href="#迁移学习在BCI的应用" class="headerlink" title="迁移学习在BCI的应用"></a>迁移学习在BCI的应用</h2><h3 id="MI"><a href="#MI" class="headerlink" title="MI"></a>MI</h3><h4 id="Cross-Subject-Session-TL"><a href="#Cross-Subject-Session-TL" class="headerlink" title="Cross-Subject/Session TL"></a>Cross-Subject/Session TL</h4><ol>
<li><blockquote>
<p>Transfer kernel common spatial patterns for motor imagery brain-computer interface classifification</p>
<p><em>Computational and Mathematical Methods in Medicine</em> 2018</p>
<p>M. Dai, D. Zheng, S. Liu, and P. Zhang</p>
<p>Dai等人提出了转移核公共空间模式（TKCSP）方法，将核公共空间模式（KCSP）和转移核学习（TKL）结合起来，用于跨受试者MI分类中的EEG试验空间滤波。它首先用TKL计算一个域不变核，然后将其应用到KCSP方法中，进一步找到两类之间能量差最大的分量。注意，TL用于脑电信号处理（空间滤波）而不是分类。</p>
</blockquote>
</li>
<li><blockquote>
<p>A parallel multiscale fifilter bank convolutional neural networks for motor imagery EEG classifification</p>
<p>H. Wu, F. Li, Y. Li, B. Fu, G. Shi, M. Dong, and Y. Niu</p>
<p><em>Frontiers in Neuroscience</em> 2019</p>
<p>Wu等人[70]提出了一种并行多尺度滤波器CNN用于MI分类。它由三个层次组成：一个从脑电信号中提取时间和空间特征的CNN，一个具有平方和对数非线性函数的特征约简层，然后是池化和droput层。dense层进行微调。</p>
<p><img src="https://jzh-markdown-pics.oss-cn-beijing.aliyuncs.com/img/fnins-13-01275-g002.jpg" alt=""></p>
</blockquote>
</li>
</ol>
<h4 id="Cross-Device-TL"><a href="#Cross-Device-TL" class="headerlink" title="Cross-Device TL"></a>Cross-Device TL</h4><ol>
<li><blockquote>
<p>Xu等人[71]研究了跨数据集TL中深度学习的性能。考虑了8个公开可用的MI数据集。虽然不同的数据集使用不同的脑电图设备、通道和MI任务，但他们只选择了三个常见的通道（C3、CZ、C4）以及左手和右手MI任务。他们通过在线递归计算黎曼平均值并将其作为EA方法中的参考矩阵，将在线预对准策略应用于每个受试者的每次脑电图试验。他们发现在线预对准显著提高了跨数据集TL中深度学习模型的性能</p>
</blockquote>
</li>
</ol>
<h4 id="方法总结"><a href="#方法总结" class="headerlink" title="方法总结"></a>方法总结</h4><h5 id="Euclidean-Alignment-EA"><a href="#Euclidean-Alignment-EA" class="headerlink" title="Euclidean Alignment (EA)"></a><em>Euclidean Alignment (EA)</em></h5><script type="math/tex; mode=display">
\bar{R}_{s}=\frac{1}{N_{s}} \sum_{n=1}^{N_{s}} X_{s}^{n}\left(X_{s}^{n}\right)^{\top}
\\\tilde{X}_{s}^{n}=\bar{R}_{s}^{-1 / 2} X_{s}^{n}</script><p><img src="https://jzh-markdown-pics.oss-cn-beijing.aliyuncs.com/img/image-20201213210516371.png" alt="image-20201213210516371"></p>
<h5 id="CSP"><a href="#CSP" class="headerlink" title="CSP"></a>CSP</h5><p>CSP对EEG进行有监督的空间滤波，目的是找到一组空间滤波器来最大化两类之间的方差比。</p>
<p><em>Combined CSP (CCSP)</em> 是对CSP在无标签上数据集使用。</p>
<p><em>Regularized CSP (RCSP)</em> </p>
<h3 id="ERP"><a href="#ERP" class="headerlink" title="ERP"></a>ERP</h3><h3 id="SSVEP"><a href="#SSVEP" class="headerlink" title="SSVEP"></a>SSVEP</h3><h3 id="ABCI"><a href="#ABCI" class="headerlink" title="ABCI"></a>ABCI</h3><h4 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h4><p>情绪可以分为离散的类别（快乐、悲伤、生气等）或者2D的连续值（arousal和valence）、3D的连续值（arousal，valence，dominance）。所以，aBCI可以是回归问题，也可以是分类问题。但是目前的研究基本将它看作分类问题。</p>
<p>常用的数据集是DEAP和SEED。</p>
<ol>
<li>DEAP：DEAP由32名受试者在观看1分钟长的音乐视频时，通过BioSemi ActiveTwo设备记录的32通道脑电图组成。</li>
<li>SEED：SEED由15名受试者在观看4分钟电影剪辑时，通过ESI NeuroScan设备记录的62通道脑电图组成。</li>
</ol>
<p>Zheng等人，利用微分熵特征，发现在不同的session和subjet中stable pattern确实存在。</p>
<h4 id="Cross-Subject-Session-TL-1"><a href="#Cross-Subject-Session-TL-1" class="headerlink" title="Cross-Subject/Session TL"></a>Cross-Subject/Session TL</h4><ol>
<li><blockquote>
<p>A Fast, Efficient Domain Adaptation Technique for Cross-Domain Electroencephalography(EEG)-Based Emotion Recognition</p>
<p>Sensors 2017</p>
<p>Chai Xin</p>
<p>方法：adaptive subspace feature matching (ASFM)，使用的是微分熵特征。</p>
<ol>
<li>利用PCA对进行降维。</li>
<li>源域投影到$Z<em>{s} Z</em>{s}^{\mathrm{T}} Z<em>{t}$，目标域投影到$Z</em>{t}$。</li>
<li>利用迭代伪标签和真实标签训练逻辑回归器。</li>
</ol>
</blockquote>
</li>
<li><blockquote>
<p>Improving EEG-Based Emotion Classification Using Conditional Transfer Learning</p>
<p>Frontiers in Human Neuroscience, 2017</p>
<p>Yuan-Pin Lin</p>
<p>本研究提出了一个条件迁移(cTL)框架，以促进每个个体的正迁移。通过对26的个体进行实验，相比仅仅利用自身的数据，在valence分类上提升了15%，在arousal分类上提升了26%。</p>
<p>简单来讲，cTL设置了一个阈值，如果准确率不高，则可以考虑迁移学习(利用其他相似个体的数据)，否则没必要进行迁移学习。</p>
</blockquote>
</li>
<li><blockquote>
<p>Incorporation of multiple-days information to improve the generalization of EEG-based emotion recognition over time</p>
<p><em>Frontiers in Human Neuroscience</em> 2018</p>
<p>S. Liu</p>
<p>方法：我们将60导的数据δ、θ、α、β、低和高γ波段的光谱功率，作为初始特征。利用递归特征消除来选择特征。使用SVM进行分类。他们发现，脑电图的变异性会显著削弱情绪分类的表现，而在训练期间使用更多天的数据可以显著提高泛化能力。</p>
</blockquote>
</li>
<li><blockquote>
<p>Unsupervised domain adaptation techniques based on auto-encoder for non-stationary EEG-based emotion recognition</p>
<p>Computers in Biology and Medicine 2016</p>
<p>XinChai</p>
<p>首先，使用堆叠自动编码器将来自两个域的差分熵特征转换成域不变子空间。然后，利用核主成分分析、图正则化和最大均值差异来减小两个域之间的特征分布差异。之后，在源域中训练的分类器可以直接应用于目标域。</p>
<p><img src="https://jzh-markdown-pics.oss-cn-beijing.aliyuncs.com/img/1-s2.0-S0010482516302797-gr4.jpg" alt="Fig. 4"></p>
</blockquote>
</li>
<li><blockquote>
<p>Cross-session classifification of mental workload levels using EEG and an adaptive deep learning model</p>
<p>Biomedical Signal Processing and Control 2017</p>
<p>Zhong Yina, Jianhua Zhang </p>
<p>Yin和Zhang提出了一种自适应叠加去噪自动编码器（SDAE），用于从EEG中对精神负荷水平进行跨会话二分类。在测试阶段，利用增加的测试样本及其伪标签，自适应地更新SDAE浅隐神经元的权值。</p>
<p><img src="https://jzh-markdown-pics.oss-cn-beijing.aliyuncs.com/img/image-20201212132725108.png" alt="image-20201212132725108"></p>
</blockquote>
</li>
<li><blockquote>
<p>Inter-subject Transfer Learning with End-to-end Deep Convolutional Neural Network for EEG-based BCI </p>
<p>Journal of Neural Engineering 2019</p>
<p>Fatemeh Fahimi</p>
<p>我们开发了一个端到端的深度CNN来解码来自EEG时间序列的注意力信息。我们还通过向网络中输送三种不同的脑电图表示来探索输入表示对深层CNN性能的影响。为了加快训练速度，利用cross-subject的迁移策略作为分类依据。</p>
<p>数据处理：50%重叠的2s滑动窗口分割数据，滤波到0.5Hz以上。</p>
<p>数据表达:</p>
<ol>
<li>DR1：原始数据</li>
<li>DR2：带通滤波0.5-40Hz</li>
<li>DR3：提取五个频率带的信号</li>
</ol>
<p><img src="https://jzh-markdown-pics.oss-cn-beijing.aliyuncs.com/img/image-20201011225415624.png" alt="image-20201011225415624"></p>
<p><img src="https://jzh-markdown-pics.oss-cn-beijing.aliyuncs.com/img/image-20201011225406068.png" alt="image-20201011225406068"></p>
</blockquote>
</li>
<li><blockquote>
<p>From Regional to Global Brain: A Novel Hierarchical Spatial-Temporal Neural Network Model for EEG Emotion Recognition</p>
<p><em>IEEE Trans. on Affective Computing</em> 2019</p>
<p>Yang Li</p>
<p>方法：R2G-STNN，R2G-STNN由空间和时间神经网络层组成，具有区域到全局(R2G)的特征学习过程层次，以捕捉不同大脑区域的情绪反应和结构关系，从而学习有区别的时空脑电特征。</p>
<ol>
<li>特征提取：用双向LSTM提取脑区内和脑区间的时空特征，使用Attention来给脑区贡献权重。</li>
<li>分类器和判别器：判别器来缓解源域数据和目标域数据之间的域偏移，这将使分层特征学习过程能够生成判别性的情感但域自适应的脑电特征。</li>
</ol>
<p>研究过程：</p>
<p><strong>空间特征提取</strong>：$\mathbf{X}=\left[\mathbf{x}<em>{1}, \mathbf{x}</em>{2}, \cdots, \mathbf{x}<em>{T}\right] \in \mathbb{R}^{d \times n \times T}$  ，T=9，此时已经不是时间序列，而是人工提取的特征。然后我们把特征${x}</em>{i}$分成区域，我们人为划分了16个区域，每个区域由多个导组成。然后送入双向LSTM^1^中，注意，此时的LSTM不是按照时间，而是按照区域内的顺序。我们获得了对应${x}_{i}$局部空间特征。</p>
<p><img src="https://jzh-markdown-pics.oss-cn-beijing.aliyuncs.com/img/image-20201013163034315.png" alt="image-20201013163034315" style="zoom:33%;" /></p>
<p>然后利用Attention来对LSTM的最后的隐藏状态赋予权值，因为认为不同区域有不同的权重。</p>
<p>然后每个区域的加权特征，送入双向LSTM^2^来学习全局的空间特征。然后用类似全连接的方式，将LSTM^2^的16个输出变成K个。我们就构造了对应${x}_{i}$的全局特征。</p>
<p><strong>时域特征提取：</strong> </p>
<p>前文已经得到了对应${x}_{i}$局部空间特征，具体来讲是获得了16个区域的局部空间特征，对这些区域分别走双向LSTM^3^，此时T=9，得到了局部时域特征。</p>
<p>全局特征提取类似，只需要走一个LSTM^4^即可，T=9。</p>
<p>我们拼接16个局部时域特征和一个全局特征作为最后分类。</p>
<p><strong>分类器和判别器：</strong></p>
<p>分类器比较简单，一个全连接接softmax。</p>
<p>损失函数为交叉熵函数。</p>
<p>训练样本和测试样本可能来自不同的域，例如不同的受试者，这时候训练集的模型用来测试不一定有好的效果，我们引入了一个鉴别器，来生成域不变的特征。</p>
<script type="math/tex; mode=display">
L_{d}\left(\mathbf{X}_{i}^{S}, \mathbf{X}_{j}^{T} ; \theta_{f}, \theta_{d}\right)=-\sum_{i=1}^{M_{1}} \log P\left(0 \mid \mathbf{X}_{i}^{S}\right)-\sum_{j=1}^{M_{2}} \log P\left(1 \mid \mathbf{X}_{j}^{T}\right)</script><p>最大化损失函数，我们可以得到域不变的特征。</p>
<p>最终损失函数</p>
<script type="math/tex; mode=display">
\begin{aligned} L\left(\mathbf{X}^{S}, \mathbf{X}^{T} \mid \theta_{f}, \theta_{c}, \theta_{d}\right)=& L_{c}\left(\mathbf{X}^{S} ; \theta_{f}, \theta_{c}\right) \\ &-L_{d}\left(\mathbf{X}^{S}, \mathbf{X}^{T} ; \theta_{f}, \theta_{d}\right) \end{aligned}</script><p>引入了GRL，即梯度反转层。</p>
<p><img src="https://jzh-markdown-pics.oss-cn-beijing.aliyuncs.com/img/v2-217ddc7463ae8f0d8841281eb2a9623f_b.jpg" alt="img"></p>
<p>数据采用SEED数据集，62导，15个受试者，每个受试者3个session，1个session有15次实验，一次实验有200个样本左右，一个session共有3200个样本，标签为3类，积极、中性和消极。</p>
<p><strong>依赖（非独立）受试者的情感识别：</strong></p>
<p>训练集和测试集，我们选择了相同的受试者，但是来自不同的实验（trials）。</p>
<p>15个实验中，9个作为训练集，6个作为测试集。</p>
<p><img src="https://jzh-markdown-pics.oss-cn-beijing.aliyuncs.com/img/image-20201013211610080.png" alt="image-20201013211610080"></p>
<p><strong>独立受试者的情感识别：</strong></p>
<p>留一法进行测试。</p>
<p><img src="https://jzh-markdown-pics.oss-cn-beijing.aliyuncs.com/img/image-20201013211910093.png" alt="image-20201013211910093"></p>
</blockquote>
</li>
<li><blockquote>
<p>A Bi-hemisphere Domain Adversarial Neural Network Model for EEG Emotion Recognition</p>
<p>Li Yang</p>
<p><em>IEEE Trans. on Affective Computing</em> 2018</p>
<p>研究表明，左额叶皮层的脑电图信号与积极情绪密切相关，而右额叶皮层的脑电图信号与消极情绪有关。</p>
<p><img src="https://jzh-markdown-pics.oss-cn-beijing.aliyuncs.com/img/image-20201014205256724.png" alt="image-20201014205256724" style="zoom:33%;" /></p>
<p><strong>特征提取：</strong> 首先提取五个频带的信息，使用差分熵DE，共310维的特征向量，T=9，所以输入特征为[310,9]</p>
<p><img src="https://jzh-markdown-pics.oss-cn-beijing.aliyuncs.com/img/image-20201014210423768.png" alt="image-20201014210423768" style="zoom:50%;" /></p>
<p><strong>baseline:</strong></p>
<p><img src="C:\Users\Jiao\AppData\Roaming\Typora\typora-user-images\image-20201014212450581.png" alt="image-20201014212450581" style="zoom:33%;" /></p>
<p><img src="https://jzh-markdown-pics.oss-cn-beijing.aliyuncs.com/img/image-20201014212501856.png" alt="image-20201014212501856" style="zoom:33%;" /></p>
<p><strong>result:</strong></p>
<p><img src="C:\Users\Jiao\AppData\Roaming\Typora\typora-user-images\image-20201014212706543.png" alt="image-20201014212706543" style="zoom:33%;" /></p>
<p><img src="https://jzh-markdown-pics.oss-cn-beijing.aliyuncs.com/img/image-20201014212728106.png" alt="image-20201014212728106" style="zoom:33%;" /></p>
</blockquote>
</li>
<li><blockquote>
<p>Domain Adaptation for EEG Emotion Recognition Based on Latent Representation Similarity</p>
<p>Jinpeng Li</p>
<p>IEEE Transactions on Cognitive and Developmental Systems 2019</p>
<p><img src="https://jzh-markdown-pics.oss-cn-beijing.aliyuncs.com/img/image-20201015090159077.png" alt="image-20201015090159077" style="zoom:50%;" /></p>
<p><img src="https://jzh-markdown-pics.oss-cn-beijing.aliyuncs.com/img/image-20201015090254303.png" alt="image-20201015090254303" style="zoom:50%;" /></p>
<p><img src="https://jzh-markdown-pics.oss-cn-beijing.aliyuncs.com/img/image-20201015090318136.png" alt="image-20201015090318136"></p>
<p>多对一迁移：</p>
<p><img src="https://jzh-markdown-pics.oss-cn-beijing.aliyuncs.com/img/image-20201015090529076.png" alt="image-20201015090529076" style="zoom:33%;" /></p>
<p>一对一迁移：</p>
<p><img src="https://jzh-markdown-pics.oss-cn-beijing.aliyuncs.com/img/image-20201015090739457.png" alt="image-20201015090739457" style="zoom:50%;" /></p>
<p><img src="https://jzh-markdown-pics.oss-cn-beijing.aliyuncs.com/img/image-20201015090746191.png" alt="image-20201015090746191" style="zoom:50%;" /></p>
</blockquote>
</li>
</ol>
<h4 id="Cross-Device-TL-1"><a href="#Cross-Device-TL-1" class="headerlink" title="Cross-Device TL"></a>Cross-Device TL</h4><ol>
<li><blockquote>
<p>Domain Adaptation Techniques for EEG-Based Emotion Recognition: A Comparative Study on Two Public Datasets</p>
<p>Zirui Lan ,Olga Sourina ,Lipo Wang ,Reinhold Scherer ,Gernot R. Muller-Putz</p>
<p>2019 IEEE Transactions on Cognitive and Developmental Systems</p>
<p>考虑了DEAP和SEED之间的跨数据集转移，这两个数据集具有不同的受试者数量，并使用不同的脑电图设备和不同的电极数进行记录。我们只使用了三个试验（一个是阳性的，一个是中性的，一个是阴性的）来自DEAP的14个被选者，并且只有两个数据集之间的32个公共通道。从每个通道中提取5个不同频带（delta、theta、alpha、beta和gamma）的5个差分熵特征，并作为特征串接。实验表明，与基线相比，域自适应，特别是转移分量分析[106]和最大独立度主适应[107]，可以有效地提高分类精度。</p>
<p><img src="https://jzh-markdown-pics.oss-cn-beijing.aliyuncs.com/img/image-20201213151121047.png" alt="image-20201213151121047"></p>
</blockquote>
</li>
<li><blockquote>
<p>Constructing a Personalized Cross-Day EEG-Based Emotion-Classification Model Using Transfer Learning</p>
<p>BIOMEDICAL AND HEALTH BIOMEDICAL AND HEALTH INFORMATICS 2020</p>
<p>提出了一种基于个体间差异的个性化分类方法。源数据集包括使用14通道Emotiv-EPOC设备的12名受试者，目标数据集包括使用30通道Neuroscan Quik-Cap的26名不同受试者。<br>首先选择Quik-Cap的26个通道中的12个与EPOC设备中14个通道中的12个对齐。Quik-Cap脑电信号进行了下采样和滤波，以匹配EPOC装置的信号。从六个左右声道对（例如，AF3-AF4，F7-F8），四个前后声道对（例如AF3-O1，F7-P7）和12个选定的通道中提取五个频带（delta、theta、alpha、beta、gamma）特征，得到每个试验的120D特征向量。特征矩阵的稀疏RPCA矩阵被用作最终特征。计算每个源受试者与目标受试者试验之间的黎曼距离作为相异测度，选择最相似的源受试者，将其试验与目标受试者的试验相结合，训练支持向量机分类器。</p>
</blockquote>
</li>
<li><blockquote>
<p>Utilizing Deep Learning Towards Multi-modal Bio-sensing and Vision-based Affective Computing</p>
<p><em>IEEE Trans. on Affective Computing</em>, 2020</p>
<p>Siddharth, Siddharth，Jung, Tzyy-Ping，Sejnowski, Terrence J.</p>
<p>Siddharth进行了多模态（如EEG、ECG、面部等）跨数据集情感分类，例如DEAP培训和MAHNOB-HCI数据库。该方法适用于具有不同电极数目和位置、不同采样率等的数据集。每次试验使用θ、α和β波段的EEG功率谱密度（PSD）绘制三个拓扑图。然后，将每个地形视为彩色图像的一个组成部分，并通过α混合的比率加权形成彩色图像。通过这种方法，每次试验获得一张代表PSD地形图的彩色图像，并可将不同脑电设备获得的图像直接组合或比较。使用预先训练的VGG-16网络从每幅图像中提取4096个特征，然后通过PCA将其减少到30个。最后采用极端学习机作为分类器进行最终分类。</p>
<p><img src="https://jzh-markdown-pics.oss-cn-beijing.aliyuncs.com/img/image-20201015092536466.png" alt="image-20201015092245803"></p>
<p><img src="https://jzh-markdown-pics.oss-cn-beijing.aliyuncs.com/img/image-20201015092436525.png" alt="image-20201015092436525"></p>
</blockquote>
</li>
</ol>
<h3 id="REGRESSION"><a href="#REGRESSION" class="headerlink" title="REGRESSION"></a>REGRESSION</h3><h3 id="ADVERSARIAL-ATTACKS"><a href="#ADVERSARIAL-ATTACKS" class="headerlink" title="ADVERSARIAL ATTACKS"></a>ADVERSARIAL ATTACKS</h3><h3 id="Sleep-Stage-Classification-And-Other"><a href="#Sleep-Stage-Classification-And-Other" class="headerlink" title="Sleep Stage Classification And Other"></a>Sleep Stage Classification And Other</h3><ol>
<li><blockquote>
<p>Transfer Learning Convolutional Neural Network for Sleep Stage Classification Using Two-Stage Data Fusion Framework</p>
<p>2020 IEEE ACESS</p>
<p>MEHDI ABDOLLAHPOUR , TOHID YOUSEFI REZAII, ALI FARZAMNIA,(Senior Member, IEEE), AND ISMAIL SAAD (Member, IEEE)</p>
<p>本文介绍了一种新的融合方法，将脑电图（EEG）和眼电图（EOG）两种信息源融合起来，在睡眠分期分类中取得了很好的效果。该方法从EEG和EOG信号中提取特征，将其分为两个特征集，分别由EEG特征和EEG与EOG的融合特征组成。然后，将每个特征集转化为水平可视图（HVG）。在一种新的框架下生成HVG图像，并用提出的传递学习卷积神经网络（TLCNN-DF）进行分类。</p>
<p><img src="https://jzh-markdown-pics.oss-cn-beijing.aliyuncs.com/img/image-20201213214724283.png" alt="image-20201213214724283"></p>
</blockquote>
</li>
<li><blockquote>
<p>Automatic sleep stage classification using time–frequency images of CWT and transfer learning using convolution neural network</p>
<p>Biocybernetics and Biomedical Engineering 2020</p>
<p>Pankaj  Jadhav Gaurav  Rajguru  Debabrata Datta  Siddhartha Mukhopadhyay </p>
<p>本文的目标是开发一种基于深度学习的方法，利用单通道脑电图（EEG）自动地利用EEG信号的时频谱，而不需要人工提取特征。采用连续小波变换（CWT）提取脑电信号时频RGB彩色图像。利用预训练的卷积神经网络的传递学习，将连续小波变换图像分为不同的睡眠阶段。<br>该方法使用一个公开可用的physoninet睡眠EDFx数据集，使用单通道EEG-Fpz-Cz通道进行评估。评价结果表明，即使使用单通道脑电信号，该方法也能达到接近技术水平的精度。</p>
<p><img src="https://jzh-markdown-pics.oss-cn-beijing.aliyuncs.com/img/image-20201214110743576.png" alt="image-20201214110743576"></p>
</blockquote>
</li>
<li><blockquote>
<p>Towards More Accurate Automatic Sleep Staging via Deep Transfer Learning</p>
<p>IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING 2020</p>
<p>Huy Phan , Oliver Y. Chen, Philipp Koch, Zongqing Lu, Ian McLoughlin, Alfred Mertins and Maarten De Vos</p>
<p>我们从一个通用的端到端深度学习框架开始，用于序列到序列的睡眠分期，并衍生出两个网络作为转移学习的手段。首先在源域（即大型数据库）中训练网络。然后在目标域（即小群体）中对预训练网络进行微调，完成知识转移。我们使用蒙特利尔睡眠研究档案（MASS）数据库（由200名受试者组成）作为源域，研究三个不同目标域的深度转移学习：Sleep-EDF扩展数据库的Sleep-case子集和Sleep-Telemetry子集，以及Surrey-cEEGrid数据库。有目的地采用目标域来覆盖与源域不同程度的数据不匹配。</p>
<p><img src="https://jzh-markdown-pics.oss-cn-beijing.aliyuncs.com/img/image-20201214112431471.png" alt="image-20201214112431471" style="zoom:67%;" /></p>
</blockquote>
</li>
<li><blockquote>
<p>EEG-Based Sleep Quality Evaluation with Deep Transfer Learning</p>
<p>Xing-Zan Zhang, Wei-Long Zheng, and Bao-Liang Lu</p>
<p>在这篇论文中，我们提出了一个与受试者无关的深度转移学习方法来评估昨晚的睡眠质量。为了减少脑电信号采集过程中脑电数据的内在跨受试者差异和背景噪声的变化，我们采用了两类转移学习方法来建立与主题无关的分类标准。</p>
<p>一种方法是利用矩阵分解和正则化理论寻找子空间，另一种方法是利用深度自动编码器学习通用的共享结构。</p>
<p>实验结果表明，与基线支持向量机（65.74%）相比，深度转移学习模型的平均分类准确率为82.16%，优于其他转移学习方法。我们的实验结果还表明，不同睡眠质量的神经模式是有区别的和稳定的：当睡眠被部分剥夺时，delta反应增加，α反应减少，4小时睡眠和6小时睡眠的神经模式与8小时睡眠更相似。</p>
<p><img src="https://jzh-markdown-pics.oss-cn-beijing.aliyuncs.com/img/image-20201214150233408.png" alt="image-20201214150233408"></p>
</blockquote>
</li>
<li><blockquote>
<p>Deep Transfer Learning for Cross-domain Activity Recognition</p>
<p><em>International Conference on Crowd Science and Engineering</em> 2018</p>
<p>Jindong Wang Vincent W. Zheng Yiqiang Chen Meiyu Huang</p>
<p>本文提出了一种有效的活动识别无监督源选择算法（USSAR）。USSAR能够从可用域列表中选择最相似的K源域。在此基础上，我们提出了一种有效的转移神经网络来进行活动识别的知识转移（TNNAR）。TNNAR可以在知识转移的同时捕捉到活动之间的时间和空间关系。在三个公共活动识别数据集上的实验表明：1）USSAR 算法在选择最佳源域方面是有效的。2） TNNAR方法在进行活动知识转移时可以达到较高的准确度</p>
<p><img src="https://jzh-markdown-pics.oss-cn-beijing.aliyuncs.com/img/image-20201214151247980.png" alt="image-20201214151247980"></p>
</blockquote>
</li>
<li><blockquote>
<p>Stratifified Transfer Learning for Cross-domain Activity Recognition</p>
<p>International Conference on Pervasive Computing and Communications 2018</p>
<p>Jindong Wang, Yiqiang Chen, Lisha Hu, Xiaohui Peng, Philip S. Yu</p>
<p>本文提出了一种新的、通用的跨域学习框架，利用类间的亲和力进行类内知识转移。</p>
<p>该框架被称为分层转移学习（STL），可以显著提高跨域活动识别的分类精度。具体来说，STL首先通过多数投票技术获得目标域的伪标签。然后，迭代地进行类内知识转移，将两个域转化为相同的子空间。最后通过第二次标注得到目标域的标签。</p>
<p><img src="https://jzh-markdown-pics.oss-cn-beijing.aliyuncs.com/img/image-20201214152815040.png" alt="image-20201214152815040"></p>
</blockquote>
</li>
<li><blockquote>
<p>Importance Weighting with Adversarial Network for Large-Scale Sleep Staging</p>
<p>ICML 2020 Workshop LifelongML Blind Submission</p>
<p><strong>Samaneh Nasiri</strong> <strong>Gari Clifford</strong> </p>
<p>这项工作联合学习患者不变的表示和加权特征（谱图系数），以增强相关特征在最终模型中的贡献，并使用无监督方法减少无关特征的影响。该方法利用了从训练集到测试集的可转换和可分辨知识。</p>
<p><img src="https://jzh-markdown-pics.oss-cn-beijing.aliyuncs.com/img/image-20201214161755724.png" alt="image-20201214161755724"></p>
</blockquote>
</li>
<li><blockquote>
<p>Tri-FeatureNet: an Adversarial Learning-Based Invariant Feature Extraction for Sleep Staging Using Single-Channel EEG</p>
<p>Yiqiao Liao, Milin Zhang, Zhihua Wang , Xiang Xie</p>
<p>IEEE International Symposium on Circuits and Systems (ISCAS) 2020</p>
<p>本文提出了一种基于双向学习的特征提取算法Tri-FeatureNet，用于学习对subject和session不变性的表征。改进了算法对个体差异的鲁棒性。将不变特征与受试者特定特征和时间特征相结合，进一步补偿对抗训练过程中睡眠信息的损失。该模型同时利用了脑电信号和睡眠分期序列中的时间信息。这是第一次提出对抗性训练来提取不同受试者和不同阶段的任务相关特征。该算法已在一个便携式睡眠分级系统中实现。<br>实验结果表明，在单通道脑电信号下，82.9%的ACC在睡眠分期任务中起作用。</p>
<p><img src="https://jzh-markdown-pics.oss-cn-beijing.aliyuncs.com/img/image-20201214162748737.png" alt="image-20201214162748737"></p>
</blockquote>
</li>
<li><blockquote>
<p>Attentive Adversarial Network for Large-Scale Sleep Staging</p>
<p>Proceedings of Machine Learning Research  2020</p>
<p><strong>Samaneh Nasiri</strong> <strong>Gari D. Clifffford</strong></p>
<p>文提出了一种基于对抗训练和注意机制的方法，从不同的数据集中提取个体间的可传递信息，同时关注更重要或相关的通道和可转移的数据部分。利用两个大型的公共脑电图数据库——Physionet 2018挑战赛（P18C）数据库中的994名患者EEG（6561小时的数据）和来自睡眠心脏健康研究（SHHS）的5793名患者（42560小时）EEG——我们证明，对手学习具有注意力机制的网络，与跨数据集场景中最先进的深度学习方法相比，显著提高了性能。</p>
<p><img src="https://jzh-markdown-pics.oss-cn-beijing.aliyuncs.com/img/image-20201215131702024.png" alt="image-20201215131702024"></p>
<script type="math/tex; mode=display">
\mathcal{L}_{c h}=\frac{1}{K n} \sum_{k=1}^{K} \sum_{\mathbf{x}_{i} \in \mathcal{D}_{t r} \cup \mathcal{D}_{t e}} L_{d}\left(G_{d}^{k}\left(\mathbf{f}_{i}^{k}\right), d_{i}\right)
\\w_{i}^{k}=1-H\left(G_{d}^{k}\left(\mathbf{f}_{i}^{k}\right)\right)=1-H\left(\hat{d}_{i}^{k}\right)</script><script type="math/tex; mode=display">
\mathcal{L}_{g}=\frac{1}{n} \sum_{\mathbf{x}_{i} \in \mathcal{D}_{t r} \cup \mathcal{D}_{t e}} L_{d}\left(G_{d}\left(\mathbf{h}_{i}, d_{i}\right)\right)
\\\mathcal{L}_{a}=-\frac{1}{n} \sum_{\mathbf{x}_{i} \in \mathcal{D}_{t r} \cup \mathcal{D}_{t e}} \sum_{j=1}^{c}\left(1+H\left(\hat{d}_{i}\right)\right) \cdot \mathbf{p}_{i, j} \cdot \log \left(\mathbf{p}_{i, j}\right)</script><script type="math/tex; mode=display">
\begin{aligned} C\left(\theta_{f}, \theta_{y}, \theta_{d},\left.\theta_{d}^{k}\right|_{k=1} ^{K}\right)=& \frac{1}{n_{t r}} \sum_{\mathbf{x}_{i} \in \mathcal{D}_{t r}} L_{y}\left(G_{y}\left(G_{f}\left(\mathbf{x}_{i}\right)\right), y_{i}\right) \\ &+\frac{\gamma}{n} \sum_{\mathbf{x}_{i} \in \mathcal{D}_{t r} \cup \mathcal{D}_{t e}} \sum_{j=1}^{c}\left(1+H\left(\hat{d}_{i}\right)\right) \cdot \mathbf{p}_{i, j} \cdot \log \left(\mathbf{p}_{i, j}\right) \\ &-\frac{\lambda}{n}\left[\sum_{\mathbf{x}_{i} \in \mathcal{D}_{t r} \cup \mathcal{D}_{t e}} \mathcal{L}_{d}\left(G_{d}\left(\mathbf{h}_{i}, d_{i}\right)\right)+\frac{1}{K} \sum_{k=1}^{K} \sum_{\mathbf{x}_{i} \in \mathcal{D}_{t r} \cup \mathcal{D}_{t e}} \mathcal{L}_{d}\left(G_{d}^{k}\left(\left(G_{f}\left(\mathbf{x}_{i}\right)\right)\right)\right)\right] \end{aligned}</script></blockquote>
</li>
</ol>
]]></content>
      <categories>
        <category>jzh</category>
      </categories>
      <tags>
        <tag>EEG</tag>
        <tag>迁移学习</tag>
      </tags>
  </entry>
  <entry>
    <title>jxy 【ICLR 2022】Uncertainty Modeling for out-of-distribution generalization</title>
    <url>/2022/08/10/JinXiyuan/2022%20ICLR%20Uncertainty%20Modeling%20for%20out-of-distribution%20generalization(1)/</url>
    <content><![CDATA[<h1 id="2022-ICLR-Uncertainty-Modeling-for-out-of-distribution-generalization"><a href="#2022-ICLR-Uncertainty-Modeling-for-out-of-distribution-generalization" class="headerlink" title="2022 ICLR Uncertainty Modeling for out-of-distribution generalization"></a>2022 ICLR Uncertainty Modeling for out-of-distribution generalization</h1><h1 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1 Introduction"></a>1 Introduction</h1><p>深度神经网络在计算机视觉方面取得了令人印象深刻的成功，但严重依赖于训练和测试领域遵循独立和同分布的假设（Ben-David等人，2010；Vapnik，1992）。然而，这种假设在许多实际应用中并不成立。例如，当使用在晴天针对雨雾环境训练的分割模型时（Choi等人，2021），或使用在照片上训练的模型识别艺术画时（Li等人，2017），在这种分布外（out of distriution, OOD）的部署场景中，通常可以观察到不可避免的性能下降。因此，旨在提高网络在各种未知测试域上的鲁棒性的域泛化问题变得非常重要。</p>
<p>之前的工作（Huang&amp;Belongie，2017；Li等人，2021）表明，<strong>特征统计（均值和标准差）作为学习特征的矩，具有训练数据的域特征</strong>。域特征主要指的是更特定于各个域但与任务目标不太相关的信息，例如对象识别中的照片样式和捕获环境信息。因此，<strong>具有不同数据分布的域通常具有不一致的特征统计</strong>（Wang等人，2020b；2019a；Gao等人，2021a）。大多数深度学习方法遵循经验风险最小化原则（Vapnik，1999），以最小化其对训练数据的平均误差（Shen等人，2021）。<strong>尽管在训练域上的性能令人满意，但这些方法没有明确考虑测试过程中潜在域偏移（domain shift）引起的不确定统计差异</strong>。因此，经过训练的模型往往会过度拟合训练域，并且在测试时易受统计变化的影响，这大大限制了学习表示的泛化能力。</p>
<p><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h51nzjcn7ej212e0i878s.jpg" alt="图片"></p>
<p>2-D t-SNE（Maaten&amp;Hinton，2008）风格统计的可视化（平均值和标准偏差的串联），从在四个不同域上训练的ResNet-18的第一个剩余块特征图计算（He等人，2016）（Li等人，2017）。很明显，不同的域是完全分开的</p>
<p>直观地说，与训练域相比，<strong>测试域可能会带来具有不同潜在方向和强度的不确定性统计位移</strong>（如图1所示），<strong>这意味着域偏移的不确定性</strong>。考虑到潜在域移动的这种“不确定性”，合成新的特征统计变量来模拟不同的域移动可以提高训练网络对不同测试分布的鲁棒性。为此，我们引入了一种新的概率方法，通过适当地建模具有不确定性的域偏移（Domain Shifts with Uncertainty, DSU），即将特征统计量描述为不确定分布，来提高网络泛化能力。<br><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h51nib3cxgj20kc09ymyc.jpg" alt="图片"><br>（图1 使用预先训练的样式转换自动编码器，通过合成特征统计数据可视化重建样本。特征统计信息的图示可能在强度（intensity）和方向(direction)上发生变化（即，特征统计信息向量空间中的不同偏移）。我们还展示了通过操纵不同方向和强度的特征统计位移生成的“新”域的图像。注意：这些图像仅用于可视化，而不是输入网络进行训练。）</p>
<p>在我们的方法中，我们假设在考虑潜在不确定性后，特征统计遵循多变量高斯分布，而不是将每个特征统计视为从特征测量的确定点。将分布“中心”设置为每个特征的原始统计值，分布“范围”表示考虑潜在域移动的变化强度。这里采用不确定性估计来描述概率特征统计的分布“范围”。具体而言，我们基于小批量（minibatch）统计的方差以有效的非参数方式估计分布“范围”。随后，从估计的高斯分布中随机抽样特征统计变量，然后用于替换原始确定性值，以模拟不同的域偏移，如图2所示。由于生成的特征统计具有不同的分布可能性，可以训练模型以适当地减轻域扰动并编码更好的域不变特征。<br><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h51nzwcin5j20mq0bu404.jpg" alt="图片"><br>（图2：假设特征统计在训练期间遵循多变量高斯分布。当通过该模块时，从相应分布中随机抽取的新特征统计将取代原始特征统计，以模拟不同的域转移。）</p>
<p>我们提出的方法简单但相当有效，可以缓解域偏移造成的性能下降，并且可以很容易地集成到现有网络中，而无需引入额外的模型参数或损耗约束。在广泛的视觉任务上进行的综合实验证明了我们提出的方法的优越性，表明在特征统计中引入不确定性可以很好地提高模型对域移动的泛化能力。</p>
<h1 id="2-Related-Work"><a href="#2-Related-Work" class="headerlink" title="2 Related Work"></a>2 Related Work</h1><h1 id="3-Method"><a href="#3-Method" class="headerlink" title="3 Method"></a>3 Method</h1><h2 id="3-1-Preliminaries"><a href="#3-1-Preliminaries" class="headerlink" title="3.1 Preliminaries"></a>3.1 Preliminaries</h2><p> 给定<img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h51niao7zvj205m00ymwz.jpg" alt="图片">是网络中间层的编码特征，我们表示<img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h51niahvd9j203o010jr6.jpg" alt="图片">和<img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h51niad3zuj203k012gle.jpg" alt="图片">分别为小批量中每个实例的通道特征均值和标准偏差，其公式如下：<br>   <img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h51nia2nzrj20cq04iq35.jpg" alt="图片"></p>
<p>根据之前的工作（Huang&amp;Belongie，2017；Li等人，2021），作为特征的抽象，特征统计可以捕捉对应域的信息特征（例如颜色、纹理和对比度）。在分布外（OOD）场景中，由于不同的域特征，特征统计通常与训练域不一致（Wang等人，2019a；Gao等人，2021a），这不适用于非线性层和归一化层等深度学习模块，并降低了模型的泛化能力（Wang等，2020b）。然而，大多数深度学习方法仅将特征统计视为从特征测量的确定值，而缺乏对潜在不确定统计差异的明确考虑。<strong>由于模型对这种差异的固有脆弱性</strong>，学习表示的泛化能力受到限制。最近的一些方法（Nuriel等人，2021；Zhou等人，2021b）利用特征统计来解决领域泛化问题。尽管取得了成功，他们通常对成对样本采用线性操作（即交换和插值）来生成新的特征统计，这限制了合成变化的多样性。具体而言，其变体的方向由所选参考样本确定，并且这种内部操作限制了其变体的张力。因此，这些方法在处理现实世界中的不同和不确定的域转移时是次优的。</p>
<h2 id="3-2-MODELING-DOMAIN-SHIFTS-WITH-UNCERTAINTY"><a href="#3-2-MODELING-DOMAIN-SHIFTS-WITH-UNCERTAINTY" class="headerlink" title="3.2  MODELING DOMAIN SHIFTS WITH UNCERTAINTY"></a>3.2  MODELING DOMAIN SHIFTS WITH UNCERTAINTY</h2><p>鉴于任意测试域在方向和强度上都具有不确定的特征统计位移，正确建模域位移成为解决域泛化问题挑战的一项重要任务。</p>
<p>考虑到域偏移的不确定性和随机性，本文“不确定性”方法来处理域偏移的“不确定性”。在本文中，我们提出了一种新的方法，通过不确定性域偏移建模（DSU）。我们假设，在考虑潜在不确定性后，每个特征统计的分布遵循多变量高斯分布，而不是将每个特征统计视为从学习特征测量的确定值。这意味着每个特征统计量都有一个从特定分布中提取的概率表示，即特征统计量的平均值和标准偏差分别遵循<img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h51ni9q195j203401ct8i.jpg" alt="图片">和<img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h51ni9kmurj202o00ygle.jpg" alt="图片">。具体而言，相应的高斯分布的中心被设置为每个特征的原始统计信息，而高斯分布的标准偏差描述了不同潜在位移的不确定性范围。通过使用概率方法随机抽样不同的合成特征统计，可以训练模型，以提高网络对统计变化的鲁棒性。</p>
<h3 id="3-2-1-UNCERTAINTY-ESTIMATION"><a href="#3-2-1-UNCERTAINTY-ESTIMATION" class="headerlink" title="3.2.1 UNCERTAINTY ESTIMATION"></a>3.2.1 UNCERTAINTY ESTIMATION</h3><p>考虑到域偏移的不确定性，我们方法中的不确定性估计旨在描述每个概率特征统计量的不确定性范围。然而，测试域未知，这使得获得适当的变异范围具有挑战性（希望能够对域的特征统计量有一个范围的感知）</p>
<p>一些基于生成的研究（沈和周，2021；王等人，2019b）表明，特征之间的方差包含隐含的语义，方差较大的方向可以暗示更有价值的语义变化的潜力。受此启发，我们提出了一种简单而有效的非参数不确定性估计方法，利用特征统计的方差提供一些说明：<br><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h51ni98mqcj20bk05cq35.jpg" alt="图片"></p>
<p>其中<img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h51ni93kd9j203k00w742.jpg" alt="图片">与<img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h51ni8xk9xj203m012a9u.jpg" alt="图片"> 分别表示特征平均值µ和特征标准偏差σ的不确定性估计。不确定性估计的大小可以揭示相应信道可能发生潜在变化的可能性。尽管域位移的潜在分布是不可预测的，但从小批量中捕获的不确定性估计可以为每个特征通道提供适当且有意义的变化范围，这不会损害模型训练，但可以模拟各种潜在位移。</p>
<h3 id="3-2-2-PROBABILISTIC-DISTRIBUTION-OF-FEATURE-STATISTICS"><a href="#3-2-2-PROBABILISTIC-DISTRIBUTION-OF-FEATURE-STATISTICS" class="headerlink" title="3.2.2 PROBABILISTIC DISTRIBUTION OF FEATURE STATISTICS"></a>3.2.2 PROBABILISTIC DISTRIBUTION OF FEATURE STATISTICS</h3><p>一旦获得每个特征通道的不确定性估计，就可以建立概率特征统计的高斯分布。为了使用随机性来建模不确定性，我们采用随机抽样来进一步利用概率表示中的不确定性。新的特征统计量，均值<img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h51ni8rownj205q010mx0.jpg" alt="图片">和标准偏差<img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h51ni8xk9xj203m012a9u.jpg" alt="图片">可以从相应的分布中随机抽取，如下所示：<br><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h51ni8ebkcj20d8036jrj.jpg" alt="图片"></p>
<p>在这里，我们使用重新参数化技巧（Kingma&amp;Welling（2013））使采样操作可微，µ和σ均遵循标准高斯分布。通过利用给定的高斯分布，随机抽样可以生成具有不同方向和强度组合的各种新特征统计信息。</p>
<h3 id="3-2-3-IMPLEMENTATION"><a href="#3-2-3-IMPLEMENTATION" class="headerlink" title="3.2.3 IMPLEMENTATION"></a>3.2.3 IMPLEMENTATION</h3><p>我们的方法是通过AdaIN（Huang&amp;Belongie（2017））实现的，并用随机抽取的特征统计替换特征统计以实现转换。建议方法的最终形式可表述为：<br><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h51ni84zehj20jk02sjrm.jpg" alt="图片"></p>
<p>备注：<br>使用实例特定均值和标准偏差对特征张量进行归一化可有效去除样式转换（style transfer）模型中的图像样式（Ulyanov等人，2016；Huang&amp;Belongie，2017；Dumoulin等人，2017）。这种操作被广泛称为实例规范化（IN，Ulyanov等人（2016））。<br><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h51nrxvjxaj20ee02st8r.jpg" alt="图片"></p>
<p><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h51ns6fst0j205m01ujr8.jpg" alt="图片">为可学习的参数，</p>
<p>Huang&amp;Belongie（2017）引入了自适应实例规范化（AdaIN），它简单地将缩放和移位参数与样式输入y的特征统计重新放置在等式（1）中，以实现任意样式转换：<br><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h51nt5sp12j20ja03mwep.jpg" alt="图片"></p>
<p>可以实现向目标风格的统计量迁移</p>
<p>MixStyle(2021 ICLR)在特征统计量上实现了风格迁移：<br><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h51ntg7jvuj20gi03o0t2.jpg" alt="图片"></p>
<p><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h51ntn3qb7j20lc03wglv.jpg" alt="图片"></p>
<p>上述操作可以作为一个灵活的模块集成在网络的各个位置。请注意，该模块仅在模型训练期间工作，并且可以在测试时丢弃。为了权衡这个模块的强度，我们设置了一个超参数p，表示应用它的概率。附录中描述了算法。得益于所提出的方法，使用不确定特征统计训练的模型将获得更好的性能<br><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h51ntv7qzqj210c0qqq9j.jpg" alt="图片"></p>
<h1 id="4-EXPERIMENTS"><a href="#4-EXPERIMENTS" class="headerlink" title="4. EXPERIMENTS"></a>4. EXPERIMENTS</h1><p>为了验证所提出的方法在提高网络泛化能力方面的有效性，我们在广泛的任务上进行了实验，包括图像分类、语义分割、实例检索和对损坏的鲁棒性，其中训练集和测试集具有不同的分布变化情况，例如样式变化，合成到真实间隙、场景变化和像素级损坏。</p>
<h2 id="4-1-GENERALIZATION-ON-MULTI-DOMAIN-CLASSIFICATION"><a href="#4-1-GENERALIZATION-ON-MULTI-DOMAIN-CLASSIFICATION" class="headerlink" title="4.1  GENERALIZATION ON MULTI-DOMAIN CLASSIFICATION"></a>4.1  GENERALIZATION ON MULTI-DOMAIN CLASSIFICATION</h2><p><strong>设置和实现细节</strong>：我们在PACS（Li et al.（2017））上评估了提出的方法，PACS是一个广泛使用的领域综合基准(benchmark)，具有四种不同风格：艺术绘画(Art)、卡通(Cartoon)、照片(Photo)和草图(Sketch)，共计9991张图片和7种类别。该实现遵循MixStyle的官方设置（Zhou等人（2021b）），使用一个离开域协议（leave-one-domain-out，在三种域上训练，剩下一种做测试），并使用ResNet18（He等人，2016）作为主干(backbone)。<strong>MixStyle的随机混洗版本用于公平比较，它不使用域标签</strong>。除PACS外，我们还在附录中使用Office Home（Venkateswara等人，2017）进行多域泛化实。</p>
<p><strong>实验结果</strong>：表1所示的实验结果证明了我们对基线方法的显著改进，这表明了我们对传统确定性方法的优势。特别是在艺术和素描方面，我们的方法平均准确度提高了近10%。此外，我们的方法的性能也优于竞争方法，这表明我们在特征统计上建模不同的不确定移位的方法有效地提高了针对不同域移位的网络泛化能力。Photo具有与ImageNet数据集相似的域特征，轻微下降可能是由于ImageNet预训练（也在（Xu等人，2021）中讨论）。我们的DSU增强了功能，并扩大了培训活动的多样性。相比之下，基线方法保留了来自ImageNet的更多预训练知识，因此倾向于过度拟合受益于预训练的照片样式数据集<br><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h51nwv1om8j20t60aewip.jpg" alt="图片"></p>
<p><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h51nx6lh28j21im0fcjyx.jpg" alt="图片"></p>
<h2 id="4-2-GENERALIZATION-ON-SEMANTIC-SEGMENTATION"><a href="#4-2-GENERALIZATION-ON-SEMANTIC-SEGMENTATION" class="headerlink" title="4.2 GENERALIZATION ON SEMANTIC SEGMENTATION"></a>4.2 GENERALIZATION ON SEMANTIC SEGMENTATION</h2><h2 id="4-3-GENERALIZATION-ON-INSTANCE-RETRIEVAL"><a href="#4-3-GENERALIZATION-ON-INSTANCE-RETRIEVAL" class="headerlink" title="4.3  GENERALIZATION ON INSTANCE RETRIEVAL"></a>4.3  GENERALIZATION ON INSTANCE RETRIEVAL</h2><h2 id="4-4-ROBUSTNESS-TOWARDS-CORRUPTIONS"><a href="#4-4-ROBUSTNESS-TOWARDS-CORRUPTIONS" class="headerlink" title="4.4 ROBUSTNESS TOWARDS CORRUPTIONS"></a>4.4 ROBUSTNESS TOWARDS CORRUPTIONS</h2><h1 id="5-ABLATION-STUDY"><a href="#5-ABLATION-STUDY" class="headerlink" title="5.ABLATION STUDY"></a>5.ABLATION STUDY</h1><p>在本节中，我们利用在ResNet上训练的模型，对PACS和分段任务（GTA5到城市景观）上提出的方法进行了广泛的消融研究。下面分析所提出方法的不同插入位置和超参数的影响。同时，我们还分析了不确定性分布的不同选择的影响。</p>
<p><strong>不同插入位置的效果</strong>：DSU可以是一个即插即用模块，可以随时插入任何位置。在这里，我们将第一个Conv、最大池层、第1、2、3、4个ConvBlock之后的ResNet位置分别命名为0、1、2、、3、4、5。如表5所示，无论模块插入何处，性能始终高于基线方法。结果表明，在位置0-5插入模块将具有更好的性能，这也表明对所有训练阶段的不确定性建模将具有更好效果。根据分析，我们在所有实验中将模块插入位置0-5。<br><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h51nxgausrj20l405a0tm.jpg" alt="图片"></p>
<p><strong>超参数效应</strong>：概率p的超参数是为了权衡特征统计增强的强度。如图4所示，结果对概率设置不敏感，当p设置为0.5时，精度达到最佳结果，如果未指定，也将其作为所有实验的默认设置。<br> <img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h51nxy9txgj20dc084aax.jpg" alt="图片"></p>
<p><strong>不确定性分布的选择</strong>：在我们的方法中，采用具有不确定性估计的高斯分布作为默认设置，我们还在表6中进行其他分布的比较。具体而言，随机表示直接添加从固定高斯<img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h51ny504z6j20380180sj.jpg" alt="图片">得出的随机位移，均匀表示从<img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h51nyblqbjj203m01aglf.jpg" alt="图片">，其中∑是从我们的不确定性估计中获得的范围。如我们所见，直接使用具有不当变化范围的高斯分布将损害模型性能，这表明特征统计的变化范围应该有一些指导。<br><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h51nyjfl7ij20ne05kab2.jpg" alt="图片"></p>
<p>我们还进行了实验，以测试用不同电位处理不同通道的有效性。信道共享表示样本的所有信道共享相同的不确定性分布，即使用信道之间的平均不确定性估计。如表9所示，结果表明，在不同渠道之间共享相同的不确定性分布效果较差，这忽略了渠道的不同潜力，并将限制其性能。同时，提出的方法明确考虑了不同信道的不同潜力，并带来了更好的性能</p>
<p><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h51nyp2fafj20l803s74r.jpg" alt="图片"></p>
<h1 id="6-QUANTITATIVE-ANALYSIS-ON-THE-PROPOSED-METHOD"><a href="#6-QUANTITATIVE-ANALYSIS-ON-THE-PROPOSED-METHOD" class="headerlink" title="6.  QUANTITATIVE ANALYSIS ON THE PROPOSED METHOD"></a>6.  QUANTITATIVE ANALYSIS ON THE PROPOSED METHOD</h1><p>在本小节中，我们将分析所提出的方法对中间特征和特征表示的影响。定量实验在PACS上进行，我们选择艺术绘画（Art）作为看不见的测试域，其余部分作为训练域。</p>
<p>为了研究特征统计移位现象，我们在ResNet18中捕获第二个块后的中间特征，并分别在训练域和测试域中测量一个类别的平均特征统计值。特征统计的分布如图5所示。正如之前的工作（Wang等人，2020b；2019a）所示，从基线模型提取的特征统计由于不同的数据分布而显示出明显的变化。可以看出，用我们的方法训练的模型具有较小的偏移。我们的方法可以帮助模型获得对域偏移的鲁棒性，因为它正确地建模了潜在的特征统计偏移。<br><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h51nywxgpij20x607e3zy.jpg" alt="图片"></p>
<p><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h51nz5h07yj20mo09sjt8.jpg" alt="图片"></p>
<p>为了分析对特征表示的影响，我们使用t-SNE（Van der Maaten&amp;Hinton，2008）在看不见的域中对不同类别的特征表示向量进行了统计。得益于所提出的方法，同一类别的特征变得更加紧凑。因为我们的方法可以减轻训练期间的域扰动，并使模型专注于内容信息，获得更不变的特征表示。</p>
<h1 id="7-CONCLUSIONS"><a href="#7-CONCLUSIONS" class="headerlink" title="7. CONCLUSIONS"></a>7. CONCLUSIONS</h1><p>在本文中，我们提出了一种概率方法，通过在训练期间使用合成特征统计对域移动的不确定性进行建模来提高网络泛化能力。假设每个特征统计量遵循多变量高斯分布，以模拟不同的电位位移。由于生成的特征统计具有不同的分布可能性，因此模型可以对不同的域转移获得更好的鲁棒性。实验结果证明了该方法在提高网络泛化能力方面的有效性。</p>
]]></content>
      <categories>
        <category>靳希源</category>
      </categories>
      <tags>
        <tag>不确定性</tag>
        <tag>域偏移 - 特征统计</tag>
      </tags>
  </entry>
  <entry>
    <title>lwh 时序数据库</title>
    <url>/2021/04/09/LiWenhao/%E6%97%B6%E5%BA%8F%E6%95%B0%E6%8D%AE%E5%BA%93/</url>
    <content><![CDATA[<h2 id="1-时序场景特点"><a href="#1-时序场景特点" class="headerlink" title="1.时序场景特点"></a>1.时序场景特点</h2><ul>
<li>写入平稳、高并发高吞吐：时序数据的产生通常是以一个固定的时间频率产生，不会受其他因素的制约，其数据生成的速度是相对比较平稳的。时序数据是由每个个体独立生成，所以当个体数量众多时，写入的并发和吞吐量都是很高的</li>
<li>数据量大：每天可能会有TB，PB级的数据需要存储</li>
<li>写多读少：监控的指标很多，但是通常只关心几个特定的指标、特定的场景。</li>
<li>实时写入：时序数据的写入是实时的，且每次写入都是最近生成的数据。因为其数据生成是随着时间推进的，很少有更新删除的操作。</li>
<li>近期数据的关注度更高，时间久远的数据极少被访问，冷热分明</li>
<li>多维查询、分析</li>
</ul>
<a id="more"></a>
<h2 id="2-对时序数据库的要求"><a href="#2-对时序数据库的要求" class="headerlink" title="2.对时序数据库的要求"></a>2.对时序数据库的要求</h2><ul>
<li>高吞吐、高并发的写入能力：时序数据具有典型的写多读少特征，在读和写上，首要权衡的是写的能力。对于数据库的高并发、高吞吐写入能力有很高的要求。</li>
<li>高可用：分布式架构，系统要具有水平扩展的能力。</li>
<li>数据分级存储 ：将最近小时级别的数据放到内存中，将最近天级别的数据放到SSD，更久远的数据放到更加廉价的HDD或者直接使用TTL过期淘汰掉。</li>
<li>高压缩率：一方面是节省成本，另一个方面是压缩后的数据可以更容易保证存储到内存中</li>
<li>多维度查询、聚合：交互级的查询延迟，并且是在数据基数（TB级）较大的情况下，也能够达到很低的查询延迟。在很大的数据量的基础上将满足条件的原始数据查询出来并聚合，原始值可能因为时间比较久远而不在内存。</li>
</ul>
<h2 id="3-时序建模"><a href="#3-时序建模" class="headerlink" title="3.时序建模"></a>3.时序建模</h2><h3 id="核心概念"><a href="#核心概念" class="headerlink" title="核心概念"></a>核心概念</h3><ul>
<li>metric   采集的数据指标</li>
<li>tag    标签</li>
<li>field    域</li>
<li>timestamp    时间戳</li>
</ul>
<p><img src="https://gitee.com/lwh233/blogimage/raw/master/img/image-20210405164517997.png" alt=""></p>
<h3 id="按数据源建模"><a href="#按数据源建模" class="headerlink" title="按数据源建模"></a>按数据源建模</h3><p><img src="C:\Users\16281\AppData\Roaming\Typora\typora-user-images\image-20210407153555192.png" alt="image-20210407153555192" style="zoom: 80%;" /><img src="https://gitee.com/lwh233/blogimage/raw/master/img/image-20210407153555192.png" alt=""></p>
<p><img src="https://gitee.com/lwh233/blogimage/raw/master/img/v2-a9b615e76149a9ef71b3ab67c3d0fb58_r.jpg" style="zoom: 50%;" /></p>
<h3 id="按指标建模"><a href="#按指标建模" class="headerlink" title="按指标建模"></a>按指标建模</h3><p><img src="https://gitee.com/lwh233/blogimage/raw/master/img/image-20210407153430628.png" style="zoom:50%;" /></p>
<p><img src="https://gitee.com/lwh233/blogimage/raw/master/img/v2-4eabe030c388f195f9a04674da5a86c5_r.jpg" style="zoom:50%;" /></p>
<h2 id="4-时序数据库分类"><a href="#4-时序数据库分类" class="headerlink" title="4.时序数据库分类"></a>4.时序数据库分类</h2><p>第一种，在关系数据库基础上进行改进的时序数据库，比如基于PG开发的Timescale。</p>
<p>第二种，在KV数据库的基础之上进行改进的时序数据库，比如，基于HBase开发的OpenTSDB、基于Cassandra的KairosDB</p>
<p>第三种，为时序数据量身定制的时序数据库，InfluxDB、ApacheIoTDB等</p>
<h2 id="5-时序数据为什么不适合存在关系型数据库"><a href="#5-时序数据为什么不适合存在关系型数据库" class="headerlink" title="5.时序数据为什么不适合存在关系型数据库"></a>5.时序数据为什么不适合存在关系型数据库</h2><ul>
<li>存储成本大 对时序数据的压缩不佳</li>
<li>维护成本高 单机系统</li>
<li>写入吞吐差 单机写入吞吐低，无法满足千万级的写入压力</li>
<li>查询性能差  适用于交易处理，海量数据的聚合能力差</li>
</ul>
<p><strong>基于B/B+树</strong>:造成很多随机IO 存储的地址不连续-&gt;关系型数据库写入速度慢</p>
<p><img src="https://gitee.com/lwh233/blogimage/raw/master/img/v2-467b2c27f41bad29b01be13e1e5cd1bb_b.gif" alt=""></p>
<p>如果一个节点已经写入磁盘了，后面树形发生变化之后，节点分裂，原先存储到一个磁盘块的数据，就会分开存储到2个新的磁盘块，那么原先的磁盘块就要删除。这样反复的操作，那就造成了Btree/B+tree很多的随机IO</p>
<h2 id="6-LSM-tree"><a href="#6-LSM-tree" class="headerlink" title="6.LSM tree"></a>6.LSM tree</h2><p><strong>核心思路：</strong>假定内存足够大，因此不需要每次有数据更新就必须将数据写入到磁盘中，而可以先将最新的数据驻留在内存中，等到积累到足够多之后，再使用归并排序的方式将内存内的数据合并追加到磁盘队尾。放弃部分读能力，换取写能力。</p>
<p><strong>WAL</strong> 预写log 。当插入一条数据时，数据先顺序写入 WAL 文件中，之后插入到内存中的 MemTable 中。这样就保证了数据的持久化，不会丢失数据，并且都是顺序写，速度很快。</p>
<p><strong>MemTable: </strong>对应的就是 WAL 文件，是该文件内容在内存中的存储结构。写入操作会直接将数据写入到Memtable后返回。读取操作又会首先尝试从Memtable中进行查询，允许写入和读取。当Memtable写入的数据占用内存到达指定数量，则自动转换为Immutable Memtable，等待Dump到磁盘中，系统会自动生成新的Memtable供写操作写入新数据。</p>
<p><strong>SSTable:</strong> 是 MemTable 中的数据在磁盘上的有序存储，其内部数据是根据 key 从小到大排列的。通常为了加快查找的速度，需要在 SSTable 中加入数据索引，可以快读定位到指定的 k-v 数据</p>
<p><img src="https://gitee.com/lwh233/blogimage/raw/master/img/1329243358-5d94891acb4a2_fix732" alt=""></p>
<h2 id="7-基于kv"><a href="#7-基于kv" class="headerlink" title="7.基于kv"></a>7.基于kv</h2><p>​    基于LSM设计的面向分布式场景的HBase，再基于HBase设计了openTSDB。这类时序数据库都是采用了一个比较成熟的数据库来作为底层存储引擎。自己的主要逻辑仅仅是在存储引擎层之上很薄的一个逻辑层</p>
<h4 id="基于HBase的数据库的问题？"><a href="#基于HBase的数据库的问题？" class="headerlink" title="基于HBase的数据库的问题？"></a><strong>基于HBase的数据库的问题？</strong></h4><ul>
<li>为了套用HBase结构，存储中有很多无用的信息。Rowkey里面的metric是一个业务字符串，这些数据在实际存储过程中很多冗余，造成存储成本的浪费</li>
<li>数据采集指标冗余</li>
<li>HBase是弱类型问题，不能对Value部分根据业务的不同字段类型进行专门的压缩</li>
<li>Rowkey部分包含很多tag信息，没有对Rowkey和tag进行倒排索引，不能完全保证多维度的查询能力</li>
</ul>
<h4 id="openTSDB的优化："><a href="#openTSDB的优化：" class="headerlink" title="openTSDB的优化："></a><strong>openTSDB的优化：</strong></h4><ul>
<li>时间粒度为小时，每次读一个小时</li>
<li>将业务字符串映射为uid，简化存储</li>
</ul>
<p><img src="https://gitee.com/lwh233/blogimage/raw/master/img/td6.png" alt=""></p>
<h2 id="8-原生时序数据库"><a href="#8-原生时序数据库" class="headerlink" title="8.原生时序数据库"></a>8.原生时序数据库</h2><p>基于LSM设计面向时序数据的influxDb,ioTDB</p>
<h4 id="influxdb-tsm"><a href="#influxdb-tsm" class="headerlink" title="influxdb(tsm)"></a>influxdb(tsm)</h4><ul>
<li><p>tags不再冗余存储 metric+tag -&gt; series key</p>
</li>
<li><p>数据分区：按不同的时间范围划分为不同的分区（Shard），写入通常是在最新的分区，而不会散列到多个分区。分区的优点是数据回收的物理删除非常简单，直接把整个分区删除即可</p>
</li>
<li><p>针对时序和不同类型的压缩方案 delta-delta</p>
<ul>
<li><img src="https://gitee.com/lwh233/blogimage/raw/master/img/image-20210406103056005.png" alt=""></li>
<li><img src="https://gitee.com/lwh233/blogimage/raw/master/img/image-20210406103123647.png" alt=""></li>
<li>时间戳8byte-&gt; 64bit 最大间隔3600秒-&gt;13bit</li>
<li>delta 64 + 13 *7 = 155bit</li>
<li>delta of delta 64 + 9 <em> 4 + 1 </em> 3 = 103bit</li>
</ul>
</li>
<li><p>倒排索引 高效查找 </p>
</li>
<li><p>对cache的设计：Cache内部提供了一个ring结构，取series key前8个bit进行hash,来对数据进行分桶/分区管理，降低读写时候锁的竞争。确保连续数据存储在一个磁盘块。</p>
<ul>
<li><img src="https://gitee.com/lwh233/blogimage/raw/master/img/image-20210407155516363.png" style="zoom:50%;" /></li>
</ul>
</li>
<li><p>对于时序实用的功能:</p>
<ul>
<li>ContinuousQueries，每小时触发一次，每次待计算数据区间是90分钟，分组区间是30分钟</li>
</ul>
</li>
</ul>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p>时序数据库技术体系－时序数据存储模型设计:<a href="http://hbasefly.com/2017/11/19/timeseries-database-2/">http://hbasefly.com/2017/11/19/timeseries-database-2/</a></p>
<p>No.1-时序数据库随笔 - Time Series DBMS 综述:<a href="https://developer.aliyun.com/article/782579?spm=a2c6h.13262185.0.0.60b372994locIc">https://developer.aliyun.com/article/782579?spm=a2c6h.13262185.0.0.60b372994locIc</a></p>
<p>Writing a Time Series Database from Scratch:<a href="https://fabxc.org/tsdb/">https://fabxc.org/tsdb/</a></p>
<p>时间序列数据的存储和计算 - 概述:<a href="https://zhuanlan.zhihu.com/p/32709932">https://zhuanlan.zhihu.com/p/32709932</a></p>
<p>B+tree:<a href="https://zhuanlan.zhihu.com/p/149287061">https://zhuanlan.zhihu.com/p/149287061</a></p>
<p>delta-of-delta编码:<a href="https://blog.csdn.net/yapuge/article/details/102765248">https://blog.csdn.net/yapuge/article/details/102765248</a></p>
]]></content>
      <categories>
        <category>lwh</category>
      </categories>
      <tags>
        <tag>时间序列</tag>
      </tags>
  </entry>
  <entry>
    <title>lyx GAN ensemble for anomaly detection</title>
    <url>/2021/10/21/LiuYunxiao/2021_(AAAI)_Han_GAN%20Ensemble%20for%20Anomaly%20Detection/</url>
    <content><![CDATA[<h1 id="1-研究背景"><a href="#1-研究背景" class="headerlink" title="1.研究背景"></a>1.研究背景</h1><p>当异常检测形式化为一个无监督的学习问题时，通常需要模型学习正常数据的分布。基于GAN的方法以及改进版本已经被提出。很多工作主要是修改生成器的结构。</p>
<a id="more"></a> 
<h1 id="2-研究动机"><a href="#2-研究动机" class="headerlink" title="2.研究动机"></a>2.研究动机</h1><p>GAN方法存在模式塌陷以及训练不稳定的问题。</p>
<p>图像生成任务中相关的研究表明GAN集成通常比单个GAN更加稳定。</p>
<p>因此，本研究提供了构造基于GAN的异常检测方法进行集成，从而更好提高异常检测性能。</p>
<h1 id="3-基于GAN的异常检测集成方法"><a href="#3-基于GAN的异常检测集成方法" class="headerlink" title="3. 基于GAN的异常检测集成方法"></a>3. 基于GAN的异常检测集成方法</h1><h2 id="3-1-基于GAN的异常检测模型"><a href="#3-1-基于GAN的异常检测模型" class="headerlink" title="3.1 基于GAN的异常检测模型"></a>3.1 基于GAN的异常检测模型</h2><p>基于GAN的异常检测模型通常包含一个编码-解码结构的生成器和一个分类模型作为解码器。现有的一些基于GAN的异常检测模型都可以统一到这个框架中 (f-AnoGAN, EGBAD, GANomaly, Skip-GANomaly等)。</p>
<p><strong>生成器</strong>：通常由一个编码网络和一个解码网络组成</p>
<p>​            编码网络：$G<em>{e}(\cdot,\phi):\mathbb{R}^d \rightarrow \mathbb{R}^{d’}$，解码网络： $G</em>{d}(\cdot,\psi):\mathbb{R}^{d’} \rightarrow \mathbb{R}^{d}$;</p>
<p>​                                 $\bold{z}=G<em>{e}(\bold{x},\phi) , \tilde{\bold{x}}=G</em>{d}(\bold{z},\psi)$</p>
<p><strong>鉴别器</strong>：$D(\cdot,\gamma): \mathbb{R}^d \rightarrow \mathbb{R}$</p>
<p>基于GAN的异常检测模型通常会考虑以下四种损失函数：</p>
<ol>
<li>对抗损失<ol>
<li>vanilla GAN：$L_{a-g}(\bold{x}) = \log {D(x)+\log ({1-D(G_d(G_e(\bold{x})))}})$</li>
<li>WGAN：$L_{a-wg}(\bold{x}) = D(\bold{x}) + D(G_d(\tilde{\bold{z}}))$</li>
<li>BiGAN：$L_{a-bg}(\bold{x}) = \log {D(\bold{x}, G_e(\bold{x}))+\log ({1-D(G_d(G_d(\tilde{\bold{z}}),\tilde{\bold{z}})}})$</li>
</ol>
</li>
<li>重构损失：$L_r(\bold{x})=||\bold{x}-G_d(G_e(\bold{x}))||_l^{l}$</li>
<li>鉴别损失：$L_d(\bold{x})=||f_D(\bold{x})-f_D(G_d(G_e(\bold{x})))||_l^{l}$</li>
<li>编码损失：$L_e(\bold{x})=||G_e(\bold{x};\phi)-G_e(G_d(G_e(\bold{x};\phi));\tilde{\phi})||_l^l$</li>
</ol>
<p>为训练鉴别器，这些GAN的模型需要最小化对抗损失；</p>
<script type="math/tex; mode=display">
\max_\limits{\gamma} \quad \sum_{i=1}^{N}L_a(\bold{x}_i;\phi, \psi, \gamma)</script><p>而为了训练生成器，这些GAN模型需要最小化上面提到的四种损失函数。</p>
<script type="math/tex; mode=display">
\min_\limits{\phi, \psi, \tilde{\phi}} \quad \sum_{i=1}^{N} \alpha_1 L_a(\bold{x}_i;\phi, \psi, \gamma)
+\alpha_2 L_r(\bold{x}_i;\phi, \psi)
+\alpha_3 L_e(\bold{x}_i;\phi, \psi, \tilde{\phi})
+ \alpha_4 L_d(\bold{x}_i;\phi, \psi, \gamma) \\</script><p>训练完成之后，异常分数通常是重构误差和鉴别损失的加权和：</p>
<script type="math/tex; mode=display">
A(\bold{x}’)=L_r(\bold{x}’) + \beta L_d(\bold{x}’ )</script><p>几个基于GAN的异常检测方法：</p>
<p><strong>f-AnoGAN</strong></p>
<p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/image-20211021114049170.png" alt="image-20211021114049170"></p>
<p><strong>鉴别器</strong>：</p>
<script type="math/tex; mode=display">
\max_\limits{\gamma} \quad \sum_{i=1}^{N}L_a(\bold{x}_i;\phi, \psi, \gamma)\\</script><p>采用WGAN的对抗损失$L_{a-bg}(\bold{x}) = \log {D(\bold{x}, G_e(\bold{x}))+\log ({1-D(G_d(G_d(\tilde{\bold{z}}),\tilde{\bold{z}})}})$。</p>
<p><strong>生成器</strong>：</p>
<script type="math/tex; mode=display">
\min_\limits{\phi, \psi, \tilde{\phi}} \quad \sum_{i=1}^{N} \alpha_1 L_a(\bold{x}_i;\phi, \psi, \gamma)
+\alpha_2 L_r(\bold{x}_i;\phi, \psi)
+\alpha_3 L_e(\bold{x}_i;\phi, \psi, \tilde{\phi})
+ \alpha_4 L_d(\bold{x}_i;\phi, \psi, \gamma) \\
\alpha_2 = \alpha_3 =  \alpha_4 = 0;</script><p>生成器只利用了对抗损失。</p>
<p>然后固定鉴别器和生成器，以$\alpha_1=\alpha_3=0$训练编码器。</p>
<p><strong>EGBAN</strong></p>
<p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/image-20211021114208417.png" alt="image-20211021114208417"></p>
<p><strong>鉴别器</strong>：</p>
<script type="math/tex; mode=display">
\max_\limits{\gamma} \quad \sum_{i=1}^{N}L_a(\bold{x}_i;\phi, \psi, \gamma)\\</script><p>采用BiGAN的对抗损失$L_{a-bg}(\bold{x}) = \log {D(\bold{x}, G_e(\bold{x}))+\log ({1-D(G_d(G_d(\tilde{\bold{z}}),\tilde{\bold{z}})}})$。</p>
<p><strong>生成器</strong>：</p>
<script type="math/tex; mode=display">
\min_\limits{\phi, \psi, \tilde{\phi}} \quad \sum_{i=1}^{N} \alpha_1 L_a(\bold{x}_i;\phi, \psi, \gamma)
+\alpha_2 L_r(\bold{x}_i;\phi, \psi)
+\alpha_3 L_e(\bold{x}_i;\phi, \psi, \tilde{\phi})
+ \alpha_4 L_d(\bold{x}_i;\phi, \psi, \gamma) \\
\alpha_2 = \alpha_3 = \alpha_4 = 0;</script><p>生成器只利用了对抗损失。</p>
<p><strong>GANomaly</strong></p>
<p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/image-20211021114227885.png" alt="image-20211021114227885"></p>
<p><strong>鉴别器</strong>：</p>
<script type="math/tex; mode=display">
\max_\limits{\gamma} \quad \sum_{i=1}^{N}L_a(\bold{x}_i;\phi, \psi, \gamma)\\</script><p>采用VanillaGAN的对抗损失$L_{a-g}(\bold{x}) = \log {D(x)+\log ({1-D(G_d(G_e(\bold{x})))}})$。</p>
<p><strong>生成器</strong>：</p>
<script type="math/tex; mode=display">
\min_\limits{\phi, \psi, \tilde{\phi}} \quad \sum_{i=1}^{N} \alpha_1 L_a(\bold{x}_i;\phi, \psi, \gamma)
+\alpha_2 L_r(\bold{x}_i;\phi, \psi)
+\alpha_3 L_e(\bold{x}_i;\phi, \psi, \tilde{\phi})
+ \alpha_4 L_d(\bold{x}_i;\phi, \psi, \gamma) \\</script><p>生成器利用了上述所说的各种损失函数，唯一例外的是异常分数使用了$L_r$。</p>
<p><strong>Skip-GANomaly</strong></p>
<p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/image-20211021114337312.png" alt="image-20211021114337312"></p>
<p>训练生成器的时候没有使用编码误差。</p>
<h2 id="3-2-基于GAN异常检测算法的集成学习"><a href="#3-2-基于GAN异常检测算法的集成学习" class="headerlink" title="3.2 基于GAN异常检测算法的集成学习"></a>3.2 基于GAN异常检测算法的集成学习</h2><p>一组生成器：</p>
<p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/image-20211021114411780.png" alt="image-20211021114411780"></p>
<p>一组鉴别器：</p>
<p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/image-20211021114423492.png" alt="image-20211021114423492"></p>
<p>将生成器和鉴别器两类配对，将索引为(i,j)的生成器和鉴别器对的对抗损失和鉴别损失记做：</p>
<p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/image-20211021114434333.png" alt="image-20211021114434333"></p>
<p>类似的，将每个生成器的重构损失和编码损失记为：</p>
<p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/image-20211021114445317.png" alt="image-20211021114445317"></p>
<p><strong>集成GAN异常检测的目标是：</strong></p>
<p>最大化对抗损失的和训练鉴别器，同时最小化生成器的损失训练鉴别器：</p>
<p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/image-20211021114523041.png" alt="image-20211021114523041"></p>
<p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/image-20211021114532072.png" alt="image-20211021114532072"></p>
<p>异常评分是来自多个生成器和鉴别器的平均：</p>
<p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/image-20211021114542638.png" alt="image-20211021114542638"></p>
<h1 id="4-实验评估"><a href="#4-实验评估" class="headerlink" title="4. 实验评估"></a>4. 实验评估</h1><h2 id="4-1-数据集"><a href="#4-1-数据集" class="headerlink" title="4.1 数据集"></a>4.1 数据集</h2><ul>
<li>KDD99 </li>
<li>OCT</li>
<li>MNIST</li>
<li>CIFAE-10</li>
</ul>
<h2 id="4-2-对比方法"><a href="#4-2-对比方法" class="headerlink" title="4.2 对比方法"></a>4.2 对比方法</h2><ul>
<li>f-AnoGAN</li>
<li>EGBAD </li>
<li>GANomaly </li>
<li>Skip-GANomaly</li>
</ul>
<p>实验设置：所有的实验都是利用3个生成器和3个鉴别器，即$I=J=3$。</p>
<h2 id="4-3-性能比较"><a href="#4-3-性能比较" class="headerlink" title="4.3 性能比较"></a>4.3 性能比较</h2><p><strong>MNIST数据集上构造了10个异常检测任务，每类数字作为异常类，其余的9类作为正常数据。性能如表1所示。</strong></p>
<p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/image-20211021114553207.png" alt="image-20211021114553207"></p>
<p><strong>CIFAR10数据集上也是构造了10个异常检测任务。结果如表2所示。</strong></p>
<p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/image-20211021114609434.png" alt="image-20211021114609434"></p>
<p><strong>OCT数据集，三类任务</strong></p>
<p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/image-20211021114618807.png" alt="image-20211021114618807"></p>
<p><strong>KDD99数据集</strong></p>
<p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/image-20211021114627399.png" alt="image-20211021114627399"></p>
<h2 id="4-4-集成大小分析"><a href="#4-4-集成大小分析" class="headerlink" title="4.4 集成大小分析"></a>4.4 集成大小分析</h2><p>生成模型和鉴别模型的数目在{1,3,5,7}之间变化。</p>
<p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/image-20211021114638379.png" alt="image-20211021114638379"></p>
<h2 id="4-5-Encoding-vector和hidden-vector分析"><a href="#4-5-Encoding-vector和hidden-vector分析" class="headerlink" title="4.5 Encoding vector和hidden vector分析"></a>4.5 Encoding vector和hidden vector分析</h2><p>Encoding vector：指的是从编码器的编码输出</p>
<p>hidden vector： 指的是鉴别器最后一个隐层的输出</p>
<p>集成模型的Encoding vector 和hidden vector取得是多个模型的平均。</p>
<ul>
<li>如图4(a),4(b)所示，正常样本和异常样本的encoding vector混合在一起。意味着重构误差并不能将异常和正常样本分开。</li>
<li>如图4(b)所示，在基模型的鉴别器中，训练样本和测试样本得到了不同的表示，意味着单个模型的鉴别器可能会过拟合训练数据。而如图4(e)所示，集成训练展示了训练数据和测试数据的表示是类似的。</li>
<li>如图4(c)所示，单个模型的鉴别器不能区分测试正常和异常样本，图4(f)所示，异常和正常似乎有一些区分。</li>
</ul>
<p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/image-20211021114655086.png" alt="image-20211021114655086"></p>
<h2 id="4-6-参数-beta"><a href="#4-6-参数-beta" class="headerlink" title="4.6 参数$\beta$"></a>4.6 参数$\beta$</h2><p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/image-20211021114708627.png" alt="image-20211021114708627"></p>
<p>$\beta$：表示重构损失与鉴别损失的相对权重。</p>
<p>随着$\beta$值的增加，鉴别损失对于异常评分的贡献越大，检测性能提高。说明鉴别损失对于异常检测是重要的。</p>
<p>与基模型相比，对于大的$\beta$值，集成模型提升更多。表明集成模型主要是提高了基模型的鉴别损失。</p>
<h1 id="5-总结"><a href="#5-总结" class="headerlink" title="5. 总结"></a>5. 总结</h1><ul>
<li>本文对现有的基于GAN的异常检测方法进行了框架统一；</li>
<li>本文主要介绍了将现有的基于GAN的异常检测算法的集成方法；</li>
<li>本文在多个领域的实验结果表明集成方法确实得到了更好的性能。并且也从编码向量和隐向量的角度验证了理论分析以及集成学习的益处。</li>
</ul>
]]></content>
      <categories>
        <category>lyx</category>
      </categories>
      <tags>
        <tag>异常检测</tag>
        <tag>GAN</tag>
      </tags>
  </entry>
  <entry>
    <title>【ICLR2019】mpt Integrating Physiological Time Series and Clinical Notes with Deep Learning for Improved ICU Mortality Prediction</title>
    <url>/2021/10/21/MaPeitao/2021Integrating%20Physiological%20Time%20Series%20and%20Clinical%20Notes/</url>
    <content><![CDATA[<h1 id="不规则采样时间序列的插值预测网络"><a href="#不规则采样时间序列的插值预测网络" class="headerlink" title="不规则采样时间序列的插值预测网络"></a>不规则采样时间序列的插值预测网络</h1><h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a><strong>摘要</strong></h3><p>本文提出了一种新的<strong>深度学习体系结构</strong>,来解决具有<strong>稀疏和不规则采样</strong>的<strong>多元时间序列</strong>的<strong>监督学习</strong>问题。该架构基于<strong>插值网络</strong>的使用，随后是<strong>预测网络</strong>的应用。</p>
<ul>
<li><strong>插值网络</strong>允许在插值阶段<strong>跨多元时间序列的多个维度共享信息</strong>，而任何<strong>标准深度学习模型</strong>都可以用于<strong>预测网络</strong>。这项工作的动机是分析电子健康记录中的<strong>生理时间序列数据</strong>，这些数据是稀疏的、不规则采样的和多变量的。我们研究了这个架构在<strong>分类和回归任务上的性能</strong>，表明我们的方法优于一系列基线和最近提出的模型。</li>
</ul>
<a id="more"></a>
<h3 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a><strong>介绍</strong></h3><p>在过去几年中，在开发专门的模型和架构方面取得了重大进展，这些模型和架构可以适应<strong>稀疏和不规则采样的时间序列</strong>作为输入。</p>
<ul>
<li><strong>不规则采样的时间序列</strong>是指在其<strong>观测时间之间</strong>具有<strong>不规则间隔</strong>的样本序列。当<strong>连续观测</strong>之间的<strong>间隔</strong>通常很<strong>大</strong>时，不规则采样的数据被认为是<strong>稀疏</strong>的。在<strong>监督学习设置中特别感兴趣</strong>的是直接使用多元稀疏和不规则采样时间序列作为输入来<strong>执行端到端学习的方法</strong>，而<strong>不需要</strong>单独的插值或插补步骤。</li>
<li>在这项工作中，我们提出了一个新的模型架构，用于监督学习多元稀疏和不规则采样数据的插值预测网络。该架构基于使用<strong>组织成插值网络的几个半参数插值层</strong>，然后应用可以<strong>利用任何标准深度学习模型的预测网络</strong>。</li>
<li>在这项工作中，我们使用<strong>GRU网络</strong>作为预测网络。<strong>插值网络允许包含</strong>在每个输入时间序列中的信息有助于模型中所有其他时间序列的<strong>插值。插值和预测网络的参数通过由</strong>监督和非监督成分组成的复合目标函数被<strong>端到端地学习。</strong></li>
<li>医院系统捕捉<strong>密集</strong>的生理数据流仍然很少。相反，电子健康记录中的生理时间序列数据通常<strong>既稀疏又不规则采样</strong>。观察时间在<strong>生理变量之间缺乏一致性</strong>的额外问题也非常普遍。</li>
</ul>
<h3 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a><strong>相关工作</strong></h3><p>这项工作感兴趣的问题是从<strong>稀疏和不规则采样的多元时间序列中学习监督机器学习模型</strong>。如引言中所述，稀疏且不规则采样的时间序列是指在其<strong>观测时间之间具有大且不规则间隔的样本序列</strong>。这种数据通常出现在<strong>电子健康记录中</strong>，对于<strong>监督和非监督学习</strong>方法来说，这都是一个重大问题。稀疏和不规则采样的时间序列数据也出现在一系列具有类似复杂观测过程的其他领域，包括气候科学、生态学、生物学和天文学。</p>
<p>一个密切相关(但不同)的问题是在<strong>存在缺失数据的情况下执行监督学习</strong>。主要区别在于缺失数据问题通常是相对于固定维特征空间定义的。<strong>在不规则采样的时间序列问题中，观测值通常出现在连续时间内</strong>，对于某些域可能没有“正常”或“预期”采样频率的概念。</p>
<p>在监督学习中<strong>处理缺失数据的方法</strong>包括<strong>插补</strong>方法的预应用和<strong>特征和标签的联合学习</strong>模型。联合模型可以通过<strong>生成学习</strong>来优化特征和标签的联合似然性，也可以通过<strong>区分学习</strong>来优化标签的条件似然性。通过将<strong>时间轴离散成不重叠的区间，可以将不规则采样问题转化为缺失数据问题</strong>。然后，<strong>没有观测值的区间被称为包含缺失值</strong>。这种方法强制选择离散化间隔长度。</p>
<ul>
<li>当间隔很长时，丢失的数据会更少，但在同一间隔内也可以有多个观察值，这必须使用临时方法进行说明。</li>
<li>当间隔较短时，大多数间隔最多包含一个值，但许多间隔可能为空。</li>
</ul>
<p>将<strong>不规则采样问题转化为丢失数据</strong>问题的另一种选择是构建能够<strong>直接使用不规则采样的时间序列作为输入的模型</strong>。机器学习和统计文献包括几个具有这种能力的模型。在<strong>概率环境</strong>下，<strong>高斯过程模型</strong>能够通过使用<strong>均值和协方差</strong>函数来表示<strong>连续</strong>时间数据(Rasmussen，2006)。这些模型具有类似于用<strong>核</strong>来定义的非概率类似物。例如，Lu等人。提出了一种基于核的方法，可用于产生<strong>两个不规则采样时间序列之间的相似性函数</strong>。Li&amp;Marlin随后将该方法推广到高斯过程模型之间的核的情况。Li&amp;Marlin展示了如何使用重新参数化技巧来扩展这些想法，以实现对堆叠在高斯过程层之上的深度神经网络模型(前馈、卷积或递归)的端到端训练。</p>
<p>另一项单独的工作着眼于使用<strong>更多的局部插值方法</strong>，同时仍然直接在<strong>连续时间输入</strong>上操作。例如，Che等人提出了几种基于<strong>门控递归单元(GRU)网络</strong>的方法，并结合了简单的推算方法，包括<strong>平均推算和用过去值向前填充</strong>。Che等人还考虑了一种方法，该方法将由<strong>观测值</strong>和观测这些值的<strong>时间戳</strong>组成的序列作为输入。先前观察到的输入值随着时间向总体平均值<strong>衰减</strong>。</p>
<p>这些<strong>现有方法</strong>在<strong>插值层内使用高斯过程</strong>表示。由此产生的计算可能是昂贵的，并且如上所述，在多变量情况下的协方差函数的设计可能是具有挑战性的。相比之下，我们提出的模型使用了<strong>半参数、确定性、前馈插值层</strong>，允许在层内和层间进行非常灵活的插值。我们的体系结构中的插值层产生<strong>规则采样的插值</strong>，可以作为任意的、未修改的、深度分类和回归网络的输入。这与切等人的做法形成了鲜明对比。其中直接修改了循环网络架构，降低了该方法的模块性。最后，与Lipton等人类似。我们的模型包括有关<strong>观测发生的时间的信息</strong>。然而，我们使用<strong>半参数强度函数</strong>将观测事件序列直接建模为<strong>连续时间点过程</strong>，而<strong>不是预先</strong>离散化输入并根据二进制观测掩模或一组缺失数据指标来查看这些信息。</p>
<h3 id="符号"><a href="#符号" class="headerlink" title="符号"></a><strong>符号</strong></h3><ul>
<li>设D={(Sn，yn)|n=1，…，N}表示包含<strong>N个数据案例</strong>的数据集。单个数据案例包括单个<strong>目标值yn</strong>(分类时为<strong>离散值</strong>，回归情况下为<strong>实值</strong>)，以及多维、稀疏和不规则采样的多变量时间序列<strong>sn</strong>。多变量时间序列的<strong>不同维度d</strong>可以在不同的时间具有观测值，以及不同的观测总数<strong>Ldn</strong>。因此，我们将n个数据案例的时间序列d表示为tuple，<strong>sdn=(tdn，xdn)</strong>，其中tdn=[t1dn，…，tLdndn]是定义<strong>观测的时间点列表</strong>，xdn=[x1dn，…，xLdndn]是相应的<strong>观测值</strong>列表。</li>
</ul>
<h3 id="模型体系结构"><a href="#模型体系结构" class="headerlink" title="模型体系结构"></a><strong>模型体系结构</strong></h3><ul>
<li>结构由<strong>两个主要组件</strong>组成：<strong>插值网络和预测网络</strong>。插值网络相对于一组<strong>参考时间点r</strong>=[r1，…，rt]对多变量、稀疏和不规则采样的输入时间序列<strong>进行插值</strong>。我们假设所有的时间序列都定义在一个<strong>共同的时间间隔内</strong>(例如，对于MIMIC-III数据集，在入院后的<strong>第一个24或48小时内</strong>)。在这项工作中，两层内插网络，每一层执行<strong>不同类型的内插</strong>。</li>
<li>第二个部件是预测网络，它将<strong>插值网络的输出作为其输入</strong>，并产生目标变量的预测<strong>yn</strong>。<strong>预测网络可以由任何标准的监督神经网络结构(全连接前馈、卷积、递归等)组成</strong>。因此，就<strong>不同</strong>预测网络的使用而言，该体系结构是完全模块化的。为了训练内插网络，除了来自预测网络的监督学习信号之外，该体系结构还包括自动编码组件以提供非监督学习信号。</li>
</ul>
<h3 id="插值网络"><a href="#插值网络" class="headerlink" title="插值网络"></a><strong>插值网络</strong></h3><p>插值网络的<strong>目标</strong>是<strong>提供</strong>在<strong>参考时间点r</strong>=[r1，…，rt]定义的<strong>每个D维多变量输入时间序列</strong>的<strong>插值的集合</strong>。在这项工作中，我们对每个<strong>D维输入时间序列</strong>使用总计C=3的<strong>输出</strong>。</p>
<ul>
<li>这<strong>三个输出</strong>捕获<strong>平滑趋势、瞬变和观测强度信息</strong>。我们定义fθ为插值网络输出S’n的函数，输出S’n是一个固定大小数组，对于所有输入Sn，其维数(DC)×T。</li>
</ul>
<p>插值网络中的<strong>第一层</strong>分别对<strong>每个时间序列</strong>执行<strong>三个半参数单变量变换</strong>。<strong>每个变换</strong>都基于一个<strong>径向基函数</strong>(RBF)网络，以适应<strong>连续时间观测</strong>。变换是<strong>低通(或平滑)</strong>插值<strong>σ</strong>d、<strong>高通(或非平滑)</strong>插值<strong>γd</strong>和<strong>强度函数λd</strong>。对于每个数据情况和每个输入时间序列d，这些变换在参考时间点计算。平滑插值<strong>σ</strong>d使用具有参数αd的<strong>RBF核</strong>，而非平滑插值γd使用具有参数κ*αd的RBF核，κ&gt;1。</p>
<ul>
<li>径向基函数核（RBF kernel），也被称为高斯核或平方指数核是常见的核函数。RBF核被应用各类核学习算法中，包括支持向量机、高斯过程回归等。</li>
<li>径向基函数 (RBF), 通常定义为空间中任一点x到某一中心xc之间欧氏距离的单调函数。<strong>径向基函数插值法</strong></li>
</ul>
<p><img src="C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20211020174201936.png" alt="image-20211020174201936"></p>
<p><strong>第二内插层</strong>通过考虑所有时间序列上的<strong>可学习相关性</strong>ρdd‘，在<strong>每个参考时间点</strong>合并所有时间序列上的<strong>所有D维时间序列上的信息</strong>。这导致针对每个输入维度的<strong>交叉维插值</strong>χd。我们还将每个输入维度的<strong>瞬态分量Td</strong>定义为<strong>来自第一层的高通(或非平滑)插值γd和平滑交叉维度插值χd之间的差</strong>。</p>
<p>在下一节介绍的实验中，我们使用每个维度d，总共<strong>三个插值网络输出</strong>作为预测网络的<strong>输入</strong>。我们使用<strong>平滑的跨通道内插值χd来捕获平滑趋势</strong>，使用<strong>瞬变分量Td来捕获瞬变</strong>，使用<strong>强度函数λd</strong>来及时捕捉有关<strong>观测点的信息</strong>。</p>
<h3 id="预测网络"><a href="#预测网络" class="headerlink" title="预测网络"></a><strong>预测网络</strong></h3><p><strong>所有D维输入多变量时间序列</strong>都被<strong>重新表示</strong>为在<strong>规则间隔的参考时间点集合</strong>T=r1，…，rt上定义C输出(在我们的实验中，如上所述，我们使用C=3。同样，我们将<strong>插补网络输出的完整集合称为S’n</strong>=fθ(r，sn)，其可以表示为大小为(DC)×T的矩阵。</p>
<p><strong>预测网络</strong>必须<strong>获取S’A输入</strong>并<strong>输出目标值yn的预测值</strong>y’n用于数据情况。该模型的这个组件有许多可能的选择。例如，<strong>矩阵可以转换成单个长向量</strong>，并作为输入提供给<strong>标准多层前馈网络</strong>。<strong>时间卷积模型</strong>或像GRU或LSTM这样的递归模型可以应用于<strong>矩阵S’n的时间片</strong>。在这项工作中，我们利用<strong>GRU网络</strong>作为预测网络进行实验。</p>
<h3 id="参数学习"><a href="#参数学习" class="headerlink" title="参数学习"></a>参数学习</h3><p>为了学习模型参数，我们使用了一个由<strong>监督组件</strong>和<strong>非监督组件组成的</strong>复合目标函数。这是由于在给定可用训练数据量的情况下，仅受<strong>监督组件不足以学习插值网络参数的合理参数</strong>。所使用的<strong>非监督分量对应于类似自动编码器的损失函数</strong>。但是，通过将<strong>RBF核参数设置为非常大的值</strong>，半参数RBF插值层能够<strong>精确拟合输入点</strong>。</p>
<p>为了避免这种解决方案，并迫使内插层学会正确地内插输入数据，有必要在学习期间<strong>保持一些观测数据点</strong>dn，然后只计算这些数据点的<strong>重构损失</strong>。这是大容量自动编码器的一个众所周知的问题，过去的工作已经使用了类似的策略来避免在<strong>没有学习有用结构的情况下简单地记忆输入数据</strong>的问题。</p>
<p>我们假设预测网络的损失(分类使用<strong>交叉熵损失</strong>，回归使用<strong>误差平方</strong>)。我们采用插值网络自动编码器<strong>损失</strong>(我们使用<strong>标准平方误差</strong>)。</p>
<h3 id="实验和结果"><a href="#实验和结果" class="headerlink" title="实验和结果"></a>实验和结果</h3><p>在本节中，我们提供了<strong>基于稀疏和不规则样本多变量时间序列的分类和回归任务</strong>的实验。在这两种情况下，<strong>预测网络的输入是稀疏且不规则采样的时间序列</strong>，而<strong>输出是代表预测类别或回归目标变量的单个标量</strong>。我们在<strong>两个公开可用的真实世界数据集</strong>上测试了模型框架：Mimic-III以及UWave手势是由分为八类的简单手势模式组成的单变量时间序列数据集。我们以MIMIC-III死亡率和住院时间预测任务为例，对<strong>多变量时间序列进行分类和回归</strong>。我们使用uWave手势分类任务来评估相对于<strong>单变量基线模型</strong>的训练时间和性能。</p>
<h4 id="基准模型"><a href="#基准模型" class="headerlink" title="基准模型"></a>基准模型</h4><p>我们将我们提出的模型与<strong>一些基线方法进行了比较</strong>，包括使用基本特征学习的现成分类和回归模型，以及基于定制神经网络模型的较新方法。</p>
<h5 id="非神经网络基线模型"><a href="#非神经网络基线模型" class="headerlink" title="非神经网络基线模型"></a>非神经网络基线模型</h5><p>对于非神经网络基线，我们评估Logistic回归、支持向量机(SVM)、随机森林(RF)和AdaBoost用于<strong>分类任务</strong>。对于住院时间预测任务，我们使用了线性回归、支持向量回归、AdaBoost回归和随机森林回归。所有这些模型的标准实例都需要<strong>固定大小的特征表示</strong>。在丢失数据的情况下，我们使用<strong>时间离散化和前向填充来创建固定大小的表示</strong>，并将该表示用作非神经网络基线的特征集。</p>
<h5 id="神经网络基线模型"><a href="#神经网络基线模型" class="headerlink" title="神经网络基线模型"></a>神经网络基线模型</h5><p>我们使用简单的内插或推算方法，与几个建立在<strong>GRU上的现有深度学习基线进行比较</strong>。此外，我们还与目前最先进的死亡率预测模型进行了比较。他们的工作建议使用递归神经网络(RNNs)通过在输入层或隐藏层引入时间衰减来处理不规则采样和丢失的数据。我们还评估了可伸缩的端到端高斯过程适配器以及多任务高斯过程RNN分类器，分别用于不规则样本的单变量和多变量时间序列分类。</p>
<ul>
<li>GP-GRU：以GRU为分类器的端到端高斯过程（高斯过程中任意随机变量的线性组合都服从<strong>正态分布</strong>,高斯过程的性质与其协方差函数有密切联系，在构造高斯过程时，一些特定形式的协方差函数被称为<strong>核函数</strong>）。</li>
<li>GRU-M：用<strong>训练示例中变量的全局平均值</strong>替换缺失的观测值。</li>
<li>GRU-F：设置为该时间序列内<strong>最后观察到的测量值的缺失值</strong>(称为正向填充)。</li>
<li>GRU-S：用<strong>全局平均值替换缺失的值</strong>。输入与掩蔽变量和指示特定变量缺失多长时间的时间间隔连接在一起</li>
<li>GRU-D：为了捕捉更丰富的信息，在<strong>GRU的输入层和隐藏层都引入了衰减</strong>。不是用最后一次测量来替换遗漏的值，而是随着时间的推移，遗漏的值向经验平均值衰减。</li>
<li>GRU-HD：GRU-D的变体，只在隐藏层引入衰减。</li>
</ul>
<h3 id="评估指标"><a href="#评估指标" class="headerlink" title="评估指标"></a><strong>评估指标</strong></h3><p><img src="C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20211020174838027.png" style="height:200px"></img></p>
<p>图2:UWAVEGENTURE数据集上的分类性能。具有几乎相同性能的模型用相同的点显示，例如（GRU-M，GRU-F）和（GRU-D，GRU-HD）。</p>
<p>表1：<strong>MIMIC-III上死亡率(分类)</strong>和<strong>住院时间预测(回归)任务</strong>的性能。损失：交叉熵损失，MedAE：绝对误差中位数(天)，EV：解释方差</p>
<p><img src="C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20211020174926865.png" style="height:200px"></img></p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>在本文中，我们提出了一种<strong>新的框架来处理稀疏和不规则样本时间序列中的监督学习问题</strong>。建议的框架是完全模块化的。它使用<strong>内插网络来适应使用稀疏和不规则采样数据作为监督学习输入所产生的复杂性</strong>，然后应用<strong>预测网络</strong>，该预测网络在由内插网络提供的规则间隔且完全观察到的<strong>多通道输出</strong>上运行。所提出的方法还解决了现有方法的一些困难，包括中使用的高斯过程插值层的复杂性，以及Che等人的方法缺乏模块性。我们的框架还引入了新的元素，包括使用<strong>半参数前馈插值层</strong>，以及将<strong>不规则采样的输入时间序列分解为多个采样时间序列</strong>。有很多不同的信息渠道。我们的结果显示，与一系列基线和最先进的方法相比，分类和回归任务在统计上都有<strong>显著的改善</strong>。</p>
<h1 id="将生理时间序列和临床笔记与深度学习相结合，提高ICU死亡率预测"><a href="#将生理时间序列和临床笔记与深度学习相结合，提高ICU死亡率预测" class="headerlink" title="将生理时间序列和临床笔记与深度学习相结合，提高ICU死亡率预测"></a>将生理时间序列和临床笔记与深度学习相结合，提高ICU死亡率预测</h1><p><img src="C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20211020163023828.png" style="height:160px"></img></p>
<p><strong>期刊：arXiv 2021</strong></p>
<h3 id="摘要-1"><a href="#摘要-1" class="headerlink" title="摘要"></a><strong>摘要</strong></h3><p>重症监护室电子健康记录<strong>存储患者的多模式数据</strong>，包括<strong>临床记录</strong>、稀疏和不规则采样的<strong>生理时间序列</strong>、实验室测量值等。迄今为止，大多数从重症监护室EHR数据中学习预测模型的方法都集中在<strong>单一模式上</strong>。</p>
<p>在本文中，我们利用最近提出的<strong>插值-预测深度学习架构</strong>(Shukla和Marlin  2019)作为<strong>基础</strong>，探索如何将生理时间序列数据和临床笔记<strong>集成</strong>到统一的死亡率预测模型中。我们研究<strong>早期和晚期融合</strong>方法，并演示临床文本和生理数据的<strong>相对预测值如何随时间变化</strong>。我们的结果表明，与单独使用单一模式相比，<strong>后期融合方法</strong>可以在死亡率预测性能方面提供<strong>统计学上的显著改善</strong>。</p>
<h3 id="介绍-1"><a href="#介绍-1" class="headerlink" title="介绍"></a><strong>介绍</strong></h3><p>电子健康记录(EHRs)存储与个人病史相关的<strong>多模式</strong>数据，包括临床记录、生理测量、实验室结果、放射学图像等。重症监护室电子健康记录特别有趣，因为它们包含<strong>多个生理变量（心率，血压，血氧饱和度等）随时间的测量值</strong>。通过创建基于机器学习和数据挖掘技术的改进决策支持工具，对这些数据的分析有可能<strong>改善护理</strong>。然而，数据的<strong>复杂性</strong>导致了对孤立分析单一数据模式的关注。</p>
<p>在本文中，我们探讨了将生理时间序列数据和临床文本整合到统一的死亡率预测模型中的<strong>预测价值</strong>。具体来说，我们通过时间<strong>利用临床笔记的内容</strong>，并将它们包含的信息与生理时间序列数据融合。我们基于最近提出的插值-预测深度学习架构作为稀疏建模框架和不规则采样的生理时间序列。我们研究了几种表达临床文本的方法，以及<strong>整合两种数据模式的早期和晚期融合方法</strong>。我们从介绍生理时间序列<strong>建模</strong>、临床文本和融合方法的<strong>相关工作</strong>开始。接下来，我们将介绍所提出的方法，包括对<strong>插值预测网络</strong>的简要回顾。最后，我们在MIMIC-III数据集上展示了死亡率预测实验，证明了临床文本和生理数据的<strong>相对预测值在入院后的前48小时内是如何变化的</strong>。我们表明，较之单独使用单个模态，<strong>后期融合</strong>方法可以提供显著的改进。</p>
<h3 id="相关工作-1"><a href="#相关工作-1" class="headerlink" title="相关工作"></a><strong>相关工作</strong></h3><p>这项工作感兴趣的问题是通过将<strong>临床时间序列与非结构化临床文本数据相融合</strong>来学习<strong>有监督</strong>的机器学习模型。在本节中，我们回顾了临床文本和不规则采样的生理时间序列的<strong>稀疏建模和分析</strong>的相关工作，以及<strong>融合方法</strong>的相关工作。</p>
<ul>
<li><p><strong>临床文本</strong>:过去几年，随着临床笔记的访问越来越多，在<strong>理解临床文本数据和使用</strong>这些数据来改善临床结果预测方面取得了重大进展。<strong>自然语言处理</strong>和信息提取技术已成功应用于包括临床概念提取、关系提取、问题回答、预测建模等任务。使用叙事笔记预测临床结果的方法包括使用<strong>基于规则的医学概念提取</strong>或机器学习技术。然而，这种方法在规则构建、关键词选择、文本注释或<strong>有监督机器学习</strong>的特征工程方面需要<strong>大量</strong>的工作。</p>
</li>
<li><p><strong>主题建模</strong>等<strong>无监督方法</strong>可以用来解决这个问题。主题建模(Ghassemi等人，2012)方法依赖于从临床文本数据中提取<strong>主题特征</strong>。Lehman等人结合了<strong>主题建模和医学概念提取方法</strong>来预测住院死亡率。最近，包括word2vec和GloV  e (2014)在内的<strong>单词嵌入方法</strong>在众多自然语言处理任务中取得了成功，受此启发，Minarro  Gimenez、Marin Alonso和Samwald (2014)学习了一种用于<strong>医学文本数据的嵌入</strong>模型。De  Vine等人(2014)使用期刊摘要来训练嵌入。Choi，Yi-I Chiu和Sontag  (2016)评估了<strong>单词嵌入在捕捉医学概念</strong>之间关系的效率。Boag等人(2018)比较了由单词包(BOW)、word2vec和所学LSTM的最终隐藏层生成的临床笔记表示，用于下游临床预测任务。他们的结果表明，没有简单的获胜代表。<strong>BoW和word2vec</strong>在预测住院死亡率方面取得了相似的表现。在最近的其他工作中，Ghassemi等人(2015)使用<strong>高斯过程</strong>将临床笔记序列建模为主题的时间序列。在这项工作中，我们将临床笔记视为单词或句子的序列，并使用<strong>递归网络</strong>来预测住院死亡率。我们使用简单平均值(Pennington，Socher和Manning  2014)以及单词嵌入的加权平均值生成句子嵌入。与Boag等人(2018年)相似，我们比较了单词包和手套模型。最后，与Kalchbrenner、Grefenstette和Blunsom  (2014)相似，我们也使用<strong>卷积模型</strong>进行预测，其中<strong>临床笔记</strong>以<strong>单词嵌入</strong>的方式表示。</p>
</li>
<li><p><strong>不规则采样的生理时间序列：</strong>稀疏和不规则采样的<strong>时间序列</strong>是在它们的观测<strong>时间之间</strong>具有<strong>大的和不规则的</strong>间隔的样本序列。这种数据通常出现在电子健康记录中，对于监督学习方法和非监督学习方法来说都是一个<strong>重大问题</strong>(Marlin等人，2012年)。一个密切相关的问题是在<strong>存在缺失数据</strong>的情况下执行监督学习(Little和Rubin  2014)。事实上，通过离散化时间轴并指示没有观察到样本的间隔丢失，<strong>分析稀疏和不规则采样数据的问题可以转化为丢失数据的问题</strong>(通常伴随着信息或推理效率的损失)。马林等人(2012年)以及利普顿、卡勒和韦特泽尔(2016年)采用了这种方法来处理不规则采样。</p>
<p>随着<strong>缺失数据量的增加</strong>，学习通常会变得更加困难，因此<strong>选择离散化间隔长度</strong>必须作为这种方法的<strong>超参数</strong>来处理。预离散化的替代方法是构建能够直接使用不规则采样时间序列作为输入的模型。</p>
<ul>
<li>例如，Lu等人(2008)提出了一种基于<strong>核</strong>的方法，该方法可用于产生两个不规则采样时间序列之间的相似性函数。李和马林(2015)随后对此进行了概括<strong>高斯过程模型之间核</strong>情况的探讨。Li和Marlin  (2016)展示了<strong>深度神经网络</strong>模型(前馈、卷积或递归)如何通过<strong>端到端训练</strong>叠加在<strong>高斯过程层</strong>之上，而Futoma等人(2017)展示了如何将这种方法从单变量推广到多变量。上述模型的一个<strong>重要特性</strong>是，它们允许将来自<strong>所有可用时间点</strong>的所有信息<strong>合并到全局插值模型</strong>中。</li>
<li>另一个独立的研究方向是使用更多的<strong>局部插值</strong>方法，同时仍然<strong>直接对连续时间输入</strong>进行操作。例如，Che等人(2018年)提出了几种基于<strong>门控递归单位</strong>(GRU)网络(Chung等人，2014年)的方法，结合了<strong>简单的插补方法</strong>，包括均值插补和用过去的值进行正向填充。Che等人(2018年)还考虑了一种方法，该方法将由观察到的值和观察到这些值的时间戳组成的序列作为输入。先前观察到的<strong>输入值</strong>随着时间朝着总平均值<strong>衰减</strong>。在另一个变体中，<strong>隐藏状态类似地衰减到零</strong>。Yoon，Zame和van  der Schaar  (2017)提出了另一种基于<strong>多方向RNN</strong>的类似方法，该方法除了在<strong>流内</strong>运行之外，还在<strong>流间</strong>运行。</li>
</ul>
<p>在这项工作中，我们使用最近提出的<strong>插值预测网络</strong>来建模稀疏和不规则采样的生理时间序列(Shukla和Marlin  2019)。该框架<strong>解决了一些困难</strong>，包括Li和Marlin  (2016)和Futoma等人(2017)中使用的<strong>高斯过程插值层</strong>的复杂性，以及Che等人(2018)的方法缺乏模块化。</p>
</li>
</ul>
<ul>
<li><p><strong>融合模型：</strong>学习<strong>多模态表示</strong>是一个基本的研究问题。Ngiam等人(2011)引入了一个多模态深度学习框架，将<strong>视频和音频结合起来用于语音识别</strong>。具有语言和视觉子空间的多模态学习已经被用于<strong>提高图像字幕任务</strong>的性能。Srivastava使用多模态(<strong>文本和图像</strong>)的融合表示作为区分任务的输入。Silberer使用<strong>堆叠自动编码来融合多模态</strong>数据，而Kiela和Bottou  (2014)采用简单的串联策略，并使用<strong>卷积模型提取视觉特征和文本的跳格模型</strong>来实现经验改进。</p>
<p>另一项工作是将<strong>时间序列数据和文本信息</strong>结合起来。唐、杨和周(2009)分析了<strong>新闻报道以提高对股价的预测</strong>，而罗德里格斯、马高和佩雷拉(2018)使用简单的串联方法来<strong>组合时间序列和文本数据</strong>，用于通过学习它们的潜在表示来预测出租车需求。在临床数据空间中，Fiterau等人(2017年)展示了<strong>如何结合年龄、性别、身高等结构化信息</strong>。用时间序列数据可以提高性能。徐等(2018)通过<strong>整合连续</strong>监测数据和<strong>离散</strong>临床事件序列，开发了临床预测模型。Rajkomar等人(2018年)结合了多种模式，如<strong>人口统计、供应商订单、诊断、程序、药物、实验室值、临床文本数据和生命体征</strong>，并在多项任务中表现出改进的表现。</p>
<p>金等(2018)将<strong>非结构化临床文本数据与生理时间序列数据相结合</strong>，用于<strong>院内死亡率预测</strong>，类似于目前的工作。相对于这项工作，我们考虑了多种临床文本表示，将我们的时间序列模型基于<strong>插值预测网络</strong>(Shukla和Marlin  2019)，并关注<strong>临床文本和生理数据</strong>的<strong>相对值如何随时间变化</strong>。此外，我们考虑了<strong>早期和晚期融合</strong>方法，扩展了Kiela和Bottou  (2014)和Fiterau等人(2017)的前期工作。</p>
</li>
</ul>
<h3 id="模型"><a href="#模型" class="headerlink" title="模型"></a><strong>模型</strong></h3><ul>
<li><strong>插值预测网络框架</strong>。该架构基于使用组织成插值网络的几个半参数插值层，然后应用可以利用任何标准深度学习模型的预测网络。</li>
</ul>
<p><img src="C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210708215847574.png" alt="image-20210708215847574"></p>
<p>​    <strong>插值网络</strong>和<strong>预测网络</strong>，在融合的情况下，我们使用这个目标来<strong>单独预训练插值预测网络参数</strong>。</p>
<ul>
<li><p><strong>文本模型（预训练纯文本模型，用于提供纯文本基线）：</strong>我们考虑了几种不同的<strong>非结构化文本建模</strong>方法，包括基于<strong>单词包和单词嵌入表示</strong>的方法。</p>
<p><strong>TF-IDF:</strong>首先使用从单词包（词袋）计算出的<strong>TFIDF特征</strong>表示每个文本文档。我们在TF-IDF输入上应用一个大小为128的单隐层(1NN)全连接网络，然后是预测网络的其余部分。</p>
<p><strong>单词嵌入(WE):</strong>首先将每个文档表示为矩阵，其中行是文档中的单词，列是单词嵌入维度。</p>
<p><strong>未加权句子嵌入(USE):</strong>首先将每个文档表示为矩阵，其中行是文档中的句子，列是句子嵌入维度。</p>
<p><strong>加权句子嵌入(WSE):</strong>每个文档表示为一个矩阵，其中行是文档中的句子，列是句子嵌入维度。</p>
</li>
<li><p><strong>混合模型：插值预测网络</strong>与用于表示非结构化文本的<strong>基于嵌入的模型</strong>相结合</p>
</li>
</ul>
<p><img src="C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210708221720832.png" alt="image-20210708221720832"></p>
<p><strong>后期融合:</strong>该架构如图2(<strong>左</strong>)所示。在这种方法中，<strong>预测网络</strong>使用与Shukla和Marlin  (2019)使用的相同的<strong>GRU架构</strong>来提取<strong>生理时间序列数据</strong>的固定维潜在表示。该表示与文本嵌入层连接，并且使用线性层将<strong>组合的潜在表示</strong>连接到预测目标。</p>
<p><strong>早期融合:</strong>如图2(<strong>右</strong>)所示，我们考虑对<strong>生理时间序列和临床笔记中包含的信息进行更深入的整合</strong>。在这种方法中，我们的预测网络可以在通过GRU层合并生理时间序列数据<strong>之前访问临床文本数据</strong>。</p>
<h3 id="实验和结果-1"><a href="#实验和结果-1" class="headerlink" title="实验和结果"></a>实验和结果</h3><h4 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h4><p>在<strong>MIMIC-III数据集</strong>中，为患者的每一个独特的入院到出院事件分配一个独特的<strong>ID</strong>。每集的数据都被视为独立的。在训练-测试分割中，我们根据医院入院ID分割数据(即80%  (27510)的ID用于训练，20% (8597)用于测试)。训练集中另外留出20% (6877个数据案例)用作验证集。</p>
<p>我们只使用单个入院到出院事件的数据，所以我们构建的数据案例在时间上是不重叠的。</p>
<p>我们的实验基于公开可用的MIMIC-III数据集。该数据集包含<strong>稀疏和不规则采样的生理信号</strong>、出院总结、进展记录、药物治疗、诊断代码、住院死亡率、住院时间、人口统计信息等。它包括大约58，000份住院记录。我们专注于使用临床文本和时间序列数据预测住院死亡率。我们从Shukla和Marlin  (2019)中使用的<strong>数据集1</strong>开始，该数据集由<strong>住院到出院住院时间超过48小时</strong>的住院记录组成。从这个数据集中，我们获得了42，984条实验记录，这些记录是在<strong>移除了</strong>新生儿和不包含临床记录的入院记录后获得的。入院可能相当于零次或多次重症监护室发作。在本文中，我们只考虑住院期间<strong>至少一次</strong>入住重症监护室的数据病例。类似于Shukla和Marlin  (2019)，我们从每个记录中提取了<strong>12个标准生理变量</strong>。<strong>表1显示了变量和采样率</strong>(每小时)。</p>
<ul>
<li><p>我们使用<strong>入院时已知的文本数据</strong>，如主诉、既往病史和当前病史。为了避免任何信息泄露，我们小心地从<strong>出院总结</strong>中提取这些信息。</p>
</li>
<li><p>我们还从<strong>非出院报告</strong>中提取<strong>进展记录</strong>，如呼吸、心电图、回声、放射学和护理报告。我们使用这些报告上的日期和时间戳来创建一组在<strong>入院后6到48小时内</strong>可用的笔记。请注意，生理数据和临床笔记以保守的方式对齐。如果一个临床记录有相关的日期和时间，我们假设信息在指定的时间是可用的。对于有日期但没有时间可用的笔记，我们假设信息在指定日期结束时可用。数据集中的一些心电图和回声报告会出现这种情况。</p>
</li>
<li>SpO2:血氧饱和度，HR:心率，RR:呼吸频率，SBP: 收缩压，DBP:舒张压，Temp：体温，TGCS:CRR:UO:，FIO2:吸入氧浓度百分比，Glucose:葡萄糖，pH:酸碱度（12个<strong>非规则采样</strong>的生理时间序列）</li>
</ul>
<p><img src="C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210708222653718.png" alt="image-20210708222653718"></p>
<h4 id="具体预处理细节"><a href="#具体预处理细节" class="headerlink" title="具体预处理细节"></a><strong>具体预处理细节</strong></h4><p>所有模型都经过训练，以最小化交叉熵损失。对于所有的模型，我们独立地调整超参数——隐藏层的数量、隐藏单元、卷积滤波器、滤波器大小、学习率、辍学率和验证集上的正则化参数。</p>
<h4 id="评估指标-1"><a href="#评估指标-1" class="headerlink" title="评估指标"></a><strong>评估指标</strong></h4><p>我们的实验集中在<strong>纯文本模型</strong>、<strong>纯时间序列模型</strong>和<strong>融合模型</strong>对住院死亡率预测问题的相对预测性能上。</p>
<p>我们将融合模型与许多分别对生理时间序列或临床文本数据建模的基线方法进行比较。Shukla和Marlin  (2019)表明，对于稀疏和不规则采样的时间序列，插值预测网络在<strong>分类和回归</strong>任务上<strong>优于</strong>一系列基线和最近提出的模型。因此，我们使用<strong>插值预测网络作为我们的纯时间序列基线模型</strong>。</p>
<p>我们使用在测试集上计算的泛化性能的估计来评估所有模型。我们根据<strong>ROC曲线下的面积(AUC分数)</strong>报告测试集的性能。</p>
<p>我们介绍死亡率预测实验的结果。我们从纯文本和时序基线结果开始，然后是融合模型结果。</p>
<p>1.<strong>纯文本基线</strong>:表2显示了描述的<strong>纯文本模型</strong>的分类性能。我们在入院时可用文本数据的情况下评估所有模型。这些结果表明，基于<strong>TFIDF</strong>的模型明显<strong>优于嵌入</strong>方法。这可能是因为健康特定的概念在所使用的标准手套嵌入中没有得到很好的体现。另一个可能的原因可能是<strong>使用缩写术语</strong>，这在临床笔记中非常常见。因此，我们在根据入院后所有可用的进展记录进行预测时，仅考虑TF-IDF模型。我们可以看到，随着时间的推移，随着<strong>更多的文本数据</strong>变得可用，使用TF-IDF模型的预测性能显著提高。</p>
<p><img src="C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210708223323853.png" style="height:220px"></img></p>
<p>2.<strong>仅时间序列基线</strong>:表3评估了描述的仅时间序列<strong>插值预测网络</strong>的预测性能。正如预期的那样，预测性能随着观察到的生理<strong>数据量的增加</strong>而增加。我们注意到，这里报告的结果与Shukla和Marlin  (2019)的结果不同，因为<strong>移除</strong>不包含临床数据的医院入院记录需要额外的数据过滤笔记和新生儿<strong>数据</strong>。与表2中的结果相比，我们可以看到入院时可用的临床文本的预测值超过了入院后42小时内可用的生理数据的预测值。下一组实验旨在评估这两种模式融合后是否能提高性能。</p>
<p><img src="C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210708223715564.png" style="height:220px"></img></p>
<p>3.<strong>融合方法:</strong>基于在纯文本基线实验中观察到的基于TF-IDF的模型的成功，我们检查了使用基于TF-IDF的模型嵌入临床文本数据的融合方法的性能。我们首先评估一种融合方法的性能，这种方法只能访问入院时可用的临床文本数据，但会增加入院后48小时内的生理时间序列数据。表3显示了在该实验场景下早期和晚期融合模型的分类性能。图3<strong>显示了早期和晚期融合相对于纯时间序列和纯文本基线的性能</strong>。我们可以看到，在入院后的前30小时内，晚期融合方法比早期融合方法获得了更好的性能，而<strong>晚期融合方法则显著提高了纯时间序列基线</strong>。然而，我们看到，随着生理数据量的增加，包含生理数据的所有三个模型的预测性能都在提高。此外，我们看到融合模型和仅时间序列模型之间的性能差距随着时间的推移而减小，这表明<strong>初始融合与入院时可用的文本数据</strong>所提供的优势随着时间的推移而减小，因为该信息变得不太相关。最后，我们注意到，<strong>后期融合模型始终优于纯文本基线</strong>，而早期融合模型最初表现出比纯文本TF-IDF基线更低的性能，但继续匹配，然后优于纯文本基线。</p>
<p>对于这个实验，我们只考虑基于TF-IDF的文本嵌入模型，并将讨论限制在后期融合方法，因为这些模型在我们迄今为止的实验中取得了最好的性能。我们考虑<strong>文本只在入院时可用，但生理时间序列的数量不断增加</strong>。以及<strong>不断增加生理时间序列和文本记录的情况</strong>。</p>
<ul>
<li>纳入<strong>入院时0时</strong>已知的文本数据，然后是<strong>入院后6至48小时</strong>内已知的所有笔记的文本。</li>
</ul>
<p><img src="C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210708224705190.png" style="height:260px"></img></p>
<h3 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h3><p>在本文中，我们开发了用于调查重症监护室电子病历中临床笔记内容和生理时间序列数据的相对预测值的方法。我们已经<strong>考虑了仅基于临床文本的模型，仅基于生理时间序列的模型，以及结合两种模态的新融合方法</strong>。我们的实验侧重于使用这种方法来评估临床文本和生理数据的相对预测值，作为入院后时间的函数。我们的重点是预测入院后超过48小时的住院死亡率事件。我们的结果表明，随着观察到更多的生理数据，入院时已知的文本记录中信息的相对<strong>价值会随着时间的推移而降低</strong>。然而，合并新可用的文本数据可以显著提高预测性能。最后，我们的结果有力地支持了融合两种数据模式导致最佳整体预测性能的结论。</p>
]]></content>
      <categories>
        <category>mpt</category>
      </categories>
      <tags>
        <tag>生理信号</tag>
      </tags>
  </entry>
  <entry>
    <title>mpt 【Mathematical Problems in Engineering-2020】Hydrologic Time Series Anomaly Detection Based on Flink</title>
    <url>/2021/03/03/MaPeitao/Hydrologic%20Time%20Series%20Anomaly%20Detection%20Based%20on%20Flink(1)/</url>
    <content><![CDATA[<p>关键词：大规模，异常检测</p>
<p><img src="https://i.loli.net/2021/03/05/S43oUgMiD9875qk.png" alt="image-20210305112946386.png"></p>
<p><strong>摘要</strong>:数据挖掘和时间序列计算在关键应用中仍值得研究。目前，在水文时间序列领域，大部分异常值的检测都集中在提高特异性上。为了有效检测海量水文传感器数据中的异常值，提出了一种基于<strong>Flink</strong>的水文时间序列异常检测方法。首先，利用<strong>滑动窗口</strong>和<strong>ARIMA模型</strong>对数据流进行预测。然后对预测结果计算<strong>置信区间</strong>，区间范围外的结果判断为备选异常数据。最后，基于历史批次数据，使用<strong>KMeans++算法</strong>对批次数据进行<strong>聚类</strong>。计算<strong>状态转移概率</strong>，对异常数据进行质量评估。以从楚江获取的水文传感器数据为实验数据，分别进行了检测时间和异常检测性能的实验。结果表明，在计算数千万个数据时，两个从机花费的时间比一个从机少，最大减少量为17.43%。评价的灵敏度从72.91%提高到92.98%。延迟方面，不同从机的平均延迟大致相同，维持在20ms以内。结果表明，在大数据平台下，该算法能有效提高数千万数据的水文时间序列检测的计算效率，并给出可靠的置信度，以提高整体灵敏度（不漏报）。在大量的水文时间序列中可以快速，准确地检测到异常值。</p>
<a id="more"></a>
<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>水文数据根据其物理量分为各种类型的水文时间序列。目前，水文时间序列通常由确定的和随机的成分组成。确定成分具有一定的物理概念，而随机成分是由不规则振荡和随机影响产生的。水文时间序列主要表现出随机性，模糊性，非线性，非平稳性和多时间尺度变化的复杂特征。</p>
<p>随着世界变得更加硬件化和互联，我们看到了各种硬件（例如传感器）或软件生成的大量数字数据。随着信息化的发展，水文站积累了大量重要数据，其中包含许多异常值。异常值通常包含重要信息，通过准确地找到数据背后的隐含价值，这对于后续的分析决策非常重要。目前，对于水文时间序列，传统方法仅适用于小型数据集，不适用于当前的大数据环境。而且，准确度虽达到99％的特异性（Specificity，不误报，TPR = TP / (TP + FN) ），灵敏度（Sensitivity，不漏报，召回率、查全率，TNR = TN / (TN + FP) ）仍然有提高的空间。随着数据量的增加，如何有效地进行计算已成为不可忽视的问题。在关键应用中时间序列的异常检测和计算仍然值得研究。</p>
<h2 id="Apache-Flink"><a href="#Apache-Flink" class="headerlink" title="Apache Flink"></a>Apache Flink</h2><p>Flink 是一套集<strong>高吞吐、低延迟、有状态</strong>三者于一身的<strong>分布式</strong>流式数据处理框架。</p>
<p>具体来说，Flink 是一个解决<strong>实时数据处理</strong>的计算框架，其可对有限数据流和无限数据流进行有状态计算，并能部署在各种集群环境，对各种大小的数据规模进行快速计算。</p>
<p>Flink 支持消息队列的 Events（支持实时的事件）的输入(如Kafka)，上游源源不断产生数据放入消息队列，Flink 不断消费、处理消息队列中的数据，处理完成之后数据写入下游系统，这个过程是不断持续的进行。</p>
<p>层次化的API在表达能力和易用性方面各有权衡。表达能力由强到弱（易用性由弱到强）依次是：ProcessFunction、DataStream API、SQL/Table API。</p>
<p><img src="https://img2018.cnblogs.com/common/1754004/202002/1754004-20200204092132360-1462288846.png" alt="img"></p>
<p>时间序列异常检测中，Flink具备<strong>批流一体</strong>(离线训练和在线训练同一套框架)、性能优异、并行计算等优势。针对不同的使用场景，分为基于时序预测和时序分解两种类型：</p>
<ul>
<li><p>时序预测算法适合流式数据，即时响应</p>
</li>
<li><p>时序分解算法适合全量数据，能够从全量数据中挖掘有效信息。</p>
</li>
</ul>
<h2 id="滑动窗口"><a href="#滑动窗口" class="headerlink" title="滑动窗口"></a>滑动窗口</h2><p><strong>滑动窗口</strong>就是能够根据指定的单位长度来框住时间序列，从而计算框内的统计指标（均值、方差、标准差中位数、和等）。相当于一个长度指定的滑块正在刻度尺上面滑动，每滑动一个单位即可计算滑块内的数据。</p>
<p>Flink为我们提供了方便易用的窗口算子API，我们可以将数据流切分成一个个窗口，对窗口内的数据进行实时处理。窗口的大小设置导致延迟的大小变化。（窗口越大延迟越高）</p>
<h2 id="ARIMA模型"><a href="#ARIMA模型" class="headerlink" title="ARIMA模型"></a>ARIMA模型</h2><p><strong>时间序列的平稳性</strong>：由时间序列所得到的拟合曲线在未来一段时间内仍能顺着现有的形态惯性地延续下去。平稳性要求序列的均值和方差不发生明显变化。</p>
<p><strong>AR:自回归模型</strong>，描述当前值与历史值之间的关系，用变量自身的历史时间数据对自身进行预测。</p>
<p>自回归模型的限制：<br> 1、自回归模型只能用自身的数据进行预测<br> 2、时间序列数据必须具有平稳性<br> 3、自回归只适用于预测与自身前期相关的现象（泛化不足）</p>
<p><strong>I:差分法</strong>，可以使得数据更平稳，常用的方法就是一阶差分法和二阶差分法。</p>
<p><strong>MA:移动平均模型</strong>，移动平均模型关注的是自回归模型中的误差项的累加，能有效地消除预测中的随机波动。</p>
<p><strong>ARIMA(p,d,q):差分自回归移动平均模型</strong>，将自回归模型、差分法和移动平均模型结合以来</p>
<p><strong>p</strong>是自回归(AR)的项数，用来获取自变量</p>
<p><strong>d</strong>是差分(I)的系数，为了使时间序列平稳，做d次差分</p>
<p><strong>q</strong>是移动平均(MA)的项数，为了使其光滑</p>
<p><strong>ARIMA原理</strong>：将非平稳时间序列转化为平稳时间序列，然后将因变量仅对它的滞后值以及随机误差项的当前值和滞后值进行回归所建立的模型</p>
<p>建立ARIMA模型的流程：</p>
<p>1.确定参数p,q 的值 </p>
<p>2.确定d阶</p>
<p>3.计算AIC或BIC,原则是使AIC和BIC越小越好</p>
<h2 id="置信区间"><a href="#置信区间" class="headerlink" title="置信区间"></a>置信区间</h2><p>置信区间是总体变量估计的界限，它是一个区间统计量，用于量化估计的不确定性。在应用机器学习中，我们想在展示一个预测模型的能力时使用置信区间。选择95%的置信度在展现置信区间时很常见。实践中，你可以使用任何喜欢的值。置信区间的价值在于它能够量化估计的不确定性。它提供了一个下限和上限以及一个可能性。</p>
<h2 id="KMeans-算法"><a href="#KMeans-算法" class="headerlink" title="KMeans++算法"></a>KMeans++算法</h2><p><strong>K-means与K-means++</strong>：原始K-means算法最开始随机选取数据集中K个点作为聚类中心，而K-means++按照如下的思想选取K个聚类中心：假设已经选取了n个初始聚类中心(0&lt;n&lt;K)，则在选取第n+1个聚类中心时：距离当前n个聚类中心越远的点会有更高的概率被选为第n+1个聚类中心。在选取第一个聚类中心(n=1)时同样通过随机的方法。可以说这也符合我们的直觉：聚类中心当然是互相离得越远越好。</p>
<p><img src="https://images2015.cnblogs.com/blog/1024143/201701/1024143-20170111025932213-93380420.png" alt="图1"></p>
<p><img src="https://images2015.cnblogs.com/blog/1024143/201701/1024143-20170111025934541-260409014.png" alt="https://images2015.cnblogs.com/blog/1024143/201701/1024143-20170111025934541-260409014.png"></p>
<h2 id="转移概率矩阵"><a href="#转移概率矩阵" class="headerlink" title="转移概率矩阵"></a>转移概率矩阵</h2><p>转移概率矩阵：矩阵各元素都是非负的，并且各行元素之和等于1，各元素用概率表示，在一定条件下是互相转移的，故称为转移概率矩阵。</p>
<h2 id="马尔可夫链"><a href="#马尔可夫链" class="headerlink" title="马尔可夫链"></a>马尔可夫链</h2><p><strong>马尔可夫性</strong>：过程或（系统）在时刻<em>t</em>0所处的状态为已知的条件下，过程在时刻<em>t</em> &gt; <em>t</em>0所处状态的条件分布，与过程在时刻<em>t</em>0之前所处的状态无关的特性称为马尔可夫性</p>
<p><strong>马尔可夫过程</strong>：具有马尔可夫性的随机过程称为马尔可夫过程。</p>
<p><strong>马尔可夫链</strong>：时间和状态都是离散的马尔可夫过程称为马尔可夫链，主要用于分析随机事件未来发展变化的趋势。</p>
<h2 id="基于Flink的水文时间序列异常检测算法"><a href="#基于Flink的水文时间序列异常检测算法" class="headerlink" title="基于Flink的水文时间序列异常检测算法"></a>基于Flink的水文时间序列异常检测算法</h2><p>由于该实验的时间格式，水平标记重叠并且观察效果差。因此，将<strong>天数</strong>用作水平轴。然后，我们引入时间连续的数据流以进行异常检测。</p>
<p>以下是<strong>原始水文时间序列</strong>的一部分。</p>
<p><img src="https://static-01.hindawi.com/articles/mpe/volume-2020/3187697/figures/3187697.fig.004.svgz" alt="img"></p>
<p><strong>一、数据预处理</strong></p>
<p>在进行异常检测之前，应先清理获取的数据，清理前的数据如下。</p>
<p>原始数据集中存在很多问题，例如重复，排序混乱，日期格式不符合数据挖掘要求以及不相关序列的存在。为解决上述问题，我们<strong>基于Flink</strong>处理了18910864行水文数据，消除其中的无效数据和重复数据，并统一了数据格式。</p>
<p><strong>二、异常检测</strong></p>
<p><strong>（1）本篇论文的ARIMA模型参数如何确定的？</strong></p>
<p><strong>答</strong>:我们通过对时间序列进行<strong>单位根检验</strong>，判断出是非平稳序列，再通过差分将其转换为平稳序列。最后根据<strong>AIC准则</strong>，我们确定了自回归阶数<em>p</em>和移动平均阶数<em>q，</em>并找到具有最小AIC值的<em>p</em>和<em>q</em>组合</p>
<p><strong>（2）ARIMA模型预测的是单点预测还是多点预测？</strong></p>
<p><strong>答</strong>:是<strong>多点预测</strong>，通过将初始时间序列由滑动窗口划分为一段段的序列，再由窗口滑动时，将窗口内的原始数据值输入到ARIMA模型形成一个新的时间序列</p>
<p><img src="https://i.loli.net/2021/03/05/PAcYV4UfxJ5wb92.png" alt="image-20210305115957543.png"></p>
<p>首先，时间序列的ARIMA模型{x1,x2,…,xn}通过滑动窗口的预测检验（Forecast Testing）思想建立了“预测值”，并获得了预测检验的<strong>置信区间</strong>，并将其与<strong>原始数据</strong>进行比较得出候选异常值。该算法使用滑动窗口和ARIMA模型在Flink平台上进行预测。</p>
<p>以下是设置了滑动窗口长度为6的数据集上使用ARIMA模型检测到异常的情况下，显示出置信度为95％的<strong>测量值</strong>和<strong>置信区间</strong>。由图可知，大多数点都非常接近正常值，但是在区间外还有一些点，因此它们被判断为可疑异常点。</p>
<p><img src="https://static-01.hindawi.com/articles/mpe/volume-2020/3187697/figures/3187697.fig.005.svgz" alt="img"></p>
<p><strong>三、结果验证</strong></p>
<p><strong>为什么要通过聚类再使用马尔可夫链的状态转换矩阵来计算其真实异常值的概率？</strong></p>
<p><strong>答:K-Means++算法</strong>模型训练完成后，可以得到离散的状态序列{T1,T2,…}，并且通过将矩阵转换为数据帧计算获得状态转移矩阵。再将ARIMA模型得到的可疑异常点集及其前一时刻的值输入到<strong>聚类</strong>训练好的模型中，以获取异常状态及其前一时刻状态，再通过状态转换数据帧估计异常的值及其前一时刻的值，输出真实异常值的概率。</p>
<p><strong>马尔可夫过程中的状态转移矩阵有什么意义？</strong></p>
<p><strong>答</strong>:马尔可夫每个时间点处在某一个状态，时间是离散的，每次到下一个时间点时按照图进行随机状态转移。假如某时的状态是个统计分布（看做向量），那么用状态转移矩阵（图里头边的权值）乘这个向量就得下一时刻的状态。不管初始状态是什么概率分布，状态转移矩阵不断乘它，这个状态向量最终会达到某个确定的平衡点。 </p>
<p>解释链接：<a href="https://www.zhihu.com/question/41423304?sort=created">https://www.zhihu.com/question/41423304?sort=created</a></p>
<p>在检测到异常值之后，通过<em>K</em>-Means++算法对<strong>原始数据</strong>进行聚类，并在聚类后使用状态转换矩阵来计算其真实异常值的概率。最后通过状态转移评估异常值并最终确定异常值。</p>
<ol>
<li><p>在表中，t0表示传输前的状态，t1表示传输后的状态。通过对初始水文时间序列进行聚类，选取异常值的状态和它们的前一阶矩，并在表3中查找得到真实异常值的概率，得到了以下结果。</p>
<p><img src="https://i.loli.net/2021/03/05/7tDiagf8RQshzJ9.png" alt="image-20210303151016545.png"></p>
<p>2.表中显示预测检验部分检测到的值确实是异常值的概率，可以看出某些检测值的真实异常值的概率为0，所以我们将这些真实异常值的概率小于50%的值从检测值中剔除。最终检测出水文时间序</p>
</li>
</ol>
<p>列中的异常值。</p>
<p><img src="https://i.loli.net/2021/03/05/3bdkNThVflgX6pJ.png" alt="image-20210303151153820.png"></p>
<h2 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h2><h5 id="实验环境和数据集"><a href="#实验环境和数据集" class="headerlink" title="实验环境和数据集"></a>实验环境和数据集</h5><p>运行时环境在使用四台PC的群集中部署，相关软件版本如下：Java 1.8和Flink 1.5.2，数据集为18910864行记录。</p>
<p>如果基于滑动窗口来预测时间序列，则会出现高延迟和长时间运行的计算时间。采用Flink进行计算，比较了在不同计算资源下使用Flink执行算法的时间。结果如下。</p>
<p><img src="https://i.loli.net/2021/03/05/KpLridb8OHf2AZX.png" alt="image-20210303154457730.png"></p>
<p>从图中可以看出，在选择<strong>15个和35个</strong>水文站的数据的情况下，双节点的运行速度并不理想，但是当数据量增加到<strong>数千万级</strong>时，双节点的优势可以体现出计算时间的优势。可以看出，在较大的数据集下，计算速度更快。</p>
<p><strong>有效性和准确性</strong></p>
<p>检测到的异常值，并使用状态转换矩阵来计算其真实异常值的概率。为了验证该机制的有效性和准确性，将实验结果分为四类。第一类为TP（真阳性），判断为实际异常。第二类为FN（假阴性），实际异常被判断为正常；第三类为FP（假阳性），判断为实际正常。最后一个类别是TN（真负），并且实际法线被判断为法线。TP和TN是不需要FN和FP的理想情况。本文定义了灵敏度Sensitivity=TN / (TN + FP) 以及特异性，Specificity=TP / (TP + FN)。本文将基于滑动窗口，<strong>MARS的ARIMA模型</strong>和本文的算法在相同的水文时间序列数据集上进行了比较，结果如下</p>
<p><img src="https://i.loli.net/2021/03/05/AINWv1la6UB3wjH.png" alt="image-20210303152656364.png"></p>
<p>表中显示了三种模型的最佳结果进行比较。结果表明，传统的窗口方法在<strong>特异性方面</strong>（不误报）与本文提出的方法没有显着差异，保持了较高的准确性。在<strong>灵敏度</strong>（不漏报）方面，作为一种非线性预测模型，MARS在<strong>样本较小</strong>的情况下表现较好，最高达到83.12%。但是，随着<strong>窗口大小</strong>的增加，这种增加不如本文提出的算法好，因为本文的算法包含了历史校验机制，使用历史数据对实时数据进行校验。随着窗口大小的增加，本文提出的算法与传统算法相比有了明显的提高，灵敏度从72.91%提高到92.98%。与MARS模型相比，改进幅度高达2.75%。</p>
<p><img src="https://i.loli.net/2021/03/05/q8WfhXbIAr5BHmo.png" alt="image-20210303153254069.png"></p>
<p>从图中可以看出，随着<strong>窗口数量</strong>的增加，当窗口大小约为30时，特异性和灵敏度迅速提高。在窗口大小从10增大到30的过程中，特异性提高了29.47％，达到99.47％ ，灵敏度增加了42.08％，达到了92.44％，而延迟增加了93.32％，达到了19.92 ms。但是，当窗口大小大于30时，特异性和灵敏度变化不大，但<strong>延迟率</strong>增加到57.21 ms，增加了187.2％。因此，理想的选择是将窗口长度设置为大约30，这可以使平均延迟小于20 ms。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>在大数据时代，传统的检测算法无法满足当前的需求。针对滑窗的特点以及传统滑窗检查的时间复杂度高，检错率高等缺点，提出了一种基于Flink的水文时间序列异常检测方法。通过使用<strong>Flink计算，此方法减少了计算时间</strong>，并将两个过程结合在一起。</p>
<p>以楚河水文传感器的数据为实验数据，分别对离群值的检测时间和有效性进行了实验。结果表明，使用2个从站的百万个数据在<strong>计算时间</strong>上要比1个从站花费更多的时间，但是当计算十个数据时，2个从站比1个从站要好，最大值减少了17.43％。评估的<strong>灵敏性</strong>从72.91％增加到92.98％。在延迟方面，不同从站的平均延迟大致相同，保持在20 ms以内。结果表明，当该方法用于检测数以千万计的水文数据时，通过添加节点可以有效地提高Flink的计算效率。同时，与传统方法相比，该方法的灵敏度大大提高。</p>
]]></content>
      <categories>
        <category>mpt</category>
      </categories>
      <tags>
        <tag>异常检测</tag>
        <tag>大规模</tag>
      </tags>
  </entry>
  <entry>
    <title>mpt 【KKD-2019】Time-Series Anomaly Detection Service at Microsoft</title>
    <url>/2021/01/06/MaPeitao/Time-Series%20Anomaly%20Detection%20Service%20at%20Microsoft%5BKDD&#39;%202019%5D(1)/</url>
    <content><![CDATA[<p><strong>摘要：</strong>大型公司需要实时监视其应用程序和服务中的各种<code>指标</code>（例如，“页面浏览量”和“收入”）。在Microsoft，我们开发了时间序列异常检测服务，该服务可帮助客户不断的监视时间序列并及时提醒潜在的事件。在本文中,为了解决时间序列异常检测的问题，我们提出了一种基于<strong>谱残差（SR）</strong>和<strong>卷积神经网络（CNN）</strong>的新算法。我们的工作是尝试将<strong>视觉显着性检测域中</strong>的SR模型首次迁移到时间序列异常检测中。此外，我们创新地将SR和CNN结合在一起以改善SR模型的性能。与公共数据集和Microsoft数据集的最新基准（只使用了周期相关的历史数据，没有使用上同周期相邻时刻的历史数据）模型相比，我们的方法获得了优异的实验结果。</p>
<p>关键词：异常检测，无监督，时间序列</p>
<a id="more"></a>
<h2 id="论文背景与意义"><a href="#论文背景与意义" class="headerlink" title="论文背景与意义"></a>论文背景与意义</h2><p><strong>异常检测</strong>旨在发现意外事件或数据中的稀有项。它在许多工业(以盈利为主的)应用中都很流行，并且它也是数据挖掘中的重要研究领域。准确的异常检测可以触发及时的故障排除，从而避免企业亏损，并维护了公司的声誉和品牌。为此，大公司开始建立异常检测服务来监视其业务，产品和服务的健康状况。例如，雅虎发布了EGADS系统 ，可以自动监视数百万个不同Yahoo属性的时间序列并发出警报。在Microsoft，我们构建了异常检测服务来监视例如Bing，Office和Azure等应用的数百万个指标，这使工程师能够更快地解决问题。然而在设计时序异常检测的工业服务时面临了许多挑战：</p>
<p><strong>挑战1：缺乏标签</strong>。为了给单个业务场景提供异常检测服务，系统必须同时处理<strong>数百万</strong>个时间序列。用户没有简单的方法能够手动标记每个时间序列。而且，时间序列的数据分布是<strong>不断变化</strong>的，这要求系统能识别出以前从未出现过类似数据的模式。这使得有监督模型在工业场景中应用不足。</p>
<p><strong>挑战2：泛化</strong>。需要监视来自<strong>不同业务场景</strong>的各种时间序列。如图1所示，有几种典型的时间序列模式类别。对于工业异常检测服务来说，在各种模式下正常工作是非常的重要。然而，对于不同的模式，现有的方法还没有得到足够的概括。例如，<code>Holt winters模型</code>（基于时间序列中当前已有的数据来预测其之后的走势）在（b）和（c）中总是表现出差的结果。 <code>Spot模型</code> 在（a）中总是表现出差的结果。因此，我们需要找到通用性更好的解决方案。</p>
<p><img src="https://i.loli.net/2021/03/04/cNpflAV6J3F1xHo.png" alt="image-20201208094008458.png"></p>
<p><strong>挑战3：效率</strong>。在应用程序中，监视系统必须几乎<strong>实时处理</strong>数百万甚至数十亿个时间序列。特别是对于<strong>分钟级别</strong>的时间序列，异常检测过程需要在有限的时间内完成。因此，效率是在线异常检测服务的主要前提之一。即使具有<strong>较大时间复杂度的模型</strong>在<strong>准确性方面</strong>表现出色，但在在线情况下它们通常很少使用。</p>
<h2 id="论文的目标"><a href="#论文的目标" class="headerlink" title="论文的目标"></a><strong>论文的目标</strong></h2><p>为了解决上述问题，我们的<strong>目标</strong>是开发一种<strong>准确，高效且通用</strong>的异常检测方法。传统的统计模型由于准确性不高，不足以用于工业应用。有监督模型的准确性更高，但是由于缺少标记数据（<strong>人工标记的开销太大</strong>），在我们的场景中它们也是不足的。还有一些无监督的方法，例如<code>Luminol</code>（用于时间序列数据分析的python库。将时间序列分为多个块，并使用相似块的频率来计算异常分数）和<code>DONUT</code>（一种基于<strong>变分自动编码器</strong>（<strong>VAE</strong>）的无监督异常检测方法）。但是，这些方法太耗时或参数敏感。因此，我们旨在以另一种无监督的方式开发一种同时兼顾准确性，效率和通用性的模型。</p>
<h2 id="异常检测系统架构"><a href="#异常检测系统架构" class="headerlink" title="异常检测系统架构"></a>异常检测系统架构</h2><p>整个系统由三个主要部分组成：数据提取，实验平台和在线计算。</p>
<p>首先介绍整个流程。用户可以将时间序列导入到系统来注册监视任务。支持从不同的数据源（包括Azure存储，数据库和在线流数据）提取时间序列。提取人员负责根据指定的粒度（例如分钟，小时或天）更新每个时间序列。时间序列点通过<strong>Kafka</strong>进入流传输管道，并存储到<strong>时间序列数据库</strong>中。<strong>异常检测处理器</strong>在线计算传入的时间序列点的异常状态。在监视业务指标的常见方案中，用户也可以查看时间序列数据。例如，Bing团队提取了表示不同市场和平台使用情况的时间序列。发生事件时，警报服务会整理相关时间序列的异常，然后通过电子邮件和传呼服务将其发送给用户。整合的异常事件总体状态信息将帮助用户缩短诊断问题的时间。下图展示了系统的总体流水线。</p>
<p><img src="https://i.loli.net/2021/03/04/caw1ZMfeRuphg6P.png" alt="image-20201208102604733.png"></p>
<p>2.1数据提取</p>
<p>用户可以通过创建数据源来注册监视任务。每个数据点均由“连接字符串”和“粒度”标识。连接字符串用于将用户的存储系统连接到异常检测服务。粒度表示数据Feed（采集）的更新频率；最小粒度为一分钟。提取任务将根据给定的粒度把时间序列的数据点提取到系统中。例如，如果用户将分钟设置为粒度，则提取模块将每分钟创建一个任务来提取一个新的数据点。时间序列点被吸收到influxDB（时间序列数据库）和Kafka（流处理管道）中。该模块的吞吐量达到每秒10,000到100,000个数据点左右。</p>
<p>2.2在线计算</p>
<p>在线计算模块在进入管道（pipeline）后将立即处理每个数据点。为了检测输入点的异常状态，需要时间序列数据点的滑动窗口。因此，我们使用<strong>Flink</strong>来管理内存中的点以优化计算效率。流媒体管道每天处理超过400万个时间序列。每分钟最大吞吐量可以达到400万。<strong>异常检测处理器</strong>检测每一个时间序列的异常。实际上，单个异常不足以使用户有效地诊断其服务。因此，智能警报处理器将不同时间序列的异常关联起来，并相应地生成事件报告。</p>
<p><strong>Flink</strong>支持流处理和窗口事件时间语义，Flink能够<strong>高吞吐量和低延迟</strong>；</p>
<p><strong>Kafka</strong>支持高吞吐量，每秒<strong>数百万</strong>的消息，支持通过Kafka服务器和消费机集群来分区消息。</p>
<p>2.3实验平台</p>
<p>我们建立了一个实验平台来<strong>评估</strong>异常检测模型的性能。在我们部署新模型之前，将在平台上进行离线实验和在线A / B测试。用户可以把某个点标记为异常或正常。为人工编辑人员提供了标签服务。编辑者将首先标记单个时间序列的真实异常点，然后根据特定模型的异常检测结果标记错误的异常点。已标记的数据用于评估异常检测模型的准确性。我们还评估了平台上每种模型的效率和通用性。如果验证模型有效，则平台会将其公开为Web服务并将其托管在K8s（全称Kubernetes，用于管理云平台中多个主机上的容器化应用，轻松高效地管理这些集群）上。</p>
<p>2.4系统应用</p>
<p>在微软，通常需要监视业务指标并迅速采取措施以解决突发的异常问题。为了解决该问题，我们构建了一个可伸缩的系统，能够监视来自各种数据源的分钟级时间序列。提供自动诊断意见以帮助用户有效地解决其问题。</p>
<p><strong>例子：</strong>Outlook反垃圾邮件团队曾经利用基于规则的方法来监视其垃圾邮件检测系统的有效性。但是，此方法不易于维护，并且在某些地理位置有很差的效果。因此，他们将关键指标纳入我们的异常检测服务，以监控其垃圾邮件检测模型在不同地理位置的有效性。通过我们的API，他们已将异常检测功能集成到Office DevOps平台中。通过使用此自动检测服务，与原始的基于规则的解决方案相比，他们覆盖了更多的地理位置，并且收到的误报案件更少。</p>
<h2 id="为什么要使用SR-CNN"><a href="#为什么要使用SR-CNN" class="headerlink" title="为什么要使用SR-CNN"></a>为什么要使用SR-CNN</h2><p>正如引言中所强调的，我们的挑战是开发一种没有标签数据的高效通用算法。受计算机视觉领域的启发，我们采用谱残差（SR）模型，这是一种基于<strong>快速傅立叶变换</strong>（FFT）的方法。  SR方法是无监督的，并且已被证明在视觉显着性检测应用中非常有效。因为异常点在视觉上通常很明显，因此我们认为<strong>视觉显着性检测任务</strong>和<strong>时间序列异常检测任务</strong>在本质上是相似的。此外，最近的显着性检测研究表示当有足够的标签数据可用时<strong>更倾向于</strong>使用卷积神经网络（CNN）进行端到端训练。然而，由于难以在线收集大规模的标签数据，因此单独使用CNN模型对我们的应用来说是不可行的。作为一种折衷，我们提出了一种新的方法SR-CNN，该方法将CNN直接应用于SR模型的输出。  CNN负责学习区分规则，以替换原始SR解决方案中采用单个阈值来判断异常。在SR结果上学习CNN模型比在原始输入序列上学习问题要容易得多。在以下小节中，我们分别介绍SR和SR-CNN方法的细节。</p>
<h2 id="SR（谱残差）"><a href="#SR（谱残差）" class="headerlink" title="SR（谱残差）"></a>SR（<strong>谱残差</strong>）</h2><p>SR算法包括三个主要步骤：（1）傅里叶变换以获得对数幅度谱； （2）频谱残差的计算； （3）傅立叶逆变换，将序列变换回空间域。</p>
<p><img src="https://i.loli.net/2021/03/04/z2HOqcCpFP1BmuJ.png" alt="image-20201208150037836.png"></p>
<p>数学上，给定序列x，我们有</p>
<p><img src="https://i.loli.net/2021/03/04/5RkuY4CtfGj8Jdx.png" alt="image-20201208150528569.png">分别表示<strong>傅立叶变换</strong>(<strong>时域到频域的变换，而这种变换是通过一组特殊的正交基来实现的</strong>)和<strong>傅立叶逆变换</strong>。x是形状为n×1(n维向量)的输入序列；<code>A(f)</code>是序列x的<strong>幅度谱</strong>；<code>P(f)</code>是序列x的<strong>相位谱</strong>；<code>L(f)</code>是A(f)的对数表示（对幅度谱取对数）；<code>AL(f)</code>是L(f)的<strong>平均对数谱</strong>，可以通过用<code>hq(f)</code><strong>卷积（两个相同大小的矩阵对应元素相乘后求和，乘积的和就生成了feature map中的一个像素，当一个像素计算完毕后，移动一个像素取下一个区块执行相同的运算。当无法再移动取得新区块的时候，对feature map的计算就结束了）</strong>输入序列来近似得出。其中hq(f)是一个q×q矩阵，定义为：</p>
<p><img src="https://i.loli.net/2021/03/04/V5LAztJYjRNlham.png" alt="image-20201208152131806.png"></p>
<p><code>R(f)</code>是谱残差，即对数谱L(f)减去平均对数谱AL(f)。利用<strong>剩余谱和相位谱</strong>进行傅立叶逆变换将序列转移回空间域，得到序列<code>S(x)</code>称为<strong>显著图(saliency map)</strong>。<strong>（傅里叶变换一般涉及到复数，也就是说一个实数被变换为一个具有实部和虚部的复数。通常虚部只在一部分领域有用，比如将频域变换回到时域和空域（像素域）上）</strong></p>
<p><img src="https://i.loli.net/2021/03/04/xPInZirH7Mfwy9Y.png" alt="image-20201208160558625.png"></p>
<p><strong>图4</strong>显示了经过SR处理后的原始时间序列和相应的显著性图的示例。如图所示，显著性图中的变化点（以红色显示）比原始输入中的变化点明显得多。基于显著性图，很容易利用简单的规则正确注释异常点。我们采用简单的<strong>阈值τ</strong>表示异常点。给定显著性图<code>S(x)</code>，输出序列<code>O(x)</code>的计算公式为：</p>
<p><img src="https://i.loli.net/2021/03/04/lpcir5GQTfZy6te.png" alt="image-20201208160936734.png"></p>
<p>其中xi表示序列x中的任意点； S(xi)是显著图中的对应点； S(xi) ba 是S(xi)之前z个点的局部平均值。</p>
<p>在实际应用中，FFT(快速傅里叶变换)操作是在序列的<strong>滑动窗口</strong>内进行的。此外，我们希望该算法能够发现<strong>低延迟的异常点</strong>。也就是说，给定流x1，x2，…，xn，其中xn是最近的点，我们想尽快分辨xn是否是一个异常点。但是，如果目标点（想要分辨的点）位于滑动窗口的中心，则SR方法效果更好。因此，在将序列输入到SR模型之前，我们在xn之后添加了几个<strong>估计点</strong>。估计点xn+1的值由下式计算：</p>
<p><img src="https://i.loli.net/2021/03/04/nsQogbBD6KJ1xAa.png" alt="image-20201208163331524.png"></p>
<p>其中g(xi，xj)表示点xi和xj两点之间的直线的斜率; g ba表示先前点的平均<strong>斜率</strong>（从1到m的xi和xj之间的平均斜率）。m是前面考虑的添加点的个数，我们在实现中将m=5。我们发现，第一个估计点起着决定性的作用。因此,我们复制K次点xn+1，然后把它添加到序列的尾部。总而言之,SR算法只包含3个超参数,即<strong>滑动窗口</strong>大小ω,<strong>估计点</strong>个数κ,<strong>异常检测阈值</strong>τ。我们根据经验设置了它们，并在实验中展示了它们的鲁棒性。因此，SR算法对于<strong>在线异常检测服务</strong>来说是一种很好的选择。</p>
<h2 id="SR-CNN"><a href="#SR-CNN" class="headerlink" title="SR-CNN"></a>SR-CNN</h2><p>原始的SR方法利用显著性图上的<strong>单个阈值</strong>来检测异常点，如上图所定义。然而，该规则过于简单，人们自然会寻求更复杂的决策规则。我们的理念是在精心设计的合成数据上训练一个<strong>判别模型</strong>作为异常检测器。通过将<strong>不包含</strong>在评估数据中的异常点注入到显著性图集合中，来生成合成数据。注入点标记为异常，其他点标记为正常。具体地说，我们在时间序列中随机选取几个点，计算注入值来代替原始点，得到其显著性图。异常点值的计算方法为:</p>
<p><img src="https://i.loli.net/2021/03/04/PtLV6iWZfUl8IOT.png" alt="image-20201208171907400.png"></p>
<p>其中x ba是前几个点的局部平均值；<strong>mean</strong>(均值)和<strong>var</strong>(方差)是当前滑动窗口内所有点的均值和方差；r〜N（0,1）是随机抽样的。我们选择CNN作为我们的判别模型架构。<strong>CNN</strong>是用于显著性检测的常用监督模型。但是，由于我们的场景中没有足够的标记数据，因此我们基于显著图而不是原始输入来应用CNN，这使得异常标注问题变得更加容易。在实践中，我们收集合成异常的生产时间序列作为训练数据。好处是检测器可以适应时间序列分布的变化，而无需人工标记的数据。在我们的实验中，我们总共使用了6,500万个点进行训练。  SR-CNN的体系结构如图5所示。该网络由两个<strong>一维卷积层</strong>（<strong>滤波器</strong>大小等于<strong>滑动窗口</strong>大小ω）和两个<strong>全连接层</strong>组成。第一个卷积层的信道大小等于ω；而在第二个卷积层中，通道大小增加了一倍。在输出<strong>Sigmoid</strong>之前，要堆叠两个全连接层。<strong>交叉熵</strong>被用作损失函数。训练过程中使用了<strong>SGD（随机梯度下降）优化器</strong>。</p>
<p><img src="https://i.loli.net/2021/03/04/HerS3NzkLgCtBAb.png" alt="image-20201208183856551.png"></p>
<h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><p>使用三个数据集来评估了SR-CNN模型。<code>KPI</code>和<code>Yahoo</code>是常用于<strong>评价时间序列异常检测性能</strong>的公共数据集;而<code>Microsoft</code>是在产品中收集的内部数据集。这些数据集涵盖了不同时间间隔的时间序列。在这些数据集中，<strong>异常点</strong>标记为<strong>正样本</strong>，<strong>正常点</strong>标记为<strong>负样本</strong>。这些数据集的统计数据如表1所示。</p>
<p><img src="https://i.loli.net/2021/03/04/fqZvglCbpXFVxDd.png" alt="image-20201208184848486.png"></p>
<p><code>KPI</code>由<strong>AIOps</strong>发布。该数据集由多条带有异常标签的KPI曲线组成，大部分KPI曲线相邻两个数据点之间的间隔为1分钟，部分KPI曲线的间隔为5分钟。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">数据集</span><br><span class="line">http:<span class="comment">//iops.ai/dataset_detail/?id=10</span></span><br><span class="line"></span><br><span class="line">http:<span class="comment">//iops.ai/competition_detail/?competition_id=5&amp;flag=1</span></span><br></pre></td></tr></table></figure>
<p><code>Yahoo</code>是 <strong>Ya-hoo lab</strong>发布的用于异常检测的开放数据集。时间序列曲线中的一部分是人工合成的(即模拟的)，另一部分来自雅虎服务的真实流量。模拟曲线中的异常点由算法生成，真实交通曲线中的异常点由编辑人员手动标注。所有时间序列的间隔为一小时。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">https:<span class="comment">//yahooresearch.tumblr.com/post/114590420346/a-benchmark-dataset-for-time-series-anomaly</span></span><br></pre></td></tr></table></figure>
<p><code>Microsoft</code>是从微软内部异常检测服务中获得的数据集。我们随机选取一组时间序列进行评价。选择的时间序列反映了不同的KPI，包括收入、活跃用户、页面浏览量等，异常点由客户或编辑手动标注，这些时间序列的间隔为一天。</p>
<h2 id="指标"><a href="#指标" class="headerlink" title="指标"></a>指标</h2><p>我们从准确性、效率和通用性三个方面对我们的模型进行了评估。我们使用 <strong>precision</strong>(精确率)、<strong>recall</strong>(召回率)和<strong>F1-score</strong>(F1得分)来表示我们模型的<strong>准确性</strong>。对于那些应用于在线服务的模型。在这个系统中，我们每秒必须完成数十万次计算。模型的延迟需要足够小，这样才不会阻塞整个计算管道。在我们的实验中，我们评估了三个数据集上的总执行时间，以比较不同异常检测方法的<strong>效率</strong>。除了准确性和效率，我们在评价时也强调<strong>通用性</strong>（泛化能力）。如前所述，工业异常检测模型应该能够处理不同类型的时间序列。为了评估通用性，我们将Yahoo数据集中的时间序列手工划分为三大类(如图1所示的季节性、稳定和不稳定)，并分别比较不同类别的<strong>F1得分</strong>。</p>
<p><strong>Positive正（阳性）   Negative负（阴性）   True真  False假</strong></p>
<p>在异常检测中，<strong>P和N</strong>一般是针对<strong>预测</strong>来说的，而Positive正类指的是你更关心的那一类，即<strong>异常</strong>，Negative负类就是指正常。总结来说就是：<strong>P指预测为异常，N指预测为正常</strong></p>
<p><strong>T和F</strong>是针对预测<strong>与实际的比较结果</strong>，True真是指正确匹配，具体来说就是：你预测它为正，它实际结果也为正，你预测它为负，它实际也为负，False假就是错误匹配。</p>
<p>TPR：真正类率，又叫真阳率，代表预测是异常实际也是异常的样本数,占实际总异常数的比例—值越<strong>大</strong>  性能越好</p>
<p>FPR：假正类率，又叫假阳率，代表预测是异常但实际是正常的样本数,占实际正常总数的比例—值越<strong>小</strong>  性能越好</p>
<p>P(<strong>precision</strong>)：精确率，代表<strong>预测是异常,实际也是异常</strong>的样本数,占预测是异常的总数的比例—值越<strong>大</strong>  性能越好</p>
<p>R(<strong>recall</strong>)： 召回率，意义同TPR—值越<strong>大</strong> 性能越好</p>
<p>F： P和R的加权调和平均，常用的是<strong>F1值(F1-score)</strong>—值越<strong>大</strong> 性能越好</p>
<p>A(<strong>accuracy</strong>)：正确率，与精确率的区别是，不仅考虑异常类也考虑正常类，即所有匹配样本数，占所有样本的比例—值越<strong>大</strong> 性能越好</p>
<p>FP（误报：正常被误报成异常）      FN（异常漏报：异常被误报成正常）</p>
<h2 id="SR-SR-CNN实验"><a href="#SR-SR-CNN实验" class="headerlink" title="SR/SR-CNN实验"></a>SR/SR-CNN实验</h2><p>我们将<strong>SR和SR-CNN</strong>与最新的无监督时间序列异常检测方法进行了比较。<strong>基线模型</strong>包括FFT(快速傅立叶变换)、Twitter-AD(推特异常检测)、Luminol(LinkedIn异常检测)、DONUT、SPOT和DSPOT。在这些方法中，FFT、Twitter-AD和Luminol不需要额外的数据就可以启动，所以我们将所有的时间序列作为测试数据，在<strong>冷启动</strong>（没有任何先验知识，协同过滤推荐算法中被广泛关注的一个经典问题）的情况下对这些模型进行了比较。另一方面，Spot、DSPOT和Donut需要额外的数据来训练他们的模型。因此，我们将每个时间序列的点按时间顺序一分为二。前半部分用来训练无监督模型，后半部分用来进行评估，Donut可以利用额外的标记数据来提高异常检测性能。然而，由于我们的目标是在完全无监督的情况下获得公平的比较，所以我们在实现中不使用额外的标记数据。</p>
<p>对于SR和SR-CNN，我们对超参数进行了<strong>经验设置</strong>。在SR中，Hq(f)中q被设置为3，z的局部平均数z被设置为21，阈值τ被设置为3，估计点数κ被设置为5，对于滑动窗口大小ω，KPI设置为1440，雅虎设置为64，微软设置为30。对于SR-CNN，q、z、κ和ω被设置为相同的值。</p>
<p>我们分别报告(1)F1-score；(2)Precision；(3)Recall；(4)每个数据集的CPU执行时间。我们可以看到，SR的性能明显优于当前最先进的无监督模型。此外，SR-CNN在三个数据集上都取得了进一步的改进，这表明了用CNN鉴别器取代单一阈值的优势。<strong>表2</strong>显示了冷启动情况下FFT、Twitter-AD和 Luminol的比较结果。与基准解决方案获得的最佳结果相比，我们在KPI数据集、Yahoo数据集和Microsoft数据集上的F1-score分别提高了36.1%、68.8%和21.2%。<strong>表3</strong>展示了那些需要在数据集的前半部分(不包括标签)上训练的无监督模型的比较结果。如表3所示，与最先进的结果相比，F1-Score在KPI数据集上提高了48.0%，在Yahoo数据集上提高了92.9%，在Microsoft数据集上提高了57.0%。此外，表2和表3中的总CPU执行时间表明，SR是最有效的方法。为了进行通用性比较，我们在人工分类为三类的Yahoo数据集的后半部分上进行了实验。<strong>表4</strong>分别报告了<strong>Yahoo数据集不同类别</strong>的<strong>F1-score</strong>。SR和SR-CNN在不同的时间序列模式上取得了突出的结果。SR是这三个类别中最稳定的一个。SR-CNN也表现出良好的泛化能力。</p>
<p><img src="https://i.loli.net/2021/03/04/UnPMkTLxZhbFQf2.png" alt="image-20201208205104410.png"></p>
<p><img src="https://i.loli.net/2021/03/04/JeVHF8ORzpIDjQC.png" alt="image-20201208205121958.png"></p>
<p><img src="https://i.loli.net/2021/03/04/WYIxbS9gPqroFHd.png" alt="image-20201208205210287.png"></p>
<h2 id="SR-DNN"><a href="#SR-DNN" class="headerlink" title="SR+DNN"></a>SR+DNN</h2><p>在先前的实验中，我们可以看到SR模型在<strong>无监督的异常检测</strong>情况下表现出了很好的结果。但是，在其他人已完成的工作表明，当<strong>异常标签可用</strong>时，我们可以获得更令人满意的结果，因此，我们想知道我们的方法是否<strong>有助于监督模型</strong>。具体而言，我们将SR的<strong>中间结果</strong>作为监督异常检测模型中的附加功能。我们对AIOPS中对KPI数据集进行了广泛的研究后，采用基于DNN的有监督模型，该模型是AIOPS数据竞赛的第一名。  <strong>DNN体系结构</strong>由输入层，输出层和两个隐藏层组成。</p>
<p><img src="https://i.loli.net/2021/03/04/prGeImt13YganCh.png" alt="image-20201208210054695.png"></p>
<p>我们在第二个隐藏层之后增加了一个<strong>dropout layer</strong>（丢弃层），并将丢弃率设置为0.5。此外，我们将L1 = L2 =  0.0001正则化所有层的权重。由于模型的输出表示数据点异常的可能性，因此我们在训练集上学习最佳阈值。</p>
<p>实验结果如<strong>表7</strong>所示。我们可以看到，SR功能为DNN模型带来了F1-score提高1.6％的效果。尤其是，基于SR的DNN模型在KPI数据集上建立了一个最先进的模型。据我们所知，这是迄今为止KPI数据集上报告的迄今为止最好的结果。此外，我们绘制了SR  + DNN和DNN方法的<strong>P-R曲线（右上凸效果越好）</strong>。如图8所示，在各种阈值上，SR + DNN始终优于DNN。</p>
<p><img src="https://i.loli.net/2021/03/04/vFNodC6PbTBSkAZ.png" alt="image-20201208210742680.png"></p>
<p><img src="https://i.loli.net/2021/03/04/TWywFoQZ3hnlaYq.png" alt="image-20201208211105819.png"></p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>时间序列异常检测是保证在线服务质量的关键模块。在实际应用中，一个高效、通用、准确的异常检测系统是必不可少的。在本文中，我们介绍了微软的一项时序异常检测服务。在生产过程中，每分钟最多可从400万个时间序列中检测到异常。此外，我们还首次将谱残差模型应用于时序异常检测任务，并创新性地将谱残差模型与CNN模型相结合，取得了较好的效果。</p>
]]></content>
      <categories>
        <category>mpt</category>
      </categories>
      <tags>
        <tag>异常检测</tag>
      </tags>
  </entry>
  <entry>
    <title>nxj 【TPAMI-2019】Meta-Transfer Learning through Hard Tasks</title>
    <url>/2021/03/10/MaZhaoyang/Meta-Transfer%20Learning%20through%20Hard%20Tasks(1)/</url>
    <content><![CDATA[<p>关键词： 元学习；迁移学习</p>
<h2 id="贡献"><a href="#贡献" class="headerlink" title="贡献"></a>贡献</h2><ul>
<li>提出了元迁移学习（MTL, Meta-Transfer Learning），该方法学习如何将深度神经网络的权值转移到小样本学习中任务<br>Meta：指训练多个任务；Transfer：学习每个任务的DNN权重的缩放和偏置（<strong>SS</strong>, Scale and Shift）来实现迁移</li>
<li>其次，提出了Hard Tasks（<strong>HT</strong>）进一步提高MTL的学习效率</li>
<li>在有监督和半监督的环境下，我们在minimagenet、tieredImageNet和Fewshot-CIFAR100（FC100）这三个具有挑战性的基准上对五类小样本分类任务进行了实验，验证了本文提出的HT模式训练的MTL方法具有很好的性能。消融研究表明，SS和HT两个组件有助于快速收敛和高精度。</li>
<li>另外，在每个任务上加入元梯度正则化，利用当前任务和前一任务的元梯度加权和对每个任务进行优化。其目的是迫使元学习器在以后的学习中不要忘记旧知识。</li>
</ul>
<a id="more"></a>
<p>IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI) 2019,<br>（由CVPR 2019《Meta-transfer learning for few-shot learning》扩充）</p>
<hr>
<p>作者：Qianru Sun, Yaoyao Liu, Zhaozheng Chen, Tat-Seng Chua, and Bernt Schiele, <em>Fellow, IEEE</em></p>
<p>机构：新加坡管理大学、马克斯·普朗克信息研究所、新加坡国立大学</p>
<p>Code: <a href="https://github.com/yaoyao-liu/meta-transfer-learning">https://github.com/yaoyao-liu/meta-transfer-learning</a></p>
<hr>
<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>样本过少的情况下→数据增强 / 元学习→现阶段MAML仍有缺点</p>
<ul>
<li>元学习被应用于小样本学习：关键的想法是利用大量相似的小样本任务来学习如何使基础学习器适应一个新的任务</li>
<li>元学习是一种基于任务级优化的方法。其目的是从相似的小样本学习任务中转移经验，相关方法遵循一个包含两个循环的统一训练过程。内循环学习一个基础学习器(base learner)完成一个单独的任务，外循环使用学习基础学习器的验证性能来优化元学习器。</li>
<li><p>一种先进的代表性方法称为模型不可知元学习（MAML），它学习寻找最佳的初始化状态，使基础学习器可以快速适应新的任务</p>
<ul>
<li>i）这些方法通常需要大量类似的元训练任务，成本高昂；</li>
<li>ii）每个任务通常由一个低复杂度的基础学习器建模，如浅层神经网络（SNN），避免模型过拟合到实拍训练数据，从而无法部署更深入、更强大的体系结构</li>
</ul>
</li>
<li><p>传统的meta-batch包含许多随机任务，没有考虑不同任务的困难程度。</p>
</li>
<li><p>最近的一些工作尝试使用在大规模数据集上预先训练的DNN，但大多是以直接的方式，例如：①将其权重作为元训练的热启动；②冻结其卷积层作为基础学习器的特征提取器。</p>
</li>
<li></li>
</ul>
<h2 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h2><h4 id="总体框架"><a href="#总体框架" class="headerlink" title="总体框架"></a>总体框架</h4><p>(a) 在大规模数据上的DNN预训练，即使用整个训练数据集</p>
<p>(b) 在预训练的特征提取器的基础上学习缩放和移位（SS）参数的元转移学习（MTL）<br>这一步使用 HT meta-batch 进行，并由元梯度正则化（第4.3节）正则化</p>
<p>(c) 是对不可见任务的元测试，其处理包括基本学习器（分类器）的微调（FT）阶段和最终评估阶段</p>
<p><strong>这篇文章里 meta-learner(外层优化) 指的是SS，base-learner(内层优化) 指的是classifier，还包含后期固定的feature extractor。</strong></p>
<ul>
<li><img src="http://funera-hk.oss-cn-hongkong.aliyuncs.com/img/image-20210310134342770.png" alt="image-20210310134342770"></li>
</ul>
<h4 id="Meta-transfer-learning-MTL"><a href="#Meta-transfer-learning-MTL" class="headerlink" title="Meta-transfer learning (MTL)"></a>Meta-transfer learning (MTL)</h4><p>元任务的训练集用来训练基础学习器，基础学习器（分类器）θ’的更新规则：（$\Phi_S$是SS的权重）</p>
<p><img src="http://funera-hk.oss-cn-hongkong.aliyuncs.com/img/image-20210310134112665.png" alt="image-20210310134112665"></p>
<p>$\Phi<em>{S_1}$初始化为1，$\Phi</em>{S_2}$初始化为0，并按下式更新：</p>
<p><img src="http://funera-hk.oss-cn-hongkong.aliyuncs.com/img/image-20210310134137972.png" alt="image-20210310134137972"></p>
<p>使用元任务的测试机损失及梯度，用于元参数 $\theta$ 的更新：</p>
<p><img src="http://funera-hk.oss-cn-hongkong.aliyuncs.com/img/image-20210310134151472.png" alt="image-20210310134151472"></p>
<p>$\Phi_S$是SS的权重，元训练期间冻结不予更新。</p>
<p>SS相对于“遗忘”问题有明显优势，避免以往学习的经验丢失；由大规模训练的DNN初始化，可以快速拟合；参数量少。</p>
<p>通过SS和FT（精细调整）进行更新的区别如下图：</p>
<p><img src="http://funera-hk.oss-cn-hongkong.aliyuncs.com/img/image-20210310134203234.png" alt="image-20210310134203234"></p>
<p><img src="http://funera-hk.oss-cn-hongkong.aliyuncs.com/img/image-20210310134320887.png" alt="image-20210310134320887" style="zoom: 80%;" /></p>
<h4 id="Hard-task-HT-meta-batch"><a href="#Hard-task-HT-meta-batch" class="headerlink" title="Hard task (HT) meta-batch"></a>Hard task (HT) meta-batch</h4><p>对于元任务集合$\tau$，在每次更新后，选择最低的精度排序来确定当前系统中最困难的分类样本进行任务的重新采样</p>
<p><img src="http://funera-hk.oss-cn-hongkong.aliyuncs.com/img/image-20210310134301082.png" alt="image-20210310134301082" style="zoom: 80%;" /></p>
<h4 id="Meta-gradient-regularization"><a href="#Meta-gradient-regularization" class="headerlink" title="Meta-gradient regularization"></a>Meta-gradient regularization</h4><ul>
<li>使元学习器减少对先前情节的遗忘</li>
</ul>
<p><img src="http://funera-hk.oss-cn-hongkong.aliyuncs.com/img/image-20210310134243426.png" alt="image-20210310134243426" style="zoom:80%;" /></p>
<h4 id="整体算法"><a href="#整体算法" class="headerlink" title="整体算法"></a>整体算法</h4><ul>
<li><img src="http://funera-hk.oss-cn-hongkong.aliyuncs.com/img/image-20210310152106130.png" alt="image-20210310152106130" style="zoom: 80%;" /></li>
</ul>
<h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><p><strong>数据集</strong>：<em>mini</em>ImageNet，<em>tiered</em>ImageNet， Fewshot-CIFAR100(FC100) </p>
<h4 id="基线对比"><a href="#基线对比" class="headerlink" title="基线对比"></a>基线对比</h4><ul>
<li><img src="http://funera-hk.oss-cn-hongkong.aliyuncs.com/img/image-20210310135000286.png" alt="image-20210310135000286" style="zoom: 67%;" /></li>
<li><img src="http://funera-hk.oss-cn-hongkong.aliyuncs.com/img/image-20210310135021985.png" alt="image-20210310135021985" style="zoom:67%;" /></li>
</ul>
<h4 id="组件验证（SS与FT对比）"><a href="#组件验证（SS与FT对比）" class="headerlink" title="组件验证（SS与FT对比）"></a>组件验证（SS与FT对比）</h4><ul>
<li><p><img src="http://funera-hk.oss-cn-hongkong.aliyuncs.com/img/image-20210310135041309.png" alt="image-20210310135041309" style="zoom: 80%;" /></p>
</li>
<li><p><img src="http://funera-hk.oss-cn-hongkong.aliyuncs.com/img/image-20210310135057179.png" alt="image-20210310135057179" style="zoom: 80%;" /></p>
</li>
</ul>
<h4 id="消融实验"><a href="#消融实验" class="headerlink" title="消融实验"></a>消融实验</h4><ul>
<li><img src="http://funera-hk.oss-cn-hongkong.aliyuncs.com/img/image-20210310154557787.png" alt="image-20210310154557787" style="zoom:80%;" /></li>
<li><img src="http://funera-hk.oss-cn-hongkong.aliyuncs.com/img/image-20210310135155191.png" alt="image-20210310135155191" style="zoom: 80%;" /></li>
</ul>
<p><strong>MTL vs. No meta-learning. </strong> 表6在最上面的块中显示了无元学习方法的结果。本文提出的方法取得了明显更好的性能。</p>
<p><strong>SS[Θ;θ]works better than light-weight FT variants.</strong> 表6显示使用SS[Θ;θ]的方法在所有设置中均达到了最佳性能，且SS始终优于FT。</p>
<p><strong>Meta-gradient regularization is effective.</strong> 表6最后两行显示了有效性。正则化迫使元学习器减少对先前情节的遗忘，并稳定元梯度。</p>
<p><strong>Accuracy gain by HT meta-batch.</strong> 表7、图4显示：HT meta batch可以提高模型的准确率。</p>
<p><strong>Speed of convergence of MTL with HT meta-batch.</strong>  (a)~(d)中HT mete-batch仅需1~4k次迭代达到很好的性能，而没有进行深度预训练网络的MAML需要200k次迭代。</p>
<ul>
<li><img src="http://funera-hk.oss-cn-hongkong.aliyuncs.com/img/image-20210310135139161.png" alt="image-20210310135139161" style="zoom: 80%;" /></li>
</ul>
<h4 id="SS统计分析"><a href="#SS统计分析" class="headerlink" title="SS统计分析"></a>SS统计分析</h4><p>表8中提供了有关学习到的SS权重的统计信息。 (a)和(b)中的每个点表示这些数字的分布，与高斯分布（红色）很好地匹配。</p>
<ul>
<li><img src="http://funera-hk.oss-cn-hongkong.aliyuncs.com/img/image-20210310135217125.png" alt="image-20210310135217125" style="zoom: 80%;" /></li>
</ul>
<h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>事实证明，MTL在预训练的DNN神经元上的关键操作对于使学习经验适应未知任务非常有效。</p>
<ul>
<li><p><strong>MTL</strong>的持续改进证明了大规模预训练有素的深度网络可以提供良好的“知识基础”，以进行有效的一次性学习。</p>
</li>
<li><p>就学习方案而言，<strong>HT meta-batch</strong>对于消融模型始终表现出良好的性能，而且对提高收敛速度特别有用。</p>
</li>
</ul>
<p>展望：本文模型独立于任何特定的模型或体系结构，并且只要在在线迭代中易于评估任务的难度即可很好地推广。</p>
]]></content>
      <categories>
        <category>ssk</category>
      </categories>
      <tags>
        <tag>元学习</tag>
        <tag>迁移学习</tag>
      </tags>
  </entry>
  <entry>
    <title>mzy 【AAAI2021】A Novel Visual Interpretability for Deep Neural Networks by Optimizing Activation Maps with Perturbation 一种新的深度神经网络的视觉可解释性</title>
    <url>/2022/07/20/MaZhaoyang/%E3%80%90AAAI2021%E3%80%91A%20Novel%20Visual%20Interpretability%20for%20Deep%20Neural%20Networks%20by%20Optimizing%20Activation%20Maps%20with%20Perturbation/</url>
    <content><![CDATA[<h3 id="【AAAI2021】A-Novel-Visual-Interpretability-for-Deep-Neural-Networks-by-Optimizing-Activation-Maps-with-Perturbation-一种新的深度神经网络的视觉可解释性"><a href="#【AAAI2021】A-Novel-Visual-Interpretability-for-Deep-Neural-Networks-by-Optimizing-Activation-Maps-with-Perturbation-一种新的深度神经网络的视觉可解释性" class="headerlink" title="【AAAI2021】A Novel Visual Interpretability for Deep Neural Networks by Optimizing Activation Maps with Perturbation 一种新的深度神经网络的视觉可解释性"></a>【AAAI2021】A Novel Visual Interpretability for Deep Neural Networks by Optimizing Activation Maps with Perturbation 一种新的深度神经网络的视觉可解释性</h3><p><img src="https://s2.loli.net/2022/07/20/4q6DHVa7G3UlcQK.png" alt="image-20220610142553209"></p>
<h4 id="摘要："><a href="#摘要：" class="headerlink" title="摘要："></a>摘要：</h4><p>可解释性一直被视为部署深度神经网络的一个重要组件，基于显著性的方法是最流行的可解释的方法之一，因为它可以生成单独直观的热图，突出部分输入图像最重要的决定深度网络在一个特定的分类目标。然而，<strong>由现有方法生成的热图要么包含很少的表示对象的信息（基于扰动的方法），要么不能有效地定位多类对象（基于激活的方法）。</strong>为了解决这个问题，设计了一个可视化深度神经网络可解释性的两阶段框架，称为<strong>扰动优化激活(AOP)</strong>，以优化一般基于扰动的方法和基于扰动的方法生成的激活图。最后，为了更好地解释不同类型的图像，我们进一步提出了AOP框架的一个实例，即<strong>基于平滑集成梯度的类激活图(SIGCAM)</strong>，该实例提出了一种应用特征图作为权重系数的加权梯度CAM</p>
<a id="more"></a>
<h4 id="1-引言"><a href="#1-引言" class="headerlink" title="1. 引言"></a>1. 引言</h4><p><strong>现有方法：</strong></p>
<ul>
<li>将梯度或其变体反向传播到输入图像中，以决定哪些像素或区域与预测的变化更相关=&gt;这些变化不一定表明像素或区域对预测有重大影响。</li>
</ul>
<p>（如下图：softmax层后的分类得分：双体船：0.521，海盗0.068。故逐渐将海盗进行mask并测试对于双体船的影响。结果表明：删除“海盗”对“双体船”的分类得分有显著影响，但与“双体船”无关）</p>
<p><img src="https://s2.loli.net/2022/07/20/DGzv9lcJbe46yuB.png" alt="image-20220610143347474"></p>
<ul>
<li>基于激活的方法（如GradCAM）=&gt;使用反向传播梯度作为权重来组合前向特征图=&gt;这些方法可能会捕获很多毫无意义的信息，因为特征映射并不一定与目标类别相关</li>
<li>基于扰动的方法（如EMP，I-GOS）=&gt;采用梯度作为掩模=&gt;生成的热图可能包含的用于表示对象的信息很少</li>
</ul>
<p><strong>本文贡献：</strong>本文提出平滑集成梯度类激活图SIGCAM，首先使用加权梯度WGradCAM生成表现良好base-mask在不同类型的图像上，然后使用I-GOS优化生成的base-mask。</p>
<ol>
<li>引入了一个高度灵活的两阶段框架AOP，结合基于激活的方法的优势来捕获足够的信息和基于扰动的方法生成网络决策相关掩模的能力</li>
<li>我们提出了GradCAM的扩展WGradCAM，通过将特征映射作为权重系数，它与GradCAM++相似，但更简单、更有效。</li>
<li>提出了SIGCAM，AOP的一个特殊实例，它使用I-GOS来优化所提出的WGradCAM</li>
</ol>
<h4 id="2-相关工作"><a href="#2-相关工作" class="headerlink" title="2. 相关工作"></a>2. 相关工作</h4><p>可解释性方法：</p>
<ol>
<li>基于梯度的方法</li>
<li>基于激活的方法</li>
<li>基于区域的方法</li>
<li>基于扰动的方法</li>
</ol>
<h4 id="3-方法"><a href="#3-方法" class="headerlink" title="3. 方法"></a>3. 方法</h4><h5 id="AOP（Optimizing-Activation-with-Perturbation使用扰动优化激活）"><a href="#AOP（Optimizing-Activation-with-Perturbation使用扰动优化激活）" class="headerlink" title="AOP（Optimizing Activation with Perturbation使用扰动优化激活）"></a>AOP（<strong>Optimizing Activation with Perturbation</strong>使用扰动优化激活）</h5><p>基于扰动方法允许我们直接估计出输入像素的影响，并生成更人性化的显著性映射。</p>
<p>=&gt;存在问题：它们的效率较低，而且优化过程需要数百次迭代。</p>
<p>基于激活的方法能够快速生成显著性映射，从而获取更多关于目标对象的信息。</p>
<p><strong>AOP的思想</strong>：应用基于激活的方法来生成base-mask，并利用基于扰动的方法对其进行优化。AOP的base-mask可以通过不同类型的基于激活的方法生成，优化过程可以通过各种基于扰动的方法进行，使AOP框架具有高度的可扩展性。</p>
<h5 id="WGradCAM（Weighted-GradCAM-加权GradCAM）"><a href="#WGradCAM（Weighted-GradCAM-加权GradCAM）" class="headerlink" title="WGradCAM（Weighted GradCAM 加权GradCAM）"></a>WGradCAM（<strong>Weighted GradCAM</strong> 加权GradCAM）</h5><p><img src="https://s2.loli.net/2022/07/20/BgPIvRi4otXdqCW.png" alt="image-20220610151418868"></p>
<p><img src="https://s2.loli.net/2022/07/20/E7sgBZ8zNX95WCF.png" alt="image-20220610152546162" style="zoom:80%;" />，<img src="https://s2.loli.net/2022/07/20/omaGPCJj47SfgWK.png" alt="image-20220705231329471" style="zoom:50%;" />M可以使用基于扰动的方法进行优化。</p>
<h5 id="SIGCAM"><a href="#SIGCAM" class="headerlink" title="SIGCAM"></a>SIGCAM</h5><p>由于M包含了很多非零像素，所以直接优化M很耗时/bask-mask中太多像素值较高，对人类不友好=&gt;使用滤波器过滤掉小于阈值的像素，并使用调制因子λ将其控制在一个特定范围。</p>
<p><img src="https://s2.loli.net/2022/07/20/TjfiNwnmODYEqGI.png" alt="image-20220610153333300"></p>
<p>然后将M上采样到大小小于输入图像形状的矩阵，作为基掩膜。</p>
<p>本文在微调的过程中，找到M 的最小掩膜M*使得<img src="https://s2.loli.net/2022/07/20/cgDAwsLlnzb5JSN.png" alt="image-20220720102823842" style="zoom: 33%;" />，其中<img src="https://s2.loli.net/2022/07/20/4yfO8vq3N9T5wHc.png" alt="image-20220720102904641" style="zoom:33%;" />，<img src="https://s2.loli.net/2022/07/20/XunL3c2lfKydhim.png" alt="image-20220610154541787" style="zoom:67%;" />表示把M上采样到（h1,w1)的大小。<img src="https://s2.loli.net/2022/07/20/IQesPp1NfEZohlu.png" alt="image-20220610154855406" style="zoom:67%;" /><img src="https://s2.loli.net/2022/07/20/GSO8zR6fYWxCMDu.png" alt="image-20220610154917686" style="zoom:67%;" /></p>
<p>其中<img src="https://s2.loli.net/2022/07/20/I5Btz6A2gUWoSTr.png" alt="image-20220610155128666" style="zoom: 50%;" />表示一个和I<sub>0</sub>大小一致的baseline图像，但是在类别c上的评分很低。</p>
<p>最后可以用M∗来最小化以下目标函数：</p>
<p><img src="https://s2.loli.net/2022/07/20/z18LRYxemi2l7ac.png" alt="image-20220610155431000" style="zoom: 67%;" /></p>
<p>其中||1-M||是l1正则化，TV(M)是第二项全变范数，使M更分段平滑</p>
<h4 id="4-实验"><a href="#4-实验" class="headerlink" title="4. 实验"></a>4. 实验</h4><p>数据集：ImageNet-1k、COCO2017（许多图像是<strong>多目标多类</strong>的）</p>
<p>度量方式：</p>
<p>deletion：删除与类最相关的像素/区域将导致分类分数显著下降（AUC越小越好）</p>
<p>insertion：从模糊的图像开始，逐渐重新引入内容，产生更真实的图像，并具有减轻对抗攻击的示例的影响。（AUC越大越好）</p>
<p>验证WGradCAM的有效性：</p>
<p>GradCAM对于”多目标，单类别”效果显著下降，GradCAM++对于“多目标，多类别”包含了不相关信息</p>
<p><img src="https://s2.loli.net/2022/07/20/rqtWFVAUP4bcK9H.png" alt="image-20220610160443223"></p>
<p>与其他显著性方法进行对比。<img src="https://s2.loli.net/2022/07/20/TZKX6qIjWPyGwC7.png" alt="image-20220705234526969"></p>
<p>如下图所示，Guided-bp生成的热图比其他基于梯度的方法生成的热图更有意义。vanilla</p>
<p>Back-propagation, Integrated Gradients, and SmoothGrad的显著性图噪声太多，看起来不那么友好。</p>
<p>I-GOS的热图包含更少的噪声。然而，这些热图中的像素落在分割掩模之外的可能性更高。</p>
<p>XRAI生成的热图受到分割结果的影响过大。GradCAM和GradCAM++产生更大的区域，这些区域不是那么对人类友好，但可以捕获足够的信息。</p>
<p>SIGCAM生成了所有方法中最吸引人的热图。热图比IGOS生成的热图包含更少的噪声，并捕获足够的信息来识别目标目标，如GradCAM和GradCAM++。更重要的是，SIGCAM的热图中的像素集中在分割任务中，使热图更加人性化。</p>
<p><img src="https://s2.loli.net/2022/07/20/lNcApbZT8LIrx6H.png" alt="img"></p>
]]></content>
      <categories>
        <category>mzy</category>
      </categories>
      <tags>
        <tag>可解释性</tag>
        <tag>显著性图</tag>
      </tags>
  </entry>
  <entry>
    <title>mzy 【ICCV-2019】一种严格的对于时间序列可解释性的评估方法</title>
    <url>/2022/04/13/MaZhaoyang/%E4%B8%80%E7%A7%8D%E4%B8%A5%E6%A0%BC%E7%9A%84%E5%AF%B9%E4%BA%8E%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E5%8F%AF%E8%A7%A3%E9%87%8A%E6%80%A7%E7%9A%84%E8%AF%84%E4%BC%B0%E6%96%B9%E6%B3%95/</url>
    <content><![CDATA[<p><strong>题    目：</strong>一种严格的对于时间序列可解释性的评估方法</p>
<p><strong>出    处：</strong>ICCV2019</p>
<p><strong>关键词：</strong>时间序列，可解释性</p>
<p>​        可解释的人工智能(XAI)方法通常被用于解释和调试黑盒机器学习模型。然而，大多数提出的XAI方法都是黑盒本身的，并且是为图像设计的。因此，他们依靠视觉上的可解释性来评估和证明解释。在这项工作中，我们应用了以前用于时间序列上的图像和文本域的XAI方法。我们<strong>提出了一种方法来测试和评估时间序列上的各种XAI方法</strong>，通过引入新的验证方法来纳入时间维度。我们进一步进行了初步实验，以评估在一系列数据集上使用各种验证方法对所选择的XAI方法解释的质量，并对其进行质量指标的检查。我们证明，在我们最初的实验中，Shap对所有模型都很有效，但其他模型如DeepLIFT、LRP和显著性地图在特定架构中工作得更好。</p>
<a id="more"></a>
<h3 id="1-引言"><a href="#1-引言" class="headerlink" title="1. 引言"></a>1. 引言</h3><p>​       由于深度学习在很多领域先进的表现，这种复杂模型的可解释性引起了越来越多的兴趣。机器学习系统的需求（公平性、隐私性、可靠性、信任构建）为模型提供了一个新的选择过程。</p>
<p>​        许多突出的XAI方法都是<strong>针对特定的输入类型而定制</strong>的，例如：图像=&gt;显著性图，文本=&gt;LRP。然而，例如，视频（图像序列）和音频有另一个时间维度，这是目前被XAI方法省略的。目前，XAI对时间序列数据的研究非常有限。然而，由于传感器越来越便宜，除了视频和音频之外，还会产生更多面向时间的数据，因此，首先测试已经突出的XAI方法和发现新的方法是很重要的。</p>
<p>​        因为原始时间序列很大，即使是领域专家自己也难以解释，因此通过原始数据进行评估和解释检查是不可行的。由于缺乏可连接的领域知识，需要一种可量化的方法来验证解释。在计算机视觉中存在一些关于评估可解释性的工作（例如，将相关像素设置为零），这也可以在时间序列上使用。然而，这些方法通过假设特征独立性或仅局部（短期）依赖来省略时间依赖。因此，需要对先前方法的适应或新的变体来评估对时间序列的解释。</p>
<h3 id="2-时间序列可解释性"><a href="#2-时间序列可解释性" class="headerlink" title="2. 时间序列可解释性"></a>2. 时间序列可解释性</h3><p>​        时间序列D的分类数据集，包括属于k个类$c<em>{1}, c</em>{2}, c<em>{3}, \ldots, c</em>{k}$。的n个样本。每一个样本t由m个时间点组成$t=\left(t<em>{0}, t</em>{1}, t<em>{2}, \ldots, t</em>{m}\right)$</p>
<p>​       对大多数XAI方法通常考虑的解释是局部特征的重要性，时间点转换为特性，以引入在时间序列上使用XAI方法的解决方案。局部特征的重要性产生了对每个时间点t<sub>i</sub>的相关性r<sub>i</sub>，然后可以建立一个时间序列向量$t=\left(t<em>{0}, t</em>{1}, t<em>{2}, \ldots, t</em>{m}\right)$对应的一个相关向量$r=\left(r<em>{0}, r</em>{1}, r<em>{2}, \ldots, r</em>{m}\right)$。</p>
<p>​        模型m从D的子集X以及标签Y训练得到。模型m根据给定的数据X,Y进行训练，并用于新的子集Xnew的预测。在时间序列任务中，x是一个由m个时间点组成的样本$t=\left(t<em>{0}, t</em>{1}, t<em>{2}, \ldots, t</em>{m}\right)$，一个可解释性方法可以被定义为$x a i(x, m)=e x p$，其中exp是指事后解释。对于时间序列，exp往往是指m个时间点的相关性$r=\left(r<em>{0}, r</em>{1}, r<em>{2}, \ldots, r</em>{m}\right)$。</p>
<p>​        与图像上的显著性图类似，可以基于相关性创建一个热图，可以用这个热图来丰富原始时间序列的线形图来创建一个可视化。与领域知识一起，专家可以检查所产生的解释可视化，以定性地验证结果。</p>
<p>​        使用的数据集是FordA时间序列集，模型使用的是ResNet。</p>
<p>​        FordA任务中每条数据是包含500个汽车发动机噪音测量值的时间序列，基于这个时间序列来判断汽车发动机是否有问题。</p>
<p>​        <strong>上图中，蓝色曲线表示为选取的一条FordA数据，红线表示数据中每个点的特征重要度</strong>。</p>
<p>​        红线颜色越深表示该点的特征对于输出影响越大，红色越浅表示影响越小。</p>
<p>​        <strong>上图中三个蓝色框标记的数据点表示为对输出有明显影响的特征</strong>，SHAP、LRP和DeepLIFT三种算法对于这类特征有明显的划分。</p>
<p><img src="https://flyingimage.oss-cn-beijing.aliyuncs.com/image-20220413140342914.png" alt="image-20220413140342914"></p>
<blockquote>
<p>LIME：一种和模型无关的局部可解析性算法。</p>
<p>Scaliency Maps: 基于反向传播梯度生成heatmap，显示输入像素对于输出的影响。</p>
<p>LRP: 基于反向传播relevance score生成heatmap。(主要用于图像领域，目前有不少nlp方向的应用)</p>
<p>DeepLIFT: 一种改进的基于反向传播梯度生成heatmap的算法。</p>
<p>SHAP: 基于博弈论shapely值计算特征的重要度。</p>
</blockquote>
<h3 id="3-评估时间序列的可解释性"><a href="#3-评估时间序列的可解释性" class="headerlink" title="3. 评估时间序列的可解释性"></a>3. 评估时间序列的可解释性</h3><p>​        关于如何自动评估和验证XAI解释，有多种方法。在计算机视觉中，一种常见的方法是扰动分析。这种分析方法根据图像的重要性（最大或最小相关像素）替换图像的几个像素。考虑到面向时间的数据的序列特性，我们提出了两种明确适用于时间序列的新方法。</p>
<p><strong>a. 首先通过可解释性算法计算时间序列中每个时间点ti对应的特征重要度ri</strong>：</p>
<p><img src="https://pic4.zhimg.com/80/v2-394f4995a0959c73c170618dafdcd797_1440w.jpg" alt="img" style="zoom:80%;" /></p>
<p><strong>b.扰动时间序列：Pertubation on time series</strong></p>
<p><img src="https://pic3.zhimg.com/80/v2-e1c59900784c404e09e0e91122672f06_1440w.jpg" alt="img"></p>
<p><strong>c.基于时间序列特征的扰动方法：</strong></p>
<p>​        在b中两种对于时间序列的扰动方法并不能保证对输出会有很大的影响。</p>
<p>​        如果模型能学到时间序列上的波动趋势，那么仅扰动离散的几个时间点，并不能保证随机扰动和有选择扰动两种方式对于输出的影响有很大的差异。</p>
<p>​         由此，作者又提出专门针对时间序列特性的扰动方法：</p>
<p><strong>swap time points</strong>：选取扰动时间点<strong>ti</strong>周围<strong>ns</strong>个时间点作为一个需要扰动的时间子序列，将其逆序插回原来的时间序列。</p>
<p><img src="https://flyingimage.oss-cn-beijing.aliyuncs.com/image-20220413140404595.png" alt="image-20220413140404595"></p>
<p><strong>mean time points</strong>： 选取扰动时间点<strong>ti</strong>周围<strong>ns</strong>个时间点作为一个需要扰动的时间子序列，取其平均后插回原来的时间序列。</p>
<p><img src="https://flyingimage.oss-cn-beijing.aliyuncs.com/image-20220413140414381.png" alt="image-20220413140414381"></p>
<h3 id="4-实验结果"><a href="#4-实验结果" class="headerlink" title="4. 实验结果"></a>4. 实验结果</h3><p><img src="https://flyingimage.oss-cn-beijing.aliyuncs.com/image-20220413140423790.png" alt="image-20220413140423790"></p>
<p>分别实验了5种可解释性算法在3种模型上的效果，其中分别用4种扰动方法比较准确率的波动。</p>
<p>CNN：在都使用CNN模型的情况下，基于LRP和DeepLIFT算法的扰动效果最好。</p>
<p>RNN：在都使用RNN模型的情况下，基于Saliency和SHAP算法的扰动效果最好。</p>
<p>ResNet：在都是用ResNet模型的情况下，基于SHAP算法的扰动效果最好。</p>
<p>综上所述：</p>
<p>（1）作者认为SHAP算法鲁棒性最强，在解析各种模型时都有较好的效果。</p>
<p>（2）基于LRP和DeepLIFT这类基于反向回传的可解性算法在cnn模型表现更好。</p>
<p>（3） LIME算法在解析各类模型时表现最差。</p>
<p>（4）使用swap和mean扰动时间序列时，更能区分随机扰动和选择性扰动的效果。</p>
]]></content>
      <categories>
        <category>mzy</category>
      </categories>
      <tags>
        <tag>可解释</tag>
      </tags>
  </entry>
  <entry>
    <title>nxj 【TPAMI-2019】Meta-Transfer Learning through Hard Tasks</title>
    <url>/2021/03/10/NingXiaojun/Meta-Transfer%20Learning%20through%20Hard%20Tasks(1)/</url>
    <content><![CDATA[<p>关键词： 元学习；迁移学习</p>
<h2 id="贡献"><a href="#贡献" class="headerlink" title="贡献"></a>贡献</h2><ul>
<li>提出了元迁移学习（MTL, Meta-Transfer Learning），该方法学习如何将深度神经网络的权值转移到小样本学习中任务<br>Meta：指训练多个任务；Transfer：学习每个任务的DNN权重的缩放和偏置（<strong>SS</strong>, Scale and Shift）来实现迁移</li>
<li>其次，提出了Hard Tasks（<strong>HT</strong>）进一步提高MTL的学习效率</li>
<li>在有监督和半监督的环境下，我们在minimagenet、tieredImageNet和Fewshot-CIFAR100（FC100）这三个具有挑战性的基准上对五类小样本分类任务进行了实验，验证了本文提出的HT模式训练的MTL方法具有很好的性能。消融研究表明，SS和HT两个组件有助于快速收敛和高精度。</li>
<li>另外，在每个任务上加入元梯度正则化，利用当前任务和前一任务的元梯度加权和对每个任务进行优化。其目的是迫使元学习器在以后的学习中不要忘记旧知识。</li>
</ul>
<a id="more"></a>
<p>IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI) 2019,<br>（由CVPR 2019《Meta-transfer learning for few-shot learning》扩充）</p>
<hr>
<p>作者：Qianru Sun, Yaoyao Liu, Zhaozheng Chen, Tat-Seng Chua, and Bernt Schiele, <em>Fellow, IEEE</em></p>
<p>机构：新加坡管理大学、马克斯·普朗克信息研究所、新加坡国立大学</p>
<p>Code: <a href="https://github.com/yaoyao-liu/meta-transfer-learning">https://github.com/yaoyao-liu/meta-transfer-learning</a></p>
<hr>
<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>样本过少的情况下→数据增强 / 元学习→现阶段MAML仍有缺点</p>
<ul>
<li>元学习被应用于小样本学习：关键的想法是利用大量相似的小样本任务来学习如何使基础学习器适应一个新的任务</li>
<li>元学习是一种基于任务级优化的方法。其目的是从相似的小样本学习任务中转移经验，相关方法遵循一个包含两个循环的统一训练过程。内循环学习一个基础学习器(base learner)完成一个单独的任务，外循环使用学习基础学习器的验证性能来优化元学习器。</li>
<li><p>一种先进的代表性方法称为模型不可知元学习（MAML），它学习寻找最佳的初始化状态，使基础学习器可以快速适应新的任务</p>
<ul>
<li>i）这些方法通常需要大量类似的元训练任务，成本高昂；</li>
<li>ii）每个任务通常由一个低复杂度的基础学习器建模，如浅层神经网络（SNN），避免模型过拟合到实拍训练数据，从而无法部署更深入、更强大的体系结构</li>
</ul>
</li>
<li><p>传统的meta-batch包含许多随机任务，没有考虑不同任务的困难程度。</p>
</li>
<li><p>最近的一些工作尝试使用在大规模数据集上预先训练的DNN，但大多是以直接的方式，例如：①将其权重作为元训练的热启动；②冻结其卷积层作为基础学习器的特征提取器。</p>
</li>
<li></li>
</ul>
<h2 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h2><h4 id="总体框架"><a href="#总体框架" class="headerlink" title="总体框架"></a>总体框架</h4><p>(a) 在大规模数据上的DNN预训练，即使用整个训练数据集</p>
<p>(b) 在预训练的特征提取器的基础上学习缩放和移位（SS）参数的元转移学习（MTL）<br>这一步使用 HT meta-batch 进行，并由元梯度正则化（第4.3节）正则化</p>
<p>(c) 是对不可见任务的元测试，其处理包括基本学习器（分类器）的微调（FT）阶段和最终评估阶段</p>
<p><strong>这篇文章里 meta-learner(外层优化) 指的是SS，base-learner(内层优化) 指的是classifier，还包含后期固定的feature extractor。</strong></p>
<ul>
<li><img src="http://funera-hk.oss-cn-hongkong.aliyuncs.com/img/image-20210310134342770.png" alt="image-20210310134342770"></li>
</ul>
<h4 id="Meta-transfer-learning-MTL"><a href="#Meta-transfer-learning-MTL" class="headerlink" title="Meta-transfer learning (MTL)"></a>Meta-transfer learning (MTL)</h4><p>元任务的训练集用来训练基础学习器，基础学习器（分类器）θ’的更新规则：（$\Phi_S$是SS的权重）</p>
<p><img src="http://funera-hk.oss-cn-hongkong.aliyuncs.com/img/image-20210310134112665.png" alt="image-20210310134112665"></p>
<p>$\Phi<em>{S_1}$初始化为1，$\Phi</em>{S_2}$初始化为0，并按下式更新：</p>
<p><img src="http://funera-hk.oss-cn-hongkong.aliyuncs.com/img/image-20210310134137972.png" alt="image-20210310134137972"></p>
<p>使用元任务的测试机损失及梯度，用于元参数 $\theta$ 的更新：</p>
<p><img src="http://funera-hk.oss-cn-hongkong.aliyuncs.com/img/image-20210310134151472.png" alt="image-20210310134151472"></p>
<p>$\Phi_S$是SS的权重，元训练期间冻结不予更新。</p>
<p>SS相对于“遗忘”问题有明显优势，避免以往学习的经验丢失；由大规模训练的DNN初始化，可以快速拟合；参数量少。</p>
<p>通过SS和FT（精细调整）进行更新的区别如下图：</p>
<p><img src="http://funera-hk.oss-cn-hongkong.aliyuncs.com/img/image-20210310134203234.png" alt="image-20210310134203234"></p>
<p><img src="http://funera-hk.oss-cn-hongkong.aliyuncs.com/img/image-20210310134320887.png" alt="image-20210310134320887" style="zoom: 80%;" /></p>
<h4 id="Hard-task-HT-meta-batch"><a href="#Hard-task-HT-meta-batch" class="headerlink" title="Hard task (HT) meta-batch"></a>Hard task (HT) meta-batch</h4><p>对于元任务集合$\tau$，在每次更新后，选择最低的精度排序来确定当前系统中最困难的分类样本进行任务的重新采样</p>
<p><img src="http://funera-hk.oss-cn-hongkong.aliyuncs.com/img/image-20210310134301082.png" alt="image-20210310134301082" style="zoom: 80%;" /></p>
<h4 id="Meta-gradient-regularization"><a href="#Meta-gradient-regularization" class="headerlink" title="Meta-gradient regularization"></a>Meta-gradient regularization</h4><ul>
<li>使元学习器减少对先前情节的遗忘</li>
</ul>
<p><img src="http://funera-hk.oss-cn-hongkong.aliyuncs.com/img/image-20210310134243426.png" alt="image-20210310134243426" style="zoom:80%;" /></p>
<h4 id="整体算法"><a href="#整体算法" class="headerlink" title="整体算法"></a>整体算法</h4><ul>
<li><img src="http://funera-hk.oss-cn-hongkong.aliyuncs.com/img/image-20210310152106130.png" alt="image-20210310152106130" style="zoom: 80%;" /></li>
</ul>
<h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><p><strong>数据集</strong>：<em>mini</em>ImageNet，<em>tiered</em>ImageNet， Fewshot-CIFAR100(FC100) </p>
<h4 id="基线对比"><a href="#基线对比" class="headerlink" title="基线对比"></a>基线对比</h4><ul>
<li><img src="http://funera-hk.oss-cn-hongkong.aliyuncs.com/img/image-20210310135000286.png" alt="image-20210310135000286" style="zoom: 67%;" /></li>
<li><img src="http://funera-hk.oss-cn-hongkong.aliyuncs.com/img/image-20210310135021985.png" alt="image-20210310135021985" style="zoom:67%;" /></li>
</ul>
<h4 id="组件验证（SS与FT对比）"><a href="#组件验证（SS与FT对比）" class="headerlink" title="组件验证（SS与FT对比）"></a>组件验证（SS与FT对比）</h4><ul>
<li><p><img src="http://funera-hk.oss-cn-hongkong.aliyuncs.com/img/image-20210310135041309.png" alt="image-20210310135041309" style="zoom: 80%;" /></p>
</li>
<li><p><img src="http://funera-hk.oss-cn-hongkong.aliyuncs.com/img/image-20210310135057179.png" alt="image-20210310135057179" style="zoom: 80%;" /></p>
</li>
</ul>
<h4 id="消融实验"><a href="#消融实验" class="headerlink" title="消融实验"></a>消融实验</h4><ul>
<li><img src="http://funera-hk.oss-cn-hongkong.aliyuncs.com/img/image-20210310154557787.png" alt="image-20210310154557787" style="zoom:80%;" /></li>
<li><img src="http://funera-hk.oss-cn-hongkong.aliyuncs.com/img/image-20210310135155191.png" alt="image-20210310135155191" style="zoom: 80%;" /></li>
</ul>
<p><strong>MTL vs. No meta-learning. </strong> 表6在最上面的块中显示了无元学习方法的结果。本文提出的方法取得了明显更好的性能。</p>
<p><strong>SS[Θ;θ]works better than light-weight FT variants.</strong> 表6显示使用SS[Θ;θ]的方法在所有设置中均达到了最佳性能，且SS始终优于FT。</p>
<p><strong>Meta-gradient regularization is effective.</strong> 表6最后两行显示了有效性。正则化迫使元学习器减少对先前情节的遗忘，并稳定元梯度。</p>
<p><strong>Accuracy gain by HT meta-batch.</strong> 表7、图4显示：HT meta batch可以提高模型的准确率。</p>
<p><strong>Speed of convergence of MTL with HT meta-batch.</strong>  (a)~(d)中HT mete-batch仅需1~4k次迭代达到很好的性能，而没有进行深度预训练网络的MAML需要200k次迭代。</p>
<ul>
<li><img src="http://funera-hk.oss-cn-hongkong.aliyuncs.com/img/image-20210310135139161.png" alt="image-20210310135139161" style="zoom: 80%;" /></li>
</ul>
<h4 id="SS统计分析"><a href="#SS统计分析" class="headerlink" title="SS统计分析"></a>SS统计分析</h4><p>表8中提供了有关学习到的SS权重的统计信息。 (a)和(b)中的每个点表示这些数字的分布，与高斯分布（红色）很好地匹配。</p>
<ul>
<li><img src="http://funera-hk.oss-cn-hongkong.aliyuncs.com/img/image-20210310135217125.png" alt="image-20210310135217125" style="zoom: 80%;" /></li>
</ul>
<h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>事实证明，MTL在预训练的DNN神经元上的关键操作对于使学习经验适应未知任务非常有效。</p>
<ul>
<li><p><strong>MTL</strong>的持续改进证明了大规模预训练有素的深度网络可以提供良好的“知识基础”，以进行有效的一次性学习。</p>
</li>
<li><p>就学习方案而言，<strong>HT meta-batch</strong>对于消融模型始终表现出良好的性能，而且对提高收敛速度特别有用。</p>
</li>
</ul>
<p>展望：本文模型独立于任何特定的模型或体系结构，并且只要在在线迭代中易于评估任务的难度即可很好地推广。</p>
]]></content>
      <categories>
        <category>ssk</category>
      </categories>
      <tags>
        <tag>元学习</tag>
        <tag>迁移学习</tag>
      </tags>
  </entry>
  <entry>
    <title>nxj 【ICML2020】Deep Graph Random Process for Relational-Thinking-Based Speech Recognition</title>
    <url>/2021/07/14/NingXiaojun/%5BICML2020%5D%20Deep%20Graph%20Random%20Process%20for%20Relational-Thinking-Based%20Speech%20Recognition/</url>
    <content><![CDATA[<p><strong>基于关系思维的语音识别的深度图随机过程</strong></p>
<p>作者：Hengguan Huang^1^, Fuzhao Xue^1^, Hao Wang^2^, Ye Wang^1^</p>
<p>单位：^1^新加坡国立大学；^2^麻省理工学院</p>
<p>发表：ICML 2020</p>
<a id="more"></a>
<hr>
<h2 id="一、简介与思路"><a href="#一、简介与思路" class="headerlink" title="一、简介与思路"></a>一、简介与思路</h2><ul>
<li><p><strong>关系思维</strong></p>
<ul>
<li><strong>关系思维 relational thinking</strong>：在学习的过程中，我们会接收到各种各样的信息，不管是来自视觉、听觉、触觉等，但是我们并不会有意识地去保存它们。在各种各样的信息之间隐藏着联系，这些信息及它们之间的联系组成了我们的percepts(感知)。</li>
<li>与<strong>关系推断 Relational Reasoning</strong>的主要区别：relational reasoning 是有意识地处理这些 relation information。</li>
</ul>
</li>
<li><p><strong>语音识别任务</strong></p>
<ul>
<li><p>人类对话本质上是两个或更多说话者之间交换思想的过程</p>
</li>
<li><p>机器学习中语音识别任务一般被分解为声学建模和语言解码两部分，而忽略了本质上的关系思维过程</p>
</li>
<li><p>关系思维中涉及的感知（例如，在听到声音时形成的心理印象）被认为是无数的，并且不能直接观察到</p>
</li>
</ul>
</li>
<li><p>明确地建模关系思维形成的感知仍然是一个<strong>挑战</strong></p>
<ul>
<li>混合声学递归神经网络隐马尔可夫模型(RNN-HMM模型)在许多方面仍然优于用于声学建模的端到端编码器-解码器方法</li>
<li>RNNs在捕捉顺序输入的长期时间依赖性方面做得很好，但在表示复杂关系方面做得很差</li>
</ul>
</li>
<li><p>提出一种<strong>贝叶斯非参数深度学习方法</strong>，深度图随机过程(DGP)</p>
<ul>
<li><p>将关系思维中涉及的感知建模为概率图，而在训练过程中不使用任何关系数据</p>
<ul>
<li>感知被建模为当前话语与其历史之间的关系</li>
<li>由于知觉的无意识，我们假设这种关系存在的概率接近于零（类似于先验知识）</li>
</ul>
</li>
<li><p>给定一个话语和它的历史，我们生成无限个由包含在DGP中的概率图表示的感知，其中每个节点描述一个话语的表示，每个边对应于两个节点之间的关系</p>
</li>
<li><p>假设感知图的边是按照伯努利分布分布的，边存在的概率接近于零</p>
</li>
<li><blockquote>
<p>从直觉上来理解，在我们接收信息时，信息之间并没有生成稳定的信息，各个信息之间都是会产生关联的，并且基于我们的先验知识和历史信息，会在脑海中产生各种各样的理解 — 相当于接收到的信息的不同组合，而这个组合是有无限可能的。并且，由于这些percepts是无意识的，percept graph中边的概率是接近于0的。</p>
</blockquote>
</li>
</ul>
</li>
<li>通过简单地对邻接矩阵求和来组合无数的图在计算上是很难的<strong>（计算与优化方面）</strong><ul>
<li>创建一个等价的图来找到一个解析解，其中边由二项式变量表示<ul>
<li>进一步通过一个具有有界近似误差的高斯分布为该二项式分布的推断和采样找到一个近似形式的解</li>
</ul>
</li>
<li>为了将新图形转换为“有意识的”或特定任务的图形，我们使用另一个高斯变量对新图形的每条边进行加权，该高斯变量以从二项式变量得出的边为条件</li>
<li>计算变换后的图上的图形嵌入，并将其用作声学建模的附加输入</li>
<li>为了联合优化上述组件，我们采用了变分推理框架，并成功地导出了一个有效的证据下界</li>
</ul>
</li>
</ul>
<h2 id="二、相关工作"><a href="#二、相关工作" class="headerlink" title="二、相关工作"></a>二、相关工作</h2><h3 id="1-图的贝叶斯深度学习"><a href="#1-图的贝叶斯深度学习" class="headerlink" title="1. 图的贝叶斯深度学习"></a>1. 图的贝叶斯深度学习</h3><ul>
<li><p>关系堆叠去噪自动编码器(relational stacked denoising auto-encoders, RSDAE)：将图结构结合到概率自动编码器中的原则模型，显著改善了表示学习；</p>
</li>
<li><p>关系深度学习(relational deep learning, RDL)：有监督和完全贝叶斯版本的RSDAE，以直接处理链接预测任务；</p>
</li>
<li><p>图形自动编码器(graph auto-encoders, GAEs)：以无监督的训练方式学习真实世界的图形数据，使用图卷积网络(GCN)编码器使用低维向量表示节点，并使用解码器重建邻接矩阵；</p>
</li>
</ul>
<ol>
<li>（↑这些方法应用在：发现化学分子、建模引用网络、构建知识图）</li>
</ol>
<ul>
<li><p>正则图变分自动编码器(Regularized Graph Variational Autoencoders, RGVAE)：使用对立的正则化框架来正则化解码器的输出分布，从而改进GAEs；</p>
</li>
<li><p>(Bojchevski et al., 2018)使用随机游走进一步拓展了RGVAE；</p>
</li>
</ul>
<ol>
<li><strong>缺点：以上都是静态图，限制了它们在处理动态图的现实世界问题中的模型泛化能力；</strong></li>
</ol>
<ul>
<li>变分图循环网络(Variational graph RNN, VGRNN)：通过结合GCN，RNN和GAEs来缓解这个问题，允许捕捉动态图的演变；</li>
</ul>
<ol>
<li><strong>缺点：它们需要图注释（话语之间的关系标注，很多任务都没有关系标注）</strong></li>
</ol>
<h3 id="2-变分声学建模"><a href="#2-变分声学建模" class="headerlink" title="2. 变分声学建模"></a>2. 变分声学建模</h3><ul>
<li><strong>RNN-HMM声学模型</strong>（作为一种HMM分类器）</li>
</ul>
<ol>
<li>使用RNNHMM对语音信号建模时，会遇到许多不确定性：如背景噪声对语音信号的影响</li>
<li><strong>缺点：RNN-HMM在处理这种不确定性方面是有限的，因为RNN本质上是一个确定性函数</strong></li>
</ol>
<ul>
<li><p><strong>变分的RNN(variational RNN, VRNN)</strong>：引入了一个潜在变量$\bold{z}_{i,t}$，以捕捉时间t时声学特征的不确定性</p>
<ul>
<li><p>假设这样一个潜在变量具有高斯先验分布$p\left(\mathbf{z}<em>{i, t} \mid \mathbf{h}</em>{i, t-1}\right)$，该分布依赖于先前的RNN隐藏状态$\mathbf{h}_{i, t-1}$</p>
</li>
<li><p>它的后验分布由变分分布$q\left(\mathbf{z}<em>{i, t} \mid \mathbf{x}</em>{i, t}, \mathbf{h}_{i, t-1}\right)$近似，允许使用证据下界(ELBO)进行联合学习和推理：</p>
</li>
<li><script type="math/tex; mode=display">
\begin{aligned}
\sum_{i=1}^{M}\{& \operatorname{KL}\left(q\left(\mathbf{Z}_{i} \mid \mathbf{X}_{i}, \mathbf{H}_{i}\right) \| p\left(\mathbf{Z}_{i} \mid \mathbf{H}_{i}\right)\right) 
\left.-\mathbb{E}_{\mathbf{Z}_{i}}\left[\log P\left(\mathbf{Y}_{i} \mid \mathbf{X}_{i}, \mathbf{Z}_{i}\right)\right]\right\}
\end{aligned}</script></li>
<li><p>后验分布的采样是通过使用基于重新参数化的蒙特卡罗(MC)估计来实现的</p>
</li>
<li><p>可以通过随机梯度下降来训练该模型</p>
</li>
</ul>
</li>
</ul>
<ol>
<li><strong>缺点：VRNN-HMM声学模型的一个主要限制是：所学习的潜在分布表现出不可解释的表示，因为近似分布被假设为采取缺乏表达能力的一般形式</strong></li>
</ol>
<h2 id="三、关系思维建模"><a href="#三、关系思维建模" class="headerlink" title="三、关系思维建模"></a>三、关系思维建模</h2><p><img src="http://funera-hk.oss-cn-hongkong.aliyuncs.com/img/image-20210508163925213.png" alt="image-20210508163925213" style="zoom: 67%;" /></p>
<h3 id="1-问题定义"><a href="#1-问题定义" class="headerlink" title="1. 问题定义"></a>1. 问题定义</h3><p>序列分类问题。</p>
<h3 id="2-深度图随机过程（Deep-Graph-Random-Process，DGP）"><a href="#2-深度图随机过程（Deep-Graph-Random-Process，DGP）" class="headerlink" title="2. 深度图随机过程（Deep Graph Random Process，DGP）"></a>2. 深度图随机过程（Deep Graph Random Process，DGP）</h3><p>在声学建模中，每个<strong>节点</strong>代表一个话语，其嵌入是通过对第i个话语的声学特征序列进行编码的神经网络$f_{\theta}$来计算的：</p>
<script type="math/tex; mode=display">
\mathbf{v}_{i}=f_{\theta}\left(\mathbf{X}_{i}\right)</script><p>DGP的核心是一系列作为构建模块的<strong>深度伯努利过程（DBP）</strong>，每个过程负责在DGP的两个节点之间<strong>生成边</strong></p>
<script type="math/tex; mode=display">
\left\{\alpha_{i, j}^{(k)}\right\}_{k=1}^{+\infty} \sim \operatorname{DBP}\left(\operatorname{Bern}\left(\lambda_{i, j}\right)\right)</script><p>Bern()是<strong>伯努利分布</strong>，DGP由此<strong>生成无数概率图</strong>：</p>
<script type="math/tex; mode=display">
\left\{G^{(k)}\right\}_{k=1}^{+\infty} \sim \operatorname{DGP}\left(\mathbf{v}_{i-o: i},\left\{\operatorname{DBP}\left(\operatorname{Bern}\left(\lambda_{*, *}\right)\right)\right\}\right)</script><h4 id="1-无数概率图的耦合（汇总图的生成）"><a href="#1-无数概率图的耦合（汇总图的生成）" class="headerlink" title="(1) 无数概率图的耦合（汇总图的生成）"></a>(1) 无数概率图的耦合（汇总图的生成）</h4><p>耦合的目标是获得无限个感知的<strong>汇总(summary)</strong>。直接进行求和是复杂的。</p>
<p>构建一个等价图，它可以作为原始无数图的总结或表示。它保留原始节点集，并通过从<strong>二项分布</strong>中采样来更新每个边：</p>
<script type="math/tex; mode=display">
\tilde{\alpha}_{i, j}=\sum_{k=1}^{+\infty} \alpha_{i, j}^{(k)}, \quad \tilde{\alpha}_{i, j} \sim \mathcal{B}\left(n, \lambda_{i, j}\right)</script><p>其中$n \rightarrow+\infty$ 、$\lambda_{i, j} \rightarrow 0$。</p>
<p><strong>单个percepet graph中边是服从Bernuli分布的，单考虑一条边的话，summary graph中对应边就是重复的Bernuli抽样，所以可以把summary graph中的边看作是服从Binomial分布的</strong></p>
<h4 id="2-汇总图-summary-graph-边的推断和采样"><a href="#2-汇总图-summary-graph-边的推断和采样" class="headerlink" title="(2) 汇总图(summary graph) 边的推断和采样"></a>(2) 汇总图(summary graph) 边的推断和采样</h4><p><strong>二项分布，且$n \rightarrow+\infty$ 、$\lambda_{i, j} \rightarrow 0$，是难以求解的，采用一个高斯分布来近似上文提到的二项分布。</strong></p>
<p>假设边$(i,j)$服从二项分布$\mathcal{B}\left(n, \lambda<em>{i, j}\right)$，$n \rightarrow+\infty$ 、$\lambda</em>{i, j} \rightarrow 0$。</p>
<p>从VRNN中得到启发，近似后验参数从RNN编码声学特征中估计的。但DGP包含近似后验$q\left(\tilde{\alpha}<em>{i, j} \mid \mathbf{X}</em>{i-o: i}\right)$，由于$n \rightarrow+\infty$，无法简易地进行推理、求解。</p>
<blockquote>
<h5 id="理论1："><a href="#理论1：" class="headerlink" title="理论1："></a>理论1：</h5><p>设$\mathcal{N}\left(\mu, \sigma^{2}\right)$表示$\mu&lt;1/2$的高斯分布，$\mathcal{B}\left(n, \lambda<em>{i, j}\right)$表示$n \rightarrow+\infty$ 、$\lambda</em>{i, j} \rightarrow 0$的二项分布。$n$递增，$\lambda$递减。<br>存在一个常数$m$，如果$m=n\lambda$，定义：</p>
<script type="math/tex; mode=display">
\begin{aligned}
f_{1}(x) &=\mathrm{KL}\left(\mathcal{N}(x, x(1-x)) \| \mathcal{N}\left(\mu, \sigma^{2}\right)\right) \\
f_{2}(x) &=\mathrm{KL}(\mathcal{N}(x, x(1-x)) \| \mathcal{N}(n \lambda, n \lambda(1-\lambda))\\
f_{2}^{*} &=\min _{x} f_{2}(x), \text { where } x \in(0,1)
\end{aligned}</script><p>得到：$f_1(x)$在$(0,1)$上达到最小值，$f_2(x)-f_2^*$在$(0, \sqrt{2} / 2- 1/2)$上有界，其中：</p>
<script type="math/tex; mode=display">
x=m=\frac{1+l-\sqrt{1+l^{2}}}{2}, \text { where } l=\frac{2 \sigma^{2}}{1-2 \mu}</script><p><img src="https://img-blog.csdnimg.cn/20201226225355424.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L01paGFfU2luZ2g=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
</blockquote>
<p>假设我们给定一个高斯分布$\mathcal{N}\left(\tilde{\mu}<em>{i, j}, \tilde{\sigma}</em>{i, j}^{2}\right)$，其参数$\tilde{\mu}<em>{i, j}$由神经网络具体参数化，可以保证$\tilde{\mu}</em>{i, j}&lt;1 / 2$（激活函数）。</p>
<p>通过德·莫伊弗-拉普拉斯定理，可知$\mathcal{N}\left(n \lambda<em>{i, j}, n \lambda</em>{i, j}\left(1-\lambda<em>{i, j}\right)\right)$是$\mathcal{B}\left(n, \lambda</em>{i, j}\right)$的很好的<strong>近似</strong>。当n增加时，它们是渐近等价的。</p>
<p>设$m<em>{i,j}=n\lambda</em>{i,j}$，利用定理1，可以避免无限参数$n$和近零参数$λ<em>{i,j}$的直接参数化，同时它允许使用 (Kingma &amp; Welling, 2013) 的<strong>重新参数化</strong>技巧。这个技巧**通过高斯代理从二项分布中抽取样本$\mathcal{N}\left(m</em>{i, j}, m<em>{i, j}\left(1-m</em>{i, j}\right)\right)$，$m<em>{i,j}=n\lambda</em>{i,j}$（每条边的近似高斯分布）**。</p>
<h3 id="3-将DGP应用于声学建模"><a href="#3-将DGP应用于声学建模" class="headerlink" title="3. 将DGP应用于声学建模"></a>3. 将DGP应用于声学建模</h3><ul>
<li><strong>高斯图变换</strong></li>
</ul>
<p>关系思维的另一个重要方面是，它<strong>将无数无意识的感知转化为可识别的知识概念</strong>；目标是从代表我们下游任务的无数感知图的摘要图中提取一个信息表示—声学建模；通过用<strong>高斯变量$s_{i,j}$对每个边进行加权</strong>来转换概要图来实现的：（很像注意力机制）</p>
<script type="math/tex; mode=display">
\bar{\alpha}_{i, j}=s_{i, j} * \tilde{\alpha}_{i, j}</script><p>进一步假设这样的高斯变量被限制在summary图的边$\tilde{\alpha}<em>{i, j}$上，以避免在边$\tilde{\alpha}</em>{i, j}$的一些值接近零时，这样的高斯变量的分布(如果它独立于边$\tilde{\alpha}_{i, j}$)随机地表现。其定义为:（<strong>假设：权重是以summary graph边的取值为条件的</strong>）</p>
<script type="math/tex; mode=display">
s_{i, j} \mid \tilde{\alpha}_{i, j} \sim \mathcal{N}\left(\tilde{\alpha}_{i, j} * \mu_{i, j}, \tilde{\alpha}_{i, j} * \sigma_{i, j}^{2}\right)</script><p>这种操作为高斯图变换。生成的图形称为特定任务的图（task-specific graph）。</p>
<p><strong>得到task-specific graph后，即可按照GNN/GCN的方式获得graph embedding（注意：每处理一个utterance时都会有对应的task-specific graph）。</strong></p>
<ul>
<li><strong>图嵌入</strong></li>
</ul>
<p>然后，从节点$\bold{v}_i$对应于当前话语的变换图中提取图嵌入$\bold{e}_i$：</p>
<script type="math/tex; mode=display">
\mathbf{e}_{i}=\sum_{(j, k) \in\{(j, k) \mid j<k \leq i,(j, k) \in \bar{E}\}} \bar{\alpha}_{j, k} \bar{f}_{\theta}\left(\left[\mathbf{v}_{j}, \mathbf{v}_{k}\right]\right)</script><p>其中$f_θ$是神经网络，$\bar{E}$是变换图的边集。</p>
<ul>
<li><strong>整体模型</strong></li>
</ul>
<p>生成的图形嵌入$\bold{e}_i$作为我们的声学模型的附加输入</p>
<p>整个框架称为关系思维网络(RTN)，使用简单循环单元SRU作为基本构件</p>
<p>SRU简化了LSTM的体系结构，显著提高了计算速度，而几乎没有降低性能</p>
<p>RTN的更新公式：（<strong>将graph embedding与原来的输入进行拼接，作为输入</strong>）</p>
<script type="math/tex; mode=display">
\begin{array}{c}
{\left[\hat{\mathbf{r}}_{i, t}, \hat{\mathbf{f}}_{i, t}, \hat{\mathbf{c}}_{i, t}\right]=\mathbf{W}_{x}\left[\mathbf{x}_{i, t}, \mathbf{e}_{i}\right]+\mathbf{b}} \\
\mathbf{r}_{i, t}=\sigma\left(\hat{\mathbf{r}}_{i, t}\right) \\
\mathbf{f}_{i, t}=\sigma\left(\hat{\mathbf{f}}_{i, t}\right) \\
\mathbf{c}_{i, t}=\mathbf{f}_{i, t} \odot \mathbf{c}_{i, t-1}+\left(1-\mathbf{f}_{i, t}\right) \odot \hat{\mathbf{c}}_{i, t} \\
\mathbf{h}_{i, t}=\mathbf{r}_{i, t} \odot \mathbf{c}_{i, t}+\left(1-\mathbf{r}_{i, t}\right) \odot W_{h}\left[\mathbf{x}_{i, t}, \mathbf{e}_{i}\right]
\end{array}</script><p>$\mathbf{r}<em>{i, t}$是重置门的输出，$\mathbf{f}</em>{i, t}$是遗忘门的输出，$\mathbf{c}_{i, t}$是记忆单元输出，$σ$是sigmoid激活函数。</p>
<h3 id="4-Learning：训练-amp-优化"><a href="#4-Learning：训练-amp-优化" class="headerlink" title="4. Learning：训练&amp;优化"></a>4. Learning：训练&amp;优化</h3><p>采用变分推理来联合优化DGP、高斯图变换和声学模型</p>
<p>DGP可以等效地表示为两种类型的随机变量：与<strong>感知图的边相关的伯努利变量</strong>和与<strong>summary图的边相关的二项式变量</strong></p>
<p>虽然这两个随机变量在概率分布上有不同的形式，但我们可以用这两个不同的随机变量来描述相同的随机过程数据</p>
<p>指定DGP的二项式变量完全决定了整个图随机过程。最终目标是<strong>最大化证据下界(ELBO)</strong>:</p>
<script type="math/tex; mode=display">
\begin{array}{l}
\sum_{i=1}^{M}\left\{\operatorname{KL}\left(q\left(\tilde{\mathbf{A}}, \mathbf{S} \mid \mathbf{X}_{i-o: i}\right) \| p\left(\tilde{\mathbf{A}}, \mathbf{S} \mid \mathbf{X}_{i-o: i}\right)\right)\right.
\left.-\mathbb{E}_{\tilde{\mathbf{A}}, \mathbf{S}}\left[\log P\left(\mathbf{Y}_{i} \mid \mathbf{X}_{i}, \tilde{\mathbf{A}}, \mathbf{S}\right)\right]\right\}
\end{array}</script><p>其中，$\tilde{\mathbf{A}}=[\tilde{a}<em>{i,j}]$是汇总图的邻接矩阵；$\mathbf{S}=\left[\tilde{s}</em>{i, j}\right]$是高斯图变换矩阵；$p\left(\tilde{\mathbf{A}}, \mathbf{S} \mid \mathbf{X}<em>{i-o: i}\right)$是$\tilde{\mathbf{A}}$和$\mathbf{S}$上的联合先验分布，$q\left(\tilde{\mathbf{A}}, \mathbf{S} \mid \mathbf{X}</em>{i-o: i}\right)$是相应的近似后验分布</p>
<p>由于<strong>S</strong>的每个元素都受汇总图同一边的二项式变量的制约，KL项可以进一步写成:</p>
<script type="math/tex; mode=display">
\begin{array}{l}
\sum_{(i, j) \in \tilde{E}}\left\{\operatorname {KL} \left(\mathcal{B}\left(n, \tilde{\lambda}_{i, j}\right) \| \mathcal{B}\left(n, \tilde{\lambda}_{i, j}^{(0)}\right)\right.\right. 
+\mathbb{E}_{\tilde{\alpha}_{i, j}}\left[\operatorname {KL} \left(\mathcal{N}\left(\tilde{\alpha}_{i, j} * \mu_{i, j}, \tilde{\alpha}_{i, j} * \sigma_{i, j}^{2}\right)\right.\right. 
\left.\left.\| \mathcal{N}\left(\tilde{\alpha}_{i, j} * \mu_{i, j}^{(0)}, \tilde{\alpha}_{i, j} * \sigma_{i, j}^{(0)^{2}}\right)\right]\right\}
\end{array}</script><p>由于$n \rightarrow+\infty$，第一项KL在计算上很难处理，要对其进行转化</p>
<blockquote>
<p><strong>理论2</strong></p>
<p>给定两个二项分布$\mathcal{B}\left(n, \lambda\right)$、$\mathcal{B}\left(n, \lambda^{0}\right)$，其中$n$是增加的，而$λ$和$λ_0$是减少的</p>
<p>存在一个实常数$m$和另一个实常数$m^{(0)}$，如果$m = nλ$和$m^{(0)}= nλ^{(0)}$，并且如果$λ &gt; λ^{(0)}$，有:</p>
<script type="math/tex; mode=display">
\begin{array}{r}
\mathrm{KL}\left(\mathcal{B}(n, \lambda) \| \mathcal{B}\left(n, \lambda^{0}\right)\right)<m \log \frac{m}{m^{(0)}} 
+(1-m) \log \frac{1-m+m^{2} / 2}{1-m^{(0)}+m^{(0)^{2} / 2}}
\end{array}</script></blockquote>
<p>根据定理2，可以得到一个与n无关的封闭形式的解</p>
<h2 id="四、实验及分析"><a href="#四、实验及分析" class="headerlink" title="四、实验及分析"></a>四、实验及分析</h2><ul>
<li><p><strong>使用当前语句与历史9句话来构建图</strong></p>
</li>
<li><p><strong>CHiME-2、CHiME-5数据集</strong></p>
<p><img src="http://funera-hk.oss-cn-hongkong.aliyuncs.com/img/image-20210707140643962.png" alt="image-20210707140643962" style="zoom:80%;" /></p>
<p><img src="http://funera-hk.oss-cn-hongkong.aliyuncs.com/img/image-20210707140526155.png" alt="image-20210707140526155" style="zoom:80%;" /></p>
</li>
<li><p><strong>RelationalSWB数据集</strong></p>
<ul>
<li><p>DGP关系的<strong>定量评价</strong></p>
<ul>
<li><p>在RelationalSWB数据集评估了图的边与基本事实关系的匹配程度</p>
<p><img src="http://funera-hk.oss-cn-hongkong.aliyuncs.com/img/image-20210707140051859.png" alt="image-20210707140051859" style="zoom: 80%;" /></p>
</li>
<li><p>在RelationalSWB数据集的实验结果：</p>
<p><img src="http://funera-hk.oss-cn-hongkong.aliyuncs.com/img/image-20210707140243808.png" alt="image-20210707140243808" style="zoom:80%;" /></p>
</li>
</ul>
</li>
<li><p>DGP对SWB和SwDA的<strong>定性评价</strong></p>
<ul>
<li>右边显示的总结图比左边的连接更密集</li>
<li>能够捕获话语之间的强弱关系</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><img src="http://funera-hk.oss-cn-hongkong.aliyuncs.com/img/image-20210508164204021.png" alt="image-20210508164204021" style="zoom:67%;" /></p>
<h2 id="五、结论"><a href="#五、结论" class="headerlink" title="五、结论"></a>五、结论</h2><ul>
<li><p>提出了一种<strong>新的图学习方法</strong>，称为<strong>深度图随机过程(DGP)</strong>，用于<strong>关系思维建模</strong></p>
</li>
<li><p>模型<strong>可以生成</strong>表示话语之间复杂<strong>关系的图</strong>，而<strong>无需</strong>在训练过程中使用任何<strong>关系数据</strong></p>
</li>
<li><p>DGP可以<strong>方便</strong>地与神经网络模型相结合，用于下游任务</p>
</li>
<li><p>实验结果表明，该方法在语音识别方面<strong>优于</strong>其他RNN模型</p>
</li>
</ul>
<hr>
<p><strong>相关资料</strong>：</p>
<ol>
<li><a href="https://www.zhihu.com/question/26694486/answer/349872296">如何从深刻地理解随机过程的含义？ - 知乎 (zhihu.com)</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/54101808">概率图模型 - 知乎 (zhihu.com)</a></li>
<li><a href="https://www.zhihu.com/question/352295592">贝叶斯深度学习是什么，和传统神经网络有何不同？ - 知乎 (zhihu.com)</a></li>
<li><a href="https://blog.csdn.net/Miha_Singh/article/details/111701816">Deep Graph random Process for Relational-Thinking-based Speech Recognition_Milkha的博客-CSDN博客</a></li>
<li><a href="https://blog.csdn.net/qy20115549/article/details/93074519">变分推断中的ELBO(证据下界)_qy20115549的博客-CSDN博客</a></li>
<li><a href="https://www.cnblogs.com/yifdu25/p/8181185.html">变分推断（Variational Inference） - 彼岸花杀是条狗 - 博客园 (cnblogs.com)</a></li>
</ol>
]]></content>
      <categories>
        <category>ssk</category>
      </categories>
      <tags>
        <tag>元学习</tag>
        <tag>迁移学习</tag>
      </tags>
  </entry>
  <entry>
    <title>ssk NOVELTY DETECTION WITH RECONSTRUCTION ALONG PROJECTION PATHWAY</title>
    <url>/2021/01/06/ShaoShikuan/RAPP%20NOVELTY%20DETECTION%20WITH%20RECONSTRUCTION%20ALONG%20PROJECTION%20PATHWAY/</url>
    <content><![CDATA[<ul>
<li><p><strong>作者</strong></p>
<p>Ki Hyun Kim, Sangwoo Shim, Yongsub Lim, Jongseob Jeon, Jeongwoo Choi, Byungchan Kim, Andre S. Yoon</p>
</li>
<li><p><strong>会议</strong></p>
<p>2020 ICLR</p>
</li>
<li><p><strong>贡献</strong></p>
<p>1、提出一种新的利用输入的隐藏层激活值和自编码器重构之后的隐藏层激活值异常检测方法RAPP，并且给出了识别输入异常的聚合函数</p>
<p>2、给出了RAPP的动机，将重构的观点从输入空间扩展到隐空间。展示了重构输入之后再输入到网络的隐藏激活值与对应的原始输入的隐藏重构值是等价的。</p>
<p>3、说明了RAPP在多个数据集上改进了基于自编码器的异常检测方法。此外，验证了RAPP的效果超过了最近的异常检测方法。</p>
<a id="more"></a>
</li>
<li><p><strong>介绍</strong></p>
<p>​    当只有正常值信息时应该如何来识别异常？异常检测是一种来识别数据样本相对于训练数据是否为离群点额方法，常见的例子有交易欺诈检测，视频监控，医学诊断和设备异常检测。最近深度自编码器和他们的变体在发现复杂数据的简洁表示方面展示出了杰出的表现，并且重构误差被用来作为一种检测异常值的受欢迎度量。但是这种方法有一种限制，只测量了输入空间的重构误差而没有充分利用隐空间中的层次表示。</p>
<p>​    普通的基于重构的方法是通过比较输入层的输入数据和在输出层的重构数据之间的差别，RAPP把这种比较拓展到了隐空间。首先收集一些隐藏激活值通过将原始输入喂到自编码器中，然后将自编码器的重构值输入到自编码器中计算另一份隐藏层的激活值，这个过程不需要自编码器的额外训练。接下来通过聚合这两份隐藏激活值来量化输入的异常特性。最后，开发了两种度量标准，第一种测量了输入空间和隐空间的整个重构误差数量，第二种度量标准首先标准化了重构误差，然后再求和。</p>
<p>​    介绍了开发RAPP的动机，展示了重构输入之后再输入到网络的隐藏激活值与对应的原始输入的隐藏重构值是等价的</p>
</li>
<li><p><strong>RAPP</strong></p>
<p>​    下面来介绍提出的基于自编码器的异常检测方法：RAPP，主要的思想就是比较原始输入的隐藏激活值和沿着自编码器投影路径的隐藏重构。也就是说将输入和自编码器的重构映射到隐空间来得到成对的激活值。</p>
<ul>
<li><p><strong>基于重构的异常检测</strong></p>
<p>​    一个自编码器 $A$ 是一个包含编码器 $g$ 和解码器 $f$ 的神经网络 $A=f \cdot g$ 编码器 $g$ 构造的空间叫做隐空间，提供了输入数据的更简洁的表示。</p>
<p>​    出于这种无监督表示学习的属性，自编码器广泛用于异常检测。在正常的数据样本上训练自编码器，测试样本 $x$ 是否异常通过下式的重构误差 $\varepsilon $ 来度量：</p>
<script type="math/tex; mode=display">
\varepsilon =||x-A(x)||_2</script><p>​    随着$\varepsilon (x)$的增大，测试样本 $x$ 更可能是一个异常，因为那意味着 $x$ 更加远离了自编码器所描述的流形。</p>
<p>​    即使这种方法展示了在异常检测方面有前景的结果，但重构误差没有充分利用训练好的自编码器提供的信息，特别是当自编码器很深的时候。换句话说被自编码器所识别的层次信息被忽略掉了，层次表示学习是深度神经网络被证明最成功的能力之一。</p>
</li>
<li><p><strong>隐空间中的重构误差</strong></p>
<p>​    令 $A=f \cdot g$表示一个已经训练好的自编码器，$l$ 是编码器 $g$ 的隐藏层数量，$g=g_l\cdot …\cdot g_1$ ，定义$g$的部分计算为：</p>
<script type="math/tex; mode=display">
g_{:i} = g_i...g_1</script><p>其中$1\leq i\leq l$</p>
<p>​    令$x$是输入向量，$\widehat{x}$是通过$A$的重构：$\widehat{x}=A(x)$。除了像普通自编码器那样在输入空间中比较$x$和$\widehat{x}$，还沿着$A$的投影路径来在隐空间中比较他们，也就是将$x$和$\widehat{x}$输入到$A$，得到成对的隐空间表示$(h_i,\widehat{h}_i)$，其中</p>
<script type="math/tex; mode=display">
h_i(x)=g_{:i}(x) ,</script><script type="math/tex; mode=display">
\widehat{h}_i(x)=g_{:i}(\widehat{x})=g_{:i}(A(x))</script><p>​    如下图所示，表示了计算$h_i$和$\widehat{h}_i$的过程，因此，样本$x$的异常性由公式$H(x) = { (h_i(x), \widehat{h}_i(x)) : 1 ≤ i ≤ l }$来度量。</p>
<p><img src="http://echo23334.gitee.io/pic_repo/微信截图_20201003151333.png" alt="微信截图_20201003151333" style="zoom:70%;" /></p>
<p>​    注意RAPP确实是普通重构方法的一般化，通过定义$g<em>0$和$s</em>{ord}$如下</p>
<script type="math/tex; mode=display">
s_{ord}(H(x)) = ||h_0(x) − \widehat{h}_0(x)||_2</script><p>其中$h_0(x) = g_0(x) = x$，$\widehat{h}_0(x) = g_0(\widehat{x}) = \widehat{x}$</p>
<p>​    在本文中定义了两个度量尺度$s<em>{SAP}$和$s</em>{NAP}$。当没有先验知识存在时，这两种度量尤其适用于选择层次以获得异常度量，注意，如果我们有关于空间的知识或者能够描述空间特征，可以设计出更精细的度量方法。</p>
<ul>
<li><p><strong>沿着路径的简单聚合(SAP)</strong></p>
<p>​    这是一种最直接的定义在$H$上的度量方法，对于一个样本$x$，SAP可以定义为H中的所有pair之间的欧氏距离的平方和：</p>
</li>
</ul>
<script type="math/tex; mode=display">
s_{SAP}=\sum_{i=0}^{l}||h_i(x)-\widehat{h}_i(x)||^2_2=||\textbf{h}(x)-\widehat{\textbf{h}}(x)||^2_2</script><ul>
<li><p><strong>沿着路径的标准化聚合(NAP)</strong></p>
<p>​    虽然SAP很直观，但是隐空间的属性，$H$中pairs的距离分布可能由于不同隐空间而有不同，例如，</p>
<p>距离的大小会依赖于不同的层，或者可能存在跨层的相关神经元，这些神经元无意之中在SAP中被强调。所以为了捕获更清楚的模式，通过两个步骤来标准化这些距离：正交化和缩放。</p>
<p>​    令 $\textbf{d}(x) = \textbf{h}(x) − \widehat{\textbf{h}}(x)$ ；给定一个训练集$X$，令$\textbf{D}$表示一个矩阵，它的第$i$行对应$\textbf{d}(x<em>i)$，其中$x_i \in X$，令$\overline{\textbf{D}}$表示$\textbf{D}$的列优先中心(column-wise centered)矩阵，为了标准化，计算$\overline{\textbf{D}}$的SVD分解-$U\sum V^T$，得到奇异值$\sum $和右奇异向量$V$，对于一个给定的样本$x$，定义$s</em>{NAP}$如下</p>
<script type="math/tex; mode=display">
s_{NAP}(x)=||(\textbf{d}(x)-\mu_X)^TV\sum{^{-1}}||_2^2</script><p>​    其中$\mu_X$表示D的列优先的平均值，$\textbf{d}(x)$表示为一个列向量。</p>
</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>RAPP的动机</strong></p>
<p>​    使用普通的重构方法会有一个很自然的问题：为什么只使用输入空间？或者说为什么不使用隐空间的信息？当重构误差在输入空间中广泛使用，任何类似的观点在隐空间中就都不存在。一个原因是对应的编码器层和解码器层无法保证表示出相同的空间，这是因为自编码器的目标函数没有任何涉及到中间隐藏层的激活值。因此，$f<em>{l:i+1}(g(x))$不能被认为是$g</em>{:i}(x)$的重构。</p>
<p>​    下面会介绍一种非直接的方法来计算隐空间重构，准确的说会介绍$\widehat{h}<em>i(x)=g</em>{:i}(A(x))$确实等同于$g_{:i}(x)$的重构，整体机制如下所示</p>
<p><img src="http://echo23334.gitee.io/pic_repo/微信截图_20201003201056.png" alt="微信截图_20201003201056" style="zoom:60%;" /></p>
<ul>
<li><p>隐空间重构的计算</p>
<p>​    令$A=f\cdot g$为一个已经训练好的自编码器，令$M<em>0={A(x):x \in \mathbb{R}^n}$表示为$A$所描述的低维表示，定义$M_i={g</em>{:i}(x):x \in M<em>0}$为由$g</em>{:i}$定义的$M_0$的低维映像，$g$和$f$受限于$M_0$和$M_l$，是彼此之间的逆函数。</p>
<p>​    <strong>量化隐空间的重构</strong>，我们首先假设存在一个解码器$\widetilde{f}=\widetilde{f}_1 \cdot… \cdot \widetilde{f}_l$，例如：</p>
<script type="math/tex; mode=display">
\forall x\in M_l,\widetilde{f}(x)=f(x),</script><script type="math/tex; mode=display">
\forall a \in M_i,a=(g_i \cdot \widetilde{f}_i)(a)</script><p>​    其中第二个条件使$\widetilde{f}<em>{l:i+1}$成为一个对应于$g</em>{i+1:}$的合适的解码器，因此$\widetilde{f}$能够定义第$i$层的隐重构$\widehat{h}^{‘}_i(x)$，如下式所示：</p>
<script type="math/tex; mode=display">
\widehat{h}^{'}_i(x)=(\widetilde{f}_{l:i+1}\cdot g_{i+1:})(h_i(x))</script><p>最终能够得到结论$\widetilde{h}^{‘}_i(x)$等同于$\widetilde{h}_i(x)$，对于任一$x \in M_0$，如下所示：</p>
<script type="math/tex; mode=display">
\widehat{h}^{'}_i(x)=(\widetilde{f}_{l:i+1}\cdot g_{i+1:})(h_i(x))=(\widetilde{f}_{l:i+1}\cdot g)(x)</script><script type="math/tex; mode=display">
\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space =(g_{:i}\cdot\widetilde{f}\cdot g)(x)</script><script type="math/tex; mode=display">
\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space =(g_{:i} \cdot A)(x)=h_i(\widehat{x})=\widehat{h}_i(x)</script></li>
</ul>
</li>
<li><p><strong>评价</strong></p>
<p>使用了Kaggle和UCI中用来进行异常检测和多分类的数据集，如下表所示</p>
</li>
</ul>
<p><img src="http://echo23334.gitee.io/pic_repo/微信截图_20201003230421.png" alt="微信截图_20201003230421" style="zoom:60%;" /></p>
<p>​        为了比较RAPP和最近文章中的异常检测方法，也选取了一些基数据集来评估深度学习技术：MNIST和F-MNIST。</p>
<p>​        使用AUROC将RAPP和其他的一些方法进行了比较，没有使用基于阈值的度量，例如F1-score，因为只允许在测试期间访问异常样本。</p>
<p>和基线的比较：</p>
<p><img src="http://echo23334.gitee.io/pic_repo/微信截图_20201003231256.png" alt="微信截图_20201003231256" style="zoom:60%;" /></p>
<p>和最近的方法的比较：</p>
<p><img src="http://echo23334.gitee.io/pic_repo/微信截图_20201003231303.png" alt="微信截图_20201003231303" style="zoom:60%;" /></p>
]]></content>
      <categories>
        <category>ssk</category>
      </categories>
      <tags>
        <tag>异常检测</tag>
      </tags>
  </entry>
  <entry>
    <title>ssk Transfer Anomaly Detection by Inferring Latent Domain Representations</title>
    <url>/2021/01/06/ShaoShikuan/Transfer%20Anomaly%20Detection%20by%20Inferring%20Latent%20Domain%20Representations/</url>
    <content><![CDATA[<h3 id="Transfer-Anomaly-Detection-by-Inferring-Latent-Domain-Representations"><a href="#Transfer-Anomaly-Detection-by-Inferring-Latent-Domain-Representations" class="headerlink" title="Transfer Anomaly Detection by Inferring Latent Domain Representations"></a>Transfer Anomaly Detection by Inferring Latent Domain Representations</h3><h5 id="作者：Atsutoshi-Kumagai，Tomoharu-Iwata"><a href="#作者：Atsutoshi-Kumagai，Tomoharu-Iwata" class="headerlink" title="作者：Atsutoshi Kumagai，Tomoharu Iwata"></a>作者：Atsutoshi Kumagai，Tomoharu Iwata</h5><h5 id="会议：NeurIPS-2019"><a href="#会议：NeurIPS-2019" class="headerlink" title="会议：NeurIPS 2019"></a>会议：NeurIPS 2019</h5><h5 id="贡献："><a href="#贡献：" class="headerlink" title="贡献："></a>贡献：</h5><p>​        使用源域的正常和异常实例或者仅使用正常实例训练自编码器，通过引入隐域向量(<em>latent domain vector</em>)(<em>域的隐表示，由每一个域的正常实例通过神经网络得到</em>)的概念，所提出的方法可以为目标域推断出异常检测器，而不需要在目标域中重新训练。</p>
<p>​        每一个域的隐域向量都是由每个域的正常实例来得到的，每个域的异常分数函数由自编码器的偏差来建模，并且自编码器具体的域属性由隐域向量来控制。</p>
<a id="more"></a>
<p><img src="http://echo23334.gitee.io/pic_repo/微信截图_20201123164447.png" alt="微信截图_20201123164447" style="zoom:67%;" /></p>
<h5 id="准备知识："><a href="#准备知识：" class="headerlink" title="准备知识："></a>准备知识：</h5><p>​        由于AE的简洁有效性，AE在最近的半监督异常检测中广泛使用，所以本文也使用AE作为所提出方法的基础。AE的用来训练的损失函数表示如下：</p>
<script type="math/tex; mode=display">
L(\theta_F,\theta_G):=\frac{1}{N}\sum_{n = 1}^{N}||x_n-G_{\theta_G}(F_{\theta_F}(x_n))||^2</script><h5 id="方法："><a href="#方法：" class="headerlink" title="方法："></a>方法：</h5><h6 id="Task"><a href="#Task" class="headerlink" title="Task"></a>Task</h6><p>​        令$X<em>d^+:={x</em>{dn}^+}<em>{n=1}^{N_d^+}$表示第d个域中的异常实例，其中$x</em>{dn}^+ \in R^M$，第d个域中第n个实例的M维特征向量，$N<em>d^+$是异常实例的数量，同样定义$X_d^-:={x</em>{dn}^-}_{n=1}^{N_d^-}$。我们假设$N_d^+&lt;&lt;N_d^-$，M在所有域中都是相同的，在$D_S$个源域中有异常和正常实例，在$D_T$个目标域中有正常实例，注意本文所提出的方法也可以处理源域只有正常实例的情况。</p>
<p>​        本文的目标是对于所有目标域获得一个领域具体的异常分数函数，用来输出实例的异常分数。</p>
<h6 id="Domain-specific-Anomaly-Score-Function"><a href="#Domain-specific-Anomaly-Score-Function" class="headerlink" title="Domain-specific Anomaly Score Function"></a>Domain-specific Anomaly Score Function</h6><p>​        基于AE的重构误差来定义本文的领域具体的异常分数函数。假设每一个领域都有一个<strong>K</strong>维的隐藏连续变量$\bold z_d \in R^K$，在本文中称为隐域向量，对于第d个域，定义如下的异常分数函数：</p>
<script type="math/tex; mode=display">
s_\theta(x_{dn}|z_d):=||x_{dn}-G_{\theta_G}(F_{\theta_F}(x_{dn},z_d))||^2 \qquad(1)</script><p>​        其中的参数$\theta:=(\theta_F,\theta_G)$在所有域中共享。通过改变$z_d$的值，本文的方法可以灵活的改变异常分数函数的属性。</p>
<h6 id="Models-for-Latent-Domain-Vectors"><a href="#Models-for-Latent-Domain-Vectors" class="headerlink" title="Models for Latent Domain Vectors"></a>Models for Latent Domain Vectors</h6><p>​        由于隐域向量无法被观测到，所以我们从数据中对其进行估计。通过给定的正常实例，建模隐域向量的条件概率为多元高斯分布：</p>
<script type="math/tex; mode=display">
q_\phi(z_d|X_d^-):= {\cal N}(z_d|\mu_\phi(X_d^-),diag(\sigma^2_\phi(X_d^-))) \qquad(2)</script><p>​        其中diag是对角协方差矩阵。均值$\mu<em>\phi(X_d^-)\in R^K$，方差$\sigma</em>\phi^2(X<em>d^-)\in R^K</em>+$是通过神经网络来进行建模，神经网络的参数$\phi$在所有域中共享。在这个模型中隐域向量$z_d$依赖于正常实例$X_d^-$。通过建模，当一个域的正常实例给定时，我们可以推断任何域的隐域向量。相应的就可以得到领域具体的异常分数函数，而不需要重新训练。</p>
<h6 id="Objective-Function"><a href="#Objective-Function" class="headerlink" title="Objective Function"></a>Objective Function</h6><p>​        定义本文的目标函数，使用领域具体的异常分数函数和隐域向量。首先，对于第d个<strong>源域</strong>在隐域向量$z_d$约束下的最小化目标函数定义如下：</p>
<script type="math/tex; mode=display">
L_d(\theta|z_d):=\frac{1}{N_d^-}\sum_{n = 1}^{N_d^-}s_\theta(x_{dn}^-|z_d)-\frac{\lambda}{N_d^-N_d^+}\sum_{n,m = 1}^{N_d^-,N_d^+}f(s_\theta(x_{dm}^+|z_d)-s_\theta(x_{dn}^-|z_d)) \qquad (3)</script><p>​        这种形式的目标函数由二作提出(Supervised anomaly detection based on deep autoregressive density estimators.)，但是没有考虑领域差异。    </p>
<p>​        其中超参数$\lambda\geq 0$，$f$是sigmoid函数，上式的第一项表示的是第d个域内正常实例的异常分数，因为正常实例的异常分数应该很小，所以我们最小化这一部分。上面公式的第二项是AUC的可微近似，对于类别不平衡的数据很有效，异常实例的异常分数应该比正常实例的高，$s<em>\theta(x</em>{dm}^+|z<em>d)&gt;s</em>\theta(x<em>{dn}^-|z_d)$对于任意的$x</em>{dm}^+\in X^+<em>d,x</em>{dn}^-\in X^-_d$。</p>
<p>​        当域中没有异常，或者$\lambda=0$，上式第二项等于0，第一项保留。所以这一目标函数是AE的有监督扩展。</p>
<p>​        由于隐域向量$z<em>d$具有方差$\sigma^2</em>\phi$的不确定性，也就是隐域向量是由数据估计的，因此估计往往具有不确定性。我们想要针对目标函数适当地考虑这一点，所以定义了如下的第d个<strong>源域</strong>的目标函数来最小化：</p>
<script type="math/tex; mode=display">
{\cal L}_d(\theta,\phi):=\mathbb{E}_{q_\phi(z_d|X_d^-)}[L_d(\theta|z_d)]+\beta D_{KL}(q_\phi(z_d|X_d^-)||p(z_d)) \qquad(4)</script><p>​        其中$D<em>{KL}(q</em>\phi(z<em>d|X_d^-)||p(z_d))$是$q</em>\phi(z_d|X_d^-)$和一个标准正态分布$p(z_d):= {\cal N}(0,I)$之间的KL散度，$\beta&gt;0$是一个超参。</p>
<p>​        上式第一项是公式(3)关于$q<em>\phi(z_d|X_d^-)$的期望。这一期望项可以通过重新参数化(reparametrization)技巧(trick)有效地近似，即$\mathbb{E}</em>{q<em>\phi(z_d|X_d^-)}[L_d(\theta|z_d)] \approx \frac{1}{L} \sum</em>{l=1}^LL<em>d(\theta|z_d^{(l)})$，其中，$z_d^{(l)}=\mu</em>{\phi}(X<em>d^-)+\epsilon_d^{(l)} \odot \sigma</em>{\phi}(X_d^-),\epsilon_d^{(l)} \sim {\cal N}(0,I)$，其中$\odot$表示每个元素分别相乘，$L$为随机采样$L$次</p>
<p>​        上式第二项是正则化项，防止隐域向量的过拟合，这种形式的正则化项在VAE中比较常见。</p>
<p>​        对于第d个<strong>目标域</strong>的目标函数通过忽略掉公式(4)中的异常项，因为目标域中没有异常实例，也就是：</p>
<script type="math/tex; mode=display">
{\cal L}_d(\theta,\phi):=\mathbb{E}_{q_\phi(z_d|X_d^-)}[\frac{1}{N_d^-}\sum_{n = 1}^{N_d^-}s_\theta(x_{dn}^-|z_d)]+\beta D_{KL}(q_\phi(z_d|X_d^-)||p(z_d)) \qquad(5)</script><p>​        其中的第一项也可以按上面的方法近似。所以本文所提出的方法的目标函数也就是以下各领域目标函数的加权和，${\cal L}<em>d(\theta,\phi):=\sum</em>{d = 1}^{D_S+D_T} \alpha_d {\cal L}_d(\theta,\phi)$，其中$\alpha_d\geq 0$是超参数，通过梯度下降，目标函数可以关于$\theta,\phi$最小化</p>
<h6 id="Inference"><a href="#Inference" class="headerlink" title="Inference"></a>Inference</h6><p>​        通过学习到的参数$(\theta<em>*,\phi</em>*)$和正常实例$X_{d’}^-$，为第$d’$个域推断特定域的异常分数函数，如下所示：</p>
<script type="math/tex; mode=display">
s(x_{d'}):=\int s_{\theta_*}(x_{d'}|z_{d'})q_{\phi_*}(z_{d'}|X_{d'}^-)d_{z_{d'}}\approx \frac{1}{L} \sum_{l=1}^Ls_{\theta_*}(x_{d'}|z_{d'}^{(l)})\qquad(6)</script><p>​        其中$z<em>{d’}^{(l)}=\mu</em>{\phi<em>*}(X</em>{d’}^-)+\epsilon<em>d^{(l)} \odot \sigma</em>{\phi<em>*}(X</em>{d’}^-),\epsilon<em>d^{(l)} \sim {\cal N}(0,I)$，$x</em>{d’}$是第$d’$个域的任意实例，可以得到异常分数函数，在$X_{d’}^-$没有参与到训练的情况下。</p>
<h5 id="实验："><a href="#实验：" class="headerlink" title="实验："></a>实验：</h5><p>​        本文用到了一个合成数据集和四个类别不平衡的真实数据集。</p>
<h6 id="Data"><a href="#Data" class="headerlink" title="Data"></a>Data</h6><p>​        我们创建了简单的二维数据集如下所示，此数据集由围绕(0,0)的8个双层圆(域)组成。每个双层圆有外圆和内圆，分别由正常实例和异常实例组成。使用第7个域作为目标域，其余的作为源域。使用四个真实数据集：MNIST-r, Anuran Calls, Landmine, 和 IoT。</p>
<p>​        Synthetic, MNIST-r, Anuran Calls, Landmine, 和 IoT的平均异常比例为0.048, 0.1, 0.024, 0.062, 和 0.05</p>
<h6 id="Comparison-Methods"><a href="#Comparison-Methods" class="headerlink" title="Comparison Methods"></a>Comparison Methods</h6><p>​        比较了本文的两个变体：ProT 和 ProS。ProT使用目标域中的正常实例以及异常和正常源实例进行训练。ProS不使用目标域正常实例进行训练，在使用源域训练完成后，ProS使用目标域的正常实例来推断目标域的异常分数函数而无需再训练。</p>
<p>​        比较了本文的方法和其他八个方法：NN，NNAUC，AEAUC，AE，OSVM，CCSA，TOSVM，OTL，其中AE，OSVM是半监督异常检测方法，NN，NNAUC，AEAUC是监督学习方法，AEAUC和本文的方法类似，不过没有考虑隐域向量。CCSA, TOSVM, 和 OTL是迁移学习方法或者是迁移异常检测方法。</p>
<h6 id="Results"><a href="#Results" class="headerlink" title="Results"></a>Results</h6><p><img src="http://echo23334.gitee.io/pic_repo/image-20201122163254167.png" alt="image-20201122163254167" style="zoom:67%;" /></p>
<p>​        首先是合成数据集上的结果，如上Figure 2所示。2b是通过ProS估计的隐域向量(K=2)，特别的，目标域的隐域向量通过源域的隐域向量预测出来了，尽管目标域没有参与到训练。2c表示的是通过ProS得到的目标域异常分数的热力图。2d表示的是在目标域上不同$\lambda$所得到的AUC折线，使用AEAUC作为基线，因为它是由ProS忽略隐域向量得到的。</p>
<p>​        接下来是在真实数据集上的结果。表1-4展示的是不同数据集，不同目标域上AUC的均值和标准差。</p>
<p><img src="http://echo23334.gitee.io/pic_repo/image-20201122173008338.png" alt="image-20201122173008338" style="zoom:67%;" /></p>
<p><img src="http://echo23334.gitee.io/pic_repo/image-20201122173025976.png" alt="image-20201122173025976" style="zoom:67%;" /></p>
<p><img src="http://echo23334.gitee.io/pic_repo/image-20201122173041877.png" alt="image-20201122173041877" style="zoom:67%;" /></p>
<p><img src="http://echo23334.gitee.io/pic_repo/image-20201122173053750.png" alt="image-20201122173053750" style="zoom:67%;" /></p>
<p>​        第三，研究了该方法中考虑潜在域向量不确定性的影响，为此考虑了ProT和ProS的确定性变量，称作D-ProT和D-ProS，表5展示了结果。</p>
<p>​        第四，研究了异常训练实例数量的影响，表-6展示了结果。</p>
]]></content>
      <categories>
        <category>ssk</category>
      </categories>
      <tags>
        <tag>异常检测</tag>
        <tag>迁移学习</tag>
      </tags>
  </entry>
  <entry>
    <title>ssk Transfer Learning for Anomaly Detection through Localized and Unsupervised Instance Selection</title>
    <url>/2022/07/15/ShaoShikuan/Transfer%20Learning%20for%20Anomaly%20Detection%20through%20Localized%20and%20Unsupervised%20Instance%20Selection/</url>
    <content><![CDATA[<ul>
<li>作者</li>
</ul>
<p>Vincent Vercruyssen, Wannes Meert, Jesse Davis</p>
<p>DTAI group, KU Leuven, Belgium<br>firstname.lastname@kuleuven.be</p>
<ul>
<li>会议</li>
</ul>
<p>2020 AAAI</p>
<ul>
<li><p>介绍</p>
<p>​    异常检测可以自然地作为一项无监督的学习任务，无监督的方法利用了异常不经常发生的假设，即异常会落在整个实例空间中的低密度区域。但是现实世界的数据经常违背这一假设，例如系统维护会不定期的发生，但不是异常。带标签的数据提供了修正这一差错的可能性，但是完全的监督方法却是不可行的，因为收集现实世界的异常标签是非常昂贵的。激发了对异常检测的半监督方法的研究兴趣，通常与主动学习结合来有效地收集标签。</p>
<a id="more"></a>
<p>​    现实世界的异常检测任务经常会涉及监控大量的资产，而每一项资产只有细微的差别。这些场景经常会发生在一个工厂的许多机器和零售商店的所有连锁店中。这些场景需要监控大量的资产，因此即便使用主动学习的策略也很难为每一个资产收集所有标签。鉴于这些涉及相似异常检测任务的场景，我们可以使用迁移学习将有标签的实例从一个任务迁移到另一个任务。</p>
<p>​    所以本文提出了一种专门针对异常检测的新型迁移学习算法-LOCIT。它的流程分为两步。首先，给定一部分带标签的源数据集和一个没有标签的目标数据集，LOCIT选择在源数据集和目标数据中有相似的局部数据分布的数据实例，将其迁移到目标数据集中，接下来，它使用半监督的最近邻方法分配异常分数，该方法同时考虑已迁移的带标签的源实例和不带标签的目标实例。</p>
</li>
<li><p>贡献</p>
<ul>
<li>提出一种用于异常检测的新的迁移学习算法：LOCIT(localized instance-transfer algorithm)，检查实例的局部数据分布在源和目标(目标问题)域中是否相似，以不依赖标签的方式决定是否将每个源实例迁移到目标域。</li>
<li>使用一种半监督异常检测方法，SSKNNO，它结合未标记实例和标记实例(迁移之后的)计算每个目标实例的异常分数。</li>
</ul>
</li>
<li><p>基础概念</p>
<ul>
<li><p>用于异常检测的迁移学习</p>
<p>​    迁移学习的目的是通过给定的一个相关数据集(源域)的数据来学到另一个数据集(目标域)的模型，本文关注的是异常检测，所以任务就是给目标数据集中的每一个实例分配一个分数来量化异常程度，使用$D_S(D_T)$表示源域(目标域)，使用$x_s(x_t)$表示源域或目标域数据集中的实例。</p>
<p>​    三个常见的迁移学习假设适用于异常检测任务。首先源数据和目标数据来自相同维度的空间。其次，源域和目标域的边缘分布不同(covariate shift assumption)。第三，条件分布会因上下文的变化而不同:同一行为在两个领域中可能具有不同的含义(concept shift assumption)。</p>
</li>
<li><p>Nearest Neighbors and KNNO</p>
<p>​    实例$x$的$k$距离指的是在数据集$D$中离它最近的第$k$个邻居的距离，表示为$k-dist(x,D)$，在$D$中离$x$的最近的$k$个邻居表示为$N_k(x,D)$。在加权距离KNN中标准的权重函数为$\omega(x_i,x_j)=\frac{1}{\delta (x_i,x_j)^2}$，其中$\delta $是两个实例$x_i$和$x_j$的欧氏距离。最后KNNO根据实例的$k$距离将一个数据集中的所有实例进行排序，越高的距离意味着越多的异常实例。</p>
</li>
</ul>
</li>
<li><p>LOCIT</p>
<p>问题：</p>
<p>​    给定：来自相同特征空间的一个已标记的源数据集$D_S$和一个未标记的目标数据集$D_T$</p>
<p>​    求：使用$D_T$和$D_S$的一个子集来给$D_T$中的每一个实例分配一个异常分数</p>
<p>LOCIT分两步解决上面任务，首先通过检查实例的本地数据分布在源和目标域中是否相似，以不依赖标签的方式决定是否将每个源实例迁移到目标域。LOCIT采用无监督迁移方式，因为目标标签不可用，而且源标签的值不应该影响迁移决定。其次，LOCIT使用一种新的半监督异常检测算法给每个目标实例分配一个异常分数。</p>
<ul>
<li><p>本地实例的迁移(Localized Instance-Based Transfer)</p>
<p>​    实例迁移函数$f(x_S;D_S,D_T)\mapsto{0,1}$决定是否将一个源实例$x_S \in D_S$迁移到目标域中。最理想的情况是，每一个已经迁移的源实例在两个域中有相同的含义。只有当源异常(正常)实例与目标异常(正常)实例相似时，将源异常(正常)实例迁移到目标域中才有意义。因此LOCIT做了一个假设：如果一个实例周围的源和目标边缘分布的局部结构相似，则实例在源和目标域中具有相似的意义，这里的分布结构由一阶和二阶统计量表征。</p>
<ul>
<li><p>表征实例的局部结构</p>
<p>​    给定一个源实例$x<em>S$，LOCIT使用$x_S$的$\psi $个源域中最近的邻居集合$N</em>\psi (x<em>S,D_S)$定义了局部的源分布。同样局部的目标分布也是基于$x_S$的$\psi $个目标域中最近的邻居集合$N</em>\psi (x<em>S,D_T)$。假设是：如果$N</em>\psi (x<em>S,D_S)$与$N</em>\psi (x<em>S,D_T)$之间的分布相似，那么$x_S$就可以被迁移。相似性由下面$N</em>\psi (x<em>S,D_S)$和$N</em>\psi (x_S,D_T)$的两个一阶和二阶统计量来度量。</p>
</li>
<li><p>位置距离</p>
<p>​    下面的公式定义了两个邻居集合$N1$和$N2$的质心之间的差值(即算术平均值)的l2-范数:</p>
<script type="math/tex; mode=display">
d_1(N1,N2)=||\frac{1}{k}(\sum_{x_i\in N_1}x_i-\sum_{x_j \in N_2}x_j)||_2</script><p>​    在这里，LOCIT计算了$d<em>1(N</em>\psi(x<em>S,D_S),N</em>\psi(x_S,D_T))$.直观上来看，$d_1$越大，表示两个集合覆盖的区域重叠的部分越少，也就减少了迁移这个实例的机会。</p>
</li>
<li><p>相关距离</p>
<p>​    这是两个邻居集合协方差矩阵的相对距离：</p>
<script type="math/tex; mode=display">
d_2(N1,N2)=\frac{||C_{N1}-C_{N2}||_F}{||C_{N1}||_F}</script><p>​    其中$||.||<em>F$是$F$范数，$C$是协方差矩阵。LOCIT计算了$d_2(N</em>\psi(x<em>S,D_S),N</em>\psi(x_S,D_T))$。如果$d_2$很大，这表明潜在的局部源和目标分布在形状或方向上是不同的，这再一次较少了迁移的机会。邻居集的大小$\psi$是唯一一个在LOCIT迁移过程中的超参数。</p>
</li>
<li><p>学习实例迁移函数</p>
<p>​    实例迁移函数$f$需要结合$d_1$和$d_2$提供的信息来决定是否迁移$x_s$，LOCIT在目标分布上学习了一个SVM分类器来作为$f$，分类器通过查看源实例在源数据和目标数据中的邻居集之间的相关距离和位置距离来预测源实例$x_s$是否属于目标域。</p>
<p>​    为了训练分类器，LOCIT仅考虑目标数据来生成训练数据。它利用了光滑性假设，即相邻的目标实例应该具有类似的局部分布，而远处的实例则不应该具有。因此，正训练样本是由每一个实例$x<em>t \in D_T$通过找到它的最近的邻居$x_n \in D_T $\ ${x_t}$，并且计算$d_1(N</em>\psi(x<em>t,D_T),N</em>\psi(x<em>n,D_T))$和$d_2(N</em>\psi(x<em>t,D_T),N</em>\psi(x_n,D_T))$来产生。同样的，负样本的产生是计算每一个实例$x_t \in D_T$的特征向量包括$x_t$的邻居集和距离最远的邻居$x_f \in D_T$\ ${x_t}$之间的距离。下图比较了LOCIT和一种流行的全局域策略CORAL</p>
<p><img src="http://echo23334.gitee.io/pic_repo/微信截图_20201006113453.png" alt="微信截图_20201006113453" style="zoom:60%;" /></p>
</li>
</ul>
</li>
<li><p>在目标域中预测(Prediction in the Target Domain)</p>
<p>​    迁移之后，在对目标实例进行预测时存在两个挑战。首先，目标域现在混合包含带标签和未带标签的实例。其次，由于这是一个异常检测问题，目标实例邻居中的已知标签不一定提供其标签对应的信息。</p>
<p>​    接下来就是LOCIT的第二个贡献，一种半监督异常检测方法SSKNNO，它结合未标记实例和(迁移的)标记实例计算每个目标实例的异常分数。一方面，在计算得分时考虑了未标记目标实例的局部分布。另一方面，它通过比较目标数据中(迁移的)标记实例和未标记实例的邻居来给这个分数加权。</p>
<p>​    令$D^<em>=D<em>T\cup D</em>{trans}$表示包含目标实例和已迁移源实例的集合，对于一个目标实例$x_t$，找到所有邻居的集合$N_k(x_t,D^</em>)$并将集合中已标记的子集表示为$L_k(x_t,D^*)$。在$x_t$的邻居中已标记实例的权重现在是$W_l$：</p>
<script type="math/tex; mode=display">
W_l(x_t)=\frac{|x_i:x_i \in L_k(x_t,D^*)\wedge x_t \in N_k(x_i,D^*)|}{k}</script><p>​    直观来看，当给$x_t$分配一个异常分数时，如果一个源实例和$x_t$很相似时，我们就只想考虑这个迁移过的源实例的标签。例如，如果$x_t$是一个孤立的实例，那么它的$k$个最近的邻居将是很远的。即使贴上了标签，这些实例也不能很好地预测$x_t$的标签。这反映在$W_l(x_t)$，仅仅考虑那些$x_t$邻居中的实例(这些实例中$x_t$也是他们的近邻)。</p>
<p>​    这个权重现在可以被用来计算实例$x_t$的异常分数$a(x_t)$，加权组合了一个无监督成$a_u$(考虑局部数据分布)和一个有监督成分$a_l$(考虑附近的有标签实例)，表示如下：</p>
<script type="math/tex; mode=display">
a(x_t) = (1 −W_l(x_t)) a_u(x_t) +W_l(x_t) a_l(x_t) \space\space\space\space\space\space\space\space\space\space\space\space\space\space(4)</script><p>​    有监督分数$a_l$为$x_t$相邻实例标签的距离加权平均值:</p>
<script type="math/tex; mode=display">
a_l(x_t)=\frac{\sum_{x_i \in L_k}\mathfrak{1}_{x_i=anomaly}(x_i)w(x_i;x_t)}{\sum_{x_i \in L_k}w(x_i;x_t)}</script><p>​    其中$w$在前面定义为欧氏距离；$\mathfrak{1}_{y_i=1}(x_i)$是1，如果专家给$x_i$标注的标签为异常。无监督分数$a_u$使用基于KNNO算法的$k-dist$，但使用了指数函数把范围限定在了$[0,1]$之间：</p>
<script type="math/tex; mode=display">
a_u(x_t)=1-exp(-\frac{k-dist(x_t,D^*)^2}{2 \gamma ^2})</script><p>​    其中，$\gamma$是假设的异常百分比为，设为源域中已知异常所占的比例。下图展示了SSKNNO方法</p>
<p><img src="http://echo23334.gitee.io/pic_repo/%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20201006172520.png" alt="微信截图_20201006172520" style="zoom:80%;" /></p>
<p>​    在极端情况下，权值$W_l(x_t)$可以是0或1。如果$x_t$的邻居都没有被标记，$L_k$为空，$W_l(x_t)$变为零，公式4将简化为相应的KNNO分数。如果LOCIT的迁移函数没有选择实例来迁移，就会发生这种情况。反过来，如果$x_t$的所有邻域都被标记，并且$x_t$属于每一个邻域的邻域集，那么最终的异常值就是标准的加权KNN分类器。</p>
</li>
</ul>
</li>
<li><p>基准实验评估</p>
<ul>
<li><p>比较的方法</p>
<p>​    比较了12个方法，可以分为三个范畴：异常检测的基线算法(KNNO，LOF，IFOREST，HBOS)、迁移学习的基线方法(TRANSFERALL，CORAL，TCA，GFK，JDA，TJM，JGSA，CBIT，迁移之后使用一个KNN分类器来分类)、LOCIT(本文的算法)</p>
</li>
<li><p>实验结果</p>
<p>​    </p>
</li>
</ul>
<p><img src="http://echo23334.gitee.io/pic_repo/%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20201006174619.png" alt="微信截图_20201006174619" style="zoom:80%;" /></p>
</li>
</ul>
<p>  <img src="http://echo23334.gitee.io/pic_repo/微信截图_20201006175121.png" alt="微信截图_20201006175121" style="zoom:80%;" /></p>
<p>  <img src="http://echo23334.gitee.io/pic_repo\微信截图_20201006175501.png" alt="微信截图_20201006175501" style="zoom:80%;" /></p>
<ul>
<li><p>真实世界实验评估</p>
<ul>
<li><p>数据和方法</p>
<p>​    我们有三家商店三年的用水量历史时间序列数据。数据由每五分钟记录一次的单变量测量数据组成。在每个商店，公司专家标记了大约10%的数据，每个提供的标签显示一个小时的区块(例如，01:00-02:00)是否显示正常行为。其余的数据没有标记。</p>
</li>
<li><p>实验结果</p>
</li>
</ul>
</li>
</ul>
<p><img src="http://echo23334.gitee.io/pic_repo\微信截图_20201006175657.png" alt="微信截图_20201006175657" style="zoom:80%;" /></p>
]]></content>
      <categories>
        <category>ssk</category>
      </categories>
      <tags>
        <tag>异常检测</tag>
        <tag>迁移学习</tag>
      </tags>
  </entry>
  <entry>
    <title>ssk Vincent Vercruyssen-Transfer learning and Semi-Supervised文章总结</title>
    <url>/2021/01/06/ShaoShikuan/Transfer%20learning%20and%20Semi-Supervised%E6%96%87%E7%AB%A0%E6%80%BB%E7%BB%93/</url>
    <content><![CDATA[<h4 id="1-Transfer-Learning-for-Anomaly-Detection-through-Localized-and-Unsupervised-Instance-Selection"><a href="#1-Transfer-Learning-for-Anomaly-Detection-through-Localized-and-Unsupervised-Instance-Selection" class="headerlink" title="1  -Transfer Learning for Anomaly Detection through Localized and Unsupervised Instance Selection"></a>1  -Transfer Learning for Anomaly Detection through Localized and Unsupervised Instance Selection</h4><p>Vincent Vercruyssen</p>
<p>2020 AAAI</p>
<p>提出LOCIT算法：1、选择源域(带标签)中的子集迁移到目标域(不带标签)中。2、使用半监督最近邻的方法同时考虑带标签和不带标签的实例来计算异常分数。</p>
<a id="more"></a>
<p><strong>贡献：</strong></p>
<p>1、使用实例在源域和目标域的分布(d1-局部距离和d2-相关距离)来度量是否可以迁移，使用目标域中的实例(假设了近邻的分布相同，距离很远点的分布不同)来训练一个SVM分类器判断是否可以迁移。</p>
<p>2、同时考虑目标实例近邻中的带标签和不带标签的实例(半监督)来分别计算异常分数，并为这两个异常分数根据label instance的近邻中是否也包含目标实例来分配权重。</p>
<p>LOF(基于密度的离群点检测方法)原理：利用了点O的周围密度和O的邻域内的周围密度的比值，这个值越接近1说明点O和他周围点越相似。这就和上面计算有标签和无标签的权重的方式很像</p>
<p><strong>普通数据集构建：</strong></p>
<p>​    本文确定的基准包含三个特性：1、出于经验评估的目的，benchmark应该包含大量的源域-目标域的数据对，他们之间的联合分布存在不同程度的差异。2、每一个源域-目标域对应该处于相同的特征空间。3、第三，源和目标域应该包含对分类来说并不简单的正常和异常实例。</p>
<p>​    生成过程：为了生成目标域，从最大类(第二大类)采样正常目标实例(异常目标实例)，为了确保源域和目标域的分布差异，我们从目标域相同或不同类别来采样异常和正常样本来构造源域；follow了Emmott等人的程序来满足这个过程。</p>
<p><strong>时间序列数据集构建：</strong></p>
<p>​    有三个商店的三年的用水数据(单变量，采样间隔5分钟)，首先将每条时间序列按一小时间隔划分成时间窗口，通过特征提取，每个窗口提取出31维特征。由于每天的不同时间的用水量差异很大，所以对于相同的时间间隔，就将他们分成一个组(例如11：00-12：00)，这样每个商店就可以得到24个组，为每一个组训练一个异常检测器。</p>
<p>​    这样是不是相当于把每天内，用水量的时间依赖信息给切断了。</p>
<h4 id="2-Semi-supervised-Anomaly-Detection-with-an-Application-to-Water-Analytics"><a href="#2-Semi-supervised-Anomaly-Detection-with-an-Application-to-Water-Analytics" class="headerlink" title="2  -Semi-supervised Anomaly Detection with an Application to Water Analytics"></a>2  -Semi-supervised Anomaly Detection with an Application to Water Analytics</h4><p>Vincent Vercruyssen</p>
<p>2018 ICDM</p>
<p>提出了一种新的基于约束聚类的异常检测方法，该方法可在无监督和半监督环境下工作</p>
<p><strong>贡献：</strong></p>
<p>​    1、结合机器学习方法，以设计一种新的半监督的异常检测方法；</p>
<p>​            该方法首先基于无监督模型，该模型使用基于聚类的方法(COP-k means约束聚类，)来定义典型的正常行为并识别异常(主要工作是<strong>基于三个假设定义一个异常分数，此异常分数比原来的分数相比有改进</strong>)。我们的系统采用主动学习，因此领域专家可以以真实标签的形式向模型提供反馈(Incorporating expert feedback into active anomaly discovery 2016)。只要提供反馈，该方法就会以半监督的方式运行，并以两种方式利用标签。第一，标签用于以约束形式指导聚类。第二，通过标签传播的方式更新初始的基于聚类的异常评分，以最大化所获取的标签数据的有用性。</p>
<p>​    2、说明如何将我们的方法应用于用水案例；</p>
<p>​    3、一项实证研究表明，我们提出的方法优于现有的异常检测方法以及公司的基准方法</p>
<p>​    4、讨论了已部署的系统体系结构。</p>
<p>在本文的相关工作(related work)中，作者列举了参考的其他方法，包括无监督和半监督，并且在每种方法的最后都强调了下自己方法的不同—-无监督和半监督结合，基于聚类（参考了CBLOF，参数少，并且考虑了聚类中心）等等</p>
<p>划分窗口，特征构建：</p>
<p><strong>实验：</strong></p>
<p>​    数据集划分：</p>
<p>​        这里的数据集划分和上面这篇Transfer Learning for Anomaly Detection的方法是相同的，也是将每天相同的小时组成一个组，为了进行评估，将那些包含多于50个带标签窗口的组挑选出来进行试验。 </p>
<p>​    实验设置：</p>
<p>​        将每个组中带标签的窗口划分成训练集$D<em>{train}$和测试集$D</em>{test}$，将$D’<em>{train}$初始化为空集，逐渐增加$D’</em>{train}$中元素的数量直到等于$D<em>{train}$，用来验证专家标签数量逐步增加对于半监督方法性能的提升有多大。使用$D’</em>{train}$选择最好的参数，来在$D_{test}$中测试。</p>
<p><strong>已部署</strong></p>
<h4 id="3-Transfer-learning-for-time-series-anomaly-detection"><a href="#3-Transfer-learning-for-time-series-anomaly-detection" class="headerlink" title="3 -Transfer learning for time series anomaly detection"></a>3 -Transfer learning for time series anomaly detection</h4><p>Vincent Vercruyssen</p>
<p>2017 In CEUR Work- shop Proceedings</p>
<p>​    本文的算法尝试将源域中的带标签的数据迁移到目标域(没有标签)中，迁移的方法利用了异常是低频和不经常发生的观点来决定是否将实例进行迁移。一旦迁移完成，就在目标域中构建最近邻分类器，并将动态时间规整作为相似性度量。在一个真实数据集中进行实验，并发现他的效果超过了无监督的方法。</p>
<p>本文的方法：</p>
<p>​    4.1 基于两个性质，定义了每个源实例是否迁移的<strong>权重</strong>，而这个权重需要估计<strong>源实例</strong>在<strong>目标域</strong>的<strong>概率分布</strong></p>
<script type="math/tex; mode=display">
\hat{f}_T(x_S)</script><p>​    4.2 基于密度的迁移决策函数</p>
<p>​    本文的数据是基于单变量时间序列，每条序列长度固定，<strong>将每条序列看成是一个长度为 d 的向量</strong>，将这些向量进行迁移并进行异常检测。但由于随着向量维度的增加需要指数及增加的样本来进行密度估计，但这样是不现实的，所以为了精确的概率密度估计，将长度为d的向量分割成 $l$ 个等长度 m 的子向量，然后进行密度估计。得到每条子序列的密度估计</p>
<script type="math/tex; mode=display">
\hat{f}_{T,m}(s)</script><p>​    由于上面的调整，对于一条时间序列会得到$l$个密度估计值估计，所以需要调整权重的计算方式。计算出最终的权重之后，给权重设置一个阈值，来决定是否进行迁移。</p>
<p>​    4.3 基于聚类的迁移决策函数</p>
<p>​    首先对<strong>目标域</strong>进行聚类，将整个目标域划分成大集合和小集合两个集合，并定义每个聚类的半径。最后，还是基于上面的两个性质来决定是否将<strong>源域中</strong>的实例迁移到目标域中：对于一个正常标签的实例，如果被划分到目标域中的大集合；对于一个异常标签的实例，满足其中一个条件：这个实例被划分到小集合，或者被划分到大集合，但是该实例到聚类中心的距离大于聚类半径。</p>
<p>​    4.4 监督异常检测</p>
<p>​    迁移之后，进行有监督异常检测。我们忽略目标域中没有标签的实例，只使用有标签的实例，用这些带标签的实例，构建1NN(最近邻)-DTW(dynamic time warping)分类器。</p>
<p>贡献：</p>
<p>​    对于时间序列中基于实例的迁移学习收到很少的关注。本文提出的基于实例的迁移方法不需要目标域有任何的标签，</p>
<p>实验：</p>
<p>​    本文用到的无监督基线还是CBLOF(cluster based local outlier factor)这个算法。</p>
<p>​    对于数据集，用到的也是真实数据集(用水)，对于数据集的划分，也是同样的方法-由于每天的用水量差异很大，所以也是划分成24个窗口，得到24个数据集，每一个实例都是长度为1小时的时间序列。</p>
<p><img src="http://echo23334.gitee.io/pic_repo/%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20201110202315.png" alt="微信截图_20201110202315" style="zoom:60%;" /></p>
]]></content>
      <categories>
        <category>ssk</category>
      </categories>
      <tags>
        <tag>异常检测</tag>
        <tag>迁移学习</tag>
      </tags>
  </entry>
  <entry>
    <title>ssk Multisource Transfer Learning for Cross-Subject EEG Emotion Recognition</title>
    <url>/2021/01/20/ShaoShikuan/multisource%20transfer%20learning%20for%20cross-subject%20eeg%20emotion%20recognition/</url>
    <content><![CDATA[<p>[IEEE Transactions on Cybernetics 2019]</p>
<p>Jinpeng Li, Shuang Qiu, Yuan-Yuan Shen, Cheng-Lin Liu, Fellow, IEEE, and Huiguang He, Senior Member, IEEE</p>
<h4 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h4><p>​    脑电(EEG)信号，在情绪识别中得到广泛应用。由于脑电的个体差异较大，情感识别模型无法在个体间共享，需要收集新的标记数据来为新用户训练个人模型。在一些应用中，希望尽可能快地获得新的用户的模型，并减少对标记数据的需求，所以提出了一种以现有个体为源域，以新人为目标域的多源迁移(<strong>Multisource Transfer</strong>)的学习方法。</p>
<p>​    目标数据被分开用于训练的校准过程和随后的测试过程。该方法的第一阶段是源选择，目的是选择合适的源域。第二阶段是样式转换映射(style transfer mapping)，为了减少目标与各源之间的脑电信号差异。    最后在后续过程中整合<strong>源模型</strong>来识别情绪。</p>
<a id="more"></a>
<h4 id="贡献"><a href="#贡献" class="headerlink" title="贡献"></a>贡献</h4><p>​    提出了一种迁移学习(TL)方法来探索和利用现有个体的信息，以弥补目标训练数据的不足。该方法的目标是使目标域与源域在统计上相似，从而实现源模型的共享，和传统方法不同，这里有少量的标记数据可用。</p>
<p>​    如下图，已有多个个体和它们各自的分类器，对于一个新个体，在校准阶段选择合适的源并学习样式转化映射(style transfer mapping)，以减少目标和所选的每个源之间的差异。在随后的测试阶段通过STM进行样本映射，接着集成源域分类器来得到最终的情感标签。</p>
<p>​    在样式转换映射中探索了两种类型的映射终点(destination)设置。</p>
<p><img src="http://echo23334.gitee.io/pic_repo/%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20210116094954.png" alt="微信截图_20210116094954" style="zoom:75%;" /></p>
<h4 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h4><p><img src="http://echo23334.gitee.io/pic_repo/微信截图_20210116100240.png" alt="微信截图_20210116100240" style="zoom:75%;" /></p>
<h5 id="A-Source-Selection"><a href="#A-Source-Selection" class="headerlink" title="A. Source Selection"></a>A. Source Selection</h5><p>​        现有的研究表明，强行利用与目标域不相关的资源可能会降低迁移性能，被称为“负迁移”。为了避免负迁移，在迁移前选择合适的源。$\boldsymbol{A}<em>{L}^{T}$是一些来自校准阶段的标记数据，$\boldsymbol{A}</em>{U}^{T}$是后续阶段的无标签数据。</p>
<p>​        由于$\boldsymbol{A}<em>{L}^{T}$有标签信息，所以源选择就变得很直观。枚举源域中的N个分类器来对$\boldsymbol{A}</em>{L}^{T}$进行分类，选取精度最高的$N_S$个分类器。将其对应的数据作为相应的数据源域。</p>
<p>​        这背后的假设是$\boldsymbol{A}<em>{L}^{T}$和$\boldsymbol{A}</em>{U}^{T}$之间的差异不大，可以接受因为这两种数据属于同一实验的同一个体。</p>
<h5 id="B-Style-Transfer-Mapping"><a href="#B-Style-Transfer-Mapping" class="headerlink" title="B. Style Transfer Mapping"></a>B. Style Transfer Mapping</h5><p>​        在STM中，我们将$\boldsymbol{A}^{T}$ 映射到$\boldsymbol{A}^{S p}$来联结这两个分布，不直接将$\boldsymbol{A}^{T}$ 映射到$\boldsymbol{A}^{S p}$，而是寻找一些在$\boldsymbol{A}^{S p}$的表示模式(典型的聚类中心，类均值)，在这里称$\boldsymbol{A}^{S p}$为映射“destination”终点，$\boldsymbol{A}^{T}$为“origin” 起点。</p>
<p>​        终点的点集表示为</p>
<p>​                                                                                    $D=\left{d_{i} \in R^{m} \mid i=1, \ldots, n\right}$</p>
<p>​        STM起点的点集表示为</p>
<p>​                                                                                    $O=\left{o_{i} \in R^{m} \mid i=1, \ldots, n\right}$</p>
<p>​        从$d<em>{i}$ 到 $o</em>{i}$的改变称为概念漂移，假设$d<em>{i}$ 转换到 $o</em>{i}$有置信度$f<em>{i} \in[0,1]$，那么我们就可以学习一个反变换函数将$o</em>{i}$转换回$d<em>{i}$ ，$A o</em>{i}+b$。参数$A \in R^{m \times m}$和$b \in R^{m}$通过最小化带有正则化项的加权平方误差来避免过度迁移</p>
<p>​                                                            $\min <em>{A \in R^{m \times m}, b \in R^{m}}         \sum</em>{i=1}^{n} f<em>{i}\left|A o</em>{i}+b-d<em>{i}\right|</em>{2}^{2}+\beta|A-I|<em>{F}^{2}+\gamma|b|</em>{2}^{2} \space\space\space(3)$</p>
<p>​        上式是一个凸二次规划问题，它有一个封闭形式的解</p>
<p>​                                                                                    $A=Q P^{-1}, b=\frac{1}{\hat{f}}(\hat{d}-A \hat{o})$</p>
<p>其中</p>
<p>​                                                                                    $Q=\sum<em>{i=1}^{n} f</em>{i} d<em>{i} o</em>{i}^{T}-\frac{1}{\hat{f}} \hat{d} \hat{o}^{T}+\beta I$<br>​                                                                                    $P=\sum<em>{i=1}^{n} f</em>{i} o<em>{i} o</em>{i}^{T}-\frac{1}{\hat{f}} \hat{o} \hat{o}^{T}+\beta I$<br>​                                                                                     $\hat{o}=\sum<em>{i=1}^{n} f</em>{i} o<em>{i}, \hat{d}=\sum</em>{i=1}^{n} f<em>{i} d</em>{i}$<br>​                                                                                    $\hat{f}=\sum<em>{i=1}^{n} f</em>{i}+\gamma$</p>
<h5 id="C-Mapping-Origin-and-Destination"><a href="#C-Mapping-Origin-and-Destination" class="headerlink" title="C. Mapping Origin and Destination"></a>C. Mapping Origin and Destination</h5><p>​        映射的起点是$\boldsymbol{A}^{T}$，关键的任务是定义映射的终点$\boldsymbol{A}^{S p}$（也就是）。本文使用的分类器是SVM，在源域中训练好分类器之后，由于对于支持向量的分类难度很大，所以在训练好好之后将支持向量移除，即支持向量只参与推导决策边界，而不参与映射终点的推导。</p>
<p><img src="http://echo23334.gitee.io/pic_repo/微信截图_20210116211240.png" alt="微信截图_20210116211240" style="zoom:67%;" /></p>
<p>​        本文将探索在源域中派生映射终点的两种技术。</p>
<h6 id="1）聚类Nearest-Prototype-原型"><a href="#1）聚类Nearest-Prototype-原型" class="headerlink" title="1）聚类Nearest Prototype(原型)"></a>1）聚类Nearest Prototype(原型)</h6><p><img src="http://echo23334.gitee.io/pic_repo/微信截图_20210116211711.png" alt="微信截图_20210116211711" style="zoom:67%;" /></p>
<p>​        我们使用K-means聚类在每个类上来获取原型(代表性点)：</p>
<p>​                                                                $p<em>{i j} \in R^{m}, j=i, \ldots, n</em>{i}, i=1, \ldots, M$</p>
<p>​        其中$n_i$表示每个类别的原型数量，定义每个来自类别$i$的样本的最近原型如下所示：</p>
<p>​                                                            $N(x, i)=p<em>{i j},$ where $j=\arg \min </em>{j^{\prime}=1}^{n<em>{i}}\left|x-p</em>{i j^{\prime}}\right|_{2}^{2}$</p>
<p>​        目标域$\boldsymbol{A}^{T}$中的样本$x$的终点就定义为离其真实类(标记数据)或推导类(未标记数据)最近的原型</p>
<p>​                                                                            $D_{\text {proto }}(x, y)=N(x, y)$ </p>
<h6 id="2）Gaussian-Model"><a href="#2）Gaussian-Model" class="headerlink" title="2）Gaussian Model"></a>2）Gaussian Model</h6><p><img src="http://echo23334.gitee.io/pic_repo/微信截图_20210116211718.png" alt="微信截图_20210116211718" style="zoom:67%;" /></p>
<p>​        高斯模型假设条件密度是服从高斯分布的，上图展示了基于高斯模型的终点，其中均值是$\mu<em>i$，协方差矩阵是$\Sigma</em>{i}$，定义了$x$的映射模式在类别$i$上的马氏距离</p>
<p>​                                                                $P(x, i)=\mu_{i}+\min \left{1, \frac{\rho}{d(x, i)}\right}$</p>
<p>其中$d(x, i)=\sqrt{\left(x-\mu<em>{i}\right)^{T} \Sigma</em>{i}^{-1}\left(x-\mu<em>{i}\right)}$是类别$i$的马氏距离，在目标域$\boldsymbol{A}^{T}$样本的终点可以被定义为对真实类(标记数据)或推导类(未标记数据)的投影$D</em>{\text {gauss }}(x, y)=P(x, y)$。</p>
<h5 id="D-Confidence-Setup"><a href="#D-Confidence-Setup" class="headerlink" title="D. Confidence Setup"></a>D. Confidence Setup</h5><p>​        这里有两种策略来计算STM，（1）有监督的方法，在校准阶段只使用有标签数据$\boldsymbol{A}^{T}_L$，这是一种inductive的迁移方法。（2）半监督的方法使用$\boldsymbol{A}^{T}_L$和测试数据$\boldsymbol{A}^{T}_U$来学习STM，这是一种transductive的方法。</p>
<p>​        在有监督方法中就没有必要设置置信度了，或者说置信度设置为1，而在半监督方法中设置置信度就很重要了。对于$\boldsymbol{A}^{T}$中一个没有标签的数据，我们推导它的标签，并在相应的类中找到映射终点。标签推测不是绝对可靠的。如果推断的标签是错误的，STM将把数据映射到一个错误的类。因此，我们用一个置信度值标记每个转换，出现在公式(3)的第一项中。样本的置信度越高，对STM计算的影响越大，反之亦然。置信度的设置在这里就不再展开。</p>
<h4 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h4><p>​        本文使用的数据集为<strong>SEED</strong>数据集，一个用于通过观看电影片段后的感情变化来进行情感分类数据集。</p>
<h5 id="源域数量评估"><a href="#源域数量评估" class="headerlink" title="源域数量评估"></a>源域数量评估</h5><p><img src="http://echo23334.gitee.io/pic_repo/微信截图_20210117111319.png" alt="微信截图_20210117111319" style="zoom:67%;" /></p>
<h5 id="使用一个统一的源来进行迁移"><a href="#使用一个统一的源来进行迁移" class="headerlink" title="使用一个统一的源来进行迁移"></a>使用一个统一的源来进行迁移</h5><p>​        STM与多源框架相关联，其中每个个体都被视为一个独立的源。我们可以将所有可用的受试者的数据合并为一个统一的源域。我们比较了多源方法和统一源方法的精度。</p>
<p><img src="http://echo23334.gitee.io/pic_repo/微信截图_20210117111732.png" alt="微信截图_20210117111732" style="zoom:67%;" /></p>
<h5 id="置信度评估"><a href="#置信度评估" class="headerlink" title="置信度评估"></a>置信度评估</h5><p><img src="http://echo23334.gitee.io/pic_repo/微信截图_20210117113501.png" alt="微信截图_20210117113501" style="zoom:67%;" /></p>
<p>​        评估了本文提出的置信度设置方法和之前的两种置信度设置方法之间的效果。</p>
<h5 id="个体表现"><a href="#个体表现" class="headerlink" title="个体表现"></a>个体表现</h5><p>​                                    <img src="http://echo23334.gitee.io/pic_repo/微信截图_20210117113702.png" alt="微信截图_20210117113702" style="zoom:67%;" /></p>
]]></content>
      <categories>
        <category>ssk</category>
      </categories>
      <tags>
        <tag>EEG</tag>
        <tag>迁移学习</tag>
      </tags>
  </entry>
  <entry>
    <title>wxh【CIKM-2021】AdaRNN--Adaptive Learning and Forecasting of Time Series</title>
    <url>/2022/04/13/WangXuehui/AdaRNN%20Adaptive%20Learning%20and%20Forecasting%20of%20Time%20Series%E3%80%90CIKM%202021%E3%80%91/</url>
    <content><![CDATA[<h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h3><p>时间序列预测在日常生活中有着广泛的应用，并且是一个有挑战的任务，因为<strong>时间序列的性质会随时间变化</strong>，这被称为<strong>分布偏移（distribution shift）</strong>。</p>
<p>本文提出了时间序列的<strong>时序协方差漂移问题(Temporal Covariate Shift, TCS)</strong>，进而提出了<strong>AdaRNN方法</strong>解决了此问题。AdaRNN主要由两个部件组成，第一个组件用于<strong>刻画时间序列中的分布信息</strong>，第二个组件用于<strong>减少分布的错误匹配</strong>并学习一种基于rnn的自适应时间序列预测模型。AdaRNN是一个集成了多种灵活分布距离的通用框架。</p>
<p>在<strong>分类和回归问题</strong>上比对比方法提高2.6%和9.0%的精度(RMSE)。另外，AdaRNN可以被简单地扩展到<strong>Transformer</strong>框架下，同样能够提高其表现。</p>
<a id="more"></a>
<h3 id="资源链接"><a href="#资源链接" class="headerlink" title="资源链接"></a>资源链接</h3><p>论文地址：<a href="https://arxiv.org/abs/2108.04443">https://arxiv.org/abs/2108.04443</a></p>
<p>代码链接：<a href="https://github.com/jindongwang/transferlearning/tree/master/code/deep/adarnn">https://github.com/jindongwang/transferlearning/tree/master/code/deep/adarnn</a></p>
<p>知乎讲解：<a href="https://zhuanlan.zhihu.com/p/398036372">https://zhuanlan.zhihu.com/p/398036372</a></p>
<p>视频讲解：<a href="https://www.bilibili.com/video/BV1Gh411B7rj/">https://www.bilibili.com/video/BV1Gh411B7rj/</a></p>
<h3 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h3><h4 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h4><p>时间序列 (Time Series)在日常生活中有着广泛的应用，例如，天气预测、健康数据分析，以及交通情况预测等实际问题均需要对时间序列进行建模。所谓时间序列，指的是按照时间、空间或其他定义好的顺序形成的一条序列数据。由于时间的连续性，不难想像，<strong>时间序列数据会随着时间动态变化</strong>。特别地，时间序列的一些统计信息 (例如均值、方差等)会随着时间动态变化。统计学通常将此类时间序列称为<em>非平稳时间序列 (Non-stationary Time Series)</em>。为解决此问题，传统方法通常基于<strong>马尔可夫假设</strong>来进行建模，即<strong>时间序列上的每个观测仅依赖于它的前一时刻的观测</strong>。依据此假设，隐马尔可夫模型、动态贝叶斯网络、卡尔曼滤波法以及其他统计模型如自回归移动平均模型 (Autoregressive Integrated Moving Average Model, ARIMA)发挥了重要作用。最近几年随着深度学习的兴起，基于<strong>循环神经网络</strong> (Recurrent Neural Networks, RNNs)的方法取得了比之前这些方法更好的效果。与其相比，循环神经网络对时间序列的时间规律不做显式的假设，依靠强大的神经网络，RNN能自动发现并建模序列中高阶非线性的关系，并且能实现长时间的预测。因此，RNN系列方法在解决时间序列建模上十分有效。</p>
<h4 id="时序协方差漂移问题-TCS"><a href="#时序协方差漂移问题-TCS" class="headerlink" title="时序协方差漂移问题(TCS)"></a>时序协方差漂移问题(TCS)</h4><p>==即：在前一段分布学习到的模式迁移到新一种分布上效果变差==</p>
<p>Temporal Covariate Shift，也可以叫时序协变量漂移（偏移），认为时间序列可以依据分布被切分成多个不同的段，并且在进行时间序列预测时前面的分布可见，但后面的分布不可见。</p>
<p><img src="https://pic4.zhimg.com/v2-03136c4f518a105547ba70b617d1cabb_r.jpg" alt="preview"></p>
<p>时序协方差定义和协方差漂移（Covariate Shift）类似，边缘概率分布不同，条件概率分布相同</p>
<p>协方差漂移是train和test区别，这里是每一段时间序列（上图A、B、C等）之间的区别</p>
<h4 id=""><a href="#" class="headerlink" title=""></a><img src="https://flyingimage.oss-cn-beijing.aliyuncs.com/image-20220413140853278.png" alt="image-20220413140853278"></h4><p>RNN在面对未知的数据分布时，其很可能会发生<strong>模型漂移 (Model shift)现象（出现未见过的分布）</strong></p>
<ol>
<li>时间序列的数据分布具有连续性。由于其每个时刻的数据分布都在改变，因此我们需要找到一种方法将连续的分布差异变成<strong>离散的、可计算的分布差异</strong>，最大限度地利用这些不同分布中的公共知识</li>
<li>开发一个基于RNN的分布匹配算法在捕获时间依赖性的同时，<strong>最大限度地减少它们的分布发散</strong></li>
</ol>
<h4 id="贡献"><a href="#贡献" class="headerlink" title="贡献"></a>贡献</h4><p>1) <strong>提出新问题：时序协方差漂移</strong><br>2) <strong>提出通用框架：AdaRNN来解决该问题</strong>（提出划分不同分布的方法，以及利用RNN的隐层更细粒度地缩小域间差异）<br>3) <strong>有效性：SOTA于分类和多个回归任务</strong></p>
<h3 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h3><p><strong>时间序列相关：</strong></p>
<p>CNN，RNN，LSTM等</p>
<p><strong>分布匹配（迁移学习相关）：</strong></p>
<p><strong>写者注：我觉得不用太纠结下面这段，这篇文章的思想还是偏DG的，下面似乎是在说CV的迁移学习</strong></p>
<p>本文的研究与域自适应（DA）和域泛化（DG）有区别，因为：</p>
<p>DA和DG并不用于时间分布的表征，因为域在它们的问题中是预先给定的</p>
<p>DA和DG在分类任务上通常用CNN而不是RNN，</p>
<h3 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h3><p><img src="https://flyingimage.oss-cn-beijing.aliyuncs.com/image-20220413140908561.png" alt="image-20220413140908561"></p>
<h4 id="总述"><a href="#总述" class="headerlink" title="总述"></a>总述</h4><p>分为两步：</p>
<h5 id="时序相似性量化-Temporal-Distribution-Characterization-TDC-（黄色）"><a href="#时序相似性量化-Temporal-Distribution-Characterization-TDC-（黄色）" class="headerlink" title="时序相似性量化 (Temporal Distribution Characterization, TDC)（黄色）"></a><strong>时序相似性量化 (Temporal Distribution Characterization, TDC)</strong>（黄色）</h5><p>将时间序列中连续的数据分布情形进行量化，以将其分为 <img src="https://www.zhihu.com/equation?tex=K" alt="[公式]"> 段分布<em>最不相似</em>的序列。其假设是如果模型能够将此 <img src="https://www.zhihu.com/equation?tex=K" alt="[公式]"> 段最不相似的序列的分布差异减小，则模型将具有最强的泛化能力。因此对于未知的数据预测效果会更好。</p>
<h5 id="时序分布匹配-Temporal-Distribution-Matching-TDM-（绿色）"><a href="#时序分布匹配-Temporal-Distribution-Matching-TDM-（绿色）" class="headerlink" title="时序分布匹配 (Temporal Distribution Matching, TDM)（绿色）"></a><strong>时序分布匹配 (Temporal Distribution Matching, TDM)</strong>（绿色）</h5><p>为上述 <img src="https://www.zhihu.com/equation?tex=K" alt="[公式]"> 段时间序列构建迁移学习模型以学习一个具有时序不变性的模型。</p>
<h4 id="时序相似性量化TDC"><a href="#时序相似性量化TDC" class="headerlink" title="时序相似性量化TDC"></a>时序相似性量化TDC</h4><p>为将时间序列切分为 <img src="https://www.zhihu.com/equation?tex=K" alt="[公式]"> 段最不相似的序列(对应于正式中的求最大值操作、同时使得 <img src="https://www.zhihu.com/equation?tex=K" alt="[公式]"> 最小)，时序相似性量化方法将此问题表征为一优化问题：</p>
<p><img src="https://flyingimage.oss-cn-beijing.aliyuncs.com/image-20220413140919380.png" alt="image-20220413140919380"></p>
<p>其中 <img src="https://www.zhihu.com/equation?tex=d" alt="[公式]"> 是相似度度量函数， <img src="https://www.zhihu.com/equation?tex=%5CDelta_1%2C+%5CDelta_2" alt="[公式]"> 和 <img src="https://www.zhihu.com/equation?tex=K_0" alt="[公式]"> 是为了避免无意义的解而预先定义好的参数。上述优化问题可以用动态规划算法 (Dynamic Programming)进行高效求解。</p>
<p>==<strong>尽可能使切分的每段分布差异最大化，使得分布的多样性尽可能大，从而增强模型学习后的泛化性能。</strong>==</p>
<p>这个操作类似聚类，但是不同的是聚类是点对点的度量，这里是对分布进行度量。</p>
<p>由于动态规划处理量过于庞大，使用<strong>贪婪算法</strong></p>
<p>具体来说,高效计算和避免琐碎的解决方案,我们平均时间序列分割成𝑁个（<em>N</em>=10）部分,其中每一部分是最小单位时间内不能分裂了。然后随机搜索{2,3,5,7,10}中𝐾的值。给定𝐾，我们根据贪婪策略选择长度为𝑛𝑗的时间段。分别用𝐴和𝐵表示时间序列的起点和终点。我们首先考虑𝐾= 2，通过最大化分布距离𝑑(𝑆𝐴𝐶，𝑆𝐶𝐵)，从9个候选拆分点中选取1个拆分点(记为𝐶)。确定𝐶后，我们考虑𝐾= 3，并使用相同的策略选择另一个点𝐷。类似的策略应用于𝐾的不同值。实验表明，<strong>该算法比随机分割算法能更好地选择合适的分割周期</strong>。</p>
<h4 id="时序分布匹配TDM"><a href="#时序分布匹配TDM" class="headerlink" title="时序分布匹配TDM"></a>时序分布匹配TDM</h4><h5 id="基于以上切分的普通域泛化："><a href="#基于以上切分的普通域泛化：" class="headerlink" title="基于以上切分的普通域泛化："></a>基于以上切分的普通域泛化：</h5><p>给定两个loss，一个是分类loss，一个是域差异D，使其尽可能最小化。</p>
<p><img src="https://flyingimage.oss-cn-beijing.aliyuncs.com/image-20220413140935670.png" alt="image-20220413140935670"></p>
<p>但是这样没有利用到RNN里每个 hidden state，所以本文提出了利用隐层的方法。</p>
<h5 id="进一步利用RNN里每个hidden-state的信息（更细粒度的域泛化）："><a href="#进一步利用RNN里每个hidden-state的信息（更细粒度的域泛化）：" class="headerlink" title="进一步利用RNN里每个hidden state的信息（更细粒度的域泛化）："></a>进一步利用RNN里每个hidden state的信息（更细粒度的域泛化）：</h5><p>RNN里每个hidden state对差异的贡献度不同，需要进行hidden state级细粒度的加权，筛选对分布差异最有影响的hidden state。</p>
<p>==<strong>将两个分布对齐，每个hidden state加入一个权重α（i，j，t三个变量来唯一标识一个α），在计算域差异损失的时候乘上对应的α</strong>==</p>
<p><img src="https://flyingimage.oss-cn-beijing.aliyuncs.com/image-20220413140950099.png" alt="image-20220413140950099"></p>
<h5 id="在所有分布上预训练获取更好的隐层表示"><a href="#在所有分布上预训练获取更好的隐层表示" class="headerlink" title="在所有分布上预训练获取更好的隐层表示"></a>在所有分布上预训练获取更好的隐层表示</h5><p>为了学习α学的更好</p>
<h5 id="基于boosting的方式调节α"><a href="#基于boosting的方式调节α" class="headerlink" title="基于boosting的方式调节α"></a>基于boosting的方式调节α</h5><p>RNN同一层的α初始化为1/V （V是hidden state 个数）</p>
<p>哪个α要分的更大呢？当它对应的两个分布在该hidden state算出的距离比上一个hidden state大的时候，对a进行一个增加。否则不变。（选用距离来作为boosting的indicator）</p>
<p><img src="https://flyingimage.oss-cn-beijing.aliyuncs.com/image-20220413141001239.png" alt="image-20220413141001239"></p>
<p>G是增加的系数的计算方式，计算一个大于1的数乘到当前α上。</p>
<h3 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h3><h4 id="性能实验"><a href="#性能实验" class="headerlink" title="性能实验"></a>性能实验</h4><p>四个数据集上测试，一个分类任务，三个回归任务。</p>
<p>在人类活动识别、空气质量预测、家庭用电和财务分析方面的实验表明，AdaRNN在分类任务上的准确率比一些最先进的方法高出2.6%，在回归任务上的均方误差高出9.0%。</p>
<p><strong>分类任务上（行为识别）：</strong></p>
<p><img src="https://flyingimage.oss-cn-beijing.aliyuncs.com/image-20220413141010819.png" alt="image-20220413141010819"></p>
<p><strong>回归任务上：</strong></p>
<p>（总共有3个，分别是空气质量预测、用电量预测和股价预测，下图给出的是空气质量预测）</p>
<p><img src="https://flyingimage.oss-cn-beijing.aliyuncs.com/image-20220413141019742.png" alt="image-20220413141019742"></p>
<h4 id="分析性实验"><a href="#分析性实验" class="headerlink" title="分析性实验"></a>分析性实验</h4><p>做了非常多的实验，这里选几个重点说。</p>
<h5 id="证明不同场景下最优的分割段数不同，并且本文提出的分割算法有效"><a href="#证明不同场景下最优的分割段数不同，并且本文提出的分割算法有效" class="headerlink" title="证明不同场景下最优的分割段数不同，并且本文提出的分割算法有效"></a>证明不同场景下最优的分割段数不同，并且本文提出的分割算法有效</h5><p><img src="https://flyingimage.oss-cn-beijing.aliyuncs.com/image-20220413141029275.png" alt="image-20220413141029275"></p>
<p>左：蓝色黄色两个场景下最适合的分割段分别为3和5，说明不同场景下最优的分割段数不同</p>
<p>右：第一个是随机分割，第二个是认为所有段概率分布相同，最后一个是用本文的分割算法，可以看到距离分出来是最大的（区域间差异性最强），并且最后的结果最优。</p>
<h5 id="证明预训练和boosting方法有效，细粒度考虑hidden-state是有必要的，并且本文方法与选用的距离计算函数无关"><a href="#证明预训练和boosting方法有效，细粒度考虑hidden-state是有必要的，并且本文方法与选用的距离计算函数无关" class="headerlink" title="证明预训练和boosting方法有效，细粒度考虑hidden state是有必要的，并且本文方法与选用的距离计算函数无关"></a>证明预训练和boosting方法有效，细粒度考虑hidden state是有必要的，并且本文方法与选用的距离计算函数无关</h5><p><img src="C:\Users\30331\AppData\Roaming\Typora\typora-user-images\image-20220413141039442.png" alt="image-20220413141039442"></p>
<p>左图：证明预训练和boosting是有效的。（naive是非boosting的另一种方法，可以认为是没有α，不再详细介绍，文中的remark2部分有说。）</p>
<p>右图：体现有α可以使得选用的距离计算函数无关，并且α可以提升效果，说明在RNN里考虑每个hidden state的权重必要性。</p>
<h4 id="可扩展为transformer"><a href="#可扩展为transformer" class="headerlink" title="可扩展为transformer"></a>可扩展为transformer</h4><p>我们还展示了时间分布匹配模块可以扩展到Transformer架构，以进一步提高其性能。</p>
<p>只做了简单的小实验，没有进行详细调参。</p>
<p>transformer也可以去做对齐。</p>
<p><img src="https://flyingimage.oss-cn-beijing.aliyuncs.com/image-20220413141112061.png" alt="image-20220413141112061"></p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>提出了一个基于分布变化的新颖问题（类似于跨session，但不是人工标记的session，是根据分布区分的，并且由算法自动寻找最优切分），并且采用了分布切分+减小差异两步方案解决这个问题。</p>
<p>这个工作可以被<strong>迁移和扩展</strong>。</p>
<p>比如第一阶段类似聚类的划分操作能不能有更好的深度学习方法实现。</p>
<p>或者后续工作可以直接套它第一阶段的贪心算法分割，对后面对齐的操作进行改进。</p>
<p>由于时序的连续性，本文强制采用了一种硬切分进行分割，边缘肯定存在难以区别的问题，或许可以提出一种软切分，让一个点可以归于两个或多个切分段</p>
<h2 id="不太理解的"><a href="#不太理解的" class="headerlink" title="不太理解的"></a>不太理解的</h2><p>文中说：“现有的迁移方法均为基于卷积神经网络的分类问题而设计，也无法直接用于RNN模型。”是不是有点过了</p>
<h2 id="后续问题"><a href="#后续问题" class="headerlink" title="后续问题"></a>后续问题</h2><p>根据分布切分是否最好，比如睡眠里依据波形切分是否更好，用分布可能会把某些重要波形切掉，可能这种切分还是依据任务而定，当然用分布切分更通用。</p>
<p>协方差偏移的协方差确定是指x而不是某些变量间的吗。</p>
<h2 id="补充材料"><a href="#补充材料" class="headerlink" title="补充材料"></a>补充材料</h2><h3 id="协变量偏移"><a href="#协变量偏移" class="headerlink" title="协变量偏移"></a>协变量偏移</h3><p>源域和目标域的边缘概率分布是不同的，而条件概率分布是相同的</p>
<p><a href="https://blog.csdn.net/qq_41076797/article/details/117153783">https://blog.csdn.net/qq_41076797/article/details/117153783</a></p>
<p><a href="https://blog.csdn.net/mao_xiao_feng/article/details/54317852">https://blog.csdn.net/mao_xiao_feng/article/details/54317852</a></p>
<p>会出现不符合机器学习假设训练集和测试集是独立同分布（I.I.D）的情况</p>
<h3 id="模型漂移"><a href="#模型漂移" class="headerlink" title="模型漂移"></a>模型漂移</h3><p>模型漂移指的是旧的模型随着时间的改变，在最新特征下模型的效果会越来越差。模型漂移具体分为两类：concept drift和data drift。concept drift指的是label的分布或定义发生了变化，data drift表示特征的分布发生了变化。</p>
<p><a href="https://zhuanlan.zhihu.com/p/351493222">https://zhuanlan.zhihu.com/p/351493222</a></p>
]]></content>
      <categories>
        <category>wxh</category>
      </categories>
      <tags>
        <tag>时序预测</tag>
      </tags>
  </entry>
  <entry>
    <title>syd 【AAAI 2021】Maximum Roaming Multi-Task Learning</title>
    <url>/2021/03/17/SongYudan/%E3%80%90AAAI2021%E3%80%91Maximum%20Roaming%20Multi-Task%20Learning/</url>
    <content><![CDATA[<p>关键词：多任务学习</p>
<h3 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h3><p>多任务参数<strong>联合优化</strong>是MTL中一个活跃的研究问题，对不同任务的参数进行<strong>划分</strong>（不相交或有重叠），可以放宽共享权值的优化约束，但是这种方法会<strong>削弱</strong>多任务产生的inductive bias（MTL的思想）。本文提出了新的划分参数空间的方法（Maximum Roaming），且不会削弱inductive bias。该方法受dropout启发，<strong>随机</strong>改变参数分区，迫使参数在规定的频率下尽可能<strong>多</strong>地查看任务，使网络全面适应每次更新。实验表明，与普通的分区优化策略相比，roaming带来的正则化对性能的影响更大，且整体方法灵活、易于应用。</p>
<a id="more"></a>
<p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/image-20210314121704175.png" alt="image-20210314121704175"></p>
<h3 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h3><p>MTL旨在通过共同学习多个任务，提高<strong>泛化</strong>性；利用不同任务的训练信号中所包含的多个领域特定信息，作为<strong>inductive bias</strong>，起<strong>正则器</strong>的作用。但是针对多个任务优化同一批参数，可能出现某一任务的提升会导致其他任务性能的下降，即<strong>任务干扰</strong>；不同任务所需要的表示具有<strong>特异性</strong>。</p>
<p>已有方法：用task-sepcific参数扩大网络，给任务以更大的专业化空间；采用架构适配以适应特定的任务集。但是这些方法都没有解决<strong>共享部分的任务干扰</strong>，也不能很好地随任务数量扩展。也可以通过构造特定任务参数划分，参数被更少的任务限制，这会削弱inductive bias。</p>
<p>本文提出<strong>动态划分策略</strong>——Maximum Roaming方法，控制任务干扰的前提下，产生inductive bias。该方法受dropout思想启发，参数可以在几个特定任务的子网中roam（漫游），从maximum的任务中进行学习，建立更鲁棒的表示；且该方法不是寻找一个最优的划分，而是连续的随机划分、<strong>随机给任务分配参数</strong>，允许它们从每个任务中学习，实验证明了该方法相较于SOTA的提升。</p>
<h3 id="2-Related-work"><a href="#2-Related-work" class="headerlink" title="2. Related work"></a>2. Related work</h3><p>解决任务干扰引发的问题的三个方法：</p>
<p><strong>loss加权</strong>：在优化目标中通过加权来平衡不同任务的loss，但是这些方法并不旨在<strong>解决</strong>任务干扰，只是调整每个任务在总目标中所占量级的大小。Maximum Roaming方法是明确地控制任务干扰。</p>
<p><strong>多目标优化</strong>：把MTL转化为多目标优化问题。一些现有方法使得参数最后到达一个帕累托最优状态，即不存在参数更新方向，使得某一任务性能提升且不损害其他任务性能；但是强烈的任务干扰会导致<strong>参数停滞</strong>。</p>
<p><strong>参数划分</strong>：将注意力机制用于卷积filter级别，使得每个<strong>任务</strong>在每一<strong>层</strong>选择其需要的参数<strong>子集</strong>，选择范围越大，使用给定参数的任务就越少，减少任务干扰。但是已有的方法会<strong>削弱</strong>inductive bias，不考虑每个任务对每个参数学习过程的贡献，而我们的方法使得每个参数有序地从每个任务中进行学习。</p>
<h3 id="3-Preliminaries"><a href="#3-Preliminaries" class="headerlink" title="3. Preliminaries"></a>3. Preliminaries</h3><p>定义训练集：</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/image-20210315105551576.png" alt="image-20210315105551576" style="zoom:67%;" /></p>
<p>$T$是任务个数，$N$是数据个数，用标准的深度为$D$的共享卷积网络学习$T$个任务，并在预测层对每个任务$t$都有输出，卷积核为要学习的参数，第$d$层网络的参数量记为$S^{(d)}$，用$S_{max}$代表$d$层中参数的最大值。</p>
<p>标准的MTL共享所有参数，任务$t$第$d$层的输出为：</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/image-20210315110527668.png" alt="image-20210315110527668" style="zoom:67%;" /></p>
<p>$H$为隐藏层输入，$K^{(d)}$是第$d$层的卷积核。</p>
<h4 id="3-1-参数划分"><a href="#3-1-参数划分" class="headerlink" title="3.1 参数划分"></a>3.1 参数划分</h4><p>二元参数划分矩阵：</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/image-20210315111601592.png" alt="image-20210315111601592" style="zoom:67%;" /></p>
<p>$m_t^{(d)}$是$d$层与任务$t$相关的列向量，用以下操作可以为每一个任务$t$选择一个参数子集：</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/image-20210315112647638.png" alt="image-20210315112647638" style="zoom:67%;" /></p>
<p>隐输入也取决于任务：每个任务有<strong>独立</strong>的forward pass，反向传播与特定任务相关的loss，每个参数会收到使用该参数的任务传回的梯度信息。</p>
<h4 id="3-2-参数划分初始化"><a href="#3-2-参数划分初始化" class="headerlink" title="3.2 参数划分初始化"></a>3.2 参数划分初始化</h4><p>划分矩阵中的参数都满足参数为$p$的伯努利分布：</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/image-20210315113735399.png" alt="image-20210315113735399" style="zoom:67%;" /></p>
<p>$p$控制<strong>共享率</strong>（每一层都相同），各任务参数的重叠率，如某个参数从不同任务收到的梯度信息的数量。这个数目越小，有冲突信息的概率就越低，可以减少任务干扰，简化优化问题。同时也削弱了inductive bias，影响MTL效果。</p>
<p>保证网络容量，对参数加以限制：</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/image-20210315115830436.png" alt="image-20210315115830436" style="zoom:67%;" /></p>
<p>=1，即$p=0$，不相交参数划分；=$T$，即$p=1$，完全共享网络。</p>
<blockquote>
<p><strong>dropout</strong>思想：使参数在不同的<strong>随机</strong>抽样的<strong>子网</strong>中连续学习有效表示。</p>
</blockquote>
<p>通过规律地<strong>更新</strong>参数划分<strong>矩阵</strong>，使参数依次从每个任务中进行<strong>学习</strong>，即在任务中roam，有序建立inductive bias。这就是Maximum Roaming MTL，包括两个核心要点：1）参数划分矩阵的更新策略；2）更新划分矩阵时如何选择要更新的参数</p>
<h3 id="4-Maximum-Roaming-Multi-Task-Learning"><a href="#4-Maximum-Roaming-Multi-Task-Learning" class="headerlink" title="4. Maximum Roaming Multi-Task Learning"></a>4. Maximum Roaming Multi-Task Learning</h3><p>介绍本方法的核心内容</p>
<blockquote>
<p>假设1：同时优化不同任务的参数可以得到inductive bias，也可以通过对不同任务子集的<strong>顺序优化</strong>得到。</p>
</blockquote>
<p>根据假设1，划分矩阵可以<strong>随时间</strong>演化，用3中的方法初始化，经过每一步$c$，矩阵的值就会<strong>更新</strong>，在满足约束的前提下，参数可以在不同的任务间roam。</p>
<blockquote>
<p>定义1：$A_t(c)$是任务$t$在第$c$步的参数目录，把$c$步之前的参数并集得到$B_t(c)$，即到$c$步时任务$t$访问过的参数集合，到$c+1$步时，划分矩阵按照以下规则更新：</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/image-20210315142113901.png" alt="image-20210315142113901" style="zoom:80%;" /></p>
</blockquote>
<p>$\Delta$控制矩阵更新<strong>频率</strong>，一般比较大（网络可以在一个设定下<strong>充分</strong>学习，如果更新太频繁，会导致更大的任务干扰），$c=E/\Delta$，$E$代表训练轮数，在每$\Delta$轮中用相同的参数划分进行训练，每次更新一个参数。</p>
<blockquote>
<p>引理1：更新频率$\Delta$有以下属性：</p>
<ol>
<li>更新会在$\Delta(1-p)S_{max}$训练步内完成</li>
<li>更新完成时，每个参数至少被每个任务训练了$\Delta$轮</li>
<li>在整个更新过程中，隶属于每个任务的参数量是不变的（不同任务参数划分之间的重叠保持不变，<strong>控制任务干扰</strong>）</li>
</ol>
</blockquote>
<p>证明：1）$B_t(c)$初始化为$pS$，每$\Delta$轮增加1</p>
<p>经过$c$步后，每个参数$i$被任务$t$使用的概率是：</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/image-20210316144413690.png" alt="image-20210316144413690" style="zoom:67%;" /></p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/image-20210316144443632.png" alt="image-20210316144443632" style="zoom:67%;" /></p>
<p>$r(c)$是更新进度。此式说明，随着不断的更新，<strong>概率会增加、最大化</strong>，与该参数相关的任务数量也会增加，由此学到inductive bias。</p>
<p>综上所述，在控制任务干扰的前提下学到inductive bias。</p>
<h3 id="5-Experiments"><a href="#5-Experiments" class="headerlink" title="5. Experiments"></a>5. Experiments</h3><h4 id="5-1-数据集"><a href="#5-1-数据集" class="headerlink" title="5.1 数据集"></a>5.1 数据集</h4><p><strong>Celeb-A：</strong>超过200k张名人图片，40种不同的面部属性，将40个属性划分为<strong>8</strong>组，每组创建一个属性预测任务，简化计算。</p>
<p><strong>CityScapes：</strong>5000张街景图像，有像素级标注。7个语义分割、1个深度估计，共<strong>8</strong>个任务。</p>
<p><strong>NYUv2</strong>：1449张室内图片，包含464种不同的场景。13个语义分割、深度估计、表面法线估计，共<strong>15</strong>个任务。</p>
<h4 id="5-2-baselines"><a href="#5-2-baselines" class="headerlink" title="5.2 baselines"></a>5.2 baselines</h4><ul>
<li>MTL 标准完全共享网络，各任务权重相同</li>
<li>GradNorm 完全共享网络，各任务权重可学习</li>
<li>MGDA-UB 完全共享网络，将MTL看作多目标优化问题</li>
<li>SE-MTL 参数划分方法，有可训练实值掩码</li>
<li>STL 单任务模型，每个任务一个模型</li>
</ul>
<h4 id="5-3-面部属性检测实验"><a href="#5-3-面部属性检测实验" class="headerlink" title="5.3 面部属性检测实验"></a>5.3 面部属性检测实验</h4><p>采用ResNet-18作为骨干网络</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/image-20210315163905359.png" alt="image-20210315163905359"></p>
<p><strong>Roaming的影响</strong>：研究参数roaming对MTL性能的影响。图1左给出了Max Roaming方法与固定分区方法F-scores（更新全部完成时）随共享率$p$的变化。与固定分区相比，Max Roaming可以提升性能。</p>
<p><strong>$\Delta$和更新进度$r(c)$的影响：</strong>$p$设为0.5，图1中给出了结果，当$\Delta$大于0.05时，$\Delta$越大，F-scores越大，所以$\Delta$不能过小；随着更新进行，F-scores增加。</p>
<p><strong>随机选择的影响：</strong>更新时如何选择要更新的参数？MR是随机选择，从$i<em>-$、$i</em>+$所属的集合的均匀分布中选择。另外设计了一种<strong>确定性更新方法</strong>——根据最小化平均余弦相似度，选择最有可能为任务提供额外信息的参数，丢弃冗余参数。原则如下：</p>
<p><img src="C:\Users\Meow\AppData\Roaming\Typora\typora-user-images\image-20210316154859336.png" alt="image-20210316154859336" style="zoom:67%;" /></p>
<p>$K$是各参数的卷积核，图1右给出了确定性选择参数vs随机选择参数的F-scores，在更新初期表现差不多，随着更新的进行，MR方法优于确定选择方法。</p>
<p>表1给出了MR与其他baselines的总体比较。</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/image-20210316155919158.png" alt="image-20210316155919158" style="zoom:80%;" /></p>
<h4 id="5-3-场景理解"><a href="#5-3-场景理解" class="headerlink" title="5.3 场景理解"></a>5.3 场景理解</h4><p>MR在另外两个数据集上的应用，表2-4给出了结果。</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/image-20210315165621540.png" alt="image-20210315165621540" style="zoom: 67%;" /></p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/image-20210315165634470.png" alt="image-20210315165634470" style="zoom: 67%;" /></p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/image-20210315165737427.png" alt="image-20210315165737427" style="zoom:67%;" /></p>
<p><strong>MR方法在语义分割、法线估计任务种表现最好，在深度估计中排第二。</strong>因为MR方法保留了inductive bias，可以提升比较<strong>相似</strong>的任务的性能（也就是分割任务）。与单任务相比，MTL随着任务数量增多性能可能会下降，可能不如单任务模型。</p>
<h3 id="6-Conclusion"><a href="#6-Conclusion" class="headerlink" title="6. Conclusion"></a>6. Conclusion</h3><p>提出了Maximum Roaming——动态参数划分方法，以减少任务干扰，同时充分利用多任务带来的inductive bias，该方法使参数能够连续从尽可能多的任务中学习。与其他分区方法相比，更快，无需额外参数。实验将MR应用于卷积网络，实现了性能的提升。</p>
<hr>
<p>code link：<a href="https://github.com/lucaspascal/Maximum-Roaming-Mutli-Task-Learning">https://github.com/lucaspascal/Maximum-Roaming-Mutli-Task-Learning</a>.</p>
]]></content>
      <categories>
        <category>syd</category>
      </categories>
      <tags>
        <tag>多任务学习</tag>
      </tags>
  </entry>
  <entry>
    <title>syd 【CVPR2019】Multi-task learning</title>
    <url>/2021/01/07/SongYudan/%E3%80%90CVPR%202019%E3%80%91End-To-End%20Multi-Task%20Learning%20With%20Attention/</url>
    <content><![CDATA[<h4 id="定义"><a href="#定义" class="headerlink" title="定义"></a><strong>定义</strong></h4><p>Multitask Learning is an approach to inductive transfer that improves learning for one task by using the information contained in the training signals of other related tasks.</p>
<p>多任务学习是一种<strong>归纳迁移</strong>的方法，它通过利用<strong>其他相关任务</strong>的训练信号中所包含的信息来<strong>改善</strong>对一个任务的学习，并行学习，互相帮助学习。广义的讲，只要<strong>loss有多个</strong>就算MTL。</p>
<p>具体地，基于共享表示（shared representation），把多个相关的任务放在一起学习。用<strong>相关任务的训练信号来提升主任务的泛化效果</strong>。</p>
<a id="more"></a>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/20210107142218.png" style="zoom:80%;" /></p>
<h4 id="挑战"><a href="#挑战" class="headerlink" title="挑战"></a><strong>挑战</strong></h4><p>与标准的单任务相比，在学习共享表示的同时训练多个任务有两个主要挑战：</p>
<ul>
<li><p><strong>Loss Function(how to balance tasks)：</strong>多任务学习的损失函数，对每个任务的损失进行权重分配，在这个过程中，必须保证所有任务同等重要，而不能让简单任务主导整个训练过程。手动的设置权重是低效而且不是最优的，因此，自动的学习这些权重或者设计一个对所有权重具有鲁棒性的网络是十分必要和重要的。</p>
</li>
<li><p><strong>Network Architecture(how to share)：</strong>一个高效的多任务网络结构，必须同时兼顾特征共享部分和任务特定部分，既需要学习任务间的泛化表示（避免过拟合），也需要学习每个任务独有的特征（避免欠拟合）。</p>
</li>
</ul>
<p>一个优秀的多任务网络应该具备：(1)特征共享部分和任务特定部分都能自动学习（2）对损失函数权重的选择上更robust。</p>
<h2 id="End-to-End-Multi-Task-Learning-with-Attention"><a href="#End-to-End-Multi-Task-Learning-with-Attention" class="headerlink" title="End-to-End Multi-Task Learning with Attention"></a>End-to-End Multi-Task Learning with Attention</h2><p><em>【CVPR 2019】</em></p>
<p><em>【Shikun Liu，Edward Johns，Andrew J. Davison】</em></p>
<p><em>【Department of Computing, Imperial College London】</em></p>
<p><a href="https://zhuanlan.zhihu.com/p/82234448?utm_source=wechat_session">https://zhuanlan.zhihu.com/p/82234448?utm_source=wechat_session</a></p>
<h3 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h3><p>提出了新的多任务学习结构，学习特定任务的、特征级别的注意力模块，即Multi-Task Attention Network（<strong>MTAN</strong>）。MTAN包括：一个带有全局特征池的<strong>共享网络</strong>，针对每个任务的<strong>soft-attention模块</strong>，从全局特征中学习特定任务的特征。该网络可以实现端到端训练，可以构建在任何前馈神经网络上。在图像预测和分类任务中作了实验，超过目前的方法，对多任务损失函数中的各种加权机制比较<strong>鲁棒</strong>。</p>
<h3 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h3><p>CV实际应用中，需要同时处理多任务，相关任务之间共享信息、特征。MTL中，学习共享表示的关键<strong>挑战</strong>：</p>
<ol>
<li>网络结构（任务<strong>共享层特征表示</strong>和<strong>特定任务的特征表示</strong>）</li>
<li>loss function（如何<strong>平衡各个任务</strong>，自动学习权重，设计一个对不同权重具有鲁棒性的网络）</li>
</ol>
<p>之前的MTL只关注其中一个，本文模型同时解决了两个挑战：</p>
<ol>
<li><strong>自动学习</strong>任务共享特征和特定任务的特征</li>
<li>对loss加权机制的选择具有<strong>鲁棒性</strong></li>
</ol>
<p>MTAN包<strong>括两部分</strong>：1.一个<strong>共享网络</strong>，学习所有任务特征的全局特征池，2.针对每个任务，在共享网络的每个卷积块上都加一个<strong>soft attention mask</strong>获取对自己有用的feature。以自监督、端到端的方式分别学习任务共享特征、特定任务特征，这种灵活性使我们能够学习到<strong>更有表现力</strong>的特征组合。自动选择任务共享特征、特定任务特征使得模型参数更少，更<strong>高效</strong>。</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/20210107142244.png" style="zoom:67%;" /></p>
<p>MTAN可应用于任何FNN，本文中<strong>基于SegNet构建MTAN</strong>，完成语义分割和深度估计（ CityScapes ），表面法线估计（NYUv2），基于Wide Residual Network完成图像分类。试验结果表明，MTAN效果超过目前的方法，同时参数效率更高，对loss funciton加权机制的选择更加鲁棒。提出了动态加权平均DWA。根据每个任务loss的变化率来调整权重。</p>
<h3 id="Multi-Task-Attention-Network"><a href="#Multi-Task-Attention-Network" class="headerlink" title="Multi-Task Attention Network"></a>Multi-Task Attention Network</h3><p>如何基于SegNet构建MTAN</p>
<p><strong>3.1 结构设计</strong></p>
<p>MTAN包括：一个<strong>共享网络</strong>，K个<strong>特定任务的注意力网络</strong>，连接到共享网络。每个注意力模块对共享网络的特定层应用一个<strong>soft attention mask</strong>（可以看作特征选择器，端到端自动学习），以学习特定任务的特征；共享网络可以看做是一个跨任务的特征表示。</p>
<p>图2给出了基于VGG16的MTAN可视化，也就是SegNet的encoder部分，每个注意力模块学习一个soft attention mask，共享网络特征和soft attention mask可以同时学习。</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/20210107142836.png" style="zoom:80%;" /></p>
<p><strong>3.2 特定任务的注意力模块</strong></p>
<p>通过对共享网络特征应用soft attention mask, 让<strong>特定任务网络学习与任务相关的特征</strong>，共享网络第j层的特征记为$p^j$，该层中学到的第$i$个任务的attention mask记为${a}_i^{(j)}$，特定任务特征$\hat{a}_i^{(j)}$为:</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/20210107142351.png" style="zoom:80%;" /></p>
<p>第一个注意力模块输入只有共享网络的特征，后续注意力模块输入包括共享网络特征和前一层的特定任务特征。</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/20210107142408.png" style="zoom:80%;" /></p>
<p>3.3 模型目标</p>
<p><strong>输入X和K个标签Y，loss function如下：</strong></p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/20210107142437.png" style="zoom:80%;" /></p>
<p>是各任务loss的线性组合，具体到图像分割、深度估计、图像分类loss function不同：<br>语义分割：像素级的交叉熵损失</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/20210107142457.png" style="zoom:80%;" /></p>
<p>深度估计：预测深度和真实深度的L1范数</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/20210107142516.png" style="zoom:80%;" /></p>
<p>表面法线估计：</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/20210107142532.png" style="zoom:80%;" /></p>
<p>图像分类：交叉熵损失</p>
<h3 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h3><p><strong>4.1 Image-to-Image Prediction (One-to-Many)</strong></p>
<p>4.1.1 数据集</p>
<p>数据：CityScapes，高解析度街景影像； 任务：语义分割&amp;深度检测</p>
<p>数据：NYUv2，RGB-D室内场景图像（更复杂）； 任务：语义分割，深度估计，表面法线估计</p>
<p>4.1.2 Baseline</p>
<p>基于SegNet的两个单任务+三个多任务方法</p>
<p>单任务：原始SegNet</p>
<p>单任务：STAN（MTAN的单任务形式）</p>
<p>多任务，Split（Wide，Deep）：标准的多任务学习，调整卷积核个数为Wide，调整卷积层数为Deep</p>
<p>多任务，Dense：共享网络+特定任务的网络，但是任务特定的网络包括了共享网络中的全部特征，没有注意力机制</p>
<p>多任务，Cross-Stitch（十字绣）：一种自适应多任务学习方法，构建在SegNet上</p>
<p>4.1.3 DWA</p>
<p>为了寻找<strong>各任务之间的平衡</strong>，提出简单有效的<strong>自适应加权方法</strong>DWA。根据GradNorm启发，考虑根据<strong>每个任务loss的变化率</strong>，随时间平均各任务权重， DWA只需要数值上的loss，比GradNorm更简单。第k个任务的权重如下：</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/20210107142551.png" style="zoom:80%;" /></p>
<p>$w$是相对下降率；T越大，不同任务之间越平均，K是所有权值求和。</p>
<p>4.1.4 结果（Image-to-Image Prediction）</p>
<p>MTAN与baseline对比，加权方式对比（平均，随机，DWA）</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/20210107142608.png" style="zoom:80%;" /></p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/20210107142624.png" style="zoom:80%;" /></p>
<p>MTAN+DWA的优势：1）参数少，效率高；2）鲁棒性：在不同的加权机制下，我们的模型表现都差不多</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/20210107142717.png" style="zoom:80%;" /></p>
<p>4.1.5 任务复杂性效应</p>
<p>在不同级别的语义分割任务中，2分类时，单任务训练也很好；问题变复杂时，需要共享特征、有效利用参数。<strong>随着问题变复杂，多任务模型都能提高性能</strong>，<strong>MTAN提升的最多</strong>。不同任务的attention mask作为选择器，选出来的特征是不一样的。</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/20210107142737.png" style="zoom:80%;" /></p>
<h3 id="Conclusions"><a href="#Conclusions" class="headerlink" title="Conclusions"></a>Conclusions</h3><p>提出了 Multi-Task Attention Network (<strong>MTAN)</strong>，包括<strong>全局特征池</strong>，<strong>特定任务的注意力模块</strong>，以端到端模式<strong>自动学习任务共享特征、特定任务特征</strong>，效果超过了大多数现有模型。还提出了DWA（损失函数的加权机制），保证了鲁棒性，参数高效性。</p>
]]></content>
      <categories>
        <category>syd</category>
      </categories>
      <tags>
        <tag>多任务学习</tag>
      </tags>
  </entry>
  <entry>
    <title>syd 【ICML207】Bidirectional Learning for Time-series Models with Hidden Units</title>
    <url>/2021/01/07/SongYudan/%E3%80%90ICML2017%E3%80%91notes_Bidirectional%20Learning%20for%20Time-series%20Models%20with%20Hidden%20Units/</url>
    <content><![CDATA[<p>【ICML，2017】</p>
<p>【Takayuki Osogami, Hiroshi Kajino, Taro Sekiyama，IBM Research- Tokyo】</p>
<h3 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h3><p><strong>隐单元</strong>在长程依赖或非线性时序建模中有重要作用，但是相关参数不好训练，提出后向训练来学习这样的模型。后向模型和前向模型有共同的参数集，只有一小部分参数是<strong>难训练</strong>的，在前向后向模型中是<strong>互补</strong>的。同时训练两个模型，提高参数学习的效率。在带隐单元的动态玻尔兹曼机上应用了双向学习，合成/真实数据集上演示了<strong>双向学习</strong>的优势。</p>
<a id="more"></a>
<hr>
<h3 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h3><p>在一些时序模型中，隐单元对于时序中的长程依赖和非线性是至关重要的；但是隐单元的值只有通过观测未来值才能可靠估计，训练困难。设时序模型的参数用一个或几个矩阵$M$表示，$M<em>{i,j}$可能代表节点i的历史值和节点j的后续值之间的权重，其中一些隐节点j的$M</em>{i,j}$难估计。根据参数矩阵为$M$的时序模型，构造后向模型，参数矩阵为$M^T$。</p>
<p><strong>contribution 1:</strong> 提出<strong>双向方法</strong>来训练带隐单元的时序模型。两个模型结构相同、训练方式相同（随机梯度方法）；前向模型用正常时序，后向模型用逆向时序，分别学习$M$和$M^T。$两个矩阵中难训练的元素是<strong>不同</strong>的，所以双向训练可以提高参数学习效率。</p>
<p><strong>contribution 2: </strong>在<strong>带隐单元DyBM</strong>上应用双向学习。分析了带隐单元的DyBM，阐释了参数学习的<strong>困难性</strong>；通过双向学习，学习历史可见值和后续隐值之间的权值，学习过去的哪些值对于预测是重要的。</p>
<p><strong>相关但不同的模型：</strong></p>
<p>双向训练&amp;BRNN: BRNN的双向模型没有共享参数，而双向训练会<strong>共享参数</strong>。动机不同，BRNN使用双向模型训练、预测，用前面、后面的值来估计中间的值；而双向训练只用双向模型进行训练，预测时还是<strong>只用历史值</strong>。</p>
<p>双向训练&amp;FBLG：FBLG（Forward Backward Lasso Granger，包括前向VAR和后向VAR，得到平均模型）中没有隐单元，而双向训练是为了训练<strong>带隐单元</strong>的时序模型。</p>
<p>双向训练&amp;考虑隐变量的VAR模型或线性动态系统：后者是通过隐变量估计可见变量之间的关系；双向学习是为了学习可见单元和隐单元之间的关系。</p>
<h3 id="2-DyBM-with-Hidden-Units"><a href="#2-DyBM-with-Hidden-Units" class="headerlink" title="2. DyBM with Hidden Units"></a>2. DyBM with Hidden Units</h3><p><strong>玻尔兹曼机：</strong>一种随机递归神经网络，可以看作是一种随机的Hopfield网络，通过学习数据的固有内在表示，来解决困难学习问题。一般BM可见单元和隐单元之间的<strong>能量函数</strong>为：</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/20210107135323.png" style="zoom:67%;" /></p>
<p>BM通过调整各神经元之间的权值，使模型的概率分布等于训练样本集的概率分布，使<strong>出现概率最高的全局状态得到最低的能量</strong>，最终转换为<strong>最大化似然函数</strong>。</p>
<p><strong>DyBM:</strong> 结合<strong>STDP</strong>的特殊结构的玻尔兹曼机，是一个多维时间序列的随机模型</p>
<p><strong>STDP:</strong> spike-timing dependent plasticity，脉冲时间相关的突触可塑性；它根据神经元学习的先后顺序，<strong>调整神经元之间连接的强弱</strong>。STDP可以说是Hebb学习的一种延伸，Hebb学习提出如果两个神经元常常一起活动，则二者之间的连接会增强。STDP则是进一步提出，两个神经元之间的活动，如果其他神经元的信息在本身活动产生之前，则两神经元之间的连接会增强。如果神经元本身产生活动之后才接受其他神经元传来的信息，则两神经元之间的连接会减弱。</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/20210107135347.png" style="zoom:67%;" /></p>
<p>图1给出了针对时序的特殊结构化的玻尔兹曼机，时序长T+1，水平有T+1层；每层都有隐藏部分和可见部分，第$\delta$层可见部分$x^{[t-\delta]}$代表时序$t-\delta$时刻的值。图1的BM偏置为b，权重参数为$(U,V,W,Z)$，$\theta=(V,W,b)$是和可见单元$x^{[t]}$相关的参数，$\phi=（U,Z）$是隐单元参数。DyBM的能量如下：</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/20210107135409.png" style="zoom:67%;" /></p>
<p>其中</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/20210107135433.png" style="zoom:67%;" /></p>
<p>同理定义第二项。</p>
<p>研究这种情况：$W=(W^{\delta})_{1&lt;=\delta&lt;=T}$，$\delta&gt;=d$时满足以下条件（衰减）：</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/20210107135456.png" style="zoom:67%;" /></p>
<p>其中$\lambda$是衰减率，T趋向于无穷时，式（2）的<strong>能量如下</strong>：</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/20210107135514.png" style="zoom:67%;" /></p>
<p>第二项同理，其中</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/20210107135531.png" style="zoom:67%;" /></p>
<p>式（5）的能量给出了，<strong>给出$x^{[&lt;t]}$,$h^{[&lt;t]}$下$x^{[t]}$的条件概率分布</strong>，对二进制时序中任意的$x^{[t]}$，有：<br><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/20210107135550.png" style="zoom:67%;" /></p>
<p>其中Z是使概率之和为1的归一化因子。</p>
<h3 id="3-Training-a-DyBM-with-Hidden-Units"><a href="#3-Training-a-DyBM-with-Hidden-Units" class="headerlink" title="3. Training a DyBM with Hidden Units"></a>3. Training a DyBM with Hidden Units</h3><p><strong>推导可见单元参数$\theta$的学习规则，这个规则不适用于$\phi$</strong>。</p>
<p>带隐单元的DyBM给出了时序的概率：</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/20210107135616.png" style="zoom:67%;" /><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/20210107135633.png" alt=""></p>
<p>其中：</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/20210107135633.png" style="zoom:67%;" /></p>
<p>通过最大化Jensen不等式给出的下界，来<strong>最大化给定x的对数似然函数</strong>，</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/20210107135653.png" style="zoom:67%;" /></p>
<p>其中</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/20210107135732.png" style="zoom:67%;" /><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/20210107135749.png" alt=""></p>
<p>下界对$\theta$的梯度是：</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/20210107135749.png" style="zoom:67%;" /></p>
<p>随机梯度的方法：每一步t，根据概率取样出$h^{[t-1]}$然后基于它的梯度来更新$\theta$:</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/20210107135826.png" style="zoom:67%;" /></p>
<p>下界对$\phi$的梯度：</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/20210107135904.png" style="zoom:67%;" /></p>
<p>根据概率取样出$h^{[t-1]}$然后基于它的梯度来更新$\phi$:</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/20210107135923.png" style="zoom:67%;" /></p>
<p>式27的计算复杂度随时序长度线性增长，<strong>计算效率低</strong>；而式17的复杂度和长度无关。可用递归方式近似计算G：</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/20210107135949.png" style="zoom:67%;" /></p>
<p>式26中存在一个<strong>对数似然和梯度的乘积</strong>，如果不依赖于对数似然函数，它的学习规则就与可见单元是相同的。而这两项相乘是不可避免的，因为隐单元的特定值是否有利于预测未来值，只有在看到未来值之后才能知道。</p>
<h3 id="4-Learning-with-Reversed-Time-series"><a href="#4-Learning-with-Reversed-Time-series" class="headerlink" title="4.  Learning with Reversed Time-series"></a>4.  Learning with Reversed Time-series</h3><p>$\phi$的随机梯度需要近似，$\theta$不需要，所以参数$\phi$的学习不像$\theta$一样高效。</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/20210107140009.png" style="zoom:67%;" /></p>
<p>图2是后向DyBM，和前向DyBM有共同的参数集，它是由前向DyBM得到的，结构相同，参数矩阵转置，只是逆序处理时序。前向模型中$\theta=(V,W,b)$，$\phi=（U,Z）$，后向模型中$\theta’=(U^T,W^T,b)$, $\phi’=(V^T,Z^T)$, $U$在前向模型中是比较难学习的，而在后向模型中是相对好学习的。</p>
<h3 id="5-Experiments"><a href="#5-Experiments" class="headerlink" title="5.  Experiments"></a>5.  Experiments</h3><p><strong>5.1 具体学习算法</strong></p>
<p>三种训练模式：不带隐单元的DyBM；带隐单元的DyBM只进行前向学习；带隐单元的DyBM的双向学习。</p>
<p>双向学习：前$T_0$轮迭代进行双向学习，每$F+1$步进行后向学习，剩余的迭代中只进行前向学习。前向学习时不更新U，后向学习时不更新V。</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/20210107140036.png" style="zoom:67%;" /></p>
<p><strong>5.2 合成数据</strong></p>
<p>在<strong>一维带噪声锯齿波</strong>合成数据上实验，探究双向训练的有效性。锯齿波在每个阶段末端都存在很强的不连续性，所以隐单元对于学习是至关重要的。</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/20210107140103.png" style="zoom:67%;" /></p>
<p>训练了带一个隐藏单元/没有隐藏单元的DyBM，前一半迭代$T/2$进行双向学习。</p>
<p>图3a、c是训练过程，RMSE评估预测误差。在图3c中，从T0时刻（双向学习结束之后），RMSE的下降开始加速，<strong>说明通过双向学习学到合适的U之后，更有利于学习其余参数（V W b）</strong>。虽然双向学习有助于学到合适的U，但是不一定优化DyBM的所有参数，后向DyBM和逆时序的DyBM不同。</p>
<p>图3b、d给出了预测结果。<strong>双向学习的DyBM和真实值接近，可以很好的预测到每一个周期结尾的大幅下降</strong>，而基线在这里比较平滑。</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/20210107140139.png" style="zoom:67%;" /></p>
<p><strong>5.3 真实数据</strong></p>
<p>每月太阳黑子数：一维，2820步；每周汽油柴油零售价：八维，1223步；2：1划分；NOAA全球表面温度：391维，1635步，4：1划分；数据进行归一化。</p>
<p>测试了带4个隐单元/不带隐单元的DyBM，设置不同的$T_0$和d，前d步进行前向学习和后d步进行后向学习。</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/20210107140159.png" alt=""></p>
<p>对于太阳黑子数据，双向学习没有提高，但是隐藏单元能得到更低的RMSE。对于价格和温度数据，T0轮之后，双向学习效果优于基线，并且另外两种情况会<strong>过拟合</strong>。<strong>双向学习会减慢RMSE的下降，但是停止双向训练后，会加速RMSE的下降，双向学习最终的RMSE更低</strong>。</p>
<h3 id="6-Conclusion"><a href="#6-Conclusion" class="headerlink" title="6. Conclusion"></a>6. Conclusion</h3><p>提出了带隐单元时序模型的双向学习，前向模型（训练前向序列）和后向模型（训练后向序列）有相同的参数集，<strong>一个模型中比较难学习的参数在另一个模型中可能是比较好学习的</strong>。分析了带隐单元的<strong>DyBM</strong>，可见单元$\theta(V,W,b)$和隐单元$\phi(U,Z)$的<strong>梯度不同</strong>，不能用同样的方式学习权重。所以双向学习可以提高参数学习效率，在合成/真实数据集上进行了实验，实验证明双向学习还可以<strong>避免过拟合</strong>。</p>
]]></content>
      <categories>
        <category>syd</category>
      </categories>
      <tags>
        <tag>时间序列</tag>
      </tags>
  </entry>
  <entry>
    <title>syd 【ICML2018】GradNorm:Gradient Normalization for Adaptive Loss Balancing in Deep Multitask Networks</title>
    <url>/2021/02/01/SongYudan/%E3%80%90ICML2018%E3%80%91GradNorm_notes/</url>
    <content><![CDATA[<h3 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h3><p>深度多任务网络可以用一个网络产生多个输出，与单任务网络相比，又快又好，但是不好训练。提出了<strong>梯度归一</strong>方法，通过动态调整梯度大小，自动<strong>平衡多任务中的训练</strong>。与单任务、其他loss权衡机制相比，GradNorm可以提高准确率，缓解过拟合。GradNorm只用<strong>一个不对称超参数</strong>$\alpha$，能达到或超过<strong>穷举网格搜索</strong>的效果。</p>
<a id="more"></a>
<h3 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h3><p>CV中需要同时且高效的完成多个任务，可以通过MTL实现，不同的任务间共享网络权重，在一个这种网络可伸缩，且共享特征引入更鲁棒的正则化、性能。但是多任务网络难以训练，不同的任务需要有一个<strong>恰当的平衡</strong>，参数应该收敛到鲁棒的共享特征。通过操控网络的反向传播寻找任务间的平衡，现有的方法都忽略了这一点：任务不平衡会阻碍训练，表现为反向梯度的不平衡。所以本文考虑<strong>直接调整loss</strong>，改变梯度大小，缓解这个问题。</p>
<p>多任务loss是单任务的线性组合，$L=\Sigma_iw_IL_i$，我们提出自适应方法，<strong>每一个训练步权值都变化</strong>，在训练过程中优化$w_i$，达到平衡的目的。当某个反向梯度过大或过小时，进行惩罚。所有的任务以相似的速率训练时，就达到平衡了。如果某个任务训练较快，对应的权值就要变小。</p>
<p>贡献：</p>
<ol>
<li>直接调整梯度大小，实现多任务loss平衡</li>
<li>只需调整一个参数，可以达到或超过穷举网格搜索</li>
<li>直接梯度交互可以控制MTL</li>
</ol>
<h3 id="GradNorm"><a href="#GradNorm" class="headerlink" title="GradNorm"></a>GradNorm</h3><p><strong>3.1. Definitions and Preliminaries</strong></p>
<p>期望学到的$w_i(t)$能实现以下目标：1）将不同任务的梯度规范置于同一尺度上，通过这个尺度可以推断出梯度的相对大小；2）动态调整梯度范数，使得不同的任务以相似的速率训练。</p>
<p>$W$：网络权值的子集，真正应用GradNorm的参数，一般是最后一层权值共享层</p>
<p>$G_W^{(i)}(t)$：单任务loss（$w_iL_i$）对$W$的梯度的l2范数</p>
<p>$\overline{G}_W(t)$：所有任务$G_W^{(i)}(t)$的均值</p>
<p>$\widetilde{L}_i(t)=L_i(t)/L_i(0)$：任务i在t时刻的loss比率，记为反向训练速率，这个值越小，loss降的越快，训练速度就越快</p>
<p>$r<em>i(t)=\widetilde{L}_i(t)/E</em>{task}[\widetilde{L}_i(t)]$：相对逆训练速率，越小，训练速度越快</p>
<p><strong>3.2. Balancing Gradients with GradNorm</strong></p>
<p>GradNorm讲梯度大小规范到同一尺度（平均梯度$\overline{G}_W(t)$），平衡不同任务的训练速率。相对反向训练速率$r_i(t)$用于平衡梯度，$r_i(t)$越大（说明该任务训练比较慢），梯度值应越大，加速这个任务的训练，所以得到任务i的期望梯度：</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/20210129143007.png" style="zoom: 80%;" /></p>
<p>$\alpha$是超参数，控制恢复力（将梯度拉回同一训练速率）的强度。如果任务之间非常不平衡，$\alpha$适当调大；如果任务只是轻微不平衡，$\alpha$适当调小。上式给出了任务i的目标梯度，更新loss权值$w<em>i$使得梯度朝着这个目标前进，目标梯度和当前梯度的l1范数求和，得到$L</em>{grad}$:</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/20210129144254.png" style="zoom:80%;" /></p>
<p>将后半部分看作常数，那么$L_{grad}$只与$w_i$有关。对$w_i$进行求导，它直接控制每个任务的梯度大小，利用标准更新准则进行更新；每次更新后，需要规范化使得$\Sigma w_i$为T。</p>
<p>算法：</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/20210129145617.png" style="zoom:80%;" /></p>
<hr>
<ul>
<li>补充博客：<a href="https://blog.csdn.net/leon_winter/article/details/105014677">https://blog.csdn.net/leon_winter/article/details/105014677</a></li>
</ul>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/20210129144123.png" alt=""></p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/20210129144146.png" alt=""></p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/20210129144208.png" alt=""></p>
<hr>
<h3 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h3><p>训练多个任务，具有相似的损失函数，但是尺度不同，起初$w_i$均为1，损失量级越大的、反向传播梯度越大的任务越占主导地位。应用GradNorm：</p>
<p>T个回归任务，square loss，输入250维，输出100维，B和$\epsilon_i$是常矩阵，分别服从两个IID的正态分布。每个任务共享B中的信息，也包含任务特定信息$\epsilon_i$，$\sigma_i$控制着输出$f_i$的尺度，若$\sigma_i$较大的任务占主导，不是最优训练状态。</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/20210128155658.png" style="zoom:67%;" /></p>
<p>设计了4层全连接层，ReLU激活函数，每层100个神经元，最后的仿射层给出T个任务的T个预测，<strong>$\alpha$设为0.12</strong>。我们设计的多个任务，除了$\sigma_i$外都相同，所以用$\sigma_i^2$对每个任务进行标准化然后再求和，等同于对loss比率进行求和。</p>
<p>设只有两个任务，且$(\sigma_0,\sigma_1)=(1,100)$，初始权重均为1，由于任务1的量级较大，它的学习会超过任务0，所以应该相应地增大$w_0(t)$，提高任务平衡性。下图给出了训练过程中$w_0$和$w_1$的变化。</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/20210129124840.png" alt=""></p>
<p>用10个任务进行了实验，结果如下，可以看出当任务数量变多时，梯度归一化的效果会更明显。</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/20210129143658.png" alt=""></p>
<p>应用梯度归一化后，会得到各任务loss的权值$w_i$随着训练步变化的曲线，将<strong>权值按时间进行平均</strong>，取最终的一个<strong>静态值</strong>，这个静态权重可以<strong>近似达到网格搜索的效果</strong>。</p>
<h3 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h3><p>提出了GradNorm-一种自适应的加权机制，基于不同任务的训练速率，调整各任务loss的权值。通过调整$\alpha$的大小实现不同层层次的平衡，可以达到或超过网格搜索的效果，且更高效。</p>
<hr>
<ul>
<li>这项研究由 Magic Leap 完成。这篇论文解决了一个非常有意思并且非常实用的问题，即多任务学习中多个任务难易程度不同所导致的优化不同步问题。作者提出了一种梯度传播机制，其核心思想是动态调整多个任务的权重，这些权重通过各个任务的实时梯度再进行反向传播和更新。研究表明，GradNorm 算法对多种不同的网络架构都有效，而且无论是回归任务还是分类任务，无论是合成数据集还是真实数据集，GradNorm 在多个任务上都能实现优于单任务网络的准确度并降低过拟合。GradNorm 也能得到比肩或超过穷举网格搜索方法的表现，尽管其仅涉及到单个不对称超参数 α。因此，曾经每增加一个任务都会导致计算需求指数增长的繁琐的搜索过程现在只需几次训练就能完成了，而且无论任务有多少都一样。研究者还表明梯度操作能实现对多任务网络的训练动态的更好控制。</li>
</ul>
]]></content>
      <categories>
        <category>syd</category>
      </categories>
      <tags>
        <tag>多任务学习</tag>
      </tags>
  </entry>
  <entry>
    <title>syd 【ICML2020】Which Tasks Should Be Learned Together in Multi-task Learning?</title>
    <url>/2021/07/14/SongYudan/%E3%80%90ICML2020%E3%80%91Which%20Tasks%20Should%20Be%20Learned%20Together%20in%20Multi-task%20Learning/</url>
    <content><![CDATA[<p>MTL可以训练一个神经网络同时解决多个任务，减少时间成本，但是性能一般，因为任务间可能有<strong>竞争</strong>关系。MTL中，哪些任务应该、不应该在一个网络中一起学习？</p>
<p>本文提出了一个框架，将若干个任务分配给几个网络，将<strong>协作</strong>的任务分配到同一个网络，将<strong>竞争</strong>的任务分配到不同的网络。与单个大型网络、多个单任务网络相比，该框架能提供时间-精度的折中，<strong>在有限的时间内达到尽量高的精度</strong>。</p>
<a id="more"></a>
<p>斯坦福；瑞士联邦理工学院；谷歌；加州大学伯克利分校；</p>
<h3 id="1-引言"><a href="#1-引言" class="headerlink" title="1. 引言"></a>1. 引言</h3><p>MTL用一个网络同时解决多个任务，可以提高预测精度，提高数据效率，减少训练时间。但是由于<strong>负迁移、任务干扰</strong>，预测效果不佳，不如小型的独立网络；不同任务的学习率不同，可能被某一任务主导，导致其它任务性能下降；乘加loss比较难优化。MTL是否有增益取决于任务间的<strong>关系</strong>。</p>
<p>目标：给定一系列任务，在计算成本&lt;预算b的情况下，尽可能最大化任务性能。所以我们提出了一个计算框架，<strong>把相关的任务组成一组，在给定成本b的限制下，用几个网络覆盖所有的任务，最大化任务性能</strong>。在一个网络中额外加入一个任务，可以提高其它任务的性能，（虽然该任务的性能可能只有一点点提升）。</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/image-20210711120452570.png" alt="image-20210711120452570" style="zoom:80%;" /></p>
<p>如图一所示，训练网络A完成语义分割、深度估计和表面法线预测，训练网络B完成关键点检测、边检测、表面法线预测，训练网络C单独完成表面法线预测（计算代价小）。<strong>将表面法线预测也作为网络A、B的输出</strong>，可以<strong>提升</strong>其它任务的效果，将网络C的输出作为该任务的预测结果。这种任务分组方法优于一个大网络完成五个任务、优于五个小网络完成单个任务。</p>
<p><strong>主要贡献：</strong></p>
<ol>
<li>研究了多任务学习中，网络大小、数据大小对性能的影响，以及任务如何互相影响；</li>
<li>提出了一个框架，如何将任务分配给网络，  在有限的时间内，尽可能达到好的预测效果，如何<strong>分组</strong>对最终的性能是至关重要的。                                                                                                                                                                                        </li>
</ol>
<h3 id="2-之前的工作"><a href="#2-之前的工作" class="headerlink" title="2. 之前的工作"></a>2. 之前的工作</h3><p>MTL：hard参数共享，soft参数共享。很多情况下，MTL效果不如单任务多个网络；而且这些已有的方法，没有将任务<strong>分组</strong>，soft参数共享也没有<strong>减少推理时间</strong>。</p>
<h3 id="3-实验设置"><a href="#3-实验设置" class="headerlink" title="3. 实验设置"></a>3. 实验设置</h3><p><strong>Dataset：</strong>Taskonomy，CV领域中的多任务数据集，400万样例，390万训练，5万验证，5万测试，训练集和测试集中的建筑无重叠。</p>
<p><strong>任务集：</strong>任务集1包括语义分割，深度估计，表面法线预测，SURF关键点检测，canny边检测；这些任务代表了CV中的主要任务类别，任务间也有一些重叠，用于探究相似的任务一起训练是否能提高性能。任务集2包括自编码器，表面法线预测，遮挡边缘，重塑和主曲率。语义分割任务是交叉熵损失，其余都是L1损失。</p>
<p><strong>结构：</strong>所有实验都采用标准的encoder-decoder结构。用改进的Xception encoder；所有的最大池化都用步长为2、卷积核为2<em>2的卷积层代替，16.5百万参数，输入大小为256，256。为了探究<em>*网络大小</em></em>对任务关系的影响，更小的网络（Xception17，4百万参数，乘加操作次数也更少）。轻量级decoder，4个转置卷积层和4个卷积层。</p>
<p><strong>设置：</strong></p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/image-20210711162322293.png" alt="image-20210711162322293"></p>
<p>setting2是对照组，setting1探究网络大小的影响，setting3探究数据集大小的影响，setting4探究其它任务关系。</p>
<p><strong>训练细节：</strong>loss未加权，初始lr=0.1，每次trainingloss不下降lr就减半，validloss没有改善就停止训练，</p>
<p><strong>比较：</strong>定义了计算网络代价单元，标准网络时间SNT；<strong>SNT是Xception17网络中一次乘加的时间</strong></p>
<p><strong>训练好的网络：</strong>训练了5个单任务（1-SNT），10个双任务，10个三任务，5个四任务，1个五任务网络；另外还训练了5个单任务网络（1/2-SNT）</p>
<h3 id="4-任务关系的研究"><a href="#4-任务关系的研究" class="headerlink" title="4. 任务关系的研究"></a>4. 任务关系的研究</h3><p>探究任务关系对多任务网络性能的影响</p>
<h4 id="4-1-Setting1：小网络（Xception17）"><a href="#4-1-Setting1：小网络（Xception17）" class="headerlink" title="4.1 Setting1：小网络（Xception17）"></a>4.1 Setting1：小网络（Xception17）</h4><p>探究<strong>任务数量</strong>对多任务网络性能的影响，表1是与<strong>独立训练</strong>的结果相比，第一行是与每个任务1-SNT的单任务网络相比，第二行是与几个任务一共1-SNT的单任务网络相比。</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/image-20210711170240554.png" alt="image-20210711170240554" style="zoom:80%;" /></p>
<p>单任务网络缩小到总的计算限制和多任务网络的<strong>总预算相同</strong>时，3、4、5个任务一起训练优于单任务，但是2个任务一起训练情况不同，表2显示了<strong>两个任务一起训练</strong>与1/2-SNT的网络单独训练时的对比，法线任务对每个任务都有提升。</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/image-20210711171906926.png" alt="image-20210711171906926" style="zoom:80%;" /></p>
<h4 id="4-2-Setting2：对照组"><a href="#4-2-Setting2：对照组" class="headerlink" title="4.2 Setting2：对照组"></a>4.2 Setting2：对照组</h4><p>为了探究<strong>网络容量</strong>对多任务中任务关系的影响，用更高容量的encoder对所有的网络重新训练，结果如表5（对应前面的表2）</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/image-20210711214134743.png" alt="image-20210711214134743"></p>
<p>通过表5和表2的对比可以看出，<strong>网络越大，共同训练的任务性能增益越大</strong>，也有些任务共同训练时性能下降，且表5和表2不具有相关性，任务关系复杂，<strong>说明需要一个自动框架，来确定哪些任务应该被一起训练</strong>。</p>
<h4 id="4-3-Setting3：只用5-的训练数据"><a href="#4-3-Setting3：只用5-的训练数据" class="headerlink" title="4.3 Setting3：只用5%的训练数据"></a>4.3 Setting3：只用5%的训练数据</h4><p>探究训练集大小对结果的影响，只用了199498训练数据，接近于其它多任务数据集的大小。假设是，MTL可能在low-data（低数据）场景下表现更好，可以集中监督。但是表6的结果与假设相悖，<strong>与表2相比，表6大部分任务性能都下降了</strong>，最后的average是提升也是因为edge这个任务的大幅提升。</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/image-20210711222212818.png" alt="image-20210711222212818"></p>
<h4 id="4-4-Setting4：使用任务集2"><a href="#4-4-Setting4：使用任务集2" class="headerlink" title="4.4 Setting4：使用任务集2"></a>4.4 Setting4：使用任务集2</h4><p>除了auto encoder任务，其余的四个任务基本上都对其它任务有提升作用，这四个任务是比较相似的3D任务，似乎<strong>相似</strong>的任务可以互相提升，法线任务似乎可以提高和它一起训练的所有任务，这可能是因为法线在表面上有统一的值，并且保留了3D边缘。</p>
<p>所以，选择哪些任务进行一起训练是非常关键的，那么<strong>如何对任务进行分组，达到最好的性能</strong>？</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/image-20210711225103364.png" alt="image-20210711225103364"></p>
<h3 id="5-任务分组框架"><a href="#5-任务分组框架" class="headerlink" title="5. 任务分组框架"></a>5. 任务分组框架</h3><p>对所有的任务子集都训练网络，选择最合适的分组，但是这样计算代价很高，所以提出了两种策略，来预测训练结果。</p>
<p><strong>定义：</strong>想要在给定预算b内最小化一系列任务上的loss，每个网络$n$解决任务集中的子集，其代价为$c_n$，该网络在每个任务上的loss为$L(n,t_i)$，$S$是解决所有任务的网络集合，代价是所有网络的$c_n$之和，某个任务上的loss$L(S,t_i)$为S中所有网络在该任务上loss的最小值，总体性能就是每个任务上的loss求和。<strong>我们的目标就是在给定预算的条件下，寻找任务分组和对应的网络，使得总体loss最小。</strong></p>
<h4 id="5-1-考虑哪些网络？"><a href="#5-1-考虑哪些网络？" class="headerlink" title="5.1 考虑哪些网络？"></a>5.1 考虑哪些网络？</h4><p>不仅考虑“每对”任务一起训练时是否有提升，还要考虑哪些“组合”一起训练可以提升性能，所以候选网络一共有$（2^{|T|}-1）$个。本实验有5个任务，有31个网络，其中5个是单任务网络。</p>
<p>考虑网络大小的影响，另外有5个单任务网络，网络大小是标准网络的一半（1/2-SNT），所以一共<strong>36个网络</strong>。</p>
<h4 id="5-2-网络选择"><a href="#5-2-网络选择" class="headerlink" title="5.2 网络选择"></a>5.2 网络选择</h4><p>假设已经有训练好的一系列网络$C_0={n_1,n_2,…n_m}$，每个网络解决某个任务子集，目标是选择$C_0$的一个子集，能在成本限制下解决所有任务，达到最小loss，NP-hard问题，可以选择<strong>分支定界法，二进制整数规划</strong>解决，得到<strong>最优解</strong>。</p>
<h4 id="5-3-为减少训练时间作的近似"><a href="#5-3-为减少训练时间作的近似" class="headerlink" title="5.3 为减少训练时间作的近似"></a>5.3 为减少训练时间作的近似</h4><p>减少训练时间的两个技术：1）每个网络只训练一小段时间；2）基于两个任务一起训练的基础上，引入更多的任务，看表现如何。不过这些近似都会<strong>影响最后的精度</strong>。</p>
<h5 id="5-3-1-早停近似（ESA）"><a href="#5-3-1-早停近似（ESA）" class="headerlink" title="5.3.1 早停近似（ESA）"></a>5.3.1 早停近似（ESA）</h5><p>无需训练充分，在收敛之前<strong>早停</strong>，先进行网络选择，训练时间大幅提升，但是这样选择的网络并不一定是最优的。</p>
<h5 id="5-3-2-高阶近似（HOA）"><a href="#5-3-2-高阶近似（HOA）" class="headerlink" title="5.3.2 高阶近似（HOA）"></a>5.3.2 高阶近似（HOA）</h5><p>已经有同时训练AB的网络，同时训练AC的网络，同时训练BC的网络，以及各任务在各网络中的loss，可以由此推断同时训练ABC三个网络，各任务的loss，<strong>从低阶预测高阶</strong>：</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/image-20210712161449845.png" alt="image-20210712161449845" style="zoom:67%;" /></p>
<p>用该方法预测三个或更多的任务一起训练时，可以<strong>基于充分训练的双任务网络</strong>预测网络的性能，然后进行网络选择，从头开始训练高阶网络。</p>
<h3 id="6-任务分组评估"><a href="#6-任务分组评估" class="headerlink" title="6. 任务分组评估"></a>6. 任务分组评估</h3><p><strong>baselines：</strong>五个单任务网络，一个网络训练所有任务，将任务随机分组，全局性能最差的分组（pessimal）</p>
<h4 id="6-1-Setting1"><a href="#6-1-Setting1" class="headerlink" title="6.1 Setting1"></a>6.1 Setting1</h4><p>图3是<strong>不同计算成本</strong>限制下的<strong>不同任务分组</strong>策略，以及最终的总体<strong>loss</strong>：</p>
<p>最优分组性能最佳，两种近似方法中，虽然效果都不及最优分组，但是HOA近似与最优分组的结果差距不大。</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/image-20210712164300650.png" alt="image-20210712164300650"></p>
<p>图2是baseline以及本文三种方法的loss比较，当计算限制为1SNT时，都是用一个网络训练所有任务；当计算限制&gt;1.5SNT时，<strong>将任务分组表现更好</strong>，当计算限制为5SNT时，五个网络，其中s d e的网络需要其余两个任务的辅助，而n k这两个网络单独训练效果比较好。</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/image-20210712171037595.png" alt="image-20210712171037595" style="zoom:80%;" /></p>
<h4 id="6-2-Setting2"><a href="#6-2-Setting2" class="headerlink" title="6.2 Setting2"></a>6.2 Setting2</h4><p>在该设置下（网络容量大），我们的方法超过了别的方法，而且拉开了很大差距。ESA和HOA两种近似方法，ESA与最优方法差距较大，<strong>HOA</strong>比较接近。</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/image-20210712211942415.png" alt="image-20210712211942415"></p>
<h4 id="6-3-Setting3"><a href="#6-3-Setting3" class="headerlink" title="6.3 Setting3"></a>6.3 Setting3</h4><p>即使在小数据集情况下，我们的方法也优于其它方法：</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/image-20210712212429067.png" alt="image-20210712212429067"></p>
<h4 id="6-4-Setting4"><a href="#6-4-Setting4" class="headerlink" title="6.4 Setting4"></a>6.4 Setting4</h4><p>该设置下的任务协作的很好，所以单独训练、分组训练没有很突出的优势：</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/image-20210712212805811.png" alt="image-20210712212805811"></p>
<h4 id="6-5-讨论"><a href="#6-5-讨论" class="headerlink" title="6.5 讨论"></a>6.5 讨论</h4><p>在四种设置下，<strong>最优分组</strong>的表现都是最好的，<strong>HOA近似</strong>能和最优分组达到类似的水平，ESA近似不如最优分组的表现</p>
<h3 id="7-结论"><a href="#7-结论" class="headerlink" title="7. 结论"></a>7. 结论</h3><p>我们描述了任务的兼容性，分析任务关系，多任务中的任务关系<strong>受很多因素的影</strong>响，所以需要一个计算框架，确定哪些任务<strong>应该一起训练</strong>，哪些任务应该单独训练；探索所有的可能性训练时间过长，所以我们提出了两种<strong>近似策略</strong>，大大减少训练时间。</p>
<p>我们将最优分组、两种近似策略与单任务、一个网络训练所有任务以及其它基线方法进行对比，我们的<strong>方法优于基线方法</strong>，且<strong>HOA</strong>近似方法性能接近于最优分组。</p>
]]></content>
      <categories>
        <category>syd</category>
      </categories>
      <tags>
        <tag>多任务学习</tag>
      </tags>
  </entry>
  <entry>
    <title>syd 【IEEE2019】A Hierarchical Neural Network for Sleep Stage Classification based on Comprehensive Feature Learning and Multi-flow Sequence Learning</title>
    <url>/2021/01/07/SongYudan/%E3%80%90IEEE2019%E3%80%91notes_A%20Hierarchical%20Neural%20Network%20for%20Sleep%20Stage%20Classification%20Based%20on%20Comprehensive%20Feature%20Learning%20and%20Multi-Flow%20Sequence%20Learning/</url>
    <content><![CDATA[<p>基于综合特征学习和多流序列学习的用于睡眠分期的分层神经网络</p>
<hr>
<p>【2019,IEEE Journal of Biomedical and Health Informatics】</p>
<p>【Chenglu Sun，Chen Chen， Wei Li， Jiahao Fan，Wei Chen：复旦大学，信息科学与技术学院电子工程系，智能医疗电子中心】</p>
<h3 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h3><p><strong>自动睡眠分期</strong>通常提取PSG信号中的人工特征或网络训练的特征，用多种分类器估计它属于哪个阶段。</p>
<p>本文提出了基于分层神经网络的方法处理多通道PSG信号。包含<strong>两个阶段</strong>：综合特征学习阶段和序列学习阶段。第一阶段，将人工特征和网络训得的特征融合；第二阶段用多流的循环神经网络学习睡眠周期之间的时间信息，并微调第一阶段的参数。</p>
<p>用公开数据集MASS中147份记录来评估模型，总体能达到0.878的准确率，F1-score为0.818。与目前的先进方法相比，这种方法性能<strong>更优</strong>。消融实验和模型分析证明了模型<strong>不同组成部分的有效性</strong>。该方法可以根据不同的标准、信号特征和阶段划分的多通道PSG信号对睡眠阶段进行自动分类，具有<strong>全面</strong>开发睡眠信息的潜力。</p>
<a id="more"></a>
<p>关键词：睡眠阶段分期；卷积神经网络；循环神经网络；EEG信号</p>
<h3 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h3><p><strong>背景：</strong>AASM标准将睡眠阶段分为五类：WAKE，REM，NREM1，NREM2，NREM3；把睡眠记录分为连续的阶段，专家根据一定标准将每个阶段划分为一个特定的睡眠阶段。为了减轻专家负担并提供辅助诊断，基于传统机器学习的方法应用了PSG信号中的典型特征（具有明显的物理意义），然后用不同的分类器进行睡眠分期。</p>
<p><strong>存在问题：</strong></p>
<ol>
<li><p>如何从EEG、EOG和EMG信号中提取超越现有经典特征的<strong>新的、有效的特征</strong>是一个挑战；</p>
</li>
<li><p>如果根据以已提供的特征，某个阶段的特征仍然难以<strong>全面描述</strong>，这个阶段就会比较难识别；</p>
</li>
<li>传统机器学习方法的分类器<strong>不擅长处理时间序列信号</strong>。</li>
</ol>
<p><strong>A. 睡眠阶段分期的深度学习方法：文献综述</strong></p>
<p>深度学习方法在很多领域都取得巨大成功。CNN和DBN在特征提取上性能比较好，RNN适于处理时序信号。<strong>深度网络</strong>在生理信号和医学图像处理方面都表现出<strong>良好性能</strong>。</p>
<p>睡眠分期分为两步：特征提取和序列信号分类。可以用深度网络来处理睡眠数据：CNN单通道、CNN多通道。信号越多，分类效果越好；序列分类：DBN+HMM，ReNN+LSTM，CNN+BLSTM，只用深度网络，会<strong>过度依赖于网络</strong>。</p>
<p>PSG信号可提取出三类特征：手动设计特征（可以提取到网络提取不到的特征，但是进步缓慢），网络训得的特征（难以描述和理解，有效性有待研究），从手动设计特征得到的分层特征（忽略了直接从网络提取的特征）。这些网络架构还有很大的<strong>提升空间</strong>。</p>
<p><strong>B. 本文目标</strong></p>
<p>旨在提出一个更好的方法，能<strong>综合</strong>的利用睡眠阶段知识，利用深度网络的特点（把手动设计特征和网络科学地结合起来）。还要考虑所训练特征的<strong>序列相关性</strong>；可以用于多种PSG信号，<strong>泛化性</strong>强。</p>
<p>本文中提出了基于分层网络的新的分类方法，包括两步：综合特征学习阶段（自动提取特征矩阵）&amp;序列学习阶段（BLSTM和注意力层结合的多流网络进行序列学习）</p>
<p><strong>贡献：</strong></p>
<ol>
<li>提出了一种<strong>两阶段</strong>的网络结构，提高分类效果。一阶段用三级CNN学习网络特征，将其与手工特征融合；二阶段用多流RNN&amp;注意力机制发掘序列信息，建立“序列-序列”的映射，而不是睡眠阶段之间的一对一映射。</li>
<li>为了避免样本不均衡、过拟合问题，提高泛化能力，采用了一些<strong>学习策略</strong>：focal loss function，去除无用训练轮，选择性的模型储存策略。</li>
<li>提出的模型可以完成不同数据集、不同标准、信号特征和阶段划分的睡眠分期。在4个数据集上做了实验，证明了模型的前景和<strong>鲁棒性</strong>。</li>
</ol>
<h3 id="2-Methodology"><a href="#2-Methodology" class="headerlink" title="2. Methodology"></a>2. Methodology</h3><p>介绍了模型架构，手动设计特征和分层网络。</p>
<p><strong>A. 模型架构</strong></p>
<p>模型结构如图1，初始信号自动预处理生成网络输入，然后通过网络习得特征。特征训练过程中，从网络输入中提取手动设计特征，然后将二者融合得到综合特征。然后训练模型根据综合特征学习时间信息，将网络输入喂给模型，验证模型的可行性。</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/20210107132222.png" style="zoom:67%;" /></p>
<p><strong>B. 手动设计特征</strong></p>
<p>根据AASM标准，连续30s长的睡眠阶段被分为WAKE，REM，NREM1，NREM2，NREM3五类。根据R&amp;K标准，连续20s或30s的睡眠阶段被分为Wake, S1, S2, S3, S4, REM六类。每个阶段有自己的特点，即<strong>物理特征（如频率范围、振幅、某些特定波的持续时间</strong>），物理特征可通过手工设计提取出来，因此，<strong>基于睡眠医学先验知识提取手工特征</strong>是区分睡眠阶段的一种快速而简单的方法。</p>
<p>EEG EOG EMG信号去噪后进行手工特征提取，提取了122个特征（时域、频域、形态特征），如表1所示。滑窗自动提取，进行z-score归一化，以减少受试者之间生理差异和设备相关差异的影响。特征向量拼接起来，<strong>虽然网络习得的特征也很好，但是不能完全抛弃手工设计特征，因为这些特性与睡眠知识是一致的</strong>。</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/20210107132328.png" alt=""></p>
<p><strong>C. 网络结构</strong></p>
<p>特征学习阶段（阶段1）：三个filter分别学习细节特征、结构特征、形状特征，同时提取手工特征，然后进行融合；</p>
<p>多流序列学习阶段（阶段2）：获得混合特征矩阵，习得时序信息，如阶段转换规则；微调stage1模型，得到最终模型。</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/20210107132413.png" style="zoom:67%;" /></p>
<p><strong>1）Stage1</strong></p>
<p>CNN可以捕捉局部相关性和空间不变性，参数共享，可用于特征提取。设计了三级CNN结构（图3），有三个分支，分别<strong>捕捉细节特征、结构特征、形状特征（对应的filter size和步长不同）</strong>。每一个分支有4个卷积层，2个最大池化层，一个dropout层。然后拼接，全连接，输出。</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/20210107132455.png" alt=""></p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/20210107133736.png" style="zoom:67%;" /></p>
<p>标准化的<strong>手工特征</strong>也被加入网络中（图4，公式6-8）</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/20210107132717.png" alt=""></p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/20210107132742.png" style="zoom:67%;" /></p>
<p><strong>2）Stage2</strong></p>
<p>睡眠阶段有内部阶段相关性。阶段2主要捕捉时序信息，调整阶段1模型。LSTM能捕获序列之间依赖，选择性传递信息，<strong>BLSTM，输出同时受前后信息的影响</strong>。</p>
<p>样本不平衡可能导致有些阶段被<strong>忽略/错分</strong>。<strong>为了保留被忽视的阶段，采用注意力机制</strong>。注意力层可以<strong>辅助</strong>BLSTM捕捉阶段信息（如图5所示），可以加强阶段之间的联系，通过引入新训练变量来突出一些阶段。根据前面和后面的阶段来判断本阶段属于哪个类。</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/20210107132831.png" style="zoom:67%;" /></p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/20210107132858.png" style="zoom: 67%;" /></p>
<p>$h_t$是序列h中第t个阶段BLSTM的输出，W和b是序列h的权值和偏置，$I_t$是$\mu_t$的权值矩阵，$\alpha_t$是第t个阶段占的比例，$v_t$是注意力层的输出。</p>
<p>完整的阶段2如图6所示，数据分批输入。阶段2是多流结构，有3个数据通路。三个tensor（三个阶段1的输出）拼接，全连接层，BLSTM，注意力层。三个输出的维度相同，即特征提取、BLSTM、注意力层的提供相同数量的信息（在最后加权之前）。然后经过全连接、softmax提取信息，给出类别概率。</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/20210107133841.png" alt=""></p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/20210107132951.png" style="zoom: 67%;" /></p>
<h3 id="3-Experiment"><a href="#3-Experiment" class="headerlink" title="3. Experiment"></a>3. Experiment</h3><p>介绍数据和训练过程。</p>
<p><strong>A. 数据</strong></p>
<p>用147条整晚记录来评估模型。<strong>MASS有五个子集，子集内部同质，子集之间差距较大</strong>。SS2-SS5都是健康样本，用SS2-SS5进行训练。</p>
<p>SS2-SS5的属性如表2，选共同部分用于训练：<strong>C3 EEG，EOG，chin1 EMG</strong>（以256Hz频率采样），通过60hz陷波滤波器和带通滤波器进行去噪。所有信号被降采样到128hz，便于后续处理减少、计算复杂度。</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/20210107133025.png" alt=""></p>
<p>四个数据集的人口统计资料、五类睡眠阶段比例和总的test epoch数由表3给出。用LOSO（Leave One Subject Out ）来评估模型在四个子集上的性能。训练：验证：测试=k-2:1:1,本课题独立验证更适合实际应用场景。</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/20210107133051.png" alt=""></p>
<p><strong>B. 训练过程</strong></p>
<p><strong>1）训练参数</strong></p>
<p>阶段1：Adam，batchsize，lr，epochs，cross-entropy。</p>
<p>阶段2：两层BLSTM，Adam，batchsize，epochs，SL。同时考虑阶段的时序信息，微调阶段1参数。为了避免<strong>梯度爆炸</strong>，采用启发式梯度裁剪技术；用<strong>focal loss fuction</strong>量化真实标签和预测标签之间的一致性。FL如下：</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/20210107133913.png" style="zoom:70%;" /></p>
<p>其中$p_t$是每一类的概率，权重因子$\alpha$和集中参数$\gamma$解决<strong>样本不均衡</strong>问题、区分简单/困难例子，分别设置为0.25和2。dropout，L2正则化，这些超参数的值如表4。</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/20210107133940.png" style="zoom:67%;" /></p>
<p>用全局acc、F1-score、kappa系数，精度，recall，每一类的F1-score来<strong>评估</strong>。</p>
<p><strong>2）学习策略</strong></p>
<p><strong>epoch removal：</strong>从训练集中剔除了代表睡眠阶段转换的两个变化期，使模型充分研究<strong>纯特征</strong>。</p>
<p><strong>oversampling：</strong>根据最多epoch数来确定睡眠阶段，然后在训练集中重复地从小睡眠阶段中选取相同的epoch数，使得所有睡眠阶段都有<strong>相同数目的样本</strong>。所有阶段中的信息能被充分学习。</p>
<p><strong>model storage scheme：</strong>每训练一轮，如果满足要求，储存当前模型。该方法可以在不存在过拟合现象的前提下，<strong>尽量少存储模型</strong>，减少训练时间和存储空间。</p>
<h3 id="5-结果"><a href="#5-结果" class="headerlink" title="5. 结果"></a>5. 结果</h3><p>本文模型与目前的先进模型对比，探究模型各模块的效果。</p>
<p><strong>A. 睡眠阶段分期表现</strong></p>
<p>图7给出混淆矩阵，N1分类效果相对较差，</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/20210107133201.png" alt=""></p>
<p>评估指标如表5，<strong>N1分类效果差</strong>，N1在睡眠阶段中比例相对较低，比较难分类。在SS2-SS5上总体的acc、F1-scores和kappa系数分别在0.867~0.897、0.797~0.839、0.806~0.847。kappa系数说明：分类结果和专家意见一致；acc：对于具有不同特征的四个子集，acc高且稳定；F1-score：同时兼顾精度和召回率。</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/20210107133226.png" alt=""></p>
<p>图8给出了一个样本的睡眠图，分类结果和之前提到的阶段匹配规则基本一致，错分的基本上是把N1错分为其他类（与图7显示的结果一致）。</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/20210107133248.png" alt=""></p>
<p><strong>B. 与目前先进模型对比</strong></p>
<p>a). 三层CNN+SGD+Adam+cross entropy</p>
<p>b). ReNN(探测特征)+LSTM（序列数据学习）+SGD+cross entropy</p>
<p>c). CNN（表示学习模块，提取时间不变特征）+BLSTM（序列残差学习模块）+oversampling+Adam++cross entropy</p>
<p>d). EEG features+ stacked sparse autoencoders +L-BFGS+正则化</p>
<p>图9给出四种方法和我们的模型混淆矩阵：</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/20210107133319.png" alt=""></p>
<p>表5给出评估指标的表格：除了N1类的F1-score，其余指标都高于现有模型。结果说明：RNN适于发掘时序信息，<strong>特征提取对不同的类别贡献不同</strong>。用 Wilcoxon秩和检验探究我们的方法在acc上是否和另外四种有显著差异，表格说明我们的方法有<strong>显著提高</strong>。表6列出了反映了分类结果、时间复杂度、训练时间、测试时间的指标对比。模型越复杂，训练时间越长。</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/20210107133338.png" alt=""></p>
<p><strong>C. 模型各元素（模块）的表现</strong></p>
<p>提出的结构有4个关键点：三级CNN，手工设计特征，BLSTM，注意力层；以及学习策略。从完整模型中提取5个模型：</p>
<p>1). 三级CNN（没有手工设计特征）</p>
<p>2).先提取手工设计特征，再训练网络特征，并融合</p>
<p>3).stage1+BLSTM，无注意力层</p>
<p>4).stage1+stage2，无学习策略</p>
<p>5). stage1+stage2（含学习策略），即完整模型</p>
<p>图10给出混淆矩阵结果，三级CNN是模型的<strong>基础</strong>，对分类效果有比较大的影响；模型中每个元素都能提高分类效果。</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/20210107133359.png" alt=""></p>
<p>表7是各指标结果，显示完整的模型效果最好。2、3对比：学习策略的提升效果；12对比，手工设计特征的提升效果；注意力机制有效果；学习策略有用</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/20210107133422.png" alt=""></p>
<p><strong>D. 模型分析</strong></p>
<p>记录融合层中的权值分布。权值为正，正面影响；权值为负，负面影响。权值绝对值越大，影响越大，全连接层中的<strong>权值绝对值可以反应传递过来的信息流</strong>。提取出特征拼接之后的<strong>全连接层的权值，初步总结两类特征的贡献</strong>。网络训得的特征信息量如下：</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/20210107133443.png" style="zoom: 80%;" /></p>
<p>每个特征平均信息量T/1000.</p>
<p>提取了阶段2拼接之后的第一个全连接层的权值，信息总量和平均信息量如表8：</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/20210107133603.png" style="zoom:67%;" /></p>
<p><strong>网络训得的特征</strong>总量比手工设计特征，<strong>提供更多有效信息</strong>，网络训得的特征能保存形状信息（卷积核是定长一维张量），手工特征可能会忽略形状特点（压缩了信号信息）。但是<strong>平均手工特征</strong>更大，说明它<strong>也很重要</strong>。</p>
<p>注意力机制的信息总量大于BLSTM的，说明<strong>注意力机制提供了额外的信息</strong>。网络习得的特征和手工设计特征是平行输入的，stage1、BLSTM、注意力机制是级联的。后面模块包含了前面模块的信息。</p>
<p>加入手工设计特征后，后面的全连接层的权值被提取出来。图11给出了SS4中每个手工设计特征的相对信息量，<strong>不同滑窗大小、不同时刻下特征的贡献是相似的</strong>，MSE特征不能提供足够的信息，被过滤掉了。其中，前7个能区分五个睡眠阶段的特征是：EMG信号PSD平均功率、EMG信号峰值、肌电信号中PSD的平均功率、DFA在3个阶段上的标度指数、脑电图信号中PSD的峰值功率、脑电信号的频域差值分析、EOG信号的谱熵。</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/20210107133627.png" alt=""></p>
<p>网络习得的特征是随机抽取的，下标不固定，不能定量描述形态，很难总结每个特征的贡献。</p>
<h3 id="5-discussion-amp-future-work"><a href="#5-discussion-amp-future-work" class="headerlink" title="5. discussion&amp;future work"></a>5. discussion&amp;future work</h3><p><strong>手工设计特征</strong>不能被完全丢弃，不同特征可以通过合适的网络有效结合。实际上手工设计特征也经过一系列线性/非线性操作，<strong>其实也是在加深网络</strong>，因为网络可以同时进行不同深度的训练。</p>
<p>N1和N2<strong>错分</strong>，它们比较类似，专家通过前后信息来判断，所以引入<strong>序列学习</strong>可以提高分类效果。可以试图发现新的验证特征、探究N1的时间信息，或者寻找N1阶段的<strong>数据扩增</strong>方法，来提高效果。</p>
<p>网络习得的特征比手工设计特征表现力更强。我们推测是专家主要看波形，不能发现隐藏信息。手工设计特征间接形容形态，CNN<strong>直接提取形态信息</strong>（与专家方法一致）。</p>
<p><strong>深度学习在睡眠分期上有优势</strong>。从特征提取角度，CNN能提取不同的形态信息（与专家一致）；BLSTM更擅长发掘睡眠阶段之间的联系；结合手工设计特征，得到更全面的特征；注意力机制加强睡眠阶段之间的联系 ；各种学习策略提高模型的泛化性。</p>
<p>表9给出了传统睡眠分期方法和本方法的全面比较结果，说明<strong>手工设计特征有待提高</strong>。传统方法分类效果也不错，但是样本数量都比较小。手工设计特征需要特征选择过程（避免过拟合）。深度学习方法需要大量数据，<strong>若数据量小，也可以考虑传统方法</strong>。</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/20210107134033.png" alt=""></p>
<p>局限性和未来方向：深度学习框架可解释性相对较差；手工设计特征需要一些<strong>睡眠医学的知识</strong>；本文选用的是正常人数据，有睡眠疾病的人睡眠结构会更复杂、分类更难，更多关注<strong>有睡眠疾病的人患者</strong>的睡眠分期方法，检测相关睡眠疾病；<strong>数据扩增</strong>（如GAN，可以人工生成睡眠阶段使得阶段样本平衡）；解码网络映射关系，探究不同的阶段哪个特征最相关（比较困难），考虑通过模型可解释性/信息追踪来解决这个问题。</p>
<h3 id="6-Conclusion"><a href="#6-Conclusion" class="headerlink" title="6. Conclusion"></a>6. Conclusion</h3><p>本文利用EEG、EOG、EMG信号，基于综合特征学习和多流序列学习构造了层次神经网络来解决睡眠分期问题。第一阶段，用三级CNN提取特征，将其与手工设计特征融合；第二阶段用BLSTM和注意力机制进行分类。在四个数据集上进行实验，评估模型，acc达到0.878，F1-score达到0.818，优于目前的先进模型。分析了五个不同模块组合的模型，验证各部分的效果，说明所提出的模型是有效的，有全面地发掘睡眠信息的潜力。</p>
]]></content>
      <categories>
        <category>syd</category>
      </categories>
      <tags>
        <tag>睡眠分期</tag>
      </tags>
  </entry>
  <entry>
    <title>syd 【NIPS2019】TWNet:a Dynamic Time Warping Network</title>
    <url>/2021/01/07/SongYudan/%E3%80%90NIPS2019%E3%80%91notes_DTWNet%20a%20Dynamic%20Time%20Warping%20Network/</url>
    <content><![CDATA[<p>【NIPS2019】</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/20210107134144.png" style="zoom: 67%;" /></p>
<hr>
<h3 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h3><p>DTW常用于相似性度量，由于DTW对时间轴的规整不变性，可以提供信号间的<strong>差异测量</strong>。本文提出了ANN的新组件，利用DTW进行<strong>特征提取</strong>（以往常用DTW作为损失函数）。从理论上分析了DTW损失，用随机反向传播机制来提高DTW学习的准确率和效率。所提出的框架可用作数据分析工具，进行<strong>数据分解</strong>。</p>
<a id="more"></a>
<h3 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h3><p>相似性度量很重要，闵可夫斯基距离比较常用，$dist(x,y)=(\sum_{k=1}^{d}|x_k-y_k|^p)^{1/p}$（p=1，曼哈顿距离；p=2，欧氏距离）；马氏距离是扭曲的欧氏距离，$dist(x,y)=((x-y)^T\sum^{-1}(x-y))^{1/2}$。闵可夫斯基距离和马氏距离不能反应序列数据之间的<strong>真正相似性</strong>，DTW具有对时间规整的<strong>不变性</strong>。DTW还可作为<strong>特征提取</strong>工具，可以通过DTW计算定义预定义模式，后续可以用这些模式对时间数据进行分类。</p>
<p>DTW通过cost矩阵C、动态规划得到最佳归整路径：</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/20210107134212.png" style="zoom:80%;" /></p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/20210107134237.png" style="zoom:80%;" /></p>
<p>DTW虽然可以进行相似性评估、特征提取，但是对<strong>深度学习领域</strong>没有很大贡献。好的特征提取器是ANN的关。DTW有非线性变换特性（规整），提供了针对多普勒效应的目标总结，是潜在的ANN特征提取器。本文提出了DTWNet，<strong>有可学习DTW核的神经网络。</strong></p>
<p>主要贡献：</p>
<ol>
<li>在神经网络中应用<strong>可学习的DTW核</strong>来表现多普勒不变性；</li>
<li>采用基于规整路径的<strong>随机反向传播</strong>来计算动态规划的梯度，进而学习DTW核；给出了反向传播的<strong>收敛性</strong>分析；</li>
<li>首次对<strong>DTW损失函数</strong>进行理论分析；</li>
<li>提出了一种<strong>可微流DTW学习</strong>，来克服由标准DTW的全局对齐导致的局部特征缺失问题；</li>
<li>实证研究表明，该方法是有效的，并成功地利用<strong>DTW核捕获特征</strong>，还演示了一个<strong>数据分解</strong>应用。</li>
</ol>
<h3 id="2-Related-Work"><a href="#2-Related-Work" class="headerlink" title="2. Related Work"></a>2. Related Work</h3><p><strong>2.1 DTW简介</strong></p>
<p>DTW由于多普勒效应不变性，适于处理声学数据；处理ECG、EEG等生物信号来发现潜在疾病。DTW与预定义模式结合，是时序分类任务中一个强大的特征提取器。</p>
<p>DP时间复杂度高，而且DP是顺序过程，所以DTW计算不能并行，已有一些加速计算的技巧。</p>
<p>2-D DTW：DTW扩展到二维可用于图像匹配</p>
<p><strong>2.2 SPRING算法：DTW的流版本</strong></p>
<p>为了处理DTW度量下的流数据，[18]提出了一种DTW的变体——SPRING。原始DTW找到从两个序列<strong>起始到结束</strong>的最佳对齐；流版本试图从一个给定的序列中识别所有接近于某个给定模式的<strong>子序列</strong>。SPRING算法复杂度$O(nl)$，与标准DTW一致。</p>
<p>SPRING核原始DTW计算有<strong>两个不同</strong>：首先，它在模式前添加一个通配符（模式的起点能匹配输入序列的<strong>任何位置</strong>）；利用辅助矩阵记录动态规划矩阵中每一个入口的源，这个<strong>源矩阵</strong>记录每一条候选路径，可以从尾端回溯。</p>
<p><strong>2.3 DTW损失函数</strong></p>
<p>DTW是顺序过程，计算DP矩阵过程中每一步都要最小化，最小化操作是不连续的，梯度和次梯度都不好定义。可以用<strong>soft-min</strong>代替min操作，[19]给出了soft-min的梯度，用小波学习来提高测试数据有限的时序分类效果。还有研究利用DTW中最小算子的连续松弛来解决视频对齐和分割问题。采用soft-min方法，[4]说明<strong>DTW作为损失函数比欧氏距离更好</strong>。</p>
<h3 id="3-Proposed-DTW-Layer-and-its-Backpropogation"><a href="#3-Proposed-DTW-Layer-and-its-Backpropogation" class="headerlink" title="3. Proposed DTW Layer and its Backpropogation"></a>3. Proposed DTW Layer and its Backpropogation</h3><p>DTW层包括多个提取特征的DTW核，每个核产生一个通道，产生一个DTW距离值。如果有滑窗，每个核会产生一个距离序列（像卷积核一样），DTW层可以接线形层，得到分类/回归结果。算法1给出分类任务上的DTWNet示例。</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/20210107134302.png" style="zoom:80%;" /></p>
<p><strong>梯度计算和反向传播</strong></p>
<p>DP过程后得到规整路径，序列长n，核长l，路径最长不超过$(n+l)$，DTW距离的平方为：</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/20210107134321.png" style="zoom:80%;" /></p>
<p>路径已经确定，只需<strong>沿着路径微分</strong>，DTW距离对x求导：</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/20210107134348.png" style="zoom:80%;" /></p>
<p>min操作没有梯度，直接进行自动微分会导致很大的方差，可以用softmin来解决这个问题，soft-min复杂度$O(nl)$。只依赖于路径上的元素，无需对整个cost矩阵的所有entry进行求导，只对确定路径求导$O(n+l)$。每一次迭代DP扭曲路径不同，也会有方差，所以BP被看作一个随机过程。</p>
<p><strong>时间复杂度：</strong>DP时间复杂度$O(nl)$，梯度计算时间复杂度$O(n+l)$</p>
<h3 id="4-DTW-Loss-and-Convergence"><a href="#4-DTW-Loss-and-Convergence" class="headerlink" title="4. DTW  Loss and Convergence"></a>4. DTW  Loss and Convergence</h3><p>给定输入序列，目标是得到和y最佳对齐（通过最小化dtw距离）的核。核x随机初始化，通过梯度下降来学习，$d=H_yx$是动态规划得到的DTW距离。</p>
<p><strong>定义1：</strong>所有可能的归整路径</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/20210107134415.png" style="zoom:80%;" /></p>
<p>$H_yx$和函数空间中的某个函数$f_y^{(u)}(x)$相等，<strong>所以用函数空间中的函数集合来估计$H_yx$</strong>（每一个x对应一个样本函数）。用$f_y^{(u)}(x)$的梯度进行梯度下降，问题是它的梯度是否等于$H_yx$的梯度。</p>
<p>$H_yx$在x的空间上不是处处光滑的，存在一些x：</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/20210107134435.png" style="zoom: 80%;" /></p>
<p>动态规划矩阵在每一步都有3个可选方向，在边界处只有1个可选方向，所以有：</p>
<p><strong>引理1：</strong>归整路径数$|F_y|&lt;3^{n+l}$，其中n+l是最长归整路径</p>
<p>x空间被分成区域，在某个区域，可以用$f_y^{(u)}(x)$来估计$H_yx$。用2范数的平方作为DTW loss，则$H_yx$是x的<strong>分段二次函数</strong>，如果用绝对值作为DTW loss，则$H_yx$是x的<strong>分段线性函数</strong>。</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/20210107134501.png" style="zoom:80%;" /></p>
<p>图2a，2b给出了示意。生成点来计算DTW loss，x长度为6，y长度为10，只变化x中间的两个元素，便于画出三维图像。图2a说明2范数作为DTW loss时$H_yx$是x的分段二次函数，2b是线性分段函数情况。</p>
<p><strong>逃离局部最优</strong></p>
<p>有一些工作给出了非凸神经网络损失函数全局收敛性的证明，本文通过利用损失函数的二次分段（线性分段），区域数上界是$O（3^{n+l}）$。先分析用<strong>标准梯度下降分析逃离u来进入它的邻域v</strong>，假设$y_{p:p+q}$和$x_k$对齐，可以得到u的局部二次函数，以及对$x_k$的偏导：</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/20210107134524.png" style="zoom:80%;" /></p>
<p>令偏导等于0，得到稳定点：</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/20210107134557.png" alt=""></p>
<p>相邻区域的函数$f<em>y^{v}$除了$y</em>{p+q+1}$的对齐外，都和$f_y^{u}$相同：</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/20210107134618.png" style="zoom:80%;" /></p>
<p>同理，该邻域左侧相邻区域的的稳定点如下：</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/20210107134638.png" style="zoom:80%;" /></p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/20210107134501.png" style="zoom:80%;" /></p>
<p>考虑从u跳到v（u是碗状的，想跳出），区域v有三种情况：</p>
<ol>
<li>v的稳定点不在区域v内，在它的左侧。此时全局最优解一定不在v内，u内有一部分比它更小，如果跳到v，梯度会再次让它跳回u；</li>
<li>u和v都是碗状的，需要从u到v，起点在最低点的左侧（如红色位置所示），否则会跳到w而不是v，为了保证一步跳到v，至多需要$(x<em>k^{(v)*}-x</em>{hat})$；</li>
<li>v不是碗状的，$x<em>k^{(v)<em>}$在v的右端，走$(x_k^{(v)</em>}-x</em>{hat})$来跳到v，如果v的右邻域是碗状的，则v的右邻域更小，即使v的右邻域不是碗状的，组合区域[v, v+]也可以看作是准碗或扩展的v，所以跳到此处也是合理的。</li>
</ol>
<p>考虑左邻域w，w的稳定点在w内或w左侧时，稳定点肯定在起点左侧；w的稳定点在w右侧时，把[w,u]合并为u’，u’的左邻域为w‘，上述分析对这三个新的区域仍然成立，所以有以下定理：</p>
<p><strong>定理1.</strong>假设起点在u区域（由公式5定义）内，x和y的长度分别为n和l，为了跳出u区域到达紧邻的右侧区域，步长期望满足$E(\eta)&gt;l/(2n)$</p>
<p>有若干个y，距离函数求和，梯度求和，通过小批量随机梯度下降来更新x。随机梯度是无偏估计，方差代表跳出局部最优解的能力。</p>
<h3 id="5-Streaming-DTW-Learning"><a href="#5-Streaming-DTW-Learning" class="headerlink" title="5. Streaming DTW Learning"></a>5. Streaming DTW Learning</h3><p>一个ECG序列有多个心跳脉冲，希望DTW核学到心跳脉冲模式，而端到端的DTW会使DTW核与<strong>整个序列</strong>对齐而不是<strong>一个脉冲</strong>。如果核很短，没学到有用的东西。为了解决这个问题，用SPRING算法来输出对齐子序列的模式（DTW核）：</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/20210107134721.png" style="zoom:90%;" /></p>
<p>其中i和y的长度待优化。</p>
<p>流版本试图从一个给定的序列中识别所有接近于某个给定模式的<strong>子序列</strong>。SPRING给出最佳匹配的子序列以及一系列有最小DTW距离的规整路径，提出两个机制：机制一，预设常数k，让SPRING选出<strong>k个最优</strong>的归整路径（k个不同的非重叠的、与模式x的DTW距离最小的子序列）；机制二，不是指定路径数，设置参数$\epsilon$，给出<strong>距离小于$(1+\epsilon)d^*$的路径</strong>（$d^*$是最佳归整路径的DTW距离）。随机/平均作为DTW计算结果。本文中，$\epsilon$设为0.1，随机采样。</p>
<p><strong>流DTW的正则化矩阵</strong></p>
<p>SPRING希望核x去学习输入序列中的<strong>重复模式</strong>，对模式的长度没有限制。输入数据中总会出现没有包含太多有效信息的公共部分，不加正则化的核很容易捕捉<strong>无用模式并陷入局部最优值</strong>。加入正则化来解决这个问题：</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/20210107134741.png" style="zoom:80%;" /></p>
<p><strong>正则化会得到“完整”的模式</strong>，模式的起始相隔比较近。如图3a所示，有上半个/下半个半圆待学习，不进行正则化的话，核只能学到部分模式；加入弱正则化，学到更完整的模式；合适的$\alpha$能捕捉到完整的形状。</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/20210107134810.png" style="zoom: 67%;" /></p>
<h3 id="6-Experiments-and-Applications"><a href="#6-Experiments-and-Applications" class="headerlink" title="6. Experiments and Applications"></a>6. Experiments and Applications</h3><p>将本方法与现存的方法对比，将端到端的DTW核称为Full DTW，将流版本称为 SPRING DTW。</p>
<p><strong>6.1 与卷积核的对比</strong></p>
<p>类别1有<strong>半个方形</strong>信号模式，类别2有下方的<strong>三角</strong>信号模式，模式的位置和长度随机，模式不重叠，图4a给出一些样本。</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/20210107134837.png" style="zoom: 77%;" /></p>
<p>输入序列有100个点，模式长度从10-30不等，训练集100条（1：1），测试集100条（1：1），我们比较了Full DTW、SPRING DTW和卷积核，核的长度为10，再加三层线性层，</p>
<p>图4b给出了收敛后的习得的DTW核，Full DTW试图捕捉<strong>整个</strong>序列，整个序列有两个模式，Full DTW核也有<strong>两个峰</strong>；SPRING DTW只匹配<strong>部分模式</strong>，呈扫描状；图4c和4d给出了acc和loss曲线，两个DTW的曲线几乎一致，只画出了Full DTW的图。令人意外，卷积核未能到100%，MLP表现最差。可以将这个方法扩展到多元时间序列（无需作大的修改）</p>
<p><strong>6.2 梯度计算评估</strong></p>
<p>进行质心计算，评估提出的<strong>BP机制的效率和准确性</strong>，使用了UCR数据集，将我们的方法和SoftDTW、DBA、SSG进行对比，5次实验取平均。</p>
<p>质心实验旨在找到每一类输入序列的质心，计算DTW loss，loss越小，表现越好。</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/20210107134920.png" style="zoom:67%;" /></p>
<p>表1给出了实验结果，Win意思是在85个数据集上达到最小loss的次数，还给出了平均排名、平均loss，我们的方法性能比较好。</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/20210107135113.png" style="zoom:67%;" /></p>
<p><strong>6.3 DTW分解的应用</strong></p>
<p>将DTWNet作为时间序列<strong>数据分解</strong>工具，设计五个DTW层，每层有一个DTW核。关键是将第i层的残差向前传到下一层。计算DTW距离会得到规整路径，从$y<em>j$中减去对应的$x</em>{i,j}$</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/20210107135138.png" style="zoom: 67%;" /></p>
<p>图5阐释了分解的影响，核0-核4对应第一层到最后一层，训练目标是最小化网络输出的残差，训练一定轮数后，不同层的核形成不同的形状，核0是<strong>低频</strong>的、数据<strong>整体</strong>形状，核4形状是<strong>高频</strong>的、<strong>曲折</strong>形状。<strong>层数越深，越能学到高频的部分</strong>，可被用作分解工具，可解释性强。</p>
<h3 id="7-Conclusions-and-Future-Work"><a href="#7-Conclusions-and-Future-Work" class="headerlink" title="7. Conclusions and Future Work"></a>7. Conclusions and Future Work</h3><p>将DTW核应用为<strong>特征提取器</strong>，提出了DTWNet框架。为了实现反向传播，通过动态规划评估了DTW距离，沿着确定规整路径的计算梯度，给出了DTW作为损失函数的理论研究，将DTW损失定义为分段二次/线性函数，描述了不同情况下的步长（为了跳出局部最优）。实验显示，在某些任务中DTW核比标准的卷积核表现好，评估了梯度计算核反向传播的有效性，给出了数据分解的应用。</p>
<hr>
<p>本文由腾讯AI Lab主导，与康涅狄格大学合作完成。深度神经网络在处理时间序列数据时，传统的闵可夫斯基距离不适合作为反应序列相似度的损失函数，而动态时间规整算法（DTW）可以更好地计算序列距离，<strong>因此可以用作深度网络中的损失函数和特征提取算子</strong>。<br>本文提出了一种新的估计方法，使得DTW在作为算子时可以估计输入的梯度，从而实现神经网络中的反向传播。该方法首次分析了DTW作为损失函数的函数形态和应用梯度下降法的收敛性，并且首次提出了基于部分序列匹配的DTW梯度更新算法。实验结果表明，该方法作为一种新的特征抽取手段，可以<strong>更好地提取时间序列数据中的特征</strong>。此外，本文提出的梯度估算方法在实验中展现了良好的<strong>收敛性</strong>。本文也创造性地提出了该方法在<strong>数据分解</strong>上的拓展性应用。</p>
]]></content>
      <categories>
        <category>syd</category>
      </categories>
      <tags>
        <tag>时间序列</tag>
      </tags>
  </entry>
  <entry>
    <title>syd【TNSRE 2021】AttnSleep:基于注意力的单导EEG睡眠分期方法</title>
    <url>/2022/02/23/SongYudan/%E3%80%90TNSRE2021%E3%80%91%E5%9F%BA%E4%BA%8E%E6%B3%A8%E6%84%8F%E5%8A%9B%E7%9A%84%E5%8D%95%E5%AF%BCEEG%E7%9D%A1%E7%9C%A0%E5%88%86%E6%9C%9F%E6%96%B9%E6%B3%95/</url>
    <content><![CDATA[<h3 id="0-Abstract"><a href="#0-Abstract" class="headerlink" title="0. Abstract"></a>0. Abstract</h3><p>睡眠阶段自动分类对睡眠质量的监测具有重要意义，本文提出了一种基于注意力的深度网络<strong>AttnSleep</strong>，利用<strong>单导EEG</strong>进行<strong>睡眠分期</strong>。用多分辨率卷积网络（<strong>MRCNN</strong>）提取特征，通过自适应特征重校准(<strong>AFR</strong>)对特征之间的依赖进行建模；第二模块是时间上下文编码器（<strong>TCE</strong>），用多头注意机制（MHA）来捕获所提取特征之间的时间关系，在三个公开数据集上评估了模型性能。</p>
<a id="more"></a>
<h3 id="1-Intorduction"><a href="#1-Intorduction" class="headerlink" title="1. Intorduction"></a>1. Intorduction</h3><p>研究<strong>意义</strong>：睡眠的重要性；PSG人工分类；</p>
<p>研究<strong>现状</strong>：特征工程+分类器；深度学习方法，CNN，CNN+RNN（时间相关性），注意力机制；类不均衡问题，过采样。</p>
<p>本文<strong>贡献</strong>：所以本文提出了AttnSleep，MRCNN提取高频、低频特征，AFR对特征依赖进行建模，加强特征学习；时间上下文编码器（TCE），多头注意力+因果卷积来捕获特征中的时间相关性；针对类不均衡问题设计了类相关的损失函数；在三个公开数据集上进行实验。</p>
<h3 id="2-Method"><a href="#2-Method" class="headerlink" title="2. Method"></a>2. Method</h3><h4 id="2-1-总框架"><a href="#2-1-总框架" class="headerlink" title="2.1 总框架"></a>2.1 总框架</h4><p>总体框架如图1，由<strong>三部分</strong>组成：<strong>1)</strong>特征提取块，<strong>2)</strong>时间上下文编码块，<strong>3)</strong>分类块。MRCNN提取高频、低频特征，ARF自适应地选择和突出最重要的特征；TCE模块来捕获特征中的时间相关性；softmax进行分类，类感知的损失函数。</p>
<p><img src="C:\Users\Meow\AppData\Roaming\Typora\typora-user-images\image-20220220110924685.png" alt="image-20220220110924685"></p>
<h4 id="2-2-特征提取"><a href="#2-2-特征提取" class="headerlink" title="2.2 特征提取"></a>2.2 特征提取</h4><h5 id="2-2-1-MRCNN"><a href="#2-2-1-MRCNN" class="headerlink" title="2.2.1 MRCNN"></a>2.2.1 MRCNN</h5><p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/image-20220220112301982.png" alt="image-20220220112301982"></p>
<p>不同的睡眠阶段具有不同的频率范围，所以两个不同卷积核的卷积分支，探索不同的频带，<strong>捕获不同的时间步长范围</strong>（4s，0.5s）；EEG具有非平稳特征，不同类型的特征组合对非平稳特征信号有重要意义。</p>
<p>在MRCNN模块中使用<strong>GELU</strong>激活函数，因为它允许输入的一些负权值通过，对很小的负值有较强的控制力（与leakyrelu等相比）</p>
<h5 id="2-2-2-ARF"><a href="#2-2-2-ARF" class="headerlink" title="2.2.2 ARF"></a>2.2.2 ARF</h5><p>AFR的目的是对MRCNN学习的特征进行重新校准，以提高其性能。通过residual SE块对特征之间的依赖性进行建模，自适应地选择最具<strong>鉴别</strong>性的特征。</p>
<p>在residualSE块中，包含两层<strong>卷积</strong>（kerner和stride均为1）；再用自适应平均<strong>池化</strong>来压缩全局的空间信息得到s，经过线性层-激活函数-线性层-激活函数 得到e，</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/image-20220222214454068.png" alt="image-20220222214454068" style="zoom:80%;" /></p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/image-20220222214524168.png" alt="image-20220222214524168" style="zoom:80%;" /></p>
<p>利用e对F进行放缩，得到加权求和：</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/image-20220222214906606.png" alt="image-20220222214906606" style="zoom:80%;" /></p>
<p>shortcut连接，将原始输入I和residualSE的输出相加，得到ARF最终的输出：</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/image-20220222215215070.png" alt="image-20220222215215070" style="zoom:80%;" /></p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/image-20220222213916364.png" style="zoom:80%;" /></p>
<blockquote>
<p>“Squeeze-and-Excitation(SE)”单元，对通道间的依赖关系进行建模，可以自适应的调整各通道的特征响应值；学习每个通道的重要程度，增强有用的特征，抑制无用的特征</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/image-20220222215714918.png" alt="image-20220222215714918" style="zoom: 80%;" /></p>
<p>SE block主要由三部分构成，Squeeze操作,Excitation操作，Fscale操作。</p>
<p>首先，Ftr把输入的X映射为特征图U，Ftr可以是一个最常见的卷积操作或者其他操作。</p>
<p>其次，Squeeze操作对U进行一个全局的池化操作，比如最大池化或者平均池化(WxH空间范围内进行池化)，产生一个embedding（1x1xC）。</p>
<p>再次，Excitation操作将上面产生的embedding进行一系列非线性映射(比如FC+RELU+FC)，最后跟一个sigmoid得到每个通道的权重。</p>
<p>最后，将上面得到的每个通道的权重作用于U，对每个通道的U进行加权求和。至此，就完成了整个SE block的映射。</p>
<p><strong>核心思想是不同通道的权重应该自适应分配，由网络自己学习出来。</strong></p>
<p><a href="https://zhuanlan.zhihu.com/p/70881455">https://zhuanlan.zhihu.com/p/70881455</a></p>
</blockquote>
<h4 id="2-3-TCE（时间上下文编码器）"><a href="#2-3-TCE（时间上下文编码器）" class="headerlink" title="2.3 TCE（时间上下文编码器）"></a>2.3 TCE（时间上下文编码器）</h4><p>TCE目的是捕获提取<strong>特征中的时间依赖性</strong>，TCE层由多头注意(MHA)层、归一化层和FC层组成，该结构重复两次，</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/image-20220220145538499.png" alt="image-20220220145538499"></p>
<h5 id="2-3-1-自注意力"><a href="#2-3-1-自注意力" class="headerlink" title="2.3.1 自注意力"></a>2.3.1 自注意力</h5><p>SA给感兴趣的区域赋予较高的权重，不感兴趣的区域赋予较低的权重，量化<strong>输入特征之间</strong>的相互依赖。</p>
<p>将原始输入z通过$\phi$转换到另一个空间（此处的$\phi$为因果卷积），计算第i个特征和第j个特征之间的<strong>attention score</strong>（相关度、权重），并进行归一：</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/image-20220222124458946.png" alt="image-20220222124458946" style="zoom:80%;" /></p>
<p>第i个特征的新表示是<strong>加权和</strong>：</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/image-20220222124824623.png" alt="image-20220222124824623" style="zoom:80%;" /></p>
<blockquote>
<p>自注意力：<a href="https://blog.csdn.net/rocking_struggling/article/details/106201849">https://blog.csdn.net/rocking_struggling/article/details/106201849</a></p>
</blockquote>
<h5 id="2-3-2-多头注意力"><a href="#2-3-2-多头注意力" class="headerlink" title="2.3.2 多头注意力"></a>2.3.2 多头注意力</h5><p>MHA是SA的进阶版：将输入特征划分为<strong>多个子空间</strong>，再将多个子空间的结果<strong>拼接</strong>起来。</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/image-20220222123523566.png" alt="image-20220222123523566" style="zoom:80%;" /></p>
<p>先经过因果卷积（捕获位置信息）得到X-hat，三个X-hat作为输入，</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/image-20220220154458646.png" alt="image-20220220154458646" style="zoom:80%;" /></p>
<p>将X-hat分解到H个子空间，</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/image-20220220155316071.png" alt="image-20220220155316071" style="zoom:80%;" /></p>
<p>将H个表示拼接起来，</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/image-20220220155340802.png" alt="image-20220220155340802" style="zoom:80%;" /></p>
<h5 id="2-3-3-add-amp-normalize"><a href="#2-3-3-add-amp-normalize" class="headerlink" title="2.3.3 add&amp;normalize"></a>2.3.3 add&amp;normalize</h5><p>通过残差连接将前面的输入与后面的输出相加、标准化，帮助模型利用到<strong>底层</strong>的特征，标准化也能<strong>加速</strong>训练过程。</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/image-20220222132430242.png" alt="image-20220222132430242" style="zoom:80%;" /></p>
<h4 id="2-4-类感知的损失函数"><a href="#2-4-类感知的损失函数" class="headerlink" title="2.4 类感知的损失函数"></a>2.4 类感知的损失函数</h4><p>标准的多类交叉熵损失函数对每个类分错的惩罚是相同的；在此基础上，为每个类设置一个<strong>权重</strong>w：</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/image-20220220163514761.png" alt="image-20220220163514761" style="zoom: 80%;" /></p>
<p>权值和该类出现的<strong>频次、区分的难易程度</strong>有关，样本量越少，分类难度越大，权重越大，$\mu_k$是超参数。</p>
<p>N1和N3较少，但是N3容易区分，N1难区分，所以$\mu_k$如下，a&lt;b&lt;c，通过除以K使得$\mu_k$&lt;1，对样本数量比进行放缩：</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/image-20220222134939389.png" alt="image-20220222134939389" style="zoom:80%;" /></p>
<h3 id="3-实验结果"><a href="#3-实验结果" class="headerlink" title="3. 实验结果"></a>3. 实验结果</h3><h4 id="3-1-数据集-amp-指标"><a href="#3-1-数据集-amp-指标" class="headerlink" title="3.1 数据集&amp;指标"></a>3.1 数据集&amp;指标</h4><p>sleepEDF20；sleepEDF78；SHHS</p>
<p>ACC ；<strong>MF1</strong>； Cohen Kappa (κ)； <strong>MGm</strong></p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/image-20220222140441122.png" alt="image-20220222140441122" style="zoom:80%;" /></p>
<h4 id="3-4-baseline对比"><a href="#3-4-baseline对比" class="headerlink" title="3.4 baseline对比"></a>3.4 baseline对比</h4><p>DeepSleepNet； SleepEEGNet；ResnetLSTM ；MultitaskCNN；SeqSleepNet；20折交叉验证，训练100轮，超参数设置。</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/image-20220220172854286.png" alt="image-20220220172854286"></p>
<p>AttnSleep优于其他方法，且训练时间更短（无LSTM）；在MF1和GMm指标上更优，说明有效地解决了类不均衡问题。</p>
<h4 id="3-5-消融实验"><a href="#3-5-消融实验" class="headerlink" title="3.5 消融实验"></a>3.5 消融实验</h4><p>AttnSleep由MRCNN、AFR和TCE模块以及类感知损失函数组成，消融实验的几个模型为：MRCNN  MRCNN+ARF MRCNN+TCE   MRCNN+AFR+TCE  AttnSleep</p>
<p><img src="https://gitee.com/meow3009/paper_pic/raw/master/img/image-20220220175454471.png" alt="image-20220220175454471"></p>
<p>TCE比ARF还重要；MF1和GMm指标在加入类感知的损失函数时大幅提升，有效解决了类不均衡问题。</p>
<h3 id="5-结论"><a href="#5-结论" class="headerlink" title="5. 结论"></a>5. 结论</h3><p>提出了基于注意力的单导EEG睡眠分期架构AttnSleep，基于MRCNN和ARF提取特征，TCE模块中利用MHA捕获所提取特征之间的时间相关性，设计类感知的损失函数，解决类不均衡问题，并在三个公开数据集上进行了对比实验、消融实验，证明了该模型的有效性。</p>
<hr>
<p>epoch之间的依赖性；一个epoch内部</p>
]]></content>
      <categories>
        <category>syd</category>
      </categories>
      <tags>
        <tag>EEG</tag>
        <tag>睡眠分期</tag>
      </tags>
  </entry>
  <entry>
    <title>wt【ICLR2022】Amomaly Transformer</title>
    <url>/2022/03/02/WuTao/ANOMALY%20TRANSFORMER%20TIME%20SERIES%20ANOMALY%20DETECTION%20WITH%20ASSOCIATION%20DISCREPANCY/</url>
    <content><![CDATA[<p>时间序列异常点的无监督检测是一个具有挑战性的问题，它需要模型推导出一个可识别的准则。以往的方法主要是通过学习点表示或成对关联来解决这一问题，但这两种方法都不足以对于复杂情况进行检测。近年来，Transformers在点态表示和成对关联的统一建模中表现出了巨大的威力，我们发现每个时间点的自我注意权重分布可以体现出与整个序列的丰富关联。我们的主要观察结果是，由于异常的罕见性，从异常点到整个序列建立非平凡的关联非常困难，因此，异常的关联应主要集中在其相邻的时间点上。这种相邻的关联性偏差意味着一种基于关联的标准，可以在正常点和异常点之间进行固有的区分，我们通过关联差异来强调这一点。在技术上，我们提出了一种新的异常注意机制来计算关联差异的  Anomaly Transformer。设计了一种极大极小策略来增强关联差异的正常-异常区分能力。</p>
<a id="more"></a>
<h2 id="1、INTRODUCTION"><a href="#1、INTRODUCTION" class="headerlink" title="1、INTRODUCTION"></a>1、INTRODUCTION</h2><p>现实世界中的系统总是以连续的方式工作，它可以生成由多个传感器监测的多个连续测量，如工业设备、空间探测器等。从大规模系统监测数据中发现故障可以简化为从时间序列中检测异常时间点，这对于确保安全和避免经济损失是非常有意义的。但异常通常很罕见，并且被大量的正常点隐藏，这使得数据标记困难且昂贵。因此，我们将重点放在<strong>无监督的时间序列异常检测</strong>上。</p>
<p>无监督时间序列异常检测在实践中极具挑战性。模型应该通过无监督任务从复杂的时间动态中学习信息表示。不过，它也应该有能力推导出一个可区分的标准，可以从大量正常时间序列中检测罕见的异常。各种经典异常检测方法提供了许多无监督的范例，但是经典异常检测方法（例如LOF、OC-SVM）很少考虑时间信息，这使得他们在时序场景中应用受限。</p>
<p>因此研究人员开始将目光投向深度学习领域，往往是通过循环网络（RNN）学习时序数据点级别的表征，进而依靠重建或预测误差（自回归）进行判定，这里，一个自然而实用的异常检测标准是逐点重建或预测误差。然而，由于异常的罕见性，对于复杂的时间模式，逐点表示的信息较少，并且可以由正常的时间序列数据主导，使得异常不易区分。此外，重建或预测误差是逐点计算的，这无法提供对时间上下文信息的全面描述。 </p>
<p>另一类主要的方法是基于显式关联建模来检测异常。向量自回归和状态空间模型属于这一类。通过将不同时间点的时间序列表示为顶点，并通过随机游走检测异常，该图也被用于明确捕捉关联（Cheng等人，2008；2009）。一般来说，这些经典方法很难学习信息表示和对细粒度关联建模。最近，图形神经网络（GNN）已被应用于学习多元时间序列中多变量之间的动态图，虽然学习到的图更具表现力，但仍然局限于单个时间点，这对于复杂的时间模式来说是不够的。此外，基于子序列的方法通过计算子序列之间的相似性来检测异常（Boniol&amp;Palpanas，2020）。在探索更广泛的时间背景时，这些方法无法捕捉每个时间点和整个序列之间的细粒度时间关联</p>
<p>因此，如何获取更具信息含量的表征，进而定义更加具有区分性的判据对于时序异常检测尤为关键。</p>
<p>transformer的成功归功于对序列长程全局依赖的建模学习（global representation and long-range relation），我们发现每个时间点的时间关联（association）都可以从自我注意图中获得，该图表现为其关联权重在时间维度上对所有时间点的分布。每个时间点的关联分布可以为时间上下文提供更详细的描述，指示动态模式，例如时间序列的周期或趋势。我们将上述关联分布命名为序列关联（series-association），可通过transformer从原始序列中发现</p>
<p>同时，相比于正常点来说，异常点很难与序列的所有点都构建很强的关联，且由于连续性往往更加关注邻近区域。异常关联应集中在相邻时间点， 这些时间点更有可能包含类似的异常模式。这种相邻的关联性偏差称为先验关联（prior-association）。 相比之下，主要的正常时间点可以发现与整个序列的信息关联，而不限于相邻区域。基于这一观察，我们试图利用关联分布的正常异常区分能力。这为每个时间点带来了一个新的异常标准，该标准通过每个时间点的先验关联与其序列关联之间的距离来量化，称为关联差异。如上所述，由于异常的关联更可能是相邻的，因此异常将呈现比正常时间点更小的关联差异。 </p>
<p>基于上述观察，我们提出了Anomaly Transformer模型用于建模时序关联，为了计算关联差异，我们将自我注意机制改进为异常注意，它包含两个分支结构，分别对每个时间点的先验关联和序列关联进行建模。先验关联使用可学习的高斯核表示每个时间点的邻接关联偏差，而序列关联对应于从原始序列中学习的自我注意权重。 同时利用极小极大（Minimax）关联学习策略进一步突出正常、异常点之间差别，实现了基于关联差异（Association Discrepancy）的时序异常检测。Anomaly Transformer在不同领域的5个数据集上都取得了SOTA的效果。</p>
<h2 id="2、方法："><a href="#2、方法：" class="headerlink" title="2、方法："></a>2、方法：</h2><p>作者强调无监督时间序列异常检测的关键是学习信息表示和找到可区分的标准。我们提出了Anomaly Transformer 来发现更多信息关联，并通过学习关联差异来解决这个问题，</p>
<p>Anomaly transformer模型包含用于建模时序关联的Anomaly-Attention，其整体结构是Anomaly-Attention和前馈层的交替堆叠，这有利于模型从多层次深度特征中学习潜在的时序关联。</p>
<p>如下图所示，Anomaly-Attention（左）同时建模了数据的先验关联（Prior-Association，即更关注邻近区域的先验）和序列关联（Series-Association，即从数据中挖掘的依赖）。除了重建误差之外，我们的模型还采用了极小极大策略（Minimax）用于进一步增大异常点和正常点所具有的关联差异的差距。该策略带有一个特殊设计的停止梯度机制（灰色箭头），以约束先验关联和序列关联，从而获得更明显的关联差异。 </p>
<p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/image-20220302171532932.png" alt="image-20220301223654604"></p>
<h3 id="2-1-Anomaly-Attention的具体设计"><a href="#2-1-Anomaly-Attention的具体设计" class="headerlink" title="2.1 Anomaly-Attention的具体设计"></a>2.1 Anomaly-Attention的具体设计</h3><p>我们提出的一种新的注意力机制Anomaly-Attention，用于统一建模先验关联和序列关联，进而方便关联差异的计算。</p>
<ul>
<li><p>对于先验关联<img src="https://www.zhihu.com/equation?tex=P%5El" alt="[公式]">，我们采用了可学习的高斯核函数，其中心在对应时间点的索引上。这种设计可以利用高斯分布的单峰特点，使数据更加关注邻近的点。同时，为了使得先验关联能够适应不同的时序模式，高斯核函数包含可学习的尺度参数<img src="https://www.zhihu.com/equation?tex=%5Csigma" alt="[公式]">。</p>
</li>
<li><p>对于序列关联<img src="https://www.zhihu.com/equation?tex=S%5El" alt="[公式]">，它是由标准Transformer中注意力计算获得，一个点的序列关联即是该点在注意力矩阵中对应行的注意力权重分布。该分支是为了挖掘原始序列中的关联，让模型自适应地捕捉最有效果的关联。</p>
<p>与逐点表征相比，我们的两种关联都很好地表示了每个点在时间维度上的依赖，这使得表征具有了更丰富的信息。它们也分别反映了邻近先验和习得的真实关联。这两者之间的差异，即为关联差异（Association Discrepancy)，可以天然地将正常点和异常点区分开来。</p>
</li>
</ul>
<p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/image-20220302171549339.png" alt="image-20220302171549339"></p>
<h4 id="2-1-1-关联差异（Association-Discrepancy）"><a href="#2-1-1-关联差异（Association-Discrepancy）" class="headerlink" title="2.1.1 关联差异（Association Discrepancy）"></a>2.1.1 <strong>关联差异（Association Discrepancy）</strong></h4><p>通过上面的网络结构获得了<strong>Prior-association</strong> <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BP%7D%5El" alt="[公式]">和<strong>Series-association</strong><img src="https://www.zhihu.com/equation?tex=S%5El" alt="[公式]">后，可以定义Association discrpancy</p>
<p><img src="https://www.zhihu.com/equation?tex=AssDis%28%5Cmathcal%7BP%7D%2C+%5Cmathcal%7BS%7D%3B%5Cmathcal%7BX%7D%29%3D%5CBig%5B+++%5Cfrac%7B1%7D%7BL%7D%5Csum_%7Bl%3D1%7D%5E%7BL%7D++%5Cbig%28++KL%28%5Cmathcal%7BP%7D_%7Bi%2C%3A%7D%5El+%7C%7C+%5Cmathcal%7BS%7D_%7Bi%2C%3A%7D%5El%29+%2B+KL%28%5Cmathcal%7BS%7D_%7Bi%2C%3A%7D%5El+%7C%7C+%5Cmathcal%7BP%7D_%7Bi%2C%3A%7D%5El%29+%5Cbig%29+++%5CBig%5D_%7Bi%3D1%2C%5Ccdots%2CN%7D" alt="[公式]"></p>
<p>上式利用了symmetrized KL散度计算每层中得到的两个分布的差异，这代表了这两个分布之间的信息增益，每个时间点对应一个值，异常数据相比正常数据AssDis的值会较小。</p>
<h3 id="2-2-极大极小策略"><a href="#2-2-极大极小策略" class="headerlink" title="2.2 极大极小策略"></a>2.2 极大极小策略</h3><p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/image-20220302171605065.png" alt="image-20220302171605065"></p>
<p>为了无监督地学习表征，我们利用重建误差来进行模型优化。同时，为了加大正常点和异常点之间的差距，我们使用了一个额外关联差异损失来增大关联差异。在这种设计下，由于先验关联的单峰特性，新增的关联差异损失会驱使序列关联更加关注非邻近的区域，从而使得异常点的重建更加的艰难，进而更加可辨别。</p>
<p><img src="https://pic2.zhimg.com/80/v2-3b81acaaffb3719a9a9802fd82ab1065_720w.jpg" alt="img"></p>
<p>然而直接最小化关联差异将使得高斯核的尺度参数<img src="https://www.zhihu.com/equation?tex=%5Csigma" alt="[公式]">急剧变小，结果就会导致先验分布无意义。因此，为了更好的控制关联学习的过程，我们采用了一种Minimax策略。在最小化阶段，先验关联将高斯核导出的分布族中的关联差异最小化。在最大化阶段，序列关联使重构损失下的关联差异最大化。</p>
<p>在最小化阶段，我们让先验关联<img src="https://www.zhihu.com/equation?tex=P" alt="[公式]">近似从原始时序中学得的序列关联<img src="https://www.zhihu.com/equation?tex=S" alt="[公式]">，该过程将使得先验关联适应不同的时序模式。在最大化阶段，我们优化序列关联<img src="https://www.zhihu.com/equation?tex=S" alt="[公式]">来最大化关联之间的差异，该过程将使得序列关联更加注意非临接的点，使得异常点的重建更加困难。</p>
<p><img src="https://pic1.zhimg.com/80/v2-53d9ecf16b969a98e3e23c7b193f6890_720w.jpg" alt="img"></p>
<p>最终，我们将标准化后的关联差异与重建误差结合起来制定了新的<strong>异常检测判据</strong>：</p>
<p><img src="https://pic2.zhimg.com/80/v2-58a56382fb82761e76a2c7ade332c1d9_720w.jpg" alt="img"></p>
<h2 id="实验结果与可视化分析"><a href="#实验结果与可视化分析" class="headerlink" title="实验结果与可视化分析"></a>实验结果与可视化分析</h2><p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/image-20220302171638524.png" alt="image-20220302171638524"></p>
<p>消融实验：</p>
<p><img src="C:\Users\30331\AppData\Roaming\Typora\typora-user-images\image-20220302171648598.png" alt="image-20220302171648598"></p>
<p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/image-20220302171708687.png" alt=""></p>
<p>总结：</p>
<p>本文研究无监督时间序列异常检测问题。与以前的方法不同，我们通过transformer学习了更多信息的时间点关联。在关联差异关键观测的基础上，提出了一种异常变压器(Anomaly Transformer)，该变压器包含一个具有双分支结构的异常注意来体现关联差异。采用极大极小策略进一步放大正常和异常时间点之间的差异。通过引入关联差异，提出了基于关联的准则，提高了重构性能</p>
]]></content>
      <categories>
        <category>wt</category>
      </categories>
      <tags>
        <tag>时间序列</tag>
        <tag>异常检测</tag>
      </tags>
  </entry>
  <entry>
    <title>wt【WWW2021】Understanding Electricity-Theft Behavior via Multi-Source Data</title>
    <url>/2021/07/21/WuTao/Understanding%20Electricity-Theft%20Behavior%20via%20Multi-Source%20Data/</url>
    <content><![CDATA[<p>本文提出了一种利用多源数据识别窃电行为的方法。除了用户用电记录外，我们还利用区域因素(非技术损失)和气候因素(温度)对用户行为进行了分析。通过进行分析实验，我们了解了几种有趣的现象：例如，电力可能会消耗更多的电力大致用户，特别是在极高或低温下。通过这些经验观察，我们进一步设计了识别电力盗贼的Anovel等级框架 。 基于现实世界数据集的实际结果表明，大家建议的模型可以在电力检测中实现最佳性能（例如，在F0.5方面至少+ 3.0％）相比。 最后，我们的工作已被中国国家电网应用，用来在杭州成功地捕捉电力盗窃行为，精度为15％</p>
<a id="more"></a>
<p>non-technical loss(NTL)  Technical loss</p>
<p>在实际应用中，电力配电网的损耗分为技术损耗和非技术损耗。技术损失主要是由不良影响(如电阻元件的加热、辐射等)造成的，是不可避免的。相比之下，非技术损失定义为已分配但未计费的能量</p>
<p>换句话说，这种类型的损失是在仪表到现金流程中的问题导致的。 虽然不同的问题可能导致非技术损失，但导致NTL的大部分与电力偷窃和欺诈有关[14]。 因此，从异常的NTL记录中检测电力是直接的，它非常简单[1,35]。 NTL提供变压器区域信息。 为了捕获单独的模式，许多现有的工厂利用了电力使用记录或NTL作为输入，并应用了各种机器学习技术（例如，SVM，CNN，RNN）来识别电力盗窃。 然而，由于电力使用行为的多样性和不规则性，大多数这些方法都未获得良好的性能，无论是单独使用NTL还是用电记录都几乎不可能取得较好的效果</p>
<p><img src="https://mmbiz.qpic.cn/mmbiz_jpg/B2hWWnf6Oe23gBa3V0I8uS0Z9F3SsbwFxx7vFKzXlOUqCBOu1Phhd2ibF4wVlCeXicC9qSn6lnKP8Q1YcUNhbKsA/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片"></p>
<p>图1 展示了<strong>三层多源数据</strong>：最下层是<strong>用户数据</strong>，反映的是用户个人的用电情况；上一层是<strong>台区（变压器区域）数据</strong>，反映的是一个社区（或村庄）的整体损耗情况；最上层是<strong>天气数据</strong>，反应的是一个城市整体的气候状况。</p>
<p>对于这三种不同层次的数据，该论文分别对其进行数据观察与分析，探寻里面与窃电行为有关的模式。</p>
<p><strong><em>01</em></strong></p>
<p><strong>微观级别的观察（用户）</strong></p>
<p><img src="https://mmbiz.qpic.cn/mmbiz_jpg/B2hWWnf6Oe23gBa3V0I8uS0Z9F3SsbwFCiavFOtCOatT2WTOuuVnCIvdh8lJP0VEa8JB1ZX3ygyrNibrbbKCZib2g/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片"></p>
<p>图2 用户用电与窃电行为的关系</p>
<p>图2 展示了基于用户用电数据的分析：</p>
<ul>
<li>图2a 可视化了每天峰（on-peak）谷（off-peak）两种用电情况，红色的区域代表该用户被抓到窃电的时间。可以看到<strong>当被抓到窃电时，其后统计到的用电都在大幅增加</strong>。</li>
<li>图2b 在所有的数据上，对被抓窃电前后的用户用电进行对比（左二），并用正常用户（右二）同一时刻前后的用电量做对照组。可以发现，被抓窃电后，窃电用户的用电量会急剧增加；同时，窃电用户整体的用电也比正常用户大，说明<strong>只有很高用电需求的人才有可能会去窃电</strong>。</li>
<li>除了用电量统计，作者们还对比了用电的趋势。图2c 展示了所有用户从8月份到10月份用电的一阶回归斜率。随着温度降低，正常用户（黄色）的峰值基本都是小于0，说明用电在减少；而窃电用户（蓝色）峰值在0左右，说明用电基本没有变化。这说明<strong>窃电用户的用电习惯与正常人不同</strong>。</li>
</ul>
<p><strong><em>02</em></strong></p>
<p><strong>中观级别的观察（NTL）</strong></p>
<p><img src="https://mmbiz.qpic.cn/mmbiz_jpg/B2hWWnf6Oe23gBa3V0I8uS0Z9F3SsbwFZbT7QecptK1V6eoXGcYbtJSiaaeJBcjmWXb2d5G7a3GN2ibZ9lciaIoXA/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片"></p>
<p>图3 台区NTL与窃电行为的关系</p>
<p>除了用户级别的观察，图3 展示了台区每天的NTL变化情况与用户用电的关系：</p>
<ul>
<li>图3a 展示了一个案例。黄色虚线代表台区每天的NTL电量，蓝色实线代表与之对应的台区下，一个窃电用户的用电曲线。红色区域代表被抓到窃电的时间。可以看到，当该用户用电低，台区的NTL就高，<strong>用户窃电造成了台区NTL的升高</strong>。</li>
<li>图3b 在所有数据上做了统计分析。可以看到，正常用户（绿色）在抓窃电前后用电模式基本不变，而窃电用户在被抓之前，用户的用电与台区的NTL呈现负相关关系。者说明<strong>台区的NTL可以对当前台区下是否有人窃电有很好的指示作用</strong>。</li>
</ul>
<p><strong><em>03**</em></strong>宏观级别的观察（气候）**</p>
<p>气候，或者说温度，与人们的行为特别是用电行为息息相关，例如空调、电热毯的使用等。这里先看一组统计：</p>
<p><img src="https://mmbiz.qpic.cn/mmbiz_jpg/B2hWWnf6Oe23gBa3V0I8uS0Z9F3SsbwF0QsD4k2IUtyxCT9AGTibvoPOtBDmWP22Yduxx5haQpNF4O0cUicg9wag/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片"></p>
<p>图4 不同月份全省被抓窃电的案例个数统计</p>
<p>图4 展示了一年中不同月份，被抓窃电的案例个数统计，可以看到夏天（7-9月）和冬天（11-1月），被抓个数明显比其他月份要多，而这两季，正好是用电需求高的时间。因此，论文的作者们尝试探寻温度因素与用电行为的关系。</p>
<p><img src="https://mmbiz.qpic.cn/mmbiz_jpg/B2hWWnf6Oe23gBa3V0I8uS0Z9F3SsbwFtOav3qFXX7bTCe8usmKlaQAly3TONdRSrOdfcmwDeKicEjA19KdO1Mg/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片"></p>
<p>图5 气候因素与窃电行为的关系</p>
<p>图5 展示了气温与用户用电行为之间的关系：</p>
<ul>
<li>图5a 展示了一年中整体的气温变化（黄线）与用户整体的用电（蓝线）之间的关系。可以看到，在夏天（或冬天），<strong>温度升高（降低），用户们的用电就会升高，</strong>他们之间呈现非常强的关联关系；</li>
<li>图5b 将温度划分为不同的区间，统计了该区间下正常用户（黄色）与窃电用户（蓝色）之间的用电分布，可以看到，<strong>当高温（&gt;30ºC）或者低温（&lt;9ºC）环境下，两者之间的用电分布差别很大</strong>；</li>
<li>作者们通过二元回归的方式，将不同温度下的用电进行拟合。可以发现，窃电用户用电与温度不能很好的拟合成一条规整的线（图5c），而正常用户可以（图5d）。图5e 将散点之间拟合差的平均值通过概率密度函数进行比较。可以看到，<strong>正常用户与窃电用户之间存在在不同气候条件下存在差异</strong>。</li>
</ul>
<p>该论文提出了一个<strong>层次化的深度模型，叫做 HEBR</strong></p>
<p><img src="https://mmbiz.qpic.cn/mmbiz_jpg/B2hWWnf6Oe23gBa3V0I8uS0Z9F3SsbwFNS2bT77dwRwMRNDLWNdM0aQXr315TDH6OSoX1FhiaJ6sKWpCYNsGtvg/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片"></p>
<p>图6 HEBR的结构</p>
<p>图6 展示了HEBR 的整体结构，它基于三层（用户，台区，气温）时序数据，逐层做信息抽取与融合，最终将组合的特征用于窃电行为的判定。</p>
<p>当对多源序列建模时，首先在每个时间点连接它们，然后使用一个单一的潜在表示来捕获整体的模式，如mrnn[18]，可以建立一个简单的基线。然而，来自不同来源的连接拓宽了特征维度，这可能会捕捉到不同级别信息之间的显著相关性。更具体地说，在我们的场景中，不同的用户同一变压器区域的ntl或温度观测顺序可能相同;因此，直接的连接可能会从区域和气候层面导致用户行为的混乱。因此，特征的直接连接可能会从区域和气候层面导致用户行为的混乱。因此，我们选择分别提取每个源的独立特征，然后进行成对信息融合</p>
<p>Level 1 独立捕获观测序列中的时间模式(例如温度(hc)、NTL(hl)和用户用电(he)的模式)，并将它们成对融合(hc he,hl he)。它的目的是分别模拟宏观或中观层面的因素对用户行为的影响 Level 2:分别获取初步融合后的时间模式(例如，用户气候(hec)和用户区域(hel))，然后融合hec hel的模式。其目的是统一宏观和中观层面对用户行为的影响。Level3:捕获多个中的整体时态模式</p>
<p>我们没有在同一级融合表示。这是因为我们的观察性研究(第3节)表明，这两个不同层次的信息是不相关的，尽管它们与用户的用电量密切相关。在这里，我们的目的是捕捉这两个因素如何影响用户用电行为。HEBR在层次结构的基础上，可以对各个层次进行特征提取与融合，逐步整合多源信息。</p>
<p>具体对于每一步融合，作者们提出了<strong>多步加时间关注的融合机制</strong>：</p>
<p>为了捕获不同级别的信息之间的核心关系，我们提出了多步融合机制。 这里的直觉是两个不同水平的序列之间的影响可能是延时的。除了受当今温度的影响之外，用户的电力使用也可能与昨天的天气有关; 一个具体的例子是，如果前一天是非常高的，人们往往会打开一个漫长的空调，即使今天是较冷的。 因此，我们应该尝试在时间间隔内包含更多信息，而不是仅在当时的时间点。</p>
<p><img src="https://mmbiz.qpic.cn/mmbiz_jpg/B2hWWnf6Oe23gBa3V0I8uS0Z9F3SsbwFSxkgO5sRlup74r2D6k9qcXqoUqqic2m1G9vPTIvPJ0GXvibL7NnjygIw/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片"></p>
<p>图7 多步融合机制的结构</p>
<p>针对两种不同源数据的RNN隐层表达，其中一个主要方（这个场景里主要是用户用电数据），每个时间步t，次要方（如：台区NTL，气温）都要将前面多步的信息用于当前的信息融合，再做局部attention。这里做的目的是，NTL或气温对当前用户用电的影响是有时延的，例如气温升高，并不会让用户马上开空调增加用电；但一段时间的高温就肯定会使得用户用电量增加。作者们通过这种多步融合机制，对多源信息的组合做更多的关联信息抽取。</p>
<p>然而，每个时间步的融合信息不可能对行为模式同等重要。例如，如果某人在夏季或冬季消耗很少的电力，那么他可能是电盗窃者，但这可能不是真的在秋季或春季，因为用户通常在这些月份由于季节性影响消耗更少的电力。Liu et al.[27]认为模型应该尝试在不同的时间点测量这些重要的信息。因此，设计了一种注意机制来模拟融合信息在不同时刻的意义变化</p>
<p>HEBR模型在浙江省国家电网所提供的2017-2019两年多的真实数据上进行实验，取得了还不错的效果：</p>
<p><img src="https://mmbiz.qpic.cn/mmbiz_png/B2hWWnf6Oe23gBa3V0I8uS0Z9F3SsbwFibgm22fUD0DiblZsWH84VdoItwFTWHQt8icyKkZxeSsadtEibibvzMicIOxA/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片"></p>
<p>表2 反窃电实验结果</p>
<p>如表2 所示，HEBR模型在Precision和F0.5 这两个指标上，都比baseline要好，<strong>这对于实际的排查来说更加友好</strong>。</p>
<p>同时，为了说明模型设计的有效性，论文还做了<strong>多种消融研究</strong>：</p>
<p><img src="https://mmbiz.qpic.cn/mmbiz_png/B2hWWnf6Oe23gBa3V0I8uS0Z9F3SsbwFo7f9KM3I8Kq0ul9gibpFlEapzk2uGVxJxJ4qOkphDx7xdplAE7YHiaxQ/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片"></p>
<p>表3 验证多源数据的有效性</p>
<p><img src="https://mmbiz.qpic.cn/mmbiz_png/B2hWWnf6Oe23gBa3V0I8uS0Z9F3SsbwFsVfubhUTvYJGsTXO2P109QZgTonWEzsH77VD0s37ibKDkcDicxf7U1ew/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片"></p>
<p>表4 多步融合机制的有效性</p>
<p>表3、表4 分别展现了不同源数据与融合机制对HEBR反窃电准确度的影响，可以看到，删去气温或NTL信息，都会导致反窃电准确度大大降低；同时，不采用多步融合机制或attention操作，都会让模型效果下降。</p>
<p>除了实验，浙江省国家电网应用该模型进行窃电用户识别，在浙江杭州进行了窃电排查，实地捕获了若干窃电用户。其中一个案例如下：</p>
<p><img src="https://mmbiz.qpic.cn/mmbiz_jpg/B2hWWnf6Oe23gBa3V0I8uS0Z9F3SsbwF2cdibLOfichvcEsum2DathBNYMJiaUTBgunOUEBtib7UmGS9vKJda4HzdA/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片"></p>
<p>图8 实地排查到的窃电案例</p>
<p>如图8 所示，从上到下依次展现了气温变化，台区NTL变化与用户用电的三种曲线；热力图代表了HEBR模型在三层不同位置的attention得分，红色区域代表其被抓到的时间。可以看到，当用户用电降低，台区NTL升高，同时温度很高的情况下，热力图对应的区域就越亮，attention的得分就越高。说明<strong>HEBR模型可以很好的捕捉到用户窃电的模式</strong>。</p>
<p>实验证明基于多步attention融合的HEBR模型可以<strong>有效组合多源时序数据</strong>，适用于窃电识别问题。</p>
<p>输入文件预计将是四个部分：</p>
<p>（1）电力使用记录：一个CSV文件，其中包含每个用户的每日记录：#USERID，#AREAID，#date，#total电力，#top电力，＃峰值电力，#flat电力，＃off-peak 电。</p>
<p>（2）非技术损失记录：CSV文件，其中包含每个区域的每日记录：#areaid，#date，#cost电力，#billed电力，#lost电力。 在这里，区域IID对应于（1）中的AreadID</p>
<p>（3）温度记录：CSV文件，记录日常天气，包含#AREAID，#data，#high温度，#low温度。 我们可以通过代码中的数据蜘蛛./data_factory/temperature_spider.py</p>
<p>（4）电力标签：一个CSV文件，它记录了电力盗贼被捕获的时间，包含#Userid，#areaid，#date。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">Cell</span>(<span class="params">self, input_u, input_a, input_c, hiddens, reuse=<span class="literal">False</span></span>):</span></span><br><span class="line">    <span class="keyword">with</span> tf.variable_scope(<span class="string">&#x27;HEBR_Cell&#x27;</span>):</span><br><span class="line">        cur_emb_u, cur_mem_u = self.__LSTMUnit__(input_u, prev_emb_u, prev_mem_u, dims=[self.dims[<span class="string">&#x27;user&#x27;</span>], self.dims[<span class="string">&#x27;user_hidden&#x27;</span>]], name=<span class="string">&#x27;User&#x27;</span>, reuse=reuse)</span><br><span class="line">        cur_emb_a, cur_mem_a = self.__LSTMUnit__(input_a, prev_emb_a, prev_mem_a, dims=[self.dims[<span class="string">&#x27;area&#x27;</span>], self.dims[<span class="string">&#x27;area_hidden&#x27;</span>]], name=<span class="string">&#x27;Area&#x27;</span>, reuse=reuse)</span><br><span class="line">        cur_emb_c, cur_mem_c = self.__LSTMUnit__(input_c, prev_emb_c, prev_mem_c, dims=[self.dims[<span class="string">&#x27;climate&#x27;</span>], self.dims[<span class="string">&#x27;climate_hidden&#x27;</span>]], name=<span class="string">&#x27;Climate&#x27;</span>, reuse=reuse)</span><br><span class="line"></span><br><span class="line">        input_ua, fuse_ua, score_ua = self.FeatureFusion(cur_emb_u, cur_emb_a, prev_emb_a, dims=[self.dims[<span class="string">&#x27;user_hidden&#x27;</span>], self.dims[<span class="string">&#x27;area_hidden&#x27;</span>]], name=<span class="string">&#x27;User_Area_Fusion&#x27;</span>, reuse=reuse)</span><br><span class="line">        input_uc, fuse_uc, score_uc = self.FeatureFusion(cur_emb_u, cur_emb_c, prev_emb_c, dims=[self.dims[<span class="string">&#x27;user_hidden&#x27;</span>], self.dims[<span class="string">&#x27;climate_hidden&#x27;</span>]], name=<span class="string">&#x27;User_Climate_Fusion&#x27;</span>, reuse=reuse)</span><br><span class="line"></span><br><span class="line">        cur_emb_ua, cur_mem_ua = self.__LSTMUnit__(input_ua, prev_emb_ua, prev_mem_ua, dims=[self.dims[<span class="string">&#x27;user_area&#x27;</span>], self.dims[<span class="string">&#x27;user_area_hidden&#x27;</span>]], name=<span class="string">&#x27;User_Area&#x27;</span>, reuse=reuse)</span><br><span class="line">        cur_emb_uc, cur_mem_uc = self.__LSTMUnit__(input_uc, prev_emb_uc, prev_mem_uc, dims=[self.dims[<span class="string">&#x27;user_climate&#x27;</span>], self.dims[<span class="string">&#x27;user_climate_hidden&#x27;</span>]], name=<span class="string">&#x27;User_Climate&#x27;</span>, reuse=reuse)</span><br><span class="line"></span><br><span class="line">        input_uac, fuse_uac, score_uac = self.FeatureFusion(cur_emb_ua, cur_emb_uc, prev_emb_uc, dims=[self.dims[<span class="string">&#x27;user_area_hidden&#x27;</span>], self.dims[<span class="string">&#x27;user_climate_hidden&#x27;</span>]], name=<span class="string">&#x27;User_Area_Climate_Fusion&#x27;</span>, reuse=reuse)</span><br><span class="line"></span><br><span class="line">        cur_emb_uac, cur_mem_uac = self.__LSTMUnit__(input_uac, prev_emb_uac, prev_mem_uac, dims=[self.dims[<span class="string">&#x27;user_area_climate&#x27;</span>], self.dims[<span class="string">&#x27;user_area_climate_hidden&#x27;</span>]], name=<span class="string">&#x27;User_Area_Climate&#x27;</span>, reuse=reuse)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>wt</category>
      </categories>
      <tags>
        <tag>时间序列预测</tag>
      </tags>
  </entry>
  <entry>
    <title>wt【AAAI 2021】Informer:Beyond Efficient Transformer for Long Sequence Time-Series Forecasting</title>
    <url>/2021/03/24/WuTao/informer/</url>
    <content><![CDATA[<p>关键词：时间序列预测；</p>
<h3 id="1摘要"><a href="#1摘要" class="headerlink" title="1摘要"></a>1摘要</h3><p>Informer的主要工作是使用Transfomer实现长序列预测（Long Sequence Time-Series Forecasting）,以下称为LSTF。针对Transfomer在长序列预测中的不足（平方时间复杂度、高内存占用和现有编解码结构的局限性），提出ProbSparse注意力机制、自注意力蒸馏技术和生成式解码器等模块解决或缓解上述问题。</p>
<ol>
<li>首先，LSTF任务具有重要研究意义，对政策计划和投资避险等多种需要长时预测的任务至关重要；</li>
<li>目前现有方法多专注于短期预测，模型缺乏长期预测能力；</li>
<li>Transformer具有较强捕获长距离依赖的能力，但是，在计算时间复杂度和空间复杂度以及如何加强长序列输入和输出关联上都需要优化；</li>
</ol>
<a id="more"></a>
<p>本文提出的方案同时解决了上面的三个问题，我们研究了在self-attention机制中的稀疏性问题，本文的贡献有如下几点：</p>
<ul>
<li>我们提出Informer来成功地提高LSTF问题的预测能力，这验证了类Transformer模型的潜在价值，以捕捉长序列时间序列输出和输入之间的单个的长期依赖性；</li>
<li>我们提出了ProbSparse self-attention机制来高效的替换常规的self-attention并且获得了O(LlogL)的时间复杂度以及O(LlogL)的内存使用率；</li>
<li>我们提出了self-attention distilling操作，它大幅降低了所需的总空间复杂度；</li>
<li>我们提出了生成式的Decoder来获取长序列的输出，这只需要一步，避免了在inference阶段的累计误差传播；</li>
</ul>
<p>输入: <img src="https://www.zhihu.com/equation?tex=X%5Et+%3D+%7Bx_1%5E%7Bt%7D%2C...%2Cx_%7BL_x%7D%5E%7Bt%7D+%7C+x_i%5E%7Bt%7D+%5Cin+R%5E%7Bd_x%7D%7D" alt="[公式]"> 时间 t</p>
<p>输出：<img src="https://www.zhihu.com/equation?tex=Y_t%3D%7By_1%5E%7Bt%7D%2C...%2Cy_%7BL_y%7D%5E%7Bt%7D+%7C+y_i%5Et+%5Cin+R%5E%7Bd_y%7D%7D" alt="[公式]"> 时间 t， 且<img src="https://www.zhihu.com/equation?tex=d_y+%3E%3D+1" alt="[公式]"></p>
<h3 id="2-编解码结构"><a href="#2-编解码结构" class="headerlink" title="2. 编解码结构"></a><strong>2. 编解码结构</strong></h3><p>编解码结构通常这样设计：将输入<img src="https://www.zhihu.com/equation?tex=X%5Et" alt="[公式]">编码为隐层状态<img src="https://www.zhihu.com/equation?tex=H%5Et" alt="[公式]">，然后将隐层状态解码为输出表示<img src="https://www.zhihu.com/equation?tex=Y%5Et" alt="[公式]">。通常推理阶段采用step-by-step方式，即动态解码。具体为：输入上一步隐层状态<img src="https://www.zhihu.com/equation?tex=h%5Et_k" alt="[公式]">和上一步的输出计算k+1步的隐层状态<img src="https://www.zhihu.com/equation?tex=h_%7Bk%2B1%7D%5Et" alt="[公式]">，然后预测第k+1步的输出<img src="https://www.zhihu.com/equation?tex=y_%7Bk%2B1%7D%5Et" alt="[公式]">。</p>
<h3 id="3-输入表示"><a href="#3-输入表示" class="headerlink" title="3. 输入表示"></a><strong>3. 输入表示</strong></h3><p><strong>方法介绍</strong></p>
<p><img src="C:\Users\linestao\AppData\Roaming\Typora\typora-user-images\image-20210324140229564.png" alt="image-20210324140229564"></p>
<p>在LSTF问题中，时序建模不仅需要局部时序信息还需要层次时序信息，如星期、月和年等，以及突发事件或某些节假日等。经典自注意力机制很难直接适配，可能会带来query和key的错误匹配问题，影响预测性能表现。</p>
<p><img src="C:\Users\linestao\AppData\Roaming\Typora\typora-user-images\image-20210324135837567.png" alt="image-20210324135837567"></p>
<p> 左边：编码过程，编码器接收长序列输入（绿色部分），通过ProbSparse自注意力模块和自注意力蒸馏模块，得到特征表示。（堆叠结构增加模型鲁棒性）</p>
<p>右边：解码过程，解码器接收长序列输入（预测目标部分设置为0），通过多头注意力与编码特征进行交互，最后直接预测输出目标部分（橙黄色部分）。</p>
<p><img src="C:\Users\linestao\AppData\Roaming\Typora\typora-user-images\image-20210324133904112.png" alt="image-20210324133904112" style="zoom: 150%;" /></p>
<p>Informer编码器的架构。 （1）每个水平堆栈代表图（2）中的单个编码器副本; （2）较高的堆栈是主堆栈，它接收整个输入序列，而第二个堆栈则占输入的一半。 （3）红色层是自注意机制的点积矩阵，通过在每层上进行自注意蒸馏而逐渐减少级联； （4）将2堆栈的功能图连接为编码器的输出。</p>
<h3 id="4-设计的关键"><a href="#4-设计的关键" class="headerlink" title="4.设计的关键"></a>4.设计的关键</h3><p>作者的insight是，如果将self-attention中的点积结果进行可视化分析，会发现服从长尾分布，</p>
<p><img src="https://pic4.zhimg.com/80/v2-f8c1aab1c053777f1626ac211360aba7_720w.jpg" alt="img"></p>
<p>也就是少数的几个query和key的点积计算结果主导了softmax后的分布，这种稀疏性分布是有现实含义的：序列中的某个元素一般只会和少数几个元素具有较高的相似性/关联性。</p>
<p>经过简化后，作者定义第i个Query的稀疏性度量公式为：<img src="https://www.zhihu.com/equation?tex=M%28q_i%2C+K%29+%3D+ln%5Csum_%7Bj%3D1%7D%5E%7BL_K%7De%5E%7B%5Cfrac%7Bq_ik_j%5ET%7D%7B%5Csqrt+d%7D%7D-%5Cfrac%7B1%7D%7BL_K%7D%5Csum_%7Bj%3D1%7D%5E%7BL_K%7D%5Cfrac%7Bq_ik_j%5ET%7D%7B%5Csqrt+d%7D" alt="[公式]"></p>
<p>第一项是在qi所有keys的Log-Sum-Exp(LSE)，第二项是arithmetic均值</p>
<p>如果第i个query的M值较大，说明它的注意力概率p相较其他部分差异性较大，比较大可能性是重要性部分。</p>
<p>基于上述度量方法，ProbSparse自注意力计算方式可以表示为：<img src="https://www.zhihu.com/equation?tex=A%28Q%2CK%2CV%29%3DSoftmax%28%5Cfrac%7B%5Cbar+QK%5ET%7D%7B%5Csqrt+d%7Dv%29" alt="[公式]">，其中<img src="https://www.zhihu.com/equation?tex=%5Cbar+Q" alt="[公式]">为稀疏矩阵包含TOP u个query。通过该优化，没对query-key计算需要<img src="https://www.zhihu.com/equation?tex=O%28lnL_Q%29" alt="[公式]">计算复杂度。计算M的计算复杂度为<img src="https://www.zhihu.com/equation?tex=O%28L_QL_K%29" alt="[公式]">的二次方。所以，作者采用近似思想进行了进一步的优化与化简。</p>
<h3 id="Self-attention-Distilling"><a href="#Self-attention-Distilling" class="headerlink" title="Self-attention Distilling"></a>Self-attention Distilling</h3><p>self-attention蒸馏的insight是随着Encoder层数的加深，由于序列中每个位置的输出已经包含了序列中其他元素的信息(self-attention的本职工作)，我们可以缩短输入序列的长度。”蒸馏”操作主要为使用1D卷积和最大池化，将上一层的输出送至魔改后的多头注意力模块之前做维度修剪和降低内存占用。</p>
<p>所以Encoder类似于金字塔结构：</p>
<p><img src="https://pic3.zhimg.com/80/v2-62c59f9dc721dde004b879bffeb05002_720w.jpg" alt="img"></p>
<p>如何缩短序列长度呢？卷积+最大池化。</p>
<p>基本上每一层序列长度会减半。</p>
<p>decoder上：一次前向计算，预测长序列输出。采用标准解码器结构，即堆叠两个相同的多头注意力层。不同的是，本文采用的是生成式预测（不是step-by-step方式）直接输出多步预测结果。</p>
<h3 id="5-结果"><a href="#5-结果" class="headerlink" title="5.结果"></a>5.结果</h3><p><img src="C:\Users\linestao\AppData\Roaming\Typora\typora-user-images\image-20210324134420733.png" alt="image-20210324134420733"></p>
<p>本文研究了长序列时间序列预测问题，提出了长序列预测的Informer方法。具体地：</p>
<ul>
<li>设计了ProbSparse self-attention和提取操作来处理vanilla Transformer中二次时间复杂度和二次内存使用的挑战。</li>
<li>generative decoder缓解了传统编解码结构的局限性。</li>
<li>通过对真实数据的实验，验证了Informer对提高预测能力的有效性</li>
</ul>
<p>有知乎答主 表示Informer的主要目的就是效率优化：对self-attention的时间空间优化、卷积池化蒸馏 </p>
<p>源码地址： <a href="https://github.com/zhouhaoyi/Informer2020">https://github.com/zhouhaoyi/Informer2020</a></p>
]]></content>
      <categories>
        <category>wt</category>
      </categories>
      <tags>
        <tag>时间序列预测</tag>
      </tags>
  </entry>
  <entry>
    <title>xw Adaptive Graph Convolutional Recurrent Network for Traffic Forecasting</title>
    <url>/2020/10/21/XuWei/Adaptive%20Graph%20Convolutional%20Recurrent%20Network%20for%20Traffic%20Forecasting/</url>
    <content><![CDATA[<h2 id="论文信息"><a href="#论文信息" class="headerlink" title="论文信息"></a>论文信息</h2><p>论文：<strong>Adaptive Graph Convolutional Recurrent Network for Traffic Forecasting</strong></p>
<p>会议：NIPS 2020</p>
<p>作者：</p>
<p><img src="https://imagebed-richado.oss-cn-beijing.aliyuncs.com/img/image-20201012210058579.png" alt="image-20201012210058579"></p>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h3><blockquote>
<p>在相关的时间序列数据中对复杂的空间和时间相关性进行建模对于理解交通动态并预测不断发展的交通系统的未来状态是必不可少的。 <strong>最近的工作专注于设计复杂的图神经网络，以借助预定义的图捕获共享模式。在本文中，作者认为，学习节点特定的模式对流量预测至关重要，同时可避免使用预定义的图</strong></p>
<a id="more"></a>
<p>为此，本文提出了两个具有新功能的自适应模块来增强图卷积网络(GCN): <strong>1)一个节点自适应参数学习(NAPL)模块来捕获节点特定模式;2)数据自适应图生成(DAGG)模块，自动推导出不同交通序列之间的依赖关系。</strong></p>
<p>我们进一步提出了一种自适应图卷积递推网络(AGCRN)，以自动捕获流量序列中细粒度的空间和时间相关性。我们在两个真实世界流量数据集上的实验表明，在没有预先定义空间连接图的情况下，AGCRN的表现明显优于最先进的技术</p>
</blockquote>
<h3 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h3><p><strong>特定模式</strong></p>
<p>事实上，交通序列呈现出多种多样的模式(如图1所示)，由于不同数据源的属性不同，可能出现相似、不相似甚至矛盾的情况。下图具有不同模式的交通流示例。 白天，道路3的交通流量稳定。 相比之下，道路1,2和4的交通流量分别具有明显的傍晚高峰，早晨高峰和两个高峰。</p>
<p><img src="https://imagebed-richado.oss-cn-beijing.aliyuncs.com/img/image-20201012212333738.png" alt="image-20201012212333738" style="zoom:150%;" /></p>
<p><strong>预先定义的图</strong></p>
<p>此外，现有的基于GCN的方法需要通过相似性或距离度量[14]预先定义互连图以捕获空间相关性。 这进一步需要大量的领域知识，并且对图形质量敏感。 以这种方式生成的图形通常是直观的，不完整的，并且并非直接针对预测任务。 它们可能包含偏见，并且在没有适当知识的情况下无法适应领域</p>
<h3 id="Contribution"><a href="#Contribution" class="headerlink" title="Contribution"></a>Contribution</h3><p>没有设计更复杂的网络体系结构，而是通过设计当前方法（GCN）的基本模块来分别解决上述问题，本文提出了两种简洁而有效的机制。 具体来说，本文使用两个自适应模块来增强GCN，以进行流量预测任务：</p>
<ol>
<li><p>节点自适应参数学习（NAPL）模块，用于学习每个流量系列的特定于节点的模式，NAPL对传统GCN中的参数进行分解，并根据节点嵌入从所有节点共享的权重池和偏差池中生成特定于节点的参数</p>
</li>
<li><p>一个数据自适应图生成(DAGG)模块，用于从数据中推断节点嵌入(属性)并在训练期间生成图</p>
</li>
</ol>
<p><em>NAPL和DAGG是独立的，可以分别或联合用于现有的基于GCN的流量预测模型。 可以轻松地以端到端的方式学习模块中的所有参数。 此外，我们将NAPL和DAGG与递归网络相结合，并提出了统一的流量预测模型-AdaptiveGraph卷积递归网络（AGCRN）</em></p>
<h2 id="Methodology"><a href="#Methodology" class="headerlink" title="Methodology"></a>Methodology</h2><h3 id="Problem-Definition"><a href="#Problem-Definition" class="headerlink" title="Problem Definition"></a>Problem Definition</h3><p><strong>N个相关单变量交通流量时间序列，长为t：</strong></p>
<script type="math/tex; mode=display">
\mathcal{X}=\left\{\boldsymbol{X}_{:, 0}, \boldsymbol{X}_{:, 1}, \ldots, \boldsymbol{X}_{:, t}, \ldots\right\}</script><script type="math/tex; mode=display">
\boldsymbol{X}_{:, t}=\left\{x_{1, l}, x_{2, l}, \ldots, x_{i, l}, \ldots x_{N, l}\right\}^{T} \in R^{N \times 1}</script><p><strong>图</strong></p>
<script type="math/tex; mode=display">
\mathcal{G}=(\mathcal{V}, \mathcal{E}, A)，\boldsymbol{A} \in R^{N \times N}</script><p><em>$\mathcal{V}$表示结点集合，<script type="math/tex">\mathcal{E}</script>表示边集合，<script type="math/tex">\boldsymbol{A}</script>是表示交通节点连接关系的邻接矩阵</em></p>
<p><strong>目标：</strong></p>
<p>使用过去<script type="math/tex">T</script>个时刻的交通流量数据，预测未来<script type="math/tex">\tau</script>个时刻的流量数据</p>
<script type="math/tex; mode=display">
\left\{\boldsymbol{X}_{:, t+1}, \boldsymbol{X}_{:, t+2}, \ldots, \boldsymbol{X}_{:, t+\tau}\right\}=\mathcal{F}_{\boldsymbol{\theta}}\left(\boldsymbol{X}_{:, t}, \boldsymbol{X}_{:, t-1}, \ldots, \boldsymbol{X}_{:, t-\boldsymbol{T}+\mathbf{1}}\right)</script><p><strong>problem</strong></p>
<script type="math/tex; mode=display">
\left\{\boldsymbol{X}_{:, t+1}, X_{:, t+2}, \ldots, X_{:, t+\tau}\right\}=\mathcal{F}_{\theta}\left(X_{:, t}, X_{:, t-1}, \ldots, X_{:, t-T+1} ; \mathcal{G}\right)</script><h3 id="Node-Adaptive-Parameter-Learning"><a href="#Node-Adaptive-Parameter-Learning" class="headerlink" title="Node Adaptive Parameter Learning"></a>Node Adaptive Parameter Learning</h3><h4 id="图卷积"><a href="#图卷积" class="headerlink" title="图卷积"></a>图卷积</h4><script type="math/tex; mode=display">
Z=\left(I_{N}+D^{-\frac{1}{2}} A D^{-\frac{1}{2}}\right) X \Theta+\mathrm{b}</script><p><em>注</em></p>
<p><em>$A \in R^{N \times N}$ 表示邻接矩阵， $D$表示度矩阵， $\boldsymbol{X} \in R^{N \times C},Z \in R^{N \times F}$表示图卷积层的输入和输出</em></p>
<p><em>$\Theta \in R^{C \times F},\mathrm{b} \in R^{F}$表示图卷积的参数(weights and bias)</em></p>
<p><strong>作用</strong></p>
<p>使用共享的参数完成节点特征的变换：$\boldsymbol{X}^{i} \in R^{1 \times C} \text { to } Z^{i} \in R^{1 \times F}$</p>
<p><strong>问题</strong></p>
<p><strong>共享参数可能有助于在许多问题中学习所有节点中最突出的模式，并能显著减少参数数，但对于交通预测问题，我们发现共享参数不是最优的。</strong>除了封闭相关交通序列之间存在密切的空间相关性外，由于时间序列数据的动态适宜性以及节点的各种影响交通的因素，<strong>不同交通序列之间也存在着不同的模式。</strong>来自两个相邻节点的流量流也可能由于其特定属性(如PoI、天气)而在某一特定时段呈现不同的模式。另一方面，来自两个不相交节点的交通量甚至可能显示相反的模式。 <strong>结果，仅捕获所有节点之间的共享模式不足以进行准确的流量预测，并且必须为每个节点保持唯一的参数空间以学习特定于节点的模式。</strong></p>
<h4 id="Node-Adaptive-Parameter-Learning-module"><a href="#Node-Adaptive-Parameter-Learning-module" class="headerlink" title="Node Adaptive Parameter Learning module"></a>Node Adaptive Parameter Learning module</h4><p><strong>为什么要用这个模块？</strong></p>
<p>为每一个节点分配参数 =&gt; $\Theta \in R^{N \times C \times F}$，会导致参数量巨大难以优化，同时造成 over-fitting</p>
<p><strong>方法</strong></p>
<ol>
<li>不直接学习$\Theta \in R^{N \times C \times F}$,设计一个可以学习的节点嵌入$\boldsymbol{E}<em>{G}$，以及权重池$W</em>{\mathcal{G}}$，来生成$\Theta$。</li>
<li>理解为利用节点$i$的嵌入$E<em>{\mathcal{G}}^{i}$从权重池$W</em>{\mathcal{G}}$中提取参数$\Theta^{i}$,这样每个节点都能学到独立的模式</li>
</ol>
<script type="math/tex; mode=display">
\boldsymbol{E}_{\boldsymbol{G}} \in R^{N \times d}, \boldsymbol{W}_{\boldsymbol{G}} \in R^{d \times C \times F}, d<<N</script><script type="math/tex; mode=display">
\Theta=E_{\mathcal{G}} \cdot W_{\mathcal{G}}</script><script type="math/tex; mode=display">
Z=\left(I_{N}+D^{-\frac{1}{2}} A D^{-\frac{1}{2}}\right) X E_{\mathcal{G}} W_{\mathcal{G}}+E_{\mathcal{G}} \mathrm{b}_{\mathcal{G}}</script><h3 id="Data-Adaptive-Graph-Generation"><a href="#Data-Adaptive-Graph-Generation" class="headerlink" title="Data Adaptive Graph Generation"></a>Data Adaptive Graph Generation</h3><p><strong>预定义的图存在的问题</strong></p>
<ol>
<li>预先定义的图不能包含关于空间依赖的完整信息</li>
<li>不能保证预先定义的图与预测任务的直接关系</li>
</ol>
<p><strong>方法</strong></p>
<p>随机初始化可学习的节点嵌入矩阵$\boldsymbol{E}<em>{\boldsymbol{A}} \in R^{N \times d</em>{e}}$，通过矩阵运算来得出节点之间的依赖关系</p>
<p>使用DAGG的卷积公式如下所示：</p>
<script type="math/tex; mode=display">
D^{-\frac{1}{2}} A D^{-\frac{1}{2}}=\operatorname{softmax}\left(\operatorname{ReLU}\left(E_{A} \cdot E_{A}^{T}\right)\right)</script><script type="math/tex; mode=display">
Z=\left(I_{N}+\operatorname{softmax}\left(\operatorname{Re} L U\left(E_{A} \cdot E_{A}^{T}\right)\right)\right) X \Theta</script><h3 id="Adaptive-Graph-Convolutional-Recurrent-Network"><a href="#Adaptive-Graph-Convolutional-Recurrent-Network" class="headerlink" title="Adaptive Graph Convolutional Recurrent Network"></a>Adaptive Graph Convolutional Recurrent Network</h3><p>集成NAPL-GCN、DAGG和门控循环单元(GRU)，以捕获流量级中特定节点的空间和时间相关性</p>
<p><img src="https://imagebed-richado.oss-cn-beijing.aliyuncs.com/img/image-20201014002022667.png" alt="image-20201014002022667" style="zoom:53%;" /></p>
<h2 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h2><h3 id="Datasets"><a href="#Datasets" class="headerlink" title="Datasets"></a>Datasets</h3><ol>
<li><p>PeMSD4</p>
<p>307个检测器</p>
</li>
<li><p>PeMSD8</p>
<p>170个检测器</p>
</li>
</ol>
<h3 id="Overall"><a href="#Overall" class="headerlink" title="Overall"></a>Overall</h3><p><img src="https://imagebed-richado.oss-cn-beijing.aliyuncs.com/img/image-20201014002201008.png" alt="image-20201014002201008" style="zoom:250%;" /></p>
<p><img src="https://imagebed-richado.oss-cn-beijing.aliyuncs.com/img/image-20201014002339241.png" alt="image-20201014002339241"></p>
<ol>
<li>GCN对交通流量预测任务的重要性</li>
<li>本文提出的模型实现了5%的提升</li>
</ol>
<h3 id="消融实验"><a href="#消融实验" class="headerlink" title="消融实验"></a>消融实验</h3><p><img src="https://imagebed-richado.oss-cn-beijing.aliyuncs.com/img/image-20201014110846596.png" alt="image-20201014110846596"></p>
<ul>
<li>GCGRU：GCN+GRU的传统模型</li>
<li>NAPL-GCGRU：使用本文提出的NAPL替换了传统GCN的模型</li>
<li>DAGG-GCGRU：使用本文提出的DAGG替换了传统GCN中的预定义图</li>
<li>AGCRN-I 所有模块的节点嵌入不共享</li>
<li>AGCRN 节点嵌入在所有模块中共享</li>
</ul>
<ol>
<li>NAPL-GCGRU胜过GCGRU，AGCRN-1胜过DAGG-GCGRU，这说明捕获特定于节点的模式的必要性。NAPL主要增强长期预测，对短期预测的影响较小。论文推测，其原因是长期预测缺乏来自历史观测的足够有用的信息，因此从NAPL模块学习到的特定节点嵌入中获益，从而推断出未来的模式</li>
<li>DAGG-GCGRU提升了GCGRU, AGCRN-I打败了NAPL-GCGRU。两者都显示了DAGG在推断空间相关性方面的优势。证明并不一定需要预定义的图</li>
<li>AGCRN的性能最好，说明我们可以共享所有模块的节点嵌入，并从数据中学习到每个节点统一的节点嵌入。</li>
</ol>
<h3 id="Model-Analysis"><a href="#Model-Analysis" class="headerlink" title="Model Analysis"></a>Model Analysis</h3><h4 id="Graph-Generation"><a href="#Graph-Generation" class="headerlink" title="Graph Generation"></a>Graph Generation</h4><p><img src="https://imagebed-richado.oss-cn-beijing.aliyuncs.com/img/image-20201014112913213.png" alt="image-20201014112913213"></p>
<ul>
<li>NAGG-r 去除了原本模型的中的自环连接</li>
<li>NAGG-1 本文提出的方法</li>
<li>NAGG-2 使用$D^{-\frac{1}{2}} A D^{-\frac{1}{2}}$模仿2阶切比雪夫多项式</li>
</ul>
<ol>
<li>从DAGG中删除单位矩阵会严重损害预测性能，这表明在预测中手动突出显示自我信息的重要性</li>
<li>DAGG-2和 DAGG-1的性能类似，表明生成的图拉普拉斯矩阵$D^{-\frac{1}{2}} A D^{-\frac{1}{2}}$具有与切比雪夫多项式展开式中的预定义图相似的属性</li>
</ol>
<h4 id="Embedding-Dimension"><a href="#Embedding-Dimension" class="headerlink" title="Embedding Dimension"></a>Embedding Dimension</h4><p><img src="https://imagebed-richado.oss-cn-beijing.aliyuncs.com/img/image-20201014113514138.png" alt="image-20201014113514138"></p>
<h4 id="Computation-Cost"><a href="#Computation-Cost" class="headerlink" title="Computation Cost"></a>Computation Cost</h4><p><img src="https://imagebed-richado.oss-cn-beijing.aliyuncs.com/img/image-20201014113434977.png" alt="image-20201014113434977"></p>
<p>(dim = 10性能最好)</p>
]]></content>
      <categories>
        <category>xw</category>
      </categories>
      <tags>
        <tag>时序预测</tag>
        <tag>GCN</tag>
        <tag>交通流量预测</tag>
      </tags>
  </entry>
  <entry>
    <title>xw Connecting the Dots Multivariate Time Series Forecasting with Graph Neural Networks</title>
    <url>/2020/09/24/XuWei/Connecting%20the%20Dots%20Multivariate%20Time%20Series%20Forecasting%20with%20Graph%20Neural%20Networks/</url>
    <content><![CDATA[<h2 id="论文信息"><a href="#论文信息" class="headerlink" title="论文信息"></a>论文信息</h2><p><strong>题目:</strong></p>
<p><strong>Connecting the Dots: Multivariate Time Series Forecasting with Graph Neural Networks</strong></p>
<p><strong>会议:</strong></p>
<p>KDD 2020</p>
<p><strong>作者:</strong><br><img src="https://imagebed-richado.oss-cn-beijing.aliyuncs.com/img/image-20201007210738438.png" alt="image-20201007210738438"></p>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h3><blockquote>
<p>多元时间序列建模一直是一个热门主题，吸引了来自不同领域的研究人员，包括经济、金融和交通。多元时间序列预测背后的一个基本假设是，其变量相互依赖，但仔细观察，可以说现有方法无法完全利用变量对之间的潜在空间依赖性。同时，近年来，图神经网络（GNN）在处理关系依赖方面表现出了很高的能力。GNN需要用于信息传播的定义明确的图结构，这意味着它们无法直接应用于事先不知道相关性的多元时间序列。在本文中，我们<strong>提出了一个专门为多元时间序列数据设计的通用图神经网络框架</strong>。我们的方法<strong>通过图形学习模块自动提取变量之间的单向关系，可以轻松地将诸如变量属性之类的外部知识整合到其中</strong>。进一步<strong>提出了一种新颖的混合跳跃传播层和一个扩张的起始层来捕获时间序列内的空间和时间依赖性</strong>。在端到端框架中共同学习图学习，图卷积和时间卷积模块。实验结果表明，我们提出的模型在4个基准数据集中的3个方面优于最新的基线方法，并在提供额外结构信息的两个交通数据集上与其他方法相比具有同等的性能。</p>
</blockquote>
<a id="more"></a>
<h3 id="时空图神经网络"><a href="#时空图神经网络" class="headerlink" title="时空图神经网络"></a>时空图神经网络</h3><p><strong>图神经网络由于其置换不变性、局部连通性和组合性</strong>，在处理图数据方面取得了很大的成功。通过通过结构传播信息，<strong>图神经网络允许图中的每个节点都知道它的邻域</strong>。</p>
<p>多元时间序列预测可以很自然地从图的角度来看待。<strong>多元时间序列中的变量可以看作是图中的节点，它们通过隐藏的依赖关系相互连接</strong>。因此，利用图神经网络对多变量时间序列数据进行建模是一种很有前途的方法，可以在充分利用时间序列之间的相关性的同时，保留多变量时间序列的时间轨迹。</p>
<p><strong>最适合用于多变量时间序列的图神经网络类型是时空图神经网络</strong>。时空图神经网络以多元时间序列和外部图结构作为输入，预测多元时间序列的未来值或标签。与不利用结构信息的方法相比，时空图神经网络已经取得了显著的改进。</p>
<h3 id="挑战"><a href="#挑战" class="headerlink" title="挑战"></a>挑战</h3><p><strong>挑战1:未知的图形结构。</strong>现有的GNN方法很大程度上依赖于预先设定的图结构来进行时间序列预测。在大多数情况下，多元时间序列没有明确的图结构。变量之间的关系必须从数据中发现，而不是作为基本真理知识提供。</p>
<p><strong>挑战2:图形学习与处理GNN学习。</strong>虽然有图结构，但大多数GNN方法只关注消息传递(GNN学习)，忽略了图结构不是最优的，需要在训练时进行更新。接下来的问题是如何在端到端框架中同时学习时间序列的图结构和GNN。</p>
<h3 id="模型总结"><a href="#模型总结" class="headerlink" title="模型总结"></a>模型总结</h3><p><img src="https://imagebed-richado.oss-cn-beijing.aliyuncs.com/img/image-20201007211843231.png" alt="image-20201007211843231" style="zoom:50%;" /></p>
<p><strong>框架由三个核心组件组成:图学习层、图卷积模块和时序卷积模块。</strong></p>
<ul>
<li>针对挑战1，我们提出了一种新的图学习层，它基于数据自适应地表达稀疏图邻接矩阵。此外，我们开发了一个图卷积模块来解决变量之间的空间依赖性，给定由图学习层计算的邻接矩阵。</li>
<li>最后，我们提出了一个时间卷积模块，通过改进一维卷积来捕获时间模式。它既能发现多频率的时间模式，又能处理很长的序列。</li>
<li>由于所有参数都可以通过梯度下降来学习，因此提出的框架能够以端到端的方式对多元时间序列数据进行建模并同时学习内部图形结构</li>
<li>将时间序列划分成子组，适用于长短的时间序列任务</li>
</ul>
<h3 id="贡献"><a href="#贡献" class="headerlink" title="贡献"></a>贡献</h3><p><strong>如图1所示，我们的框架由三个核心组件组成:图学习层、图卷积模块和时序卷积模块。</strong></p>
<p><strong>1.据我们所知，这是第一次使用图形神经网络从基于图形的角度对多变量时间序列数据进行研究。</strong></p>
<p><strong>2.我们提出了一个新的图学习模块来学习变量之间隐藏的空间依赖关系。该方法为GNN模型在处理数据时不需要明确的图结构打开了一扇新的大门。</strong></p>
<p><strong>3.我们提出了一个建模多元时间序列数据和学习图结构的联合框架。我们的框架比任何现有的时空图神经网络更通用，因为它可以处理多变量时间序列，无论是否使用预先修改过的图结构。</strong></p>
<p><strong>4.实验结果表明，我们的方法在4个基准数据集中的3个数据集上的性能优于现有的方法，并在两个提供额外结构信息的交通数据集上达到与其他GNNs相同的性能。</strong></p>
<h3 id="FRAMEWORK-OF-MTGNN"><a href="#FRAMEWORK-OF-MTGNN" class="headerlink" title="FRAMEWORK OF MTGNN"></a>FRAMEWORK OF MTGNN</h3><p>图2所示，最高级别的MTGNN由学习层，m个图卷积模块，m个时间卷积模块和输出模块组成。 为了发现节点之间的隐藏关联，图学习层计算图邻接矩阵，该矩阵随后用作所有图卷积模块的输入。图卷积模块与时间卷积模块交错，分别捕获空间和时间相关性。  为了避免梯度消失的问题，将残余连接从时间卷积模块的输入添加到图卷积模块的输出。 在每个时间卷积模块之后添加跳过连接。 为了获得最终输出，输出模块将隐藏特征投影到所需的输出尺寸。 </p>
<p><img src="https://imagebed-richado.oss-cn-beijing.aliyuncs.com/img/image-20201007214453265.png" alt="image-20201007214453265"></p>
<p><strong>时空卷积结合</strong></p>
<p><img src="https://imagebed-richado.oss-cn-beijing.aliyuncs.com/img/image-20201008100536371.png" alt="image-20201008100536371"></p>
<p><em>红色是t时序卷积 蓝色是空间卷积</em></p>
<h4 id="Graph-Learning-Layer"><a href="#Graph-Learning-Layer" class="headerlink" title="Graph Learning Layer"></a>Graph Learning Layer</h4><p><img src="https://imagebed-richado.oss-cn-beijing.aliyuncs.com/img/image-20201007220142608.png" alt="image-20201007220142608"></p>
<p>$E$是随机的节点嵌入(可以进行预设。外部知识)，$\Theta$是模型参数</p>
<h4 id="Graph-Convolution-Module"><a href="#Graph-Convolution-Module" class="headerlink" title="Graph Convolution Module"></a>Graph Convolution Module</h4><p>图卷积模块旨在将节点的信息与邻居的信息融合在一起，以处理图中的空间依赖性。 图卷积模块由两个混合跃点传播层组成，以分别处理通过每个节点的流入和流出信息。 通过将两个混合跳跃传播层的输出相加获得净流入信息。 下图显示了图卷积模块和mix-hop传播层的体系结构</p>
<p><img src="https://imagebed-richado.oss-cn-beijing.aliyuncs.com/img/image-20201007220652954.png" alt="image-20201007220652954"></p>
<h5 id="Mix-hop"><a href="#Mix-hop" class="headerlink" title="Mix-hop"></a>Mix-hop</h5><p>给定一个图邻接矩阵，我们提出了混合跳跃传播层来处理信息流在空间上相关的节点。 所提出的混合跳跃传播层包括两个步骤-信息传播步骤和信息选择步骤。GC module 通过A和A的转置来整合双向的信息</p>
<p><strong>信息传播：</strong></p>
<script type="math/tex; mode=display">
\mathrm{H}^{(k)}=\beta \mathrm{H}_{i n}+(1-\beta) \tilde{\mathrm{A}} \mathrm{H}^{(k-1)}</script><p><strong>信息选择:</strong></p>
<script type="math/tex; mode=display">
\mathbf{H}_{o u t}=\sum_{i=0}^{K} \mathbf{H}^{(k)} \mathbf{W}^{(k)}</script><p>k是传播的深度，$\mathbf{H}<em>{i n}$表示上一层产生的输入隐状态，$\mathbf{H}</em>{out}$表示当前层的输出</p>
<p><strong>信息传播</strong>通过k次卷积运算，计算了k-hop的邻居</p>
<p><strong>信息选择</strong>则进行信息选择和整合</p>
<h4 id="Temporal-Convolution-Module"><a href="#Temporal-Convolution-Module" class="headerlink" title="Temporal Convolution Module"></a>Temporal Convolution Module</h4><p><img src="https://imagebed-richado.oss-cn-beijing.aliyuncs.com/img/image-20201007221752735.png" alt="image-20201007221752735"></p>
<p>sigmoid起着门控的作用，控制信息流入</p>
<h3 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h3><h4 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h4><p><img src="https://imagebed-richado.oss-cn-beijing.aliyuncs.com/img/image-20201008092338113.png" alt="image-20201008092338113"></p>
<h3 id="多元时间序列的单步预测"><a href="#多元时间序列的单步预测" class="headerlink" title="多元时间序列的单步预测"></a>多元时间序列的单步预测</h3><p><img src="https://imagebed-richado.oss-cn-beijing.aliyuncs.com/img/image-20201008092414037.png" alt="image-20201008092414037"></p>
<h3 id="多元时间序列的多步预测"><a href="#多元时间序列的多步预测" class="headerlink" title="多元时间序列的多步预测"></a>多元时间序列的多步预测</h3><p><img src="https://imagebed-richado.oss-cn-beijing.aliyuncs.com/img/image-20201008092456714.png" alt="image-20201008092456714"></p>
<h3 id="消融实验"><a href="#消融实验" class="headerlink" title="消融实验"></a>消融实验</h3><p><strong>数据集：METR-LA</strong></p>
<p><img src="https://imagebed-richado.oss-cn-beijing.aliyuncs.com/img/image-20201008092605904.png" alt="image-20201008092605904"></p>
<h3 id="图学习方法对比"><a href="#图学习方法对比" class="headerlink" title="图学习方法对比"></a>图学习方法对比</h3><p><img src="https://imagebed-richado.oss-cn-beijing.aliyuncs.com/img/image-20201008092637606.png" alt="image-20201008092637606"></p>
]]></content>
      <categories>
        <category>xw</category>
      </categories>
      <tags>
        <tag>时序预测</tag>
        <tag>GCN</tag>
      </tags>
  </entry>
  <entry>
    <title>xw caNet:Frequency Channel Attention Networks</title>
    <url>/2021/01/20/XuWei/FcaNet%20Frequency%20Channel%20Attention%20Networks/</url>
    <content><![CDATA[<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><blockquote>
<p>注意机制，特别是通道注意，在计算机视觉领域取得了巨大的成功。许多研究集中在如何设计有效的通道注意机制，而忽略了一个基本问题，即使用全局平均池化(GAP)是否存在问题。在这项工作中，本文从一个不同的视角出发，用频率分析重新思考通道注意。<strong>在频域分析的基础上，用数学方法证明了全局平均池化(GAP)是频域特征分解的一种特例。通过证明，自然地将通道注意机制的预处理推广到了频域，并提出了一种新的多谱通道注意网络。</strong>该方法简单有效。只修改计算中的一行代码，以在现有的通道注意方法中实现本文的方法。在图像分类、目标检测和实例分割等任务上，与其他通道注意方法相比，该方法取得了最先进的效果。与基线SENet50相比，在相同的参数数量和计算成本下，本文的方法在ImageNet上的Top-1精度提高了1.8%。</p>
</blockquote>
<a id="more"></a>
<h2 id="论文信息"><a href="#论文信息" class="headerlink" title="论文信息"></a>论文信息</h2><p><strong>作者信息</strong></p>
<p>浙江大学（李玺团队）</p>
<p><img src="https://imagebed-richado.oss-cn-beijing.aliyuncs.com/img/image-20210112162526585.png" alt="image-20210112162526585"></p>
<h3 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h3><ol>
<li>通道注意力大都通过GAP实现，尽管GAP(global average pooling)算法简单有效，但它存在一个潜在的问题，即不能很好地捕捉到丰富的输入模式信息，从而在处理不同的输入时缺乏特征多样性。因此，出现了一个自然的问题，是否均值信息仅足以代表渠道注意中的各种渠道。</li>
</ol>
<h3 id="Contribution"><a href="#Contribution" class="headerlink" title="Contribution"></a>Contribution</h3><ol>
<li>证明了GAP是离散余弦变换(DCT)的一个特例，等价于离散余弦变换(DCT)的最低频率，仅使用GAP等价于丢弃特征信道中包含大量有用信息的其他频率分量。在此基础上，本文将通道注意推广到频域，提出了具有多谱通道注意框架的FcaNet。</li>
<li>提出了一种选择频率分量的两步准则，探讨了使用不同数量的频率分量及其不同组合的效果。</li>
<li>方法简单，改进一行代码即可。</li>
</ol>
<h2 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h2><h3 id="Revisiting-Channel-Attention-and-DCT"><a href="#Revisiting-Channel-Attention-and-DCT" class="headerlink" title="Revisiting Channel Attention and DCT"></a>Revisiting Channel Attention and DCT</h3><h4 id="Channel-Attention"><a href="#Channel-Attention" class="headerlink" title="Channel Attention"></a>Channel Attention</h4><p><strong>输入</strong></p>
<script type="math/tex; mode=display">
X \in \mathbb{R}^{C \times H \times W}</script><p><em>C是通道数</em></p>
<p><strong>注意力</strong></p>
<script type="math/tex; mode=display">
a t t=\operatorname{sigmoid}(f c(\operatorname{gap}(X)))</script><script type="math/tex; mode=display">
att\in \mathbb{R}^{C}</script><p><strong>注意力机制输出</strong></p>
<script type="math/tex; mode=display">
\widetilde{X}_{:, i,:,:}=a t t_{i} X_{:, i,:,:}, \quad \text { s.t. } \quad i \in\{0,1, \cdots, C-1\}</script><p><img src="https://pic4.zhimg.com/v2-77affb3d6037ab0fa4f564f30c38031b_r.jpg" alt="img"></p>
<h4 id="Discrete-Cosine-Transform-DCT"><a href="#Discrete-Cosine-Transform-DCT" class="headerlink" title="Discrete Cosine Transform (DCT)"></a>Discrete Cosine Transform (DCT)</h4><p><strong>一维DCT</strong></p>
<script type="math/tex; mode=display">
f_{k}=\sum_{i=0}^{L-1} x_{i} \cos \left(\frac{\pi k}{L}\left(i+\frac{1}{2}\right)\right), \text { s.t. } k \in\{0,1, \cdots, L-1\}</script><p>输入：$x \in \mathbb{R}^{L}$</p>
<p>离散余弦转换频谱：$f \in \mathbb{R}^{L}$</p>
<p><strong>二维DCT</strong></p>
<script type="math/tex; mode=display">
\begin{array}{l}f_{h, w}^{2 d}=\sum_{i=0}^{H-1} \sum_{j=0}^{W-1} x_{i, j}^{2 d} \underbrace{\cos \left(\frac{\pi h}{H}\left(i+\frac{1}{2}\right)\right) \cos \left(\frac{\pi w}{W}\left(j+\frac{1}{2}\right)\right)}_{\text {DCT weights }}, \\ \text { s.t. } h \in\{0,1, \cdots, H-1\}, w \in\{0,1, \cdots, W-1\}\end{array}</script><p>反变换</p>
<script type="math/tex; mode=display">
\begin{array}{l}x_{i, j}^{2 d}=\sum_{h=0}^{H-1} \sum_{w=0}^{W-1} f_{h, w}^{2 d} \underbrace{\cos \left(\frac{\pi h}{H}\left(i+\frac{1}{2}\right)\right) \cos \left(\frac{\pi w}{W}\left(j+\frac{1}{2}\right)\right)}_{\text {DCT weights }} \\ \text { s.t. } i \in\{0,1, \cdots, H-1\}, j \in\{0,1, \cdots, W-1\}\end{array}</script><p><strong>GAP</strong></p>
<script type="math/tex; mode=display">
\begin{aligned} f_{0,0}^{2 d} &=\sum_{i=0}^{H-1} \sum_{j=0}^{W-1} x_{i, j}^{2 d} \cos \left(\frac{0}{H}\left(i+\frac{1}{2}\right)\right) \cos \left(\frac{\theta}{W}\left(j+\frac{1}{2}\right)\right) \\ &=\sum_{i=0}^{H-1} \sum_{j=0}^{W-1} x_{i, j}^{2 d} \\ &=g a p\left(x^{2 d}\right) H W \end{aligned}</script><p>由上可见全局平均池化(GAP)是频域特征分解的一种特例（只保留低频信息）</p>
<script type="math/tex; mode=display">
B_{h, w}^{i, j}=\cos \left(\frac{\pi h}{H}\left(i+\frac{1}{2}\right)\right) \cos \left(\frac{\pi w}{W}\left(j+\frac{1}{2}\right)\right)</script><script type="math/tex; mode=display">
X=\underbrace{\operatorname{gap}(X) H W B_{0,0}^{i, j}}_{\text {utilized }}+\underbrace{f_{0,1}^{2 d} B_{0,1}^{i, j}+\cdots+f_{H-1, W-1}^{2 d} B_{H-1, W-1}^{i, j}}_{\text {discarded }}</script><h4 id="Multi-Spectral-Channel-Attention"><a href="#Multi-Spectral-Channel-Attention" class="headerlink" title="Multi-Spectral Channel Attention"></a>Multi-Spectral Channel Attention</h4><p>现有的通道注意所使用的信息不足，而通道注意间GAP预处理方法是二维DCT的特例。这样就可以很自然地将GAP推广到2D  DCT中更多的频率分量，引入更多的信息来解决信道注意信息不足的问题。</p>
<p><img src="https://imagebed-richado.oss-cn-beijing.aliyuncs.com/img/image-20210120005612174.png" alt="image-20210120005612174"></p>
<script type="math/tex; mode=display">
\begin{aligned} F r e q^{i} &=2 \mathrm{DDCT}^{u, v}\left(X^{i}\right) \\ &=\sum_{h=0}^{H-1} \sum_{w=0}^{W-1} X_{:, h, w}^{i} B_{h, w}^{u, v} \\ & \text { s.t. } i \in\{0,1, \cdots, n-1\} \end{aligned}</script><p>将通道C划分成多个C’的通道，分别进行不同频率分量的DCT运算</p>
<p>主要思想是首先确定每个频率分量的重要性，然后确定使用不同数量的频率分量一起使用的效果。</p>
<h3 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h3><p><strong>在ImageNet上使用不同频率分量的频道注意的最高精度</strong></p>
<p><img src="https://imagebed-richado.oss-cn-beijing.aliyuncs.com/img/image-20210120010126425.png" alt="image-20210120010126425" style="zoom:50%;" /></p>
<p>确定每个频率分量的重要性（性能）</p>
<p><strong>选择不同数目频率分量的准确性</strong></p>
<p>选取性能最高的K个频率分量</p>
<p><img src="https://imagebed-richado.oss-cn-beijing.aliyuncs.com/img/image-20210120010237029.png" alt="image-20210120010237029" style="zoom:50%;" /></p>
<p><strong>ImageNet</strong></p>
<p><img src="https://imagebed-richado.oss-cn-beijing.aliyuncs.com/img/image-20210120133711682.png" alt="image-20210120133711682" style="zoom:50%;" /></p>
<p><strong>COCO</strong></p>
<p><img src="https://imagebed-richado.oss-cn-beijing.aliyuncs.com/img/image-20210120133733751.png" alt="image-20210120133733751" style="zoom:50%;" /></p>
<p><strong>研究更多的频率组合</strong></p>
<p>选取Top-k频率分量的最优结果:78.52%</p>
<p><img src="https://imagebed-richado.oss-cn-beijing.aliyuncs.com/img/image-20210120135835661.png" alt="image-20210120135835661"></p>
]]></content>
      <categories>
        <category>xw</category>
      </categories>
      <tags>
        <tag>Attention</tag>
      </tags>
  </entry>
  <entry>
    <title>xw 【AAAI2021】Learnable Dynamic Temporal pooling for Time Series Classification</title>
    <url>/2021/03/31/XuWei/Learnable%20Dynamic%20Temporal%20Pooling%20for%20Time%20Series%20Classification/</url>
    <content><![CDATA[<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>关键词：时间序列；时序分类</p>
<p><strong>Abstract</strong></p>
<blockquote>
<p>随着可用时间序列数据的增加，预测它们的类别标签已成为广泛学科中最重要的挑战之一。最近关于时间序列分类的研究表明，卷积神经网络(CNN)作为单一分类器实现了最先进的性能。本文指出现有CNN分类器通常采用的全局池化层<strong>丢弃了高层特征的时间信息</strong>，因此提出了一种动态时间池(DTP)技术，通过分段聚合特征，减少了隐层表示的时间长度。为了将整个序列划分为多个片段，本文使用动态时间规整(DTW)将每个时间点按照时间顺序与片段的原型特征对齐，这可以同时与CNN分类器的网络参数进行优化。结合DTP层和全连接层，有助于进一步提取区分性特征。在单变量和多变量时间序列数据集上的大量实验表明，本文提出的池化方法显著提高了分类性能。</p>
</blockquote>
<a id="more"></a>
<h3 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h3><ol>
<li>CNN等方法不能有效利用高级特征的时序信息，CNN分类器往往采用全局平均池化(GAP)或全局最大池化(GMP)，简单地沿时间轴聚合所有隐藏向量。<strong>这样的全局聚合丢弃了隐藏特征的时间位置，使得CNN只学习到位置不变的时间特征</strong></li>
</ol>
<h3 id="Contribution"><a href="#Contribution" class="headerlink" title="Contribution"></a>Contribution</h3><ol>
<li>提出了一种新的池化方法，可以有效地<strong>减少网络输出的时间大小(即长度)，同时最小化时间信息的损失。</strong></li>
</ol>
<blockquote>
<p>由于观察到时间序列实例由多个具有不同模式的片段组成，动态时间池(DTP)为每个片段输出一个池向量，而不是为整个序列输出一个。DTP层通过在每个段中聚合隐藏向量来产生段级表示，因此它能够基于段特定的类权重来建模分类得分。换句话说，CNN分类器用segment-level池代替了全局池(后面跟着一个完全连接的层)，这允许进一步提取类区别特征，提高分类精度。本文还专门为DTP层提供了类激活图(CAM)，指出每个时间区域对预测输入时间序列的类标签有多少贡献。</p>
</blockquote>
<ul>
<li>挑战：从输入时间序列实例中找出一致的片段，这些片段在时间上没有相互对齐。<ul>
<li>DTP层使用动态时间规整(DTW)进行语义分割。</li>
<li>首先引入可训练的潜在向量，其数量与待识别的片段数相当，称为原型隐藏序列，用于按时间顺序将每个片段的原型特征编码成它们。</li>
<li>再者，DTP层将网络输出(即隐藏向量序列)与原型隐藏序列进行对齐，同时基于DTW保持其时间顺序;这将生成与每个片段匹配的连续时间点集。同时优化CNN和原型隐藏序列，也就是说，训练CNN有助于捕捉片段的原型特征，学习原型隐藏序列有助于CNN提取判别特征。</li>
</ul>
</li>
</ul>
<h2 id="Related-Work"><a href="#Related-Work" class="headerlink" title="Related Work"></a>Related Work</h2><h3 id="Deep-Learning-for-Time-Series-Classification"><a href="#Deep-Learning-for-Time-Series-Classification" class="headerlink" title="Deep Learning for Time Series Classification"></a>Deep Learning for Time Series Classification</h3><p><strong>时间池化</strong></p>
<p>多个卷积层的堆栈输出每个时间点的隐藏向量，该隐藏向量最终编码了上下文的高级特征。基于global average pooling  (GAP)或global max pooling (GMP)，将所有隐藏向量沿着时间轴汇总成一个向量(图1a)，最后用它来计算分类得分。</p>
<p><img src="https://imagebed-richado.oss-cn-beijing.aliyuncs.com/img/image-20210329160938696.png" alt="image-20210329160938696"></p>
<p>然而，这样的全局池化会丢失高级特性的时间动态信息，从而导致性能有限。在时间序列分类的情况下，局部时间模式可以有不同的含义，取决于它们的时间发生位置</p>
<h3 id="Differentiable-Dynamic-Time-Warping"><a href="#Differentiable-Dynamic-Time-Warping" class="headerlink" title="Differentiable Dynamic Time Warping"></a>Differentiable Dynamic Time Warping</h3><p>DTW是一种基于时间一致性的点对点匹配来测量两个不同长度时间序列之间距离的流行技术。给定两个长度为M和N的序列X和Y，其代价矩阵$\Delta(X, Y) \in\mathbb{R}^{M \times N}$的(m,  n)便是$X_m、Y_n$之间的距离(或对齐代价)。X与Y之间的DTW距离由代价矩阵与任意二值对齐矩阵A的最小内积定义</p>
<script type="math/tex; mode=display">
\operatorname{DTW}(X, Y)=\min \{\langle A, \Delta(X, Y)\rangle, \forall A \in \mathcal{A}\}</script><p>$\mathcal{A} \in \mathbb{R}^{M \times N}$表示是否对齐</p>
<h2 id="Dynamic-Temporal-Pooling"><a href="#Dynamic-Temporal-Pooling" class="headerlink" title="Dynamic Temporal Pooling"></a>Dynamic Temporal Pooling</h2><h3 id="Problem-Formulation"><a href="#Problem-Formulation" class="headerlink" title="Problem Formulation"></a>Problem Formulation</h3><p><strong>N个时间序列样本和标签</strong></p>
<script type="math/tex; mode=display">
\left\{\left(\mathbf{X}^{1}, y^{1}\right), \ldots,\left(\mathbf{X}^{N}, y^{N}\right)\right\} \text { where } y \in\{1, \ldots, C\}</script><p><strong>时间序列样本(D个变量，长度为T)</strong></p>
<script type="math/tex; mode=display">
\mathbf{X}=\left[\mathbf{x}_{1}, \ldots, \mathbf{x}_{T}\right] \in \mathbb{R}^{D \times T}</script><p><strong>CNN输出隐层时序向量</strong></p>
<script type="math/tex; mode=display">
\mathbf{H}=\left[\mathbf{h}_{1}, \ldots, \mathbf{h}_{T}\right] \in \mathbb{R}^{K \times T}</script><p><strong>分类分数</strong></p>
<script type="math/tex; mode=display">
\mathbf{s}=\left[s^{(1)}, \ldots, s^{(C)}\right]</script><p><img src="https://imagebed-richado.oss-cn-beijing.aliyuncs.com/img/image-20210329162250603.png" alt="image-20210329162250603"></p>
<h3 id="Temporal-Pooling-based-on-Segmentation"><a href="#Temporal-Pooling-based-on-Segmentation" class="headerlink" title="Temporal Pooling based on Segmentation"></a>Temporal Pooling based on Segmentation</h3><ol>
<li>时间池化的目的是减少隐藏表示(即f的输出)的时间大小T，同时最小化时间序列中时间信息的丢失。</li>
<li>关键思想是将一系列隐藏向量分割成L段，然后通过汇总每个段中的向量生成池表示。正式地说，时间池化层输出序列池化向量$\overline{\mathbf{H}}=\left[\overrightarrow{\mathbf{h}}<em>{1}, \ldots, \overline{\mathbf{h}}</em>{L}\right] \in \mathbb{R}^{K \times L}$， 长为L。第l个向量形式化如下：</li>
</ol>
<script type="math/tex; mode=display">
\overline{\mathbf{h}}_{l}=\phi\left(\mathbf{h}_{t_{l-1}+1}, \mathbf{h}_{t_{l-1}+2} \ldots, \mathbf{h}_{t_{l}}\right)</script><p>$\phi$是池化操作，$\mathcal{T}<em>{l}=\left{t</em>{l-1}+1, \ldots, t_{l}\right}$为属于第l段的连续时间点集合，池化操作可以使用三个函数:计算平均值(用avg表示)、求和值(用sum表示)和最大值(用max表示)。</p>
<h4 id="分割"><a href="#分割" class="headerlink" title="分割"></a>分割</h4><p>分割的一个简单策略是以静态方式将整个时间序列分割成相同长度的短序列，但它也存在一些需要解决的局限性：</p>
<ol>
<li><strong>（模式不对齐）</strong>不同样本的时间序列，不是时间对齐的，这使得它很难找到绝对的时间位置分割（下图，upper）</li>
<li><strong>（模式时间长度不同）</strong>此外，考虑分段任务的目的是发现内在同质的不同时间模式，在大多数情况下，每个最优时间序列分段的长度不可能与其他的相同（下图，lower）</li>
</ol>
<p><img src="https://imagebed-richado.oss-cn-beijing.aliyuncs.com/img/image-20210329163748056.png" alt="image-20210329163748056" style="zoom:83%;" /></p>
<h4 id="DTW"><a href="#DTW" class="headerlink" title="DTW"></a>DTW</h4><p>通过将每个时间点与它在时间顺序上语义上最近的片段匹配来执行语义分割。</p>
<p><strong>引入原型隐层序列</strong></p>
<script type="math/tex; mode=display">
\mathbf{P}=\left[\mathbf{p}_{1}, \ldots, \mathbf{p}_{L}\right] \in \mathbb{R}^{K \times L}</script><p>长度为L的片段，最好地总结了L片段的高级特征</p>
<p><strong>DTW匹配</strong></p>
<p>利用DTW将原型隐藏向量序列(即$\mathbf{P}$)与目标隐藏向量序列(即$\mathbf{H}$)进行时间对齐。根据DTW比对的结果，将隐藏向量序列分成L段，每一段由式进行合并。在这种情况下，$\mathbf{P}$和$\mathbf{H}$之间的最优对准矩阵$A^{*}$可由</p>
<script type="math/tex; mode=display">
A^{*}=\underset{A \in \mathcal{A}}{\operatorname{argmin}}\langle A, \Delta(\mathbf{P}, \mathbf{H})\rangle</script><p>$\Delta \in \mathbb{R}^{L \times T}$是对齐成本矩阵，$\delta\left(\mathbf{p}<em>{l}, \mathbf{h}</em>{t}\right)=1-\frac{\mathbf{p}<em>{l} \cdot \mathbf{h}</em>{t}}{\left|\mathbf{p}<em>{l}\right|</em>{2}\left|\mathbf{h}<em>{t}\right|</em>{2}}$表示为$\mathbf{p}<em>{l} \text { and } \mathbf{h}</em>{t}$的距离</p>
<p>与原始的DTW不同，为了限制每一个时间点只能匹配一个段，只能向右或者向右下角移动</p>
<p><img src="https://imagebed-richado.oss-cn-beijing.aliyuncs.com/img/image-20210329164550424.png" alt="image-20210329164550424" style="zoom:50%;" /></p>
<h3 id="Learnable-Dynamic-Temporal-Pooling-Layer"><a href="#Learnable-Dynamic-Temporal-Pooling-Layer" class="headerlink" title="Learnable Dynamic Temporal Pooling Layer"></a>Learnable Dynamic Temporal Pooling Layer</h3><p><img src="https://imagebed-richado.oss-cn-beijing.aliyuncs.com/img/image-20210331144906369.png" alt="image-20210331144906369" style="zoom:50%;" /></p>
<h2 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h2><h3 id="Experimental-Settings"><a href="#Experimental-Settings" class="headerlink" title="Experimental Settings"></a>Experimental Settings</h3><h4 id="Datasets"><a href="#Datasets" class="headerlink" title="Datasets"></a>Datasets</h4><ol>
<li>85个单变量时间序列数据集（UCR）</li>
<li>30个多变量时间序列数据集（UEA）</li>
</ol>
<h4 id="Baseline"><a href="#Baseline" class="headerlink" title="Baseline"></a>Baseline</h4><p>分别使用avg、sum和max操作:全局时间池(GTP)、固定池大小的静态时间池(STP)和<strong>动态时间池(DTP)</strong>。</p>
<h4 id="Evaluation"><a href="#Evaluation" class="headerlink" title="Evaluation"></a>Evaluation</h4><p>为了进行定量评估，进行了两两的posthoc analysis，根据多个数据集的准确性，统计上对不同分类器进行排名。通过临界差值(CD)图将结果可视化，该图用粗水平线表示每个分类器的平均级别。对于所有的数据集，用不同的随机种子重复训练每个分类器三次，并报告中位数精度。</p>
<h3 id="Comparison-of-Different-Pooling-Layers"><a href="#Comparison-of-Different-Pooling-Layers" class="headerlink" title="Comparison of Different Pooling Layers"></a>Comparison of Different Pooling Layers</h3><p><img src="https://imagebed-richado.oss-cn-beijing.aliyuncs.com/img/image-20210330144802332.png" alt="image-20210330144802332"></p>
<p><strong>首先直接比较本文提出的CNN分类器(使用DTP)和基线CNN分类器(使用GTP)的分类精度。单个点表示每个数据集，因此每个点距离y =  x线的距离表示两种池化方法之间的性能差距。</strong></p>
<ol>
<li>在所有的情况下，我们观察到大部分的数据集都点在每个图的右下角，这表明不管DTP的CNN架构和池操作如何，DTP的性能都优于GTP。特别是，当DTP与max操作一起使用时，它比GTP的性能改进更大。</li>
<li>由于最大池化可以有效地检测到一般的特定特征，DTP-MAX擅长于细分发现这些特征，这使得最终的表示进一步具有类区别性。</li>
</ol>
<p><strong>为了进行更多的统计评估，本文还基于两两统计检验比较了不同的时间池化方法(即GTP、STP和DTP)下图显示了它们在一组数据集上的平均rank，具有两两统计差异。粗横线显示一组分类器无显著差异(p = 0.05)。</strong></p>
<p><img src="https://imagebed-richado.oss-cn-beijing.aliyuncs.com/img/image-20210330145024442.png" alt="image-20210330145024442"></p>
<ol>
<li>DTP在所有类型的时间池中始终表现最好</li>
<li>GTP表现最差。</li>
<li>在STP的情况下，尽管与DTP考虑的段数相同，它的性能略好于GTP，但在统计上没有太大的差异;这意味着在固定的时间位置汇集来自相同长度段的向量不能有效提高CNN分类器的精度。相反,本文的DTP方法,使用变长段被大田、能够建模的高级特性取决于每一段,因此其判别能力提高了很多。可以得出结论,DTP成功地利用时间信息进行分类</li>
</ol>
<h3 id="Parameter-Analysis-on-L"><a href="#Parameter-Analysis-on-L" class="headerlink" title="Parameter Analysis on L"></a>Parameter Analysis on L</h3><p><img src="https://imagebed-richado.oss-cn-beijing.aliyuncs.com/img/image-20210330151003393.png" alt="image-20210330151003393"></p>
<p>单线表示每个数据集，其颜色由精度最高的L的最优值决定。</p>
<ol>
<li>性能的变化曲线在大多数数据集上是不一致的，而且最优的分段数也会随着数据集的不同而变化</li>
<li>为目标数据集找到最优的L值可以在实践中进一步提高CNN分类器的性能</li>
</ol>
<h3 id="Qualitative-Analysis"><a href="#Qualitative-Analysis" class="headerlink" title="Qualitative Analysis"></a>Qualitative Analysis</h3><p>Class Activation Map（类激活图）<img src="https://imagebed-richado.oss-cn-beijing.aliyuncs.com/img/image-20210330151406808.png" alt="image-20210330151406808"></p>
<ol>
<li>为了定性地比较GTP和DTP的定位性能，本文通过突出显示按分数成比例的输入时间序列来可视化他们的CAM分数。在上图a和b中，class 1和class  2的时间序列实例分别用红色和蓝色表示，对于每个时间序列实例，本文使用在[0,1]范围内归一化后的CAM分数。尽管这两个CNN分类器对这两个数据集(即GunPoint和TwoLeadECG)实现了几乎相同的精度，但它们突出了不同的区域，作为最<strong>有助于预测其类标签的判判性时间模式</strong>。值得注意的是，与GTP相比，DTP发现的局部区域在类之间的可区分性更强，这使得CNN分类器具有更好的可解释性。</li>
<li>上图c给出了DTP层的分割结果;每个时间序列实例通过垂直线分为四个部分。第l段(l =  1，…，4)所有实例共享相似(或一致的)时间模式，即使它们的原始输入序列不是时间对齐的。结果表明，原型隐序列P成功地按时间顺序编码了片段的原型高级特征，因此DTP层可以基于P和H之间的DTW对齐进行语义分割。</li>
</ol>
]]></content>
      <categories>
        <category>xw</category>
      </categories>
      <tags>
        <tag>时间序列</tag>
        <tag>时序分类</tag>
      </tags>
  </entry>
  <entry>
    <title>xw Multi-Horizon TimeSeries Forecasting with Temporal Attention Learning</title>
    <url>/2020/11/23/XuWei/Multi-Horizon%20TimeSeries%20Forecasting%20with%20Temporal%20Attention%20Learning/</url>
    <content><![CDATA[<h2 id="论文信息"><a href="#论文信息" class="headerlink" title="论文信息"></a>论文信息</h2><p>论文：<strong>Multi-Horizon TimeSeries Forecasting with Temporal Attention Learning</strong></p>
<p>会议：KDD 2019</p>
<p>作者：</p>
<p><img src="https://imagebed-richado.oss-cn-beijing.aliyuncs.com/img/image-20201122205649219.png" alt="image-20201122205649219"></p>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p><strong>时间序列预测问题</strong>是研究如何在历史观测的基础上准确地预测未来。提高预测精度有利于提高社会各方面的运行效率</p>
<h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h3><blockquote>
<p>本文提出了一种新颖的数据驱动方法来解决多水平概率预测任务，该任务可预测未来时间范围内时间序列的完整分布。本文说明，历史信息中隐藏的时间模式在长时间序列的准确预测中起着重要作用。传统的方法依赖于人工建立时间依赖关系来探索历史数据的相关模式，这在现实世界数据的长期序列预测中是不现实的。相反，<strong>本文提出显示地学习用深层神经网络构建隐藏模式表征，并关注历史的不同部分来预测未来。</strong></p>
<p>本文提出了一个用于多水平时间序列预测的端到端深度学习的框架，通过时间注意机制，以更好地捕捉历史数据中的潜在模式。基于学习到的潜在模式特征，可以同时<strong>生成多个未来水平的多分位数的预测</strong>。本文还提出了一种多模式融合机制，该机制用于<strong>组合历史不同部分的特征以更好地预测未来</strong>。实验结果表明，本文的方法在两个不同领域的大型预测数据集上均实现了最先进的性能。</p>
</blockquote>
<a id="more"></a>
<h3 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h3><ol>
<li>长期预测给基于LSTM的模型带来了挑战（局部动态来源于历史信息和未来的动态输入变量）</li>
<li>有时需要预测目标的总体分布，以帮助企业决策。(分位数预测：一个典型的例子是，库存计划需要对产品的销售进行不同程度的高估，以降低库存缺货成本。根据每种产品的受欢迎程度和缺货成本，从预测分布中选择不同的高估水平)</li>
</ol>
<h3 id="分位数回归"><a href="#分位数回归" class="headerlink" title="分位数回归"></a>分位数回归</h3><p>分位数回归：分位数回归提出的原因，就是因为不希望仅仅是研究y的期望，而是希望能探索y的完整分布状况，</p>
<p>ex1:</p>
<p><img src="https://imagebed-richado.oss-cn-beijing.aliyuncs.com/img/image-20201122232538815.png" alt="image-20201122232538815" style="zoom:50%;" /></p>
<p><em>具有分位数预测的现实世界在线销售数据上的销售预测示例。 显示了每月50,000种产品的平均日销售量。 考虑到洋红色线条所示的2018年1月至3月的历史每日销售额，任务是预测4月至6月。 黑线表示实际销售额； 深蓝色线表示分位数为0.5的预测； 蓝色阴影区域显示分位数预测为0.2和0.8。</em></p>
<p><img src="https://imagebed-richado.oss-cn-beijing.aliyuncs.com/img/image-20201124155629912.png" alt="image-20201124155629912" style="zoom:50%;" /></p>
<h3 id="Contribution"><a href="#Contribution" class="headerlink" title="Contribution"></a>Contribution</h3><ol>
<li><p>提出了一种用于多水平时间序列预测的端到端深度学习框架，该框架具有新颖的结构以更好地捕捉未来水平上的时间模式，能组合历史不同部分的特征以更好地预测未来，同时生成多分位数预测。</p>
<blockquote>
<p>这个想法是首先使用双向LSTM解码器在向前和向后两个方向上传播未来输入变量的信息，同时考虑诸如促销和日历事件之类的动态未来信息。然后在每个未来的时间步中，我们使用解码器隐藏状态关注历史的几个不同时期，并分别生成关注向量。我们将不同的历史时期视为不同的模式，通过学习每种模式在预测当前时间步长的相对重要性，我们将它们结合起来。组合特征，我们称为时间背景特征，结合历史信息和未来的背景信息，可以最好地描述当前的时间步</p>
</blockquote>
</li>
</ol>
<h2 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h2><h3 id="Basic-encoder-decoder-structure"><a href="#Basic-encoder-decoder-structure" class="headerlink" title="Basic encoder-decoder structure"></a>Basic encoder-decoder structure</h3><p>本文采用这个序列到序列的学习流水线来编码历史(和未来)的输入变量，并对未来的预测进行解码</p>
<p><strong>LSTM</strong>：将历史信息映射进潜在表示$h<em>{t-1}$: $h</em>{t}^{e}=L S T M^{e}\left(x<em>{t} ; h</em>{t-1}\right)$</p>
<script type="math/tex; mode=display">
\begin{aligned} i_{t} &=\sigma\left(W_{i x} x_{t}+W_{i m} m_{t-1}\right) \\ f_{t} &=\sigma\left(W_{f x} x_{t}+W_{f m} m_{t-1}\right) \\ o_{t} &=\sigma\left(W_{o x} x_{t}+W_{o m} m_{t-1}\right) \\ c_{t} &=f_{t} \cdot c_{t-1}+i_{t} \cdot \tanh \left(W_{c x} x_{t}+W_{c m} m_{t-1}\right) \\ h_{t} &=o_{t} \cdot \tanh \left(c_{t}\right) \end{aligned}</script><p>$x<em>{t}$为t时刻的输入， $h</em>{t}$为t时刻的隐藏状态</p>
<h4 id="BiLSTM"><a href="#BiLSTM" class="headerlink" title="BiLSTM"></a>BiLSTM</h4><script type="math/tex; mode=display">
\begin{aligned} h_{t}^{f} &=L S T M^{f}\left(x_{t} ; h_{t-1}\right) \\ h_{t}^{b} &=L S T M^{b}\left(x_{t} ; h_{t+1}\right) \\ h_{t} &=\left[h_{t}^{f} ; h_{t}^{b}\right] \end{aligned}</script><h4 id="quantile-predictions"><a href="#quantile-predictions" class="headerlink" title="quantile predictions"></a>quantile predictions</h4><p>分位数的预测（K维）</p>
<script type="math/tex; mode=display">
\begin{aligned} y_{t}^{e} &=W_{e} h_{t}^{e}+b_{e} \\ y_{t}^{d} &=W_{d} h_{t}^{d}+b_{d} \end{aligned}</script><h4 id="Structure"><a href="#Structure" class="headerlink" title="Structure"></a>Structure</h4><p><img src="https://imagebed-richado.oss-cn-beijing.aliyuncs.com/img/image-20201123205439202.png" alt="image-20201123205439202" style="zoom:35%;" /></p>
<ol>
<li>分为Encoder 和Decoder</li>
<li>Encoder 编码历史信息，使用单向的LSTM对历史信息进行编码</li>
<li>Decoder使用编码的历史信息作为初始状态，使用未来信息作为输入，生成未来序列的输出，采用的是双向的LSTM（使未来的每个时间片都能得到未来和过去的输入信息。）</li>
<li>最后的预测应该在BiLSTM中信息传播之后进行，换句话说，并不使用之前时间步的预测结果来预测当前的时间步。将信息传播阶段与预测阶段分离的目的是为了防止误差积累，特别是对于长水平预测</li>
</ol>
<h3 id="Attention"><a href="#Attention" class="headerlink" title="Attention"></a>Attention</h3><p>由于LSTM记忆机制，需要不断的擦除旧的记忆，更新新的观测值，所以很难捕捉长程依赖。可以使用基于位置的注意力模型(position-based attention model)来捕捉历史数据中的伪周期模式。但是，他们的模型存在误差积累问题，同时需要动态的未来信息，这对预测精度有很大的影响。而且，他们的模型很难直接应用于长时间的历史，因为他们的注意力适用于整个历史，可能会被明显稀释</p>
<h4 id="Stracture"><a href="#Stracture" class="headerlink" title="Stracture"></a>Stracture</h4><p><img src="https://imagebed-richado.oss-cn-beijing.aliyuncs.com/img/image-20201123232718614.png" alt="image-20201123232718614" style="zoom:40%;" /></p>
<h4 id="Temporal-attention"><a href="#Temporal-attention" class="headerlink" title="Temporal attention"></a>Temporal attention</h4><p>在译码阶段，在每个未来时间步上使用BiLSTM hidden state来关注历史的不同部分，从而形成未来步的隐藏表示。没有关注整个历史，（1. 历史数据可能非常长， 2. 分别关注不同的时期，与多模态可以结合起来捕获周期信息）</p>
<p><img src="https://imagebed-richado.oss-cn-beijing.aliyuncs.com/img/image-20201123232823979.png" alt="image-20201123232823979" style="zoom:40%;" /></p>
<p><strong>公式：</strong></p>
<script type="math/tex; mode=display">
\begin{array}{l}\mathrm{g}=\mathrm{v}_{g}^{\top} \tanh \left(\mathrm{W}_{g} \mathrm{~s}_{t}+\mathrm{V}_{g} \mathrm{~h}+\mathrm{b}_{g}\right) \\ \gamma_{i}=\frac{\exp \left(g_{i}\right)}{\sum_{j=1}^{T_{h}} \exp \left(g_{j}\right)} \quad \text { for } i=1 \ldots T_{h}\end{array}</script><script type="math/tex; mode=display">
\begin{aligned} \mathbf{c}_{t} &=\sum_{i=1}^{T_{h}} \gamma_{i} \mathbf{h}_{i} \\ \mathbf{d}_{t} &=\operatorname{ReLU}\left(\mathbf{W}_{d} \mathbf{c}_{t}+\mathbf{b}_{d}\right) \end{aligned}</script><h4 id="Multimodal-fusion"><a href="#Multimodal-fusion" class="headerlink" title="Multimodal fusion"></a>Multimodal fusion</h4><p>使用之前计算出的转换向量$\mathrm{d}_{t}^{m}$和BiLSTM隐藏状态$s_t$计算不同时间段的权值，进一步进行多模态的融合（这的多模态指的是不同的时期）。</p>
<p><img src="https://imagebed-richado.oss-cn-beijing.aliyuncs.com/img/image-20201123233028016.png" alt="image-20201123233028016" style="zoom:50%;" /></p>
<p><strong>公式：</strong></p>
<script type="math/tex; mode=display">
\begin{aligned} \mathbf{p}_{t}^{m} &=\mathbf{v}_{p}^{\top} \tanh \left(\mathbf{W}_{p} \mathbf{s}_{t}+\mathbf{V}_{p}^{m} \mathbf{d}_{t}^{m}+\mathbf{b}_{p}\right) \\ \phi_{t}^{m} &=\frac{\exp \left(p_{t}^{m}\right)}{\sum_{k=1}^{M} \exp \left(p_{t}^{k}\right)} \quad \text { for } m=1 \ldots M \end{aligned}</script><p>最终得到：</p>
<script type="math/tex; mode=display">
\mathbf{x}_{t}=\sum_{m=1}^{M} \phi_{t}^{m} \mathbf{d}_{t}^{m}</script><h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><h3 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h3><h4 id="D50K-Online-Sales-Forecasting"><a href="#D50K-Online-Sales-Forecasting" class="headerlink" title="D50K Online Sales Forecasting"></a>D50K Online Sales Forecasting</h4><p>本文从全球在线零售公司JD.com收集了庞大的现实世界在线销售数据集。 该数据集包括2014年至2018年在中国6个地区销售的不同产品的每日销售数据的50,000个时间序列。坐着感兴趣的是预测所有需求区域中所有产品感兴趣月份的每日需求量，并且感兴趣的是0.50到0.95的分位数预测</p>
<p>由于必须同时考虑多个因素，例如产品类别，地理区域，促销等，因此销售预测具有挑战性。我们简要介绍可用功能，作为数据集中提供的历史和未来信息：</p>
<ol>
<li>配送中心id</li>
<li>商品分类</li>
<li>促销活动(促销活动假定是预先计划好的，因此可以作为历史和未来的输入变量)</li>
<li>日历信息（节日等信息）</li>
</ol>
<p><strong>Loss</strong>:</p>
<script type="math/tex; mode=display">
L^{M A D}=\sum_{i} \sum_{q} \frac{1}{T} \sum_{t}\left[q\left(y_{i t}-\hat{y}_{i t}^{q}\right)^{+}+(1-q)\left(\hat{y}_{i t}^{q}-y_{i t}\right)^{+}\right]</script><p>$i \in{1,2, \ldots, 50,000}$表示第i条序列</p>
<p>$q \in{0.5,0.6,0.7,0.8,0.9,0.95}$表示预设的分位数</p>
<p>$t$表示预测的未来时间步</p>
<h4 id="GEFCom2014-Electricity-Price-Forecasting"><a href="#GEFCom2014-Electricity-Price-Forecasting" class="headerlink" title="GEFCom2014 Electricity Price Forecasting"></a>GEFCom2014 Electricity Price Forecasting</h4><p>2014年全球能源预测大赛(GEFCom2014)引入的电价预测任务评估模型。GEFCom2014价格预测数据集包含2011-01- 2013-12-31三年的小时电价。这项任务是在平均分配的12个评估周内提供未来24小时的预测。在此数据集中，基于小时的区域和总电力负荷估算是过去和未来信息中都可以使用的两个时间特征。</p>
<p><strong>Loss</strong></p>
<script type="math/tex; mode=display">
L^{M A D}=\sum_{q} \frac{1}{T} \sum_{t}\left[q\left(y_{t}-\hat{y}_{t}^{q}\right)^{+}+(1-q)\left(\hat{y}_{t}^{q}-y_{t}\right)^{+}\right]</script><h3 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h3><h4 id="Baseline"><a href="#Baseline" class="headerlink" title="Baseline"></a>Baseline</h4><ol>
<li>Benchmark ：直接复制历史值作为将来的预测</li>
<li>Gradient-Boosting:梯度提升机，这是一种用于回归和分类问题的经典机器学习方法。</li>
<li>POS-RNN ：这是一种深度学习方法，将基于位置的注意力模型应用于序列的历史，并获得一个历史特征</li>
<li>MQ-RNN：使用LSTM编码器将序列的历史总结为一个隐藏特征，并使用MLP对隐藏特征与所有未来输入变量一起对所有未来范围进行预测，避免了错误累计。</li>
<li>TRMF：通过添加可衡量观察训练时间序列可能性的正则化项，将时间依赖性纳入矩阵分解模型中。本文采用他们选择的参数进行销售预测</li>
</ol>
<h4 id="Model-variants"><a href="#Model-variants" class="headerlink" title="Model variants"></a>Model variants</h4><ol>
<li>BiLSTM-Enc-Dec(h=1)，BiLSTM-Enc-Dec(h=3)是上文提到了不包含Attention机制的 LSTM encoder and BiLSTM decoder模型，其中h表示模型编码的历史信息的周期数</li>
<li>Single-Attention(h=1), 只涉及一个历史周期的Attention计算</li>
<li>Multimodal-Attention(h=3)，接受三个时期的历史数据，并首先分别对它们进行多重关注，然后将它们与多模式融合相结合，</li>
</ol>
<h4 id="Experiment-results"><a href="#Experiment-results" class="headerlink" title="Experiment results"></a>Experiment results</h4><p><strong>分位数损失对比</strong></p>
<p><img src="https://imagebed-richado.oss-cn-beijing.aliyuncs.com/img/image-20201123233425077.png" alt="image-20201123233425077" style="zoom:33%;" /></p>
<ol>
<li>Benchmark仅仅通过复制历史信息，就达到了 4.98的分位数损失</li>
<li>POS-RNN由于使用attention挖掘历史信息，达到了2.95的分位数损失</li>
<li>MQ-RNN要比POS-RNN更好，它独立输出每个未来的结果，并避免解码阶段的错误累积</li>
<li>bi-lstm - ence - dec (h=1)和bi-lstm - ence - dec (h=3)超出了以前的方法，这多亏了使用BiLSTMdecoder，它可以向前和向后传播动态的未来信息(事件和促销)。</li>
<li>通过结合注意机制，Single-Attention(h=1)模型将bi-lstm模型提高到2.14，而多注意(h=3)模型进一步提高到2.12，该模型使用了三个月的历史数据，并将注意应用于每个月。</li>
</ol>
<p><img src="https://imagebed-richado.oss-cn-beijing.aliyuncs.com/img/image-20201123233441242.png" alt="image-20201123233441242" style="zoom:33%;" /></p>
<p><strong>MSE对比</strong></p>
<p><img src="https://imagebed-richado.oss-cn-beijing.aliyuncs.com/img/image-20201124234637201.png" alt="image-20201124234637201" style="zoom:33%;" /></p>
<p>还将在CEFCom2014和JD50K数据集上，将本文的方法Single-Attention（h = 1）和Multimodal-Attention（h = 3）与具有均方误差（MSE）的基准和TRMF [32]进行了比较。 所示，在两个数据集上，本文提出的方法总是优于基准和TRMF超过20％，Multimodal-Attention（h = 3）优于Single-Attention（h = 1）约3％</p>
<h4 id="Forecasts-visualization"><a href="#Forecasts-visualization" class="headerlink" title="Forecasts visualization"></a>Forecasts visualization</h4><p><img src="https://imagebed-richado.oss-cn-beijing.aliyuncs.com/img/image-20201125134650866.png" alt="image-20201125134650866" style="zoom:50%;" /></p>
<p>对电价预测方法进行了两周的评估。黑线表示实际价格;红色阴影区域的上下边界表示0.25和0.75的分位数的预测;黄色阴影区域的边界显示0.01和0.99分位数的预测。</p>
]]></content>
      <categories>
        <category>xw</category>
      </categories>
      <tags>
        <tag>时序预测</tag>
        <tag>Attention</tag>
      </tags>
  </entry>
  <entry>
    <title>yjn Uncovering the structure of clinical EEG signals with self-supervised learning(SSL)</title>
    <url>/2021/01/06/YeJianan/Uncovering%20the%20structure%20of%20clinical%20EEG%20signals%20with%20self-supervised%20learning(SSL)/</url>
    <content><![CDATA[<p>用自监督学习方法揭示临床上EEG信号的结构</p>
<blockquote>
<p><strong>Objective:</strong> </p>
<p>监督学习方案常常受到可用标记数据数量的限制。这种现象在临床相关数据中尤其成问题，如脑电图(EEG)，在这些数据中，根据专业知识来标记代价昂贵。目前，设计用于脑电图数据学习的深度学习架构产生了相对较浅的模型，其性能至多与传统的基于特征的方法相似。然而，在大多数情况下，会有大量没有标记的数据。通过从这些未标记的数据中提取信息，尽管无法获取标签，但仍然有可能通过深度神经网络达到竞争性能。</p>
<a id="more"></a>
<p><strong>Approach:</strong></p>
<p>本文研究了自监督学习(SSL)，一种在未标记数据中发现结构的技术，以学习脑电信号的表示。 具体来说，我们探索了两个基于时间上下文预测以及对比预测编码在两个临床相关问题的表现：基于脑电图的睡眠分期和病理检测。我们在两个拥有数千条记录的大型公共数据集上进行了实验，并用纯监督和手工设计的方法进行了baseline的比较。</p>
<p><strong>Main results:</strong></p>
<p>在SSL学习特征上训练的线性分类器在低标记数据系统中的性能始终优于纯监督的深层神经网络，同时在拥有所有标签时都达到有竞争力的性能。 此外，用每种方法学习的嵌入揭示了与生理和临床现象相关的明确的潜在结构，如年龄效应。</p>
</blockquote>
<h2 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h2><p>​    Electroencephalography (EEG) 脑电信号作为一种重要的生理模态，在医疗场景中使用的非常广泛，如睡眠分阶、心理压力监测等。因此，设计模型可以进行分类，检测，并最终“理解”生理数据是必要的。传统上，这种类型的建模主要依赖于监督方法，其中需要大量带注释的数据集来训练具有高性能的模型。</p>
<blockquote>
<p><strong>当前的机器学习方法大多依赖于标注信息，这种对标注信息的过度依赖有如下危险：</strong></p>
<ul>
<li><strong>数据的内部结构远比标注提供的信息要丰富，因此通常需要大量的训练样本，但得到的模型有时是较为脆弱的。</strong></li>
<li><strong>在高维分类问题上，我们不能直接依赖监督信息；同时，在增强学习等问题上，获取标签的成本非常高。</strong></li>
<li><strong>标签信息通常适用于解决特定的任务，而不是可以做为知识一样可以重新利用。</strong></li>
</ul>
</blockquote>
<p>​     “自监督学习”(SSL)是一种无监督学习方法，它从未标记的数据中学习表示，利用数据的结构来提供监督。这里介绍的自监督学习方法是通过构造辅助任务（pretext）来辅助下游任务（downstream）。下游任务是我们真正感兴趣的任务，但是没有注释或注释有限。另一方面，辅助任务必须与下游任务有充分的关联，以便使用类似的表示来训练它，重要的是，必须能够仅使用未标记的数据为这个辅助任务生成注释。</p>
<p>在这篇论文中，我们研究自我监督的使用作为从脑电图数据学习表征的一般方法。首次对多种类型的脑电图记录进行了SSL任务的详细分析。我们的目标是回答以下问题:</p>
<ol>
<li>哪些好的SSL任务能够捕获脑电图数据中的相关结构?</li>
<li>就下游分类性能而言，SSL特性与其他非监督和监督方法相比如何?</li>
<li>SSL学到的特性是什么?具体来说，SSL能否从未标记的脑电图中捕获与生理和临床相关的结构?</li>
</ol>
<p>self-supervised learning两大流派</p>
<ul>
<li><p>构造辅助任务，辅助下游任务</p>
<p><img src="https://i.loli.net/2020/08/25/eHAnlKa2yFwsoB5.png" alt="image-20200823201736081" style="zoom: 50%;" /></p>
<p><img src="https://i.loli.net/2020/08/25/BePLb2DkmdKZXqV.png" alt="image-20200823205036629" style="zoom:50%;" /></p>
</li>
<li><p>contrastive learning</p>
<p><img src="https://i.loli.net/2020/08/24/EGvRPnSFbx5yCeO.png" alt="image-20200824164003461"></p>
<p><img src="https://i.loli.net/2020/08/24/srjAgPwm2tx4hYl.png" alt="image-20200824164133733"></p>
</li>
</ul>
<h2 id="2-Self-supervised-learning-pretext-tasks-for-EEG"><a href="#2-Self-supervised-learning-pretext-tasks-for-EEG" class="headerlink" title="2. Self-supervised learning pretext tasks for EEG"></a>2. Self-supervised learning pretext tasks for EEG</h2><p>本文描述三种SSL 构造辅助任务的方法</p>
<h3 id="2-1-Relative-positioning"><a href="#2-1-Relative-positioning" class="headerlink" title="2.1 Relative positioning"></a><strong>2.1 Relative positioning</strong></h3><p>对于多变量时间序列$S\in \R^{C<em>M}$, $M$表示序列长度（采样点个数），$C$表示维度（channel），用相同大小的滑窗$(x<em>t,x</em>{t^{,}})$进行截取长度为$T$的片段，$x<em>t,x</em>{t^{,}}\in \R^{C</em>T} $令第一个滑窗为anchor window, 假设时间片相近的片段应该共享同样的标签。 例如，针对睡眠阶段分类，睡眠阶段通常持续1到40分钟；因此，相近的窗口可能来自同一睡眠阶段，而相距遥远的窗口则可能来自不同的睡眠阶段。给定一个持续时间的阈值$\tau<em>{pos}\in N,\tau</em>{neg}\in N$，$y_i$为该分段的标签，对序列进行采样，于是有：</p>
<p><img src="https://i.loli.net/2020/08/25/Wzq3SojM2r8K1Yi.png" alt="image-20200823203802037"></p>
<p>即采样得到的一堆时间片相距小于$\tau<em>{pos}$还是大于$\tau</em>{neg}$</p>
<p><img src="https://i.loli.net/2020/08/25/SetcyY52Gj3A1K4.png" alt="image-20200823204035561"></p>
<p>为了学习端到端如何根据时间窗口的相对位置来区分对，我们引入了两个函数hΘ和$g<em>{RP}$。$h</em>Θ：R^{C×T}→R^{D}$是一种具有参数Θ的的特征提取器，它将窗口x映射到特征空间中的表示。 最终，我们期望hΘ学会一个  原始脑电输入的信息表示，可在不同的下游任务中重用。</p>
<p> $g<em>{RP}：R^D×R^D→R^D$通过计算逐个元素绝对差，将来自窗口对的表示结合起来，$g</em>{RP}(hΘ(x),h<em>Θ(x^{,}))=|h</em>Θ(x))-h<em>Θ(x^{,})|\in R^D$。在$g</em>{RP}$将$h<em>Θ$在两个输入窗口上提取的特征向量聚合起来，并突出它们的差异，以简化对比任务。 最后，建立了线性判别模型预测相关的目标y。 利用二元逻辑损失对$g</em>{RP}$的预测，我们可以写出联合损失函数$L(Θ,w,w_0),y$是sign函数。</p>
<p><img src="https://i.loli.net/2020/08/25/PSt9r5aQ2JqFG8B.png" alt="image-20200823211354219"></p>
<h3 id="2-2-Temporal-shuffling"><a href="#2-2-Temporal-shuffling" class="headerlink" title="2.2 Temporal shuffling"></a><strong>2.2 Temporal shuffling</strong></h3><p> 我们还介绍了RP任务的一个变体，我们称之为Temporal shuffling，其中我们从正例上下文中采样了两个anchor窗口$x<em>t$和$x</em>{t^{‘’}}$，以及第三个窗口$x_{t^{,}}$ ，若在两个正例之间(视为orderd)，若在负例范围之内(视为shuffled)。 </p>
<p><img src="https://i.loli.net/2020/08/25/Xj8PZ6W53l2vK4o.png" alt="image-20200823204112296"></p>
<p><img src="https://i.loli.net/2020/08/25/2LRwNFluKjfh5eM.png" alt="image-20200825102353648"></p>
<h3 id="2-3-Contrastive-predictive-coding-CPC"><a href="#2-3-Contrastive-predictive-coding-CPC" class="headerlink" title="2.3 Contrastive predictive coding(CPC)"></a><strong>2.3 Contrastive predictive coding(CPC)</strong></h3><p>CPC通过编码信息来学习表示法</p>
<p><img src="https://i.loli.net/2020/08/24/9v5GfcAuLVOUeWy.png" alt="image-20200824164625989"></p>
<p>事实上，CPC可以看作是RP的扩展，其中单个anchor窗口$x<em>t$被一系列$N_c$不重叠窗口所取代.这样，上下文中的信息可以用一个向量$c_t∈R^{D</em>{AR}}$表示。 例如，$g_{AR}$可以作为具有门控经常单元(GRU)的递归神经网络来实现)。</p>
<p><img src="https://i.loli.net/2020/08/25/xqwEUJri8tHnMFX.png" alt="image-20200825103055459"></p>
<p>整个CPC模型采用定义为的InfoNCE loss (categorical cross-entropy loss)进行端到端训练。 我们的任务是使context与正例相似度越大越好，与负例相似度越小越好。$f$用来度量context与得到的表示$h_{\theta}$之间的相似度。</p>
<p><img src="https://i.loli.net/2020/08/25/z7IEebmfSVT4ABs.png" alt="image-20200825110944595"></p>
<p>infoNCE定义为：</p>
<p><img src="https://i.loli.net/2020/08/25/HjIFY9QOTasyntq.png" alt="image-20200825135316018"></p>
<p><img src="https://i.loli.net/2020/08/24/b7xYGsqP4Oedo8Q.png" alt="image-20200823204129270"></p>
<h2 id="3-Downstream-Tasks"><a href="#3-Downstream-Tasks" class="headerlink" title="3. Downstream Tasks"></a>3. Downstream Tasks</h2><p>我们对两个临床问题进行了基于脑电的SSL的训练，睡眠监测和病理筛查。 这两个临床问题通常导致分类任务，尽管不同的类别和不同的数据生成机制：睡眠监测是关注的  生物学事件（事件水平)，而病理筛查与单一患者相比(个体水平）。 为了能够与监督方法进行公平的比较，我们在Physionet2018， 和TUH异常脑电图数据集进行。</p>
<p>首先，对于睡眠分阶任务，目前存在几个局限：1）专家评分存在局限（不准）；2）人工标注费时费力。睡眠分期通常会引起5个分类问题，W(清醒)，N1, N2, N3(不同的睡眠水平)和R(快速眼动期)。在这里，这项任务包括预测睡眠阶段，对应于30秒的脑电图。</p>
<p>第二，对于病理检测任务，通常需要依赖于非常专业的诊断，如癫痫、痴呆等。在TUH数据集中，医学专家将记录标记为病理或非病理，这导致了二值分类问题。重要的是，这两种标签反映了高度异质的情况:病理记录可以反映由于各种医疗条件造成的异常。</p>
<h2 id="4-Deep-learning-architectures"><a href="#4-Deep-learning-architectures" class="headerlink" title="4. Deep learning architectures"></a>4. Deep learning architectures</h2><p>我们在实验中使用了两种不同的深度学习体系结构作为嵌入器$h_Θ$获得embedding，如下图。 这两种结构都是由空间卷积和时间卷积层组成，分别学习典型的脑电处理流程中的空间和时间滤波操作。</p>
<p><img src="https://i.loli.net/2020/08/24/ajGgZqCDOIzV3Yi.png" alt="image-20200824141829089"></p>
<p>第一个网络叫StagerNet, 是一种三层卷积神经网络，用于处理30s多通道脑电波窗口。</p>
<p>第二种嵌入器结构叫ShallowNet，直接取自以前关于TUH异常数据集的文献。</p>
<p>另外，我们使用一个GRU，隐藏层的大小$D<em>{AR}=100$的CPC任务的$g</em>{AR}$，用于两个数据集上的实验。</p>
<h2 id="5-Experiment"><a href="#5-Experiment" class="headerlink" title="5. Experiment"></a>5. Experiment</h2><h3 id="5-1-Data"><a href="#5-1-Data" class="headerlink" title="5.1 Data"></a>5.1 Data</h3><p><strong>Physionet Challenge 2018 dataset(PC18)</strong></p>
<p>Recording number: 994；</p>
<p>Sample rate: 200Hz</p>
<p>Channel: 6</p>
<p><strong>TUH Abnormal EEG dataset</strong></p>
<p>这个数据集包含来自在医院环境下接受临床脑电图的2329名不同患者的15分钟或更长的记录。 每个记录都被标记为“正常”（1385次记录）或“异常”(998次记录）。</p>
<p>Sample rate: 256Hz</p>
<p><strong>Preprocessing</strong></p>
<p>对于PC18，我们使用了6:2:2的随机分割，这意味着在训练、验证和测试集中分别有595、199和199条记录。 对于RP和TS，2000对或三重窗口 从每个录音中取样。 对于CPC，从每个记录中提取的批次数被计算为该记录中窗口数的0.05倍；此外，我们将批处理大小设置32</p>
<p>PC18: 降采样成100Hz，只选用两个channel( F3-M2, F4-M1), 1个滑窗大小30s,输入（3000*2）</p>
<p>TUHab：降采样成100Hz，选用21个channel, 1个滑窗大小6s,输入（600*21）</p>
<h3 id="5-2-Baseline"><a href="#5-2-Baseline" class="headerlink" title="5.2 Baseline"></a>5.2 Baseline</h3><p>(1) random weights, ( 随机权重，使用一个嵌入器，其权重在随机初始化后保持不变)</p>
<p>(2) convolutional autoencoders, </p>
<p>(3) purely supervised learning </p>
<p>(4) handcrafted features（传统机器学习提取手工特征）：均值、方差、偏度、峰度、标准差、（0.5、4.5、8.5、11.5、15.5、30）Hz之间的频率对数功率带及其所有可能的比值、peak-to-peak幅值……</p>
<h3 id="5-3-Results"><a href="#5-3-Results" class="headerlink" title="5.3 Results"></a>5.3 Results</h3><ol>
<li><p>首先，将SSL方法与基于深度学习或手工制作特性的完全监督方法进行了比较。</p>
</li>
<li><p>其次，我们探索了SSL学习的表示来突出临床相关的结构。</p>
</li>
<li><p>最后，研究了在辅助任务和下游任务中，超参选择的影响。</p>
<h4 id="5-3-1-SSL模型学习脑电图的表示，并利用有限的注释数据促进下游任务"><a href="#5-3-1-SSL模型学习脑电图的表示，并利用有限的注释数据促进下游任务" class="headerlink" title="5.3.1 SSL模型学习脑电图的表示，并利用有限的注释数据促进下游任务"></a>5.3.1 SSL模型学习脑电图的表示，并利用有限的注释数据促进下游任务</h4><p>通过在标记示例上训练线性Logistic回归模型来评估下游任务性能，其中训练集至少包含一个和最多包含所有现有标记示例。 此外，完全监督的模型直接在标记数据上进行训练，随机森林在手工制作的特征上进行训练。标记样品数量对下游性能的影响如下图所示：</p>
</li>
</ol>
<p><img src="https://i.loli.net/2020/08/24/9lo5miq6pwJ84YN.png" alt="image-20200824194133447" style="zoom:200%;" /></p>
<p>PC18  72.3% balanced accuracy(5-class,chance=20%)    </p>
<ul>
<li>标签少时：RP/CPC/TS/Handcrafted feature 显著优于 full-supervision/AE/Random weights</li>
<li>标签增多：full-supervised得到显著提高，RP/CPC/TS/Handcrafted feature依然较好</li>
</ul>
<p>TUHab 79.4% (2-class, chance=50%)</p>
<ul>
<li>总体趋势与第一个数据集表现类似</li>
<li>每个类标签少于10000时，监督方法弱于CPC</li>
</ul>
<p>这些结果证明了SSL能够为我们的下游任务学习有用的表示。 其次，比较表明SSL学习的特性与其他基线相比具有竞争力，甚至可以优于监督的方法。</p>
<h4 id="5-3-2-SSL-models-capture-physiologically-and-clinically-meaningful-features"><a href="#5-3-2-SSL-models-capture-physiologically-and-clinically-meaningful-features" class="headerlink" title="5.3.2 SSL models capture physiologically and clinically meaningful features"></a>5.3.2 SSL models capture physiologically and clinically meaningful features</h4><p>虽然SSL学习的特性在睡眠分期和病理检测任务上产生了竞争性能，但尚不清楚SSL捕获了什么样的结构。</p>
<p>通过分析它们与临床数据集中可用的不同注释和元数据的关系来观察这种嵌入之间的关系。 因此，我们将在PC18和TUHab上获得的100维嵌入投影到一个二维表示上，使用均匀流形近似和投影(UMAP)并使用表现最好的模型。</p>
<p><img src="https://i.loli.net/2020/08/24/upgUaXKGbcwSD3j.png" alt="image-20200824202455160"></p>
<p>PC18数据集上SSL特性的UMAP可视化。 子图显示了5个睡眠阶段的分布，作为TS（第一行）和CPC（第二行）特征的散点图。 轮廓线对应所有阶段的分布密度水平，用作视觉参考。 最后，每个点对应于从脑电图的30s窗口提取的特征。 在这两种情况下， 有明确的结构与睡眠阶段，虽然在训练期间没有提供标签。</p>
<p>我们认为，ssl学习特征的连续性质是所研究的神经生理现象所固有的。方便的是，这为改善生理数据的分析提供了机会。</p>
<h4 id="5-3-3-SSL-pretext-task-hyperparameters-strongly-inflfluence-downstream-task-performance"><a href="#5-3-3-SSL-pretext-task-hyperparameters-strongly-inflfluence-downstream-task-performance" class="headerlink" title="5.3.3 SSL pretext task hyperparameters strongly inflfluence downstream task performance"></a>5.3.3 SSL pretext task hyperparameters strongly inflfluence downstream task performance</h4><p>在临床脑电图任务中，如何调整各种SSL辅助任务的超参数以充分发挥自我监督的作用?</p>
<p><img src="https://i.loli.net/2020/08/24/FTDYcvAjf1RQmhO.png" alt="image-20200824205129040"></p>
<p>首先，我们重点讨论了相同记录的负采样场景，其中从与anchor窗口相同的记录中采样负示例。 对于RP，随着$τ<em>{pos}$的增加，总是使辅助任务分类更难。 这是预料中的，因为给定是$\tau</em>{pos}$的时间（上下文）越大，就越有可能得到由遥远的（因此可能不相关的）的正例对。 </p>
<p> 至于CPC，一项类似的分析表明，虽然增加了预测窗口的数量（“步数”），使辅助任务变得更加困难，但预测未来的进一步发展有助于预测，嵌入器学习更好的睡眠分期表示</p>
<p> 在这个实验中，我们证实了我们的SSL辅助任务并是对下游任务是有影响的，并且某些辅助任务超参数对下游性能有可测量的影响。</p>
<h3 id="6-Discussion"><a href="#6-Discussion" class="headerlink" title="6 Discussion"></a>6 Discussion</h3><h4 id="6-1-Finding-the-right-pretext-task-for-EEG"><a href="#6-1-Finding-the-right-pretext-task-for-EEG" class="headerlink" title="6.1 Finding the right pretext task for EEG"></a>6.1 Finding the right pretext task for EEG</h4><p> 随着人们所能想到的大量自我监督的借口任务，以及更多可能的脑电下游任务，我们如何选择辅助任务和超参数组合？</p>
<ul>
<li><p>我们引入并定制了相对定位(RP)和时间片打乱(TS)任务，依靠对脑电的先验知识。 事实上，睡眠脑电图信号具有明确的时间结构，起源于夜间睡眠阶段的连续。这意味着在时间上相近的两个窗口很可能共享相同的睡眠阶段注释和统计结构。因此，学习区分近窗和远窗应该与学习区分睡眠阶段有直观的关系。</p>
</li>
<li><p>选择辅助任务超参数对于选择正确的辅助任务配置至关重要。 例如，RP、TS和CPC通常产生非常相似的下游任务。 一旦选择了最佳的超参数，就可以进行性能测试。</p>
</li>
</ul>
<h4 id="6-2-Limitation"><a href="#6-2-Limitation" class="headerlink" title="6.2 Limitation"></a>6.2 Limitation</h4><p>本工作的目的是引入自我监督作为脑电的一种表征学习范式，我们没有关注这两类任务与早期工作中的最先进性能的表现。</p>
<h2 id="7-Conclusion"><a href="#7-Conclusion" class="headerlink" title="7. Conclusion"></a>7. Conclusion</h2><p>在本工作中，我们引入了SSL方法来学习EEG数据上的表示，并表明它们可以与两个大型临床数据集上的传统监督方法竞争，有时甚至优于传统的监督方法。 重要的是，SSL学习到的特征显示了一个清晰的结构，其中不同的生理量被编码，这验证了自监督学习的潜力，以捕捉重要的生理信息，即使在没有标记的数据。 未来的工作将分为以下两方面：</p>
<ol>
<li>证明SSL是否也可以成功地使用于其他类型的脑电图记录和任务中，如回归。</li>
<li>更好地理解如何为特定的脑电图结构设计辅助任务，对于利用自我监督学习建立作为脑电图分析流程的关键组成部分至关重要。</li>
</ol>
]]></content>
      <categories>
        <category>yjn</category>
      </categories>
      <tags>
        <tag>自监督</tag>
        <tag>EEG</tag>
      </tags>
  </entry>
  <entry>
    <title>yjn 【ICLR 2021】Unsupervised Representation Learning for Time Series with Temporal Neighborhood Coding</title>
    <url>/2021/03/24/YeJianan/%E3%80%90ICLR2021%E3%80%91Unsupervised%20Representation%20Learning%20for%20Time%20Series%20with%20Temporal%20Neighborhood%20Coding/</url>
    <content><![CDATA[<p>关键词：自监督学习，EEG，时间序列</p>
<h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>时间序列通常很复杂且信息丰富，但标记稀疏，因此很难建模。 在本文中，我们提出了一种自监督框架，用于学习非平稳时间序列的通用表示。 我们的方法称为时间邻域编码（TNC），它利用信号生成过程的局部平滑度来及时定义具有相似属性的邻域。 通过使用无偏差的对比目标（debiased contrastive objective），我们的框架通过确保在编码空间中来自邻域内的信号的编码特征与非邻域信号的编码特征是可区分的，来学习时间序列表示。 我们的动机来自医学领域，在该领域中，对时间序列数据的动态性质进行建模的能力对于在几乎不可能标记数据的环境中识别，跟踪和预测潜在患者的潜在状态尤其有价值。 我们将我们的方法与最近开发的无监督表示学习方法进行了比较，并证明了在针对多个数据集进行聚类和分类任务方面的卓越性能。</p>
<a id="more"></a>
<p>ICLR 2021</p>
<p>Sana Tonekaboni∗, Danny Eytan, Anna Goldengerg (University of Toronto &amp; Vector Institute；The Hospital for Sick Children)</p>
<h2 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h2><p>由于时间序列的复杂性以及标签在真实场景下不可获得性，监督学习变得比较困难。采用无监督表示学习可以利用数据内在的结构特点，从原始序列中提取低维的、富含信息的表示，而无需监督信息。这些表示更加通用并且鲁棒，这是因为他们不是针对某个特定的监督任务提取的。无监督表示学习在CV, NLP上都有广泛的应用，但是在时间序列上面的研究还比较少。这种建模时间序列动态特性在医学领域是非常有价值的，因为健康检测数据通常表现为时间序列。</p>
<p>本文提出了一种自监督框架来学习复杂的多变量非平稳时间序列的表示，称为TNC（Temporal Neighborhood Coding），是专门为信号随着时间变换而变化的这种时序特征设计的，目的在于捕捉序列潜在的时序动态性。我们评估了在多个数据集上学习到的表示的质量，并表明学到的表示是通用的，可转移到许多下游任务，如分类和聚类。本文贡献主要体现在下面三方面：</p>
<ul>
<li>针对非平稳多元时间序列数据，我们提出了一种新的基于邻域的无监督学习框架</li>
<li>我们引入了具有平稳性质的时间邻域的概率作为相似窗口在时间上的分布。利用信号的性质和统计测试结果<strong>自动确定邻域边界</strong></li>
<li>我们引入正例的无标记学习（Positive Unlabel learning）的概念，具体来说是对非邻域的样本进行权重调整，以解释为对比损失在抽样负样本时引入的偏差</li>
</ul>
<h2 id="2-Method"><a href="#2-Method" class="headerlink" title="2. Method"></a>2. Method</h2><p>我们提出一个自监督学习框架，学习一个表示空间，通过确保在表示空间中，可区分近端信号在时间上的分布与远端信号的分布。定义如下符号表示：</p>
<p>原信号：$X\in R^{D*T}$，$T$为序列长度，$D$为特征维数</p>
<p>时间窗：$X[t-\frac{\delta}{2},t+\frac{\delta}{2}]$ 表示以时刻$t$为中心，长度为$\delta$的窗口长度，也记为$W_t$</p>
<p>$W_t$的邻居集合：$N_t$, 是由以$t^<em>$为中心，从一个正态分布$t^</em>\sim \mathcal N(t,\eta·\delta)$采样得到。$\eta$是定义邻居范围的参数，描述了信号的统计特征如何随时间变化的特性，通常需要领域专家基于专业知识来确定。</p>
<p>$W_t$的非邻居集合：$\bar{N_t}$</p>
<p><strong>我们的目标是：来学习$W_t$的潜在表示，再通过时间上的滑窗，我们可以获得信号潜在状态的变化轨迹。</strong></p>
<p>基于这样的假设：利用信号生成过程的局部平滑性，将邻域分布特征刻画为高斯分布，对时域数据中的逐渐过渡进行建模，直观地，这些邻域样本（正样本）的表示与$W_t$的表示相似度大，而非邻域中的样本（负样本）和$W_t$的表示相似度小。</p>
<blockquote>
<p><strong><em>然而，这种假设可能会受到抽样偏差的影响，这是大多数对比学习方法中常见的问题。</em></strong></p>
<p>在随机选取负样本的时候可能存在这样的情况，虽然“负样本”距离$W_t$很远，但是和参考样本很相似，有相同的隐含状态。例如，在存在长期季节性的情况下，信号可以在遥远的时间表现出类似的特性。</p>
</blockquote>
<p><strong>$TNC$由两部分组成：</strong></p>
<ol>
<li>编码器$Enc(W_t)$将$W_t\in \mathbb{R}^{D*\delta}$编码成更低维的空间$Z_t\in \mathbb{R}^M$</li>
<li>鉴别器$\mathcal{D}(Z_t,Z)$来估计$Z$在和邻域$N_t$内的概率。确切来说，它从编码空间中接收两个样本，并预测属于同一时间邻域的样本的概率。对于鉴别器$\mathcal{D}(Z_t,Z)$，我们使用一个简单的多头二进制分类器，如果$Z$和$Z_t$是邻居在时间上的表示，则输出1，否则输出0</li>
</ol>
<p><img src="https://i.loli.net/2021/03/22/3dCjzPMTJtHSxqv.png" alt="image-20210322112042341"></p>
<p>我们希望鉴别器的概率似然估计是准确的，即输入一对近邻样本的表示时概率接近于1，输入一对相聚较远样本的表示时概率接近于0。在非邻域$\bar{N}$内，为了缓解上面提到的负样本抽样偏差问题，采用权重系数$w$来调整非邻域内的正样本。</p>
<p><img src="https://i.loli.net/2021/03/22/kgsl6fRWUoEmvXi.png" alt="image-20210322113221422"></p>
<p>我们通过优化这一目标，同时训练编码器和鉴别器。注意，鉴别器只是训练的一部分，不会在推理过程中使用。</p>
<ul>
<li>确定$\eta$值</li>
</ul>
<p>ADF-test ——可用于验证时间序列的平稳性假设</p>
<p>由于邻居样本代表相似的样本，我们需要确定$\eta$合适的值，使得在一个平稳信号生成过程中，应该能识别出这个相似时间跨度的样本分布。这里采用ADF test（Augmented Dickey-Fuller）自动根据信号本身的行为对每个时间窗确定$\eta$的范围。$\eta$太小，邻域内的许多样本会重叠，使得编码器学习到的信息都是重复信息；如果$\eta$太大，领域可能跨越多种潜在状态，使得编码器也学不到不同状态之间的变化，因此无法区分。</p>
<p>我们将每个窗口周围的时间邻域定义为信号相对平稳的区域。由于信号可能会在一段未知的时间内保持潜在状态，因此每个窗口的邻域范围$\eta$可能在大小上有所不同，必须根据信号的行为进行调整。为此，我们使用ADF-test得出邻域范围的统计检验。</p>
<ul>
<li>负样本抽样偏差的问题</li>
</ul>
<p>PU learning（Positive Unlabeled learning）——在只有正例和无标记样本的情况下训练一个二分类器</p>
<p>如上提到的偏差问题，我们考虑在$N_t$内的样本都和当前参考样本$W_t$相似，视为已知的正样本，但在的样邻域外的样本不一定和$W_t$不同。我们将非邻域样本视为 Unlabeled data。因此有两种策略去解决unlabeled data：1. 把所有无标签样本都视为负样本；2. 把无标签样本视为带更小权重的负样本。在第二种策略下，无标签数据在损失项中需要被赋予适当的权重，才能去训练一个无偏的分类器。</p>
<p>在TNC框架中，这个权重$w$指的是$\bar{N_t}$中样本与$W_t$的相似样本出现的概率。附录A.6解释了如何为我们不同的实验设置选择权重参数，也演示了权重调整对下游任务性能的影响。</p>
<p><strong>窗口大小选择的影响：</strong></p>
<p><img src="https://i.loli.net/2021/03/22/rCd6HmRkwfKoXVu.png" alt="image-20210322193157095"></p>
<p><strong>无偏损失系数$w$的影响</strong></p>
<p><img src="https://i.loli.net/2021/03/22/NzUtsgIokSfCZKi.png" alt="image-20210322194318089"></p>
<p><img src="https://i.loli.net/2021/03/22/dT8tuzom4P6j5SZ.png" alt="image-20210322194507015"></p>
<p>完成邻域分布的定义后，我们训练目标函数来鉴别邻域内样本的表示和邻域外样本的表示。理想的编码器完成编码后，得到的编码空间保留了邻域内样本的特性。设$Z_l=Enc(W_t),W_l\in N_t,Z_k=Enc(W_k),W_k\in \bar{N_t}$</p>
<h2 id="3-Experiment"><a href="#3-Experiment" class="headerlink" title="3. Experiment"></a>3. Experiment</h2><p>我们在多个时间序列数据集上评估我们的框架的可用性，这些数据集具有随时间变化的动态潜在状态。我们将时间序列的分类性能和可聚类性与两种最先进的无监督表示学习方法进行了比较:<strong>1.对比预测编码(CPC)</strong> ，使用预测编码原则训练编码器的概率对比损失。<strong>2. triplet - loss (T-Loss)</strong>，它采用基于时间的负采样和triple - loss来学习时间序列窗口的表示。triplet-loss 的目标是通过最小化正样本(子序列)之间的距离，同时最大化正样本与负样本之间的距离，确保相似的时间序列具有相似的表示。</p>
<p>为了公平比较，确保最后的性能差异不是模型的结构造成的，本文在所有baseline中用一样的Encoder网络，因为我们的目标是比较学习框架的性能，与编码器的选择无关。我们通过1)评估编码空间的聚类性和；2)使用下游分类任务的表示来评估表示的泛化性。</p>
<p>除了上述baseline，还有基于DTW的K-means/KNN </p>
<h3 id="Datasets"><a href="#Datasets" class="headerlink" title="Datasets"></a>Datasets</h3><ul>
<li><h4 id="Simulated-data"><a href="#Simulated-data" class="headerlink" title="Simulated data"></a>Simulated data</h4><p>采用HMM生成随机隐含状态，在每个状态，时间序列又由不同的过程生成如不同核函数的高斯过程，非线性自回归移动平均模型，最终生成的序列包含3个特征的2000个测量值，包含4个不同的隐含状态。我们使用了一种双向、单层递归神经网络作为编码器</p>
</li>
<li><h4 id="Clinical-Waveform-Data"><a href="#Clinical-Waveform-Data" class="headerlink" title="Clinical Waveform Data"></a>Clinical Waveform Data</h4><p>MIT-BIH Atrial Fibrillation dataset。该数据集包括25个患有房颤的人类受试者的长期心电图记录(持续10小时)。它由两个心电信号组成，每个都以250hz采样。随着时间的推移，信号被标注为4类不同类型的心律。本实验的目的是在没有任何标签信息的情况下确定每个样本的潜在心律失常类型。</p>
<p>由于简单的RNN结构不能建模高频的ECG信号，因此，这里采用6层CNN结构作为编码器。窗口大小设为2500个点，编码的表示为64维的向量。</p>
</li>
<li><h4 id="Human-Activity-Recognition-HAR-data"><a href="#Human-Activity-Recognition-HAR-data" class="headerlink" title="Human Activity Recognition (HAR) data"></a>Human Activity Recognition (HAR) data</h4><p>利用加速度计和陀螺仪测量的时间数据来预测活动类型。数据集包含30个个体，每个人监测6种活动。单层RNN编码器作为编码器。窗口设为4，代表15s的记录，编码的向量10维。</p>
</li>
</ul>
<h2 id="4-Results"><a href="#4-Results" class="headerlink" title="4. Results"></a>4. Results</h2><p>这里评估了所有baseline再所有数据集上的可聚类性能和下游任务上的分类性能。可群集性表示每种方法恢复原先状态的良好程度，而分类则评估我们的表示对下游任务的信息量有多大。</p>
<h3 id="4-1可聚类性"><a href="#4-1可聚类性" class="headerlink" title="4.1可聚类性"></a>4.1可聚类性</h3><p>许多真实世界的时间序列数据具有底层的多类别结构，这自然导致了具有集群属性的表示。如果隐含状态的信息被编码器充分学到了，那具有相同隐含状态的信号编码后应该能聚集在一起。</p>
<p>下面是针对仿真数据，利用三种不同的框架学习到的隐空间的特征表示可视化结果：</p>
<p><img src="https://i.loli.net/2021/03/22/curpoZymWHD5xfJ.png" alt="image-20210322151146107"></p>
<p>为了比较每个baseline聚类的一致性，我们使用两个常用来衡量聚类有效性的指标：Silhouette score$\in[-1,1]$，分数越高代表聚集性越好；Davies-Bouldin index，衡量类内相似性和类间差异，分数越低代表聚集性越好。我们在表示空间中使用K-means聚类来度量这些可群集性得分。</p>
<p><img src="https://i.loli.net/2021/03/22/CPnaqxjihApBoRJ.png" alt="image-20210322151809362"></p>
<p>TNC：在所有baseline和数据集上都取得了最好的得分，可聚集性表现最好</p>
<p>CPC：HAR数据集，CPC可以很好地对状态进行分组，因为大多数活动都是按照特定的顺序记录的，增强了预测性编码。在ECG波形数据上的表现接近于Triplet-loss，但在模拟数据集上表现较差，因为模拟信号是非平稳的，而且过渡难以预测</p>
<p>Triplet-loss：在模拟环境中表现良好，但无法区分状态0和状态2，可能原因是其中信号来自不同参数的自回归模型</p>
<h3 id="4-2-分类性能"><a href="#4-2-分类性能" class="headerlink" title="4.2 分类性能"></a>4.2 分类性能</h3><p>我们训练一个线性分类器来评估使用表示来分类隐藏状态的效果如何。所有baseline的性能与监督分类器进行比较，监督分类器由一个编码器和一个与无监督模型具有相同架构的分类器组成，以及一个使用DTW度量的k近邻分类器。评价指标：AUPRC（area under the precision-recall curve），因为对于不平衡分类设置，如波形数据集，AUPRC可以更准确地反映模型性能。</p>
<p><img src="https://i.loli.net/2021/03/22/gqmlaBciOYMkeTV.png" alt="image-20210322154050083"></p>
<p>TNC接近端到端有监督模型的分类效果。这进一步证明了我们的编码捕获了时间序列的信息部分，并且可泛化用于下游任务。</p>
<p>对于HAR这样的数据集，时序内部的状态更替存在一定的顺序性，因此CPC能取得较好的结果。而当时序中增加非平稳性后，性能就下降了。CPC和triple Loss方法性能相对较低也可能是因为这些方法都没有明确解释当随机选择的负样本时，仍然得到和参考样本$W_t$相似的信号段从而造成抽样偏差。</p>
<h3 id="4-3-trajectory"><a href="#4-3-trajectory" class="headerlink" title="4.3 trajectory"></a>4.3 trajectory</h3><p><img src="https://i.loli.net/2021/03/22/do4vht1sRQaZurn.png" alt="image-20210322155426855"></p>
<p>上面部分是原始序列，下面是编码序列，阴影部分表示一种隐含状态。原信号的状态转换也体现在编码特征。</p>
<h2 id="5-Conclusion"><a href="#5-Conclusion" class="headerlink" title="5. Conclusion"></a>5. Conclusion</h2><p>本文提出了TNC（Temporal Neighborhood Coding）框架，来学习非平稳，多变量时间序列的状态表示。文章的出发点是在医疗保健领域，学习丰富的时间医学数据表示对于了解患者的潜在健康状况变化非常重要。然而，现有的大多数表征学习方法都是针对特定的下游任务而设计的，需要专家进行标记。本文在多个数据集上验证了TNC学到的表示是通用的，灵活可扩展的。因此这一框架也可以用于其他数据领域。同时也可以将这种表示学习方法应用到多种下游任务比如异常检测。</p>
]]></content>
      <categories>
        <category>yjn</category>
      </categories>
      <tags>
        <tag>自监督</tag>
        <tag>EEG</tag>
      </tags>
  </entry>
  <entry>
    <title>zhj 【NIPS 2020】 What Makes Good Views for Contrastive Learning</title>
    <url>/2020/12/16/ZhangHongjun/2012_NeuriPS-2020-What%20Makes%20for%20Good%20Views%20for%20ContrastiveLearning/</url>
    <content><![CDATA[<h3 id="1-Abstract-概要"><a href="#1-Abstract-概要" class="headerlink" title="1 Abstract 概要"></a>1 Abstract 概要</h3><p>用数据的多个视图来做表示学习是当前自监督学习的热点。尽管这方面的应用很成功，但是很少有人研究怎么选择好的视图来做表示学习。本文运用理论和实证分析来更好地理解视图选择的重要性，得出的结论，在给定下游任务时，视图之间的互信息恰好都仅与下游任务有关，这时候下游任务能取得最好的结果。除此之外，本文还设计了一种半监督的方法，用来学习如何生成最好的视图。</p>
<a id="more"></a> 
<h3 id="2-什么是视图（view）？"><a href="#2-什么是视图（view）？" class="headerlink" title="2 什么是视图（view）？"></a>2 什么是视图（view）？</h3><h5 id="视图的例子"><a href="#视图的例子" class="headerlink" title="视图的例子"></a>视图的例子</h5><p>从不同的角度看同样的事物，会有不同的视图。在自监督学习里面，视图可以是同一个物体不同的角度的图片；视频中的图片、声音和字幕；图片的不同通道；不同的数据增强方式获得不同的视图；生理信号的时频图；</p>
<h5 id="视图之间的共享信息（mutual-information，-MI）"><a href="#视图之间的共享信息（mutual-information，-MI）" class="headerlink" title="视图之间的共享信息（mutual information， MI）"></a>视图之间的共享信息（mutual information， MI）</h5><p>理解为视图之间共有的信息。</p>
<p>举例：</p>
<p>例1：下面三个视图中的数字3，是他们共享的信息。</p>
<p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/image-20210113110206216.png" alt="image-20210113110206216"><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/image-20210113110239948.png" alt="image-20210113110239948"><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/image-20210113110331718.png" alt="image-20210113110331718"></p>
<p>例2：下面两个视图中的背景，是他们共享的信息。</p>
<p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/image-20210113110206216.png" alt="image-20210113110206216"><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/image-20210113111629299.png" alt="image-20210113111629299"></p>
<p>在表示学习的应用中，一般有两个阶段：</p>
<p>1.表示学习阶段：使用不同的视图，进行自监督的表示学习，训练一个编码器$f$</p>
<p>2.下游任务：固定学习好的网络$f$参数，在$f$后面加一个线性层，参数为$w$，使用少量的有标签数据训练$w$。</p>
<p>由于表示学习阶段学到了数据中的语义信息，下游任务只需要少量的标签就可以取得较好的效果。</p>
<h3 id="3-怎么样的视图是最好的视图？"><a href="#3-怎么样的视图是最好的视图？" class="headerlink" title="3 怎么样的视图是最好的视图？"></a>3 怎么样的视图是最好的视图？</h3><p>用什么样的视图来做表示学习，才能使得下游任务取得最好的效果呢？</p>
<p>在本文的定义中，最好的视图是与下游任务息息相关的。在给定下游任务之后，视图之间的互信息恰好都仅与下游任务有关，这时候下游任务能取得最好的结果。例如，在例1中，视图之间共享的信息是数字，如果下游任务是数字识别，它们就是好的视图；如果下游任务是背景识别，那就不是好的视图。例2则相反。</p>
<p>用$I(a,b)$表示a和b的互信息，x表示输入，y表示标签，$v_1,v_2$是x的两个视图，则最好的视图应该是：</p>
<script type="math/tex; mode=display">
I\left(\mathbf{v}_{\mathbf{1}} ; \mathbf{y}\right)=I\left(\mathbf{v}_{\mathbf{2}} ; \mathbf{y}\right)=I\left(\mathbf{v}_{\mathbf{1}} ; \mathbf{v}_{\mathbf{2}}\right)=I(\mathbf{x} ; \mathbf{y})</script><p>也就是$v_1，v_2$这两个视图，都包含了对下游任务有帮助的所有信息。</p>
<p>以下图有助于说明：</p>
<p>横轴是视图之间的互信息，纵轴是下游任务的效果。绿色是与下游任务有关的信息，粉红色是与下游任务无关的信息，视图重叠的部分是视图的共享信息。当视图之间共享的信息仅包含与下游任务有关的信息，此时下游任务的效果是最好的。</p>
<p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/image-20210113115134473.png" alt="image-20210113115134473"></p>
<p>最好的视图，就是视图之间的互信息恰好处于一个最佳点（Sweet Spot），视图之间的共享信息及不漏掉对下游任务用贡献的信息，也不包含对下游任务没有的信息。</p>
<p>下图b)分为3段：</p>
<ul>
<li>丢失信息：$I\left(\mathbf{v}<em>{\mathbf{1}} ; \mathbf{v}</em>{\mathbf{2}}\right)&lt;I(\mathbf{x} ; \mathbf{y})$，missing info是丢失的有用信息，视图之间的互信息没有包含太多对下游任务有用的信息，所以效果不好；</li>
<li>最佳点（Sweet Spot）：$I\left(\mathbf{v}<em>{\mathbf{1}} ; \mathbf{y}\right)=I\left(\mathbf{v}</em>{\mathbf{2}} ; \mathbf{y}\right)=I\left(\mathbf{v}<em>{\mathbf{1}} ; \mathbf{v}</em>{\mathbf{2}}\right)=I(\mathbf{x} ; \mathbf{y})$，视图之间的共享信息就是全部对下游任务有用的信息。</li>
<li>过多噪声：$I\left(\mathbf{v}<em>{\mathbf{1}} ; \mathbf{v}</em>{\mathbf{2}}\right)$，视图之间的互信息包含了太多对下游任务没用的信息，下游任务的泛化性能差。（可以参考）</li>
</ul>
<p>所以，&lt;下游任务性能-$I(v_1,v_2)$&gt; 的图像普遍是一个倒立的U形（如下图右）：</p>
<p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/image-20210113120023277.png" alt="image-20210113120023277"></p>
<p>本文的多个实验说明，图  &lt;下游任务性能-$I(v_1,v_2)$&gt;  普遍存在倒U型的图：</p>
<p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/image-20210113115838448.png" alt="image-20210113115838448"></p>
<p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/image-20210113115903284.png" alt="image-20210113115903284"></p>
<h3 id="4-学习最好的视图"><a href="#4-学习最好的视图" class="headerlink" title="4 学习最好的视图"></a>4 学习最好的视图</h3><p>以往的视图都是人工设计的视图，这里提出了一个通用的生成最佳视图的半监督方法。</p>
<p>生成最好的视图：在将视图应用到表示学习之前，先设计另外一个神经网络（生成器g），用g来生成最好的视图。</p>
<p>流程是：</p>
<p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/image-20210113122756215.png" alt="image-20210113122756215"></p>
<h5 id="4-1-无监督的生成视图方式：最小化-I-left-mathbf-v-mathbf-1-mathbf-v-mathbf-2-right"><a href="#4-1-无监督的生成视图方式：最小化-I-left-mathbf-v-mathbf-1-mathbf-v-mathbf-2-right" class="headerlink" title="4.1 无监督的生成视图方式：最小化$I\left(\mathbf{v}{\mathbf{1}} ; \mathbf{v}{\mathbf{2}}\right)$"></a>4.1 无监督的生成视图方式：最小化$I\left(\mathbf{v}<em>{\mathbf{1}} ; \mathbf{v}</em>{\mathbf{2}}\right)$</h5><p>定义生成器g，g是一个卷积核为1*1的卷积层加ReLU激活，$\hat{X}=g(X)$, 对于数据$X$，可以将$X$按通道切分为$\left{X<em>{1}, X</em>{2: 3}\right}$。</p>
<p>定义$\hat{X}<em>{1}$,$\hat{X}</em>{2: 3}$分别为两个视图；另外有$I<em>{\mathrm{NCE}}\left(\hat{X}</em>{1} ; \hat{X}<em>{2: 3}\right)$是$I\left(\hat{X}</em>{1} ; \hat{X}_{2: 3}\right)$的估计（文章中有定义）。</p>
<p>为了训练g，使得$I<em>{\mathrm{NCE}}\left(\hat{X}</em>{1} ; \hat{X}_{2: 3}\right)$最小，使用对抗训练的思想。</p>
<p>引如两个编码器$f<em>1,f_2$,训练$f_1,f_2$最大化$I</em>{\mathrm{NCE}}\left(\hat{X}<em>{1} ; \hat{X}</em>{2: 3}\right)$，与 GAN中的判别器相似。</p>
<p>同时，训练g，最小化$I<em>{\mathrm{NCE}}\left(\hat{X}</em>{1} ; \hat{X}_{2: 3}\right)$，形式化的目标函数为：</p>
<script type="math/tex; mode=display">
\min _{g} \max _{f_{1}, f_{2}} I_{\mathrm{NCE}}^{f_{1}, f_{2}}\left(g(X)_{1} ; g(X)_{2: 3}\right)</script><p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/image-20210113131115473.png" alt="image-20210113131115473"></p>
<p>结果如下图（a）所示：</p>
<p>可以看到，这么训练没有给出一个最佳的视图。虽然g生成的两个视图的互信息在减少，但是也丢失了许多对下游任务有用的信息。<img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/image-20210113125930802.png" alt="image-20210113125930802"></p>
<h5 id="半监督的生成视图方式：找到对下游任务有用的信息"><a href="#半监督的生成视图方式：找到对下游任务有用的信息" class="headerlink" title="半监督的生成视图方式：找到对下游任务有用的信息"></a>半监督的生成视图方式：找到对下游任务有用的信息</h5><p>假设我们有少量的下游任务标签y，引入两个分类器C1和C2，g不仅要最小化$I<em>{\mathrm{NCE}}\left(\hat{X}</em>{1} ; \hat{X}_{2: 3}\right)$，也要保证C1和C2分类正确。这样，就可以保留对下游任务有用的信息。</p>
<p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/image-20210113131204656.png" alt="image-20210113131204656" style="zoom: 50%;" /></p>
<p>形式化的损失函数：</p>
<script type="math/tex; mode=display">
\min _{g, c_{1}, c_{2}} \max _{f_{1}, f_{2}} \underbrace{I_{\mathrm{NCE}}^{f_{1}, f_{2}}\left(g(X)_{1} ; g(X)_{2: 3}\right)}_{\text {unsupervised: reduce } I\left(v_{1} ; v_{2}\right)}+\underbrace{\mathcal{L}_{c e}\left(c_{1}\left(g(X)_{1}\right), y\right)+\mathcal{L}_{c e}\left(c_{2}\left(g(X)_{2: 3}\right), y\right)}_{\text {supervised: keep } I\left(v_{1} ; y\right) \text { and } I\left(v_{2} ; y\right)}</script><h3 id="5-总结一些启发"><a href="#5-总结一些启发" class="headerlink" title="5 总结一些启发"></a>5 总结一些启发</h3><ol>
<li>表示学习的视图之间的互信息仅包含对下游任务有用的信息，有助于提高下游任务的泛化性。[59,]</li>
<li>在表示学习中，适当引入一下标签来提高模型的泛化性。[75, 29, 34, 69].</li>
<li>使用标签生成最佳视图用于表示学习，提高模型的泛化性。（本文）</li>
<li>本文的寻找最佳视图的方式，同样适用于时序数据。</li>
</ol>
]]></content>
      <categories>
        <category>zhj</category>
      </categories>
      <tags>
        <tag>自监督</tag>
        <tag>表示学习</tag>
      </tags>
  </entry>
  <entry>
    <title>zhj 自编码器 异常检测</title>
    <url>/2020/12/09/ZhangHongjun/Buzz/</url>
    <content><![CDATA[<h2 id="自编码器-异常检测"><a href="#自编码器-异常检测" class="headerlink" title="自编码器-异常检测"></a>自编码器-异常检测</h2><a id="more"></a> 
<h3 id="1-1-VAE"><a href="#1-1-VAE" class="headerlink" title="1.1 VAE"></a>1.1 VAE</h3><p><strong>Paper</strong>：<em>Variational Autoencoder based Anomaly Detection using Reconstruction Probability</em></p>
<p> 2015，<a href="https://scholar.google.com/citations?user=ULc8ybUAAAAJ&amp;hl=zh-CN&amp;oi=sra">J An</a>, <a href="https://scholar.google.com/citations?user=dEdyEc0AAAAJ&amp;hl=zh-CN&amp;oi=sra">S Cho</a> - Special Lecture on IE</p>
<h4 id="1-1-1-autoencoder-based-anomaly-detection"><a href="#1-1-1-autoencoder-based-anomaly-detection" class="headerlink" title="1.1.1 autoencoder based anomaly detection"></a>1.1.1 autoencoder based anomaly detection</h4><p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/20201021105152.png" alt="image-20201021105145861" style="zoom:67%;" /></p>
<p>一般认为使用正常样本将编码器训练好之后，正常样本能够很好地被重构出来， 而异常样本不能被很好地重构出来。</p>
<p>loss function:</p>
<script type="math/tex; mode=display">
E=\sum_{i=1}^{N}\left\|x^{(i)}-g_{\theta}\left(f_{\phi}\left(x^{(i)}\right)\right)\right\|</script><p>detection, anomaly score ( reconstrction error):</p>
<script type="math/tex; mode=display">
\operatorname{error}(i)=\left\|x^{(i)}-g_{\theta}\left(f_{\phi}\left(x^{(i)}\right)\right)\right\|</script><h4 id="1-1-2-Variational-autoencoder-based-anomaly-detection"><a href="#1-1-2-Variational-autoencoder-based-anomaly-detection" class="headerlink" title="1.1.2 Variational autoencoder based anomaly detection"></a>1.1.2 Variational autoencoder based anomaly detection</h4><p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/20201021113221.png" style="zoom: 50%;" /></p>
<p>一般假设z的先验分布是标准正态分布：</p>
<script type="math/tex; mode=display">
p_\theta z =\mathcal{N}(0, \mathrm{I})</script><p>z的后验分布是正态分布:</p>
<script type="math/tex; mode=display">
q_{\phi}(\mathbf{z} \mid \mathbf{x})=\mathcal{N}\left(\boldsymbol{\mu}_{\mathbf{z}}, \boldsymbol{\sigma}_{\mathbf{z}}^{2} \mathbf{I}\right)</script><p>这个$\mu<em>{\mathbf{z}}$ 和 $\sigma </em>{\mathbf{z}}$ 就是编码器生成的z的均值和方差。</p>
<p>解码器（decoder）输出的， 是x的后验分布  $p_{\theta}(\mathrm{x} \mid \mathrm{z})$，的均值， 在这个分布上采样， 才得到我们想要的重构后的$\vec{x}^{\prime}$。</p>
<p>object function， 最小化以下函数 ：</p>
<script type="math/tex; mode=display">
E=\sum_{i=1}^{N}D_{K L}\left(q_{\phi}\left(z \mid x^{(i)}\right) \| p_{\theta}(z)\right)-\frac{1}{L} \sum_{l=1}^{L}\left(\log p_{\theta}\left(x^{(i)} \mid z^{(i, l)}\right)\right)</script><p><strong>其中，前一项</strong>， $D<em>{K L}\left(q</em>{\phi}\left(z \mid x^{(i)}\right) | p<em>{\theta}(z)\right)$，是z的近似后验分布 $q</em>{\phi}\left(z \mid x^{(i)}\right)$ ， 和z的先验分布 $p<em>\theta z =\mathcal{N}(0, \mathrm{I})$， 这两个分布的KL散度，放在损失函数里面，是希望 encoder 生成的z的后验分布 $q</em>{\phi}\left(z \mid x^{(i)}\right)$ ，逼近假设的z的先验分布 $p_\theta z =\mathcal{N}(0, \mathrm{I})$。</p>
<p><strong>其中，后一项</strong>，$\frac{1}{L} \sum<em>{l=1}^{L}\left(\log p</em>{\theta}\left(x^{(i)} \mid z^{(i, l)}\right)\right)$， 用来度量输入样本x和x的后验分布的距离。用正态分布来举例：</p>
<p>正态分布：</p>
<script type="math/tex; mode=display">
f(x)=\frac{1}{\sqrt{2 \pi} \sigma} \exp \left(-\frac{(x-\mu_x)^{2}}{2 \sigma^{2}}\right)</script><p>综上所述，在vae训练过程中，目标函数不仅约束了重构样本$\hat{x}$, 还约束了中间隐变量z，让z的分布往假设的先验分布$p_\theta z =\mathcal{N}(0, \mathrm{I})$靠近。</p>
<p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/image-20210106132206049.png" alt="image-20210106132206049"></p>
<p>在检测阶段，异常分数为：</p>
<script type="math/tex; mode=display">
score(i) =-\frac{1}{L} \sum_{l=1}^{L} p_{\theta}\left(x^{(i)} \mid \boldsymbol{\mu}_{\hat{\boldsymbol{x}}^{(i, l)}}, \boldsymbol{\sigma}_{\hat{\boldsymbol{x}}^{(i, l)}}\right)</script><p>重构的样本与输入样本越相近， 这个异常分数越小。设定一个阈值， 当这个重构概率大于阈值时， 就认为它是异常样本。</p>
<h3 id="1-2-donut-VAE"><a href="#1-2-donut-VAE" class="headerlink" title="1. 2. donut(VAE)"></a>1. 2. donut(VAE)</h3><p><strong>Paper</strong>：<em>Unsupervised Anomaly Detection via Variational Auto-Encoder for Seasonal KPIs in Web Applications</em></p>
<p>2018， 裴丹， The Web Conference 2018 - Proceedings of the World Wide Web Conference, WWW 2018</p>
<p>关键词：周期性KPI</p>
<p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/20201021155142.png" alt="image-20201021154918466" style="zoom:67%;" /></p>
<p>大体上还是VAE， 中间加了一些小技巧。</p>
<p><strong>trick1：</strong>计算方差时使用soft plus</p>
<p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/20201021194859.png" alt="image-20201021194859135"></p>
<p>一般的vae获得方差$\sigma$的方式：方差$\sigma &gt;= 0$, 隐藏层输出$h$不符合这个条件。可以假设$h = log \sigma$, 这样$\sigma = exp(h)$ 就满足大于等于0的条件。而在异常检测场景中，我们感兴趣的KPI的局部变化非常小，即$\sigma \rightarrow 0$, 导致$h \rightarrow -\infty$, 在计算的时候会问题。</p>
<p>改用softplus：$\sigma_=\operatorname{SoftPlus}(h)+{\epsilon}=log(1+exp(h))+\epsilon$, 其中$\epsilon$是很小的，大于零的超参，本文设置为$\epsilon=10^{-4}$。</p>
<p><strong>trick2：</strong>修改损失函数</p>
<p>原来的vae目标函数为</p>
<script type="math/tex; mode=display">
=\mathbb{E}_{q_{\phi}(\mathrm{z} \mid \mathrm{x})}\left[\log p_{\theta}(\mathrm{x} \mid \mathrm{z})+\log p_{\theta}(\mathrm{z})-\log q_{\phi}(\mathrm{z} \mid \mathrm{x})\right]</script><p>考虑缺失点和异常值点, 修改目标函数为:</p>
<script type="math/tex; mode=display">
\tilde{\mathcal{L}}(\mathrm{x})=\mathbb{E}_{\boldsymbol{q}_{\phi}(\mathbf{z} \mid \mathbf{x})}\left[\sum_{\boldsymbol{w}=1}^{W} \alpha_{\boldsymbol{w}} \log p_{\theta}\left(x_{\boldsymbol{w}} \mid \mathbf{z}\right)+\beta \log p_{\theta}(\mathbf{z})-\log q_{\phi}(\mathbf{z} \mid \mathbf{x})\right]</script><p>$\alpha<em>w\in \left{ 0,1 \right} $, 正常点取1,异常点取0, $\beta$是放缩系数,$\beta=\left(\sum</em>{w=1}^{W} \alpha_{w}\right) / W$</p>
<p><strong>trick3</strong>:检测时, 异常值和缺失值补全</p>
<p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/20201021203227.png" alt="image-20201021203227211"></p>
<p>在一个窗口中,异常点和缺失点,先使用训练好的vae,经过M次迭代, 得到新的窗口序列, 然后再进行异常检测.</p>
<p>效果: 降噪</p>
<p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/20201021210122.png" alt="image-20201021210122601"></p>
<p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/20201021210218.png" alt="image-20201021210218109"></p>
<p>甚至修复:</p>
<p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/20201021211803.png" alt="image-20201021211803428"></p>
<h3 id="1-3-bagel-CVAE"><a href="#1-3-bagel-CVAE" class="headerlink" title="1.3. bagel(CVAE)"></a>1.3. bagel(CVAE)</h3><p><strong>Paper</strong>：<em>Robust and Unsupervised KPI Anomaly Detection Based on Conditional Variational Autoencoder</em></p>
<p>2018 ,裴丹， <em>2018 IEEE 37th International Performance Computing and Communications Conference, IPCCC</em></p>
<p><strong>time information related anomalies</strong>:</p>
<p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/20201021205159.png" alt="image-20201021205159731"></p>
<p>如上图的周期性KPI, 在最右边的蓝色框内为正常序列, 但是前后被异常序列包围. 由于Donut是使用滑动窗口的方法采样,而且训练的时候是将样本顺序打乱之后输入到网络中,所以面对这样的样本时, 很容易出现虚假警报. 本文提出使用CVAE的方法, 引入时间信息来解决这个问题.</p>
<p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/20201021203757.png" alt="image-20201021203757438" style="zoom:67%;" /></p>
<h3 id="2-buzz-adversarial-training-VAE"><a href="#2-buzz-adversarial-training-VAE" class="headerlink" title="2. buzz(adversarial training VAE)"></a>2. buzz(adversarial training VAE)</h3><p><strong>Paper</strong>：<em>Unsupervised Anomaly Detection for Intricate KPIs via Adversarial Training of VAE</em></p>
<p>2019,裴丹， <em>Proceedings - IEEE INFOCOM</em></p>
<p>以上介绍的方法, 都只适用于周期性的KPI. 本文的模型适用于复杂的kpi</p>
<p><strong>复杂的kpi:</strong></p>
<p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/20201022154945.png" alt="image-20201022154945274"></p>
<p>KPI分为两种, 一种为周期平滑的KPI, 另外一种为复杂的KPI. 前者通常是服务级别的指标,比如每分钟交易次数. 后者是更加底层的指标,比如 每秒的I/O请求数量, 通常粒度更细.  通常可以认为, 周期性kpi的噪声是独立的高斯噪声, 而复杂KPI的噪声不是这种简单的高斯噪声.</p>
<p>复杂的kpi 虽然局部的抖动很严重, 但是 总体上还是有一定的模式.</p>
<p><strong>网络结构:</strong></p>
<p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/20201022151230.png" alt="image-20201022151230779"></p>
<p>window size=128, reshape: [8, 16], 然后卷积</p>
<p><strong>训练流程:</strong></p>
<p>两个超参数:s=32, b=8</p>
<p>取时刻点集合$\mathcal{W}= \left{w<em>{1}, w</em>{2}, \ldots, w<em>{b}\right}$,  是一个mini_batch的时刻点集合. 满足一下条件:$w</em>{i}$是s的倍数,  这样, 每个单元的数据是$\mathbf{x}^{(w)}, \mathbf{x}^{(w+1)}, \ldots, \mathbf{x}^{(w+s-1)}$,</p>
<p>训练过程中, 每经过40个epoch, 更新$s = s /2, b=b*2$, 直到$s=1$</p>
<p><strong>目标函数:</strong></p>
<p>最大化该函数</p>
<p>令判别器为 $F$, 生成器为$G$,  </p>
<script type="math/tex; mode=display">
\tilde{\mathcal{L}}_{B u z z}=-\lambda \sup _{F}\left[\sum_{w \in \mathcal{W}}(|\mathcal{T}(F, w)|-\eta \mathcal{R}(F, w))\right]-\mathcal{K}-\log Z(\lambda)</script><p>其中一项:</p>
<script type="math/tex; mode=display">
\mathcal{K}=\frac{1}{b s} \sum_{w \in \mathcal{W}} \sum_{i=0}^{s-1} \mathrm{KL}\left[q_{\phi}\left(\mathbf{z} \mid \mathbf{x}^{(w+i)}\right) \| \mathcal{N}(\mathbf{0}, \mathbf{1})\right]</script><p>$\mathcal{K}$是隐变量$z$的先验分布和后验分布的KL散度, 意义是让z的后验分布往先验分布靠拢.</p>
<p>其中另外一项:</p>
<script type="math/tex; mode=display">
\mathcal{T}(F, w)=\frac{1}{b s} \sum_{i=0}^{s-1} \mathbb{E}_{q_{\phi}\left(\mathbf{z} \mid \mathbf{x}^{(w+i)}\right)}\left[F\left(\mathbf{x}^{(w+i)}\right)-F(G(\mathbf{z}))\right]</script><p>目的是让判别器F, 判别原始样本$\mathbf{x}^{(w+i)}$, 判别生成的样本$G(\mathbf{z})$.两者的输出差距越大越好.</p>
<p><strong>检测方法:</strong></p>
<p>先用训练好的vae,重构x,得到$\overline{\mathbf{x}} \leftarrow \mathbf{x}$, 然后计算$\log p<em>{\theta}(\mathbf{x})-\log p</em>{\theta}(\overline{\mathbf{x}})$,</p>
<script type="math/tex; mode=display">
\log \frac{1}{L} \sum_{l=1}^{L}\left[\frac{p_{\theta}\left(\mathbf{x} \mid \mathbf{z}^{(l)}\right) p_{\theta}\left(\mathbf{z}^{(l)}\right)}{q_{\phi}\left(\mathbf{z}^{(l)} \mid \overline{\mathbf{x}}\right)}\right]-\log \frac{1}{L} \sum_{l=1}^{L}\left[\frac{p_{\theta}\left(\overline{\mathbf{x}} \mid \mathbf{z}^{(l)}\right) p_{\theta}\left(\mathbf{z}^{(l)}\right)}{q_{\phi}\left(\mathbf{z}^{(l)} \mid \overline{\mathbf{x}}\right)}\right]</script><p>结果:</p>
<p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/20201022155242.png" alt="image-20201022155242807"></p>
]]></content>
      <categories>
        <category>zhj</category>
      </categories>
      <tags>
        <tag>异常检测</tag>
      </tags>
  </entry>
  <entry>
    <title>zhj DEEP SEMI-SUPERVISED ANOMALY DETECTION</title>
    <url>/2020/12/09/ZhangHongjun/DEEP%20SEMI-SUPERVISED%20ANOMALY%20DETECTION/</url>
    <content><![CDATA[<h3 id="DEEP-SEMI-SUPERVISED-ANOMALY-DETECTION（2020-ICLR）"><a href="#DEEP-SEMI-SUPERVISED-ANOMALY-DETECTION（2020-ICLR）" class="headerlink" title="DEEP SEMI-SUPERVISED ANOMALY DETECTION（2020 ICLR）"></a>DEEP SEMI-SUPERVISED ANOMALY DETECTION（2020 ICLR）</h3><h4 id="1-优点（解决的问题）。"><a href="#1-优点（解决的问题）。" class="headerlink" title="1.优点（解决的问题）。"></a>1.优点（解决的问题）。</h4><ul>
<li><p>在半监督异常检测方法中，除了利用无标签的样本，大多数监督方法只利用了标记出来的正常样本，本方法同时利用的标记的正常样本和异常样本。</p>
</li>
<li><p>在Mnist，fashion-mnist、cifar-10和其他异常检测基准数据集上，与浅层的方法、混合的方法以及深度的方法比较， 效果相当或者比它们好。</p>
</li>
<li><p>使用很少的有标签样本能够明显提高效果。</p>
</li>
</ul>
<a id="more"></a> 
<h4 id="2-模型原理"><a href="#2-模型原理" class="headerlink" title="2. 模型原理"></a>2. 模型原理</h4><h5 id="2-1-SVDD（Support-Vector-Data-Description）支持向量数据描述"><a href="#2-1-SVDD（Support-Vector-Data-Description）支持向量数据描述" class="headerlink" title="2.1 SVDD（Support Vector Data Description）支持向量数据描述"></a>2.1 SVDD（Support Vector Data Description）支持向量数据描述</h5><p>一分类问题。训练出一个最小的超球面，将数据全部包起来。在识别新的数据时， 如果数据在球内，就属于这个类。</p>
<p>实现思路：原始数据–高维表示–Min超球体积–求得c和R。</p>
<p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/20200830221831.png" alt="image-20200830221831085"></p>
<h5 id="2-2-deep-SVDD"><a href="#2-2-deep-SVDD" class="headerlink" title="2.2 deep SVDD."></a>2.2 deep SVDD.</h5><p>同作者论文：Deep One-Class Classification, PMLR, 2018</p>
<p>应用场景：Anomaly Detction</p>
<p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/20200830214926.png" alt="image-20200830214925996"></p>
<p>使用神经网络来将数据映射到高维空间。</p>
<p>超球体中心为C， 半径为R。</p>
<p>目标：最小化超球面的体积， 正常的样本在球内，异常样本在球外。</p>
<p>得到球体中心：利用autoencoder，使用所有样本训练autoencoder。 使用收敛之后的encoder部分作为初始化的网络， 同时将所有样本在encoder的输出的平均值作为超球体中心C。</p>
<p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/20200831120602.png" alt="image-20200831120602081"></p>
<p>目标函数：</p>
<p>n个样本， $\Phi$是代表网络的函数， $x_i$是输入样本， $W$是网络权重。</p>
<p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/20200830215431.png" alt="image-20200830215431541"></p>
<p>预先定义球体中心C，迫使所有的样本向C靠拢，离球中心越远的样本越可能是异常样本。</p>
<p>异常分数：</p>
<p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/20200830221730.png" alt="image-20200830221730565"></p>
<h5 id="2-3-（本文）DEEP-SAD（deep-semi-supervised-anomaly-detection）"><a href="#2-3-（本文）DEEP-SAD（deep-semi-supervised-anomaly-detection）" class="headerlink" title="2.3 （本文）DEEP SAD（deep semi-supervised anomaly detection）"></a>2.3 （本文）DEEP SAD（deep semi-supervised anomaly detection）</h5><p>目标函数：</p>
<p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/20200830222630.png" alt="image-20200830222630686"></p>
<p>$\tilde{y}=-1$表示异常，$\tilde{y}=+1$表示正常。</p>
<p>意义： 对于无标签的样本，尽量往球体中心靠拢； 对于便签为正常的样本， 尽量往球体中心靠拢； 对于便签为异常的样本， $\tilde{y}=-1$, 括号内的值越大越好， 也就是异常样本尽量远离球体中心。</p>
<p>参数$\eta$与前一项分子上的1对应，控制有标签的样本和无标签的样本的影响， $\eta&gt;1$ 则侧重于有标签样本， $\eta &lt; 1$ 则侧重于无标签样本。</p>
<h4 id="3-实验"><a href="#3-实验" class="headerlink" title="3.实验"></a>3.实验</h4><h5 id="3-1对比实验："><a href="#3-1对比实验：" class="headerlink" title="3.1对比实验："></a>3.1对比实验：</h5><p>shallow unsupervised baselines：</p>
<ul>
<li>OC-SVM</li>
</ul>
<p>deep unsupervised competitors：</p>
<ul>
<li>Deep SVDD</li>
</ul>
<p>浅层的半监督方法：</p>
<ul>
<li>shallow SSAD method</li>
</ul>
<p>深层的自监督方法： 缺乏深层的自监督方法（同时利用标记的正常样本和异常样本），这里自行构建</p>
<ul>
<li>hybrid SSAD：自编码器和SSAD</li>
</ul>
<p>深层的自监督方法：只利用标记的正常样本。</p>
<ul>
<li>Semi-Supervised Deep Generative Model (SS-DGM)</li>
</ul>
<p>有监督方法：</p>
<ul>
<li>supervised deep classifier</li>
</ul>
<h5 id="3-2-实验场景"><a href="#3-2-实验场景" class="headerlink" title="3.2 实验场景"></a>3.2 实验场景</h5><p>MNIST, Fashion-MNIST, 以及 CIFAR-10都是十分类问题。设置其中一类为正常样本（无标签），其余九类构成异常样本池， 从池中抽取一下异常样本作为有便签异常样本。这样就满足假设：大多数无标签样本为正常样本（这里设置为全部无标签样本为正常样本）。</p>
<h5 id="场景一：加入有便签的异常样本（不同比例）"><a href="#场景一：加入有便签的异常样本（不同比例）" class="headerlink" title="场景一：加入有便签的异常样本（不同比例）"></a>场景一：加入有便签的异常样本（不同比例）</h5><p>比例$\gamma_l=m/(n+m)$， </p>
<p>m：有标签样本数量，n: 无标签样本数</p>
<p>在取异常样本时，只从其中9个异常类别中的一类中选取，测试时同时使用9个异常类别。这样在测试时， 会有模型从没见过的异常类别。</p>
<p>实验数量：对于每个$\gamma_l$, 进行10 * 9 = 90 次实验。</p>
<p>结果： 90次实验AUC的均值和标准差。</p>
<p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/20200831100546.png" alt="image-20200831100546365"></p>
<p>$\gamma_l=0$, 退化为无监督问题。</p>
<p>在数据较为复杂的CIFAR10上， 本文的Deep SAD 表现最好。</p>
<p>hybrid SSAD表现也较好。</p>
<h5 id="场景二：污染训练数据"><a href="#场景二：污染训练数据" class="headerlink" title="场景二：污染训练数据"></a>场景二：污染训练数据</h5><p>在无标签的正常样本中混入无标签异常样本。</p>
<p>固定$\gamma_l=0.05$, 取不同的污染比列$\gamma_p$, </p>
<p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/20200831101617.png" alt="image-20200831101617372"></p>
<p>原文：最鲁棒的是本文的Deep SAD</p>
<p>观察:</p>
<p>在Mnist和Fashion Mnist上，最好的反而是OC-SVM Hybrid。</p>
<p>在CIFAR-10上最好是本文的Deep SAD。(数据较复杂)</p>
<h5 id="场景三：不同的已知异常类别数"><a href="#场景三：不同的已知异常类别数" class="headerlink" title="场景三：不同的已知异常类别数"></a>场景三：不同的已知异常类别数</h5><p>已知异常类别数：$k_l$,</p>
<p>选取异常样本方法：随机抽取$k_l$个样本。对于每个$k_l$, 做10次随机抽取，10个类别，共10*10=100次实验。</p>
<p>结果：</p>
<p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/20200831104502.png" alt="image-20200831104502119"></p>
<p>训练时使用的异常类别越多，效果越好。</p>
<p>总体而言，我们看到Deep SAD在更复杂的数据上特别有用。</p>
<p>同时暴露了有监督分类的一个问题：在测试时出现没有见过的异常类型， 表现较差。</p>
<h5 id="超参的影响"><a href="#超参的影响" class="headerlink" title="超参的影响"></a>超参的影响</h5><ul>
<li><p>设定   有便签异常样本比例：$\gamma_l=0.05$，无标签样本污染比例：$\eta_p=0.1$,  已知异常类别数$k_l=1$,</p>
<p>$\eta$的影响如下图， 结论：对$\eta$的变化是鲁棒的。</p>
</li>
</ul>
<p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/20200831114314.png" alt="image-20200831114314276"></p>
<ul>
<li>隐表示的维度d    </li>
</ul>
<p>  <img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/20200831115723.png" alt="image-20200831115723567"></p>
<p>  <img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/20200831114942.png" alt="image-20200831114942261"></p>
<p>  结论：d越大越好。</p>
<h4 id="4-结论"><a href="#4-结论" class="headerlink" title="4.结论"></a>4.结论</h4><p>介绍了一个泛化的自监督方法（同时利用有标签的正常和异常样本）， 在同时获得有标签的正常和异常样本时， 本文方法是更好的。</p>
]]></content>
      <categories>
        <category>zhj</category>
      </categories>
      <tags>
        <tag>异常检测</tag>
      </tags>
  </entry>
  <entry>
    <title>zhj Memorizing Normality to Detect  Anomaly</title>
    <url>/2020/12/09/ZhangHongjun/a-Memorizing-Normality-to-Detect-Anomaly/</url>
    <content><![CDATA[<p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/20201201183707.png" alt="image-20201201183707250"></p>
<p>ICCV, 2020</p>
<h4 id="概要"><a href="#概要" class="headerlink" title="概要"></a>概要</h4><p>autoencoder被广泛应用到异常检测.</p>
<p>前提假设:在正常的数据上训练, 在异常样本上会有较大的重构误差, 使用重构误差作为检测异常的标准. </p>
<a id="more"></a>
<p>然而, 这一假设在实际应用中不一定成立. 有时autoencoder的泛化性太好, 而导致在面对异常样本时也能很好地重构, 即重构误差小, 这会导致漏报异常.  为了缓解这个问题, 本文提出了memory-augmented autoencoder(MemAE). 给定一个输入样本, MemAE首先使用编码器获得隐变量z, 然后使用z作为一个查询, 在memory中检索出与z最相近的条目, 然后将这些条目组合输入到解码器用于重构. 在训练阶段, memory中的内容不断更新. 在测试的使用, memory被固定, 不再更新. 这样做会使用重构的样本非常像正常的样本(训练的时候只有正常样本, 所以memory是用正常样本编码获得的.)  这样做可以使得异常样本的重构误差更大.  此外, MemAE不限定数据类型, 所以它适用于各种数据类型的异常检测.</p>
<p>下图为检索数量为1的情况下的示意图:</p>
<p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/20201201220151.png" alt="image-20201201220151716"></p>
<h3 id="Memory-augmented-Autoencoder"><a href="#Memory-augmented-Autoencoder" class="headerlink" title="Memory-augmented Autoencoder"></a>Memory-augmented Autoencoder</h3><h4 id="1-Overview"><a href="#1-Overview" class="headerlink" title="1. Overview"></a>1. Overview</h4><p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/20201201232017.png" alt="image-20201201232017450"></p>
<p>模型有3个组成成分: encoder, decoder 和 memory.  给定一个输入, 首先编码获得隐变量z, 在训练的时候, 使用z去Memory中检索与z最像的一些记录, 然后将这些记录组合成新的隐变量$\hat{z}$, 然后传给解码器用于重构. </p>
<p>在训练的时候, 编码器, 解码器优化的方向是最小化重构误差. Memory同时不断更新.</p>
<p>在测试时, 输入一个测试样本, 只会使用Memory中的一些记录来重构. 这样的话, 重构样本会趋近与更像正常样本. 正常样本重构出来的重构误差更小, 异常样本的重构误差更大.</p>
<h4 id="2-Enocder-and-Decoder"><a href="#2-Enocder-and-Decoder" class="headerlink" title="2.Enocder and Decoder"></a>2.Enocder and Decoder</h4><p>定义编码器为$f<em>{e}(\cdot): \mathbb{X} \rightarrow \mathbb{Z}$, 解码器为$f</em>{d}(\cdot): \mathbb{Z} \rightarrow \mathbb{X}$,  给定一个输入$x$, 首先通过编码器获得$z$, 然后从Memory中检索出$\hat{z}$, 然后经过解码器获得$\hat{x}$</p>
<script type="math/tex; mode=display">
\mathbf{z}=f_{e}\left(\mathbf{x} ; \theta_{e}\right)
\\
\widehat{\mathbf{x}}=f_{d}\left(\widehat{\mathbf{z}} ; \theta_{d}\right)</script><p>使用的损失函数为MSE: $e=|\mathbf{x}-\widehat{\mathbf{x}}|_{2}^{2}$</p>
<h4 id="3-Memory-Module-with-Attention-based-Sparse-Addressing"><a href="#3-Memory-Module-with-Attention-based-Sparse-Addressing" class="headerlink" title="3.Memory Module with Attention-based Sparse Addressing"></a>3.Memory Module with Attention-based Sparse Addressing</h4><p>本文所提出的memory模块包括两个部分: 存储模块和检索模块.</p>
<h5 id="3-1-Memory设计"><a href="#3-1-Memory设计" class="headerlink" title="3.1 Memory设计"></a>3.1 Memory设计</h5><p>memory是一个矩阵$\mathbf{M} \in \mathbb{R}^{N \times C}$, 包含$N$个向量, 每个向量的维度是$C$ , $z$的维度是$C$. 设$m_i$是M的第i行. 给定一个query(查询)$\mathbf{z} \in \mathbb{R}^{C}$,首先获得一个寻址向量$\mathbf{w} \in \mathbb{R}^{1 \times N}$,  获得$\hat{z}$的方式为:</p>
<script type="math/tex; mode=display">
\widehat{\mathbf{z}}=\mathbf{w} \mathbf{M}=\sum_{i=1}^{N} w_{i} \mathbf{m}_{i}</script><p>$w$是和为1的非负向量, 相当于$\hat{z}$是$m_i$的加权求和. 经过实验, 认为模型对$N$的取值不是很敏感, 一个足够大的$N$就能够在所有数据集上都取得较好的效果.</p>
<h5 id="3-2-w的计算方式"><a href="#3-2-w的计算方式" class="headerlink" title="3.2 w的计算方式"></a>3.2 w的计算方式</h5><p>计算$w_i$:</p>
<script type="math/tex; mode=display">
w_{i}=\frac{\exp \left(d\left(\mathbf{z}, \mathbf{m}_{i}\right)\right)}{\sum_{j=1}^{N} \exp \left(d\left(\mathbf{z}, \mathbf{m}_{j}\right)\right)}</script><p>$d(\cdot, \cdot)$是距离度量, 本文使用的是余弦距离:</p>
<script type="math/tex; mode=display">
d\left(\mathbf{z}, \mathbf{m}_{i}\right)=\frac{\mathbf{z} \mathbf{m}_{i}^{\top}}{\|\mathbf{z}\|\left\|\mathbf{m}_{i}\right\|}</script><p>在训练的时候, 由于Memory的空间有限, MemAE通过使用有限的m组合来重构样本, 这样会迫使模型充分利用Memory, 使得Memory存储的是最具代表性的原型模式. 下图是使用9作为正常样本来训练MemAE, 并从Memory中随机选几个m, 经过解码之后重构出来的样本. 这张图是为了说明Memory中存储的是有代表性的原型模式. </p>
<p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/20201202103206.png" alt="image-20201202103206688"></p>
<p>在测试阶段, 给定训练好的Memory, 异常样本的重构也只能利用正常的m组合形成$\hat{z}$, 然后重构. 下图中, 左图是使用5来训练, 测试时输入9. 右图是使用2来训练, 测试时输入4. 重构出来的样本都很像是训练样本. </p>
<p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/20201202103625.png" alt="image-20201202103625165"></p>
<h5 id="3-3-稀疏寻址-硬收缩"><a href="#3-3-稀疏寻址-硬收缩" class="headerlink" title="3.3 稀疏寻址(硬收缩)"></a>3.3 稀疏寻址(硬收缩)</h5><p>作者指出, 如果w很稠密, 即w的每个分量都很小, 会导致多个m组合之后, 使用模型仍然具有较好的泛化性, 也有可能重构出异常样本. 为了缓解这个问题, 迫使w变得稀疏:</p>
<script type="math/tex; mode=display">
\widehat{w}_{i}=h\left(w_{i} ; \lambda\right)=\left\{\begin{array}{ll}
w_{i}, & \text { if } w_{i}>\lambda \\
0, & \text { otherwise }
\end{array}\right.</script><p>简单来说是设定一个阈值$\lambda$, 小于$\lambda$就设为0.</p>
<p>上式不容易反向传播, 修改为(continuous ReLU activation function):</p>
<script type="math/tex; mode=display">
\widehat{w}_{i}=\frac{\max \left(w_{i}-\lambda, 0\right) \cdot w_{i}}{\left|w_{i}-\lambda\right|+\epsilon}</script><p>根据经验, $\lambda$在区间$[1 / N, 3 / N]$内取值会取得比较理想的效果.</p>
<p>经过以上压缩之后,重新标准化:$\widehat{w}<em>{i}=\widehat{w}</em>{i} /|\widehat{\mathbf{w}}|_{1}$.  这样一来, $\widehat{\mathbf{z}}=\widehat{\mathbf{w}} \mathbf{M}$</p>
<p>以上的稀疏寻址操作有两个好处: 一是迫使Memory中的m是更具有代表性的原型; 二是降低模型泛化性导致异常样本也能重构的可能性.</p>
<h5 id="3-4-训练"><a href="#3-4-训练" class="headerlink" title="3.4 训练"></a>3.4 训练</h5><p>损失函数包括两部分:</p>
<p>一. 样本重构误差</p>
<script type="math/tex; mode=display">
R\left(\mathbf{x}^{t}, \widehat{\mathbf{x}}^{t}\right)=\left\|\mathbf{x}^{t}-\widehat{\mathbf{x}}^{t}\right\|_{2}^{2}</script><p>二. 除上述的硬收缩之外, 通过损失函数使得w更加稀疏.</p>
<p>​    考虑到$\hat{\mathbf{w}}$中的元素非负且$|\widehat{\mathbf{w}}|_{1}=1$, 最小化它的交叉熵就可以达到稀疏化的效果.</p>
<script type="math/tex; mode=display">
E\left(\widehat{\mathbf{w}}^{t}\right)=\sum_{i=1}^{T}-\widehat{w}_{i} \cdot \log \left(\widehat{w}_{i}\right)</script><p>总体的损失函数如下:</p>
<script type="math/tex; mode=display">
L\left(\theta_{e}, \theta_{d}, \mathbf{M}\right)=\frac{1}{T} \sum_{t=1}^{T}\left(R\left(\mathbf{x}^{t}, \widehat{\mathbf{x}}^{t}\right)+\alpha E\left(\widehat{\mathbf{w}}^{t}\right)\right)</script><p>$\alpha$是调节权重的超参, 本文设定为0.0002</p>
<h4 id="4-实验"><a href="#4-实验" class="headerlink" title="4 实验"></a>4 实验</h4><h5 id="4-1-图像数据"><a href="#4-1-图像数据" class="headerlink" title="4.1 图像数据"></a>4.1 图像数据</h5><p>平均AUC. </p>
<p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/20201202112919.png" alt="image-20201202112919657" style="zoom: 80%;" /></p>
<h5 id="4-2-视频数据"><a href="#4-2-视频数据" class="headerlink" title="4.2 视频数据"></a>4.2 视频数据</h5><p>AUC:</p>
<p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/20201202114254.png" alt="image-20201202114254063" style="zoom: 50%;" /></p>
<p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/20201202114413.png" alt="image-20201202114413583"></p>
<h5 id="4-3-网络安全数据"><a href="#4-3-网络安全数据" class="headerlink" title="4.3 网络安全数据"></a>4.3 网络安全数据</h5><p> KDDCUP99 </p>
<p>Each sample can be organized as a vector with 120 dimensions </p>
<p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/20201210202446.png" alt="image-20201202114638957"></p>
<h5 id="消融实验"><a href="#消融实验" class="headerlink" title="消融实验"></a>消融实验</h5><p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/20201210202446.png" alt="image-20201202114807190"></p>
<p>AE-ℓ1:最小化z的ℓ1范数.</p>
<p>MemAE-nonSpar: 不做稀疏化处理</p>
<p>MemAE w/o Shrinkage:没有硬收缩</p>
<p>MemAE w/o Entropy loss:损失函数中没有交叉熵</p>
]]></content>
      <categories>
        <category>zhj</category>
      </categories>
      <tags>
        <tag>异常检测</tag>
      </tags>
  </entry>
  <entry>
    <title>zhj anoGan</title>
    <url>/2020/12/09/ZhangHongjun/anoGan-f-anoGan/</url>
    <content><![CDATA[<h2 id="anoGan"><a href="#anoGan" class="headerlink" title="anoGan"></a>anoGan</h2><p><strong>Paper</strong>：<em>Unsupervised Anomaly Detection with Generative Adversarial Networks to Guide Marker Discovery</em></p>
<p>2017, IPMI ( Information Processing in Medical Imaging ) </p>
<p>生物医学影像与影像引导治疗系, 奥地利维也纳医科大学</p>
<p>数据类型为医学影像, 光学相干层析成像(Optical Coherence tomography, OCT)技术</p>
<p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/20201027112727.png" alt="image-20201027112720144"></p>
<a id="more"></a> 
<h4 id="异常检测前提"><a href="#异常检测前提" class="headerlink" title="异常检测前提"></a>异常检测前提</h4><p>使用正常样本来训练生成器和判别器, 正常样本能够很好地被重构出来， 而异常样本不能被很好地重构出来。</p>
<h4 id="模型结构"><a href="#模型结构" class="headerlink" title="模型结构"></a>模型结构</h4><p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/20201027153314.png" alt="image-20201027153314856"></p>
<h4 id="模型训练"><a href="#模型训练" class="headerlink" title="模型训练"></a>模型训练</h4><p>生成器G, 将隐变量z经过一系列的反卷积操作, 生成样本.</p>
<p>判别器D, 最后一层的激活函数是sigmoid, 输出一个概率, $\in[0,1 ]$, 越大代表判别器D认为输入的样本为真实的样本.</p>
<p>使用健康人的样本来训练模型.  隐变量Z,服从标准正态分布.  采样z, 经过生成器G(z), 得到生成的图片G(z). 将生成的图片样本G(z) 和 健康人图片样本x, 一起输入到判别器D. </p>
<p>训练步骤:</p>
<ol>
<li>将G(z), x 输入到判别器D,  根据以下目标函数更新判别器D的参数:</li>
</ol>
<script type="math/tex; mode=display">
\max _{D} V(D, G)=\mathbb{E}_{\mathbf{x} \sim p_{\text {data}}(\mathbf{x})}[\log D(\mathbf{x})]+\mathbb{E}_{\mathbf{z} \sim p_{\mathbf{z}}(\mathbf{z})}[\log (1-D(G(\mathbf{z})))]</script><p>​    意义是,  对于输入样本为真实样本x, 希望判别器的输出值趋近1; 对于输入样本为生成样本G(z), 希望判别器的输出值趋近于0.</p>
<ol>
<li>固定判别器D的参数, 根据以下目标函数更新生成器G的参数:<script type="math/tex; mode=display">
\min _{G} V(D, G)=\mathbb{E}_{\mathbf{x} \sim p_{\text {data}}(\mathbf{x})}[\log D(\mathbf{x})]+\mathbb{E}_{\mathbf{z} \sim p_{\mathbf{z}}(\mathbf{z})}[\log (1-D(G(\mathbf{z})))]</script>意义是, 通过调整生成器G的参数,让生成的样本G(z)更像真实样本x, 让判别器D无法判别真实样本和生成样本.</li>
</ol>
<p>经过这样的对抗训练之后, 生成样本G(z)越来越像真实样本.</p>
<h4 id="找到输入样本x对应的隐变量z"><a href="#找到输入样本x对应的隐变量z" class="headerlink" title="找到输入样本x对应的隐变量z"></a>找到输入样本x对应的隐变量z</h4><p>生成器G可以将隐变量z映射到x, $G(\mathbf{z})=\mathbf{z} \mapsto \mathbf{x}$. 如果给定x, 很难直接找到这个x对应的z, 使得G(z)看起来跟x很像. 为了找到最好的z,  固定生成器G的参数. 先随机采样一个$z<em>1$, 生成一个图像$G(z_1)$,  利于一个损失函数来提供梯度, 去更新$z_1$的系数, 更新后的位置设为$z_2$.  为了找到与输入图片样本x最相似的生成图片样本$G\left(\mathbf{z}</em>{\Gamma}\right)$, 需要经过迭代过程$\gamma=1,2, \ldots, \Gamma$.</p>
<p>以上使用的损失函数, 包括两个部分:</p>
<ol>
<li><p><strong>Residual Loss</strong></p>
<p>利用生成器G:生成样本和真实样本之间像素级别的差距.</p>
</li>
</ol>
<script type="math/tex; mode=display">
\mathcal{L}_{R}\left(\mathbf{z}_{\gamma}\right)=\sum\left|\mathbf{x}-G\left(\mathbf{z}_{\gamma}\right)\right|</script><ol>
<li><p><strong>Discrimination Loss</strong></p>
<p>利用判别器D: </p>
<p>原始的版本:交叉熵损失</p>
</li>
</ol>
<script type="math/tex; mode=display">
   \mathcal{L}_{\hat{D}}\left(\mathbf{z}_{\gamma}\right) = -ylog(D(G(z_\gamma))) - (1-y)log(1-D(G(z_\gamma)))</script><p>   其中目标为1, 即希望判别器D不能判别出$G(z_\gamma)$为生成样本, 以上公式化简为:</p>
<script type="math/tex; mode=display">
   \mathcal{L}_{\hat{D}}\left(\mathbf{z}_{\gamma}\right) = -ylog(D(G(z_\gamma)))</script><p>   本文改进的版本: 利用判别器的中间结果:</p>
<script type="math/tex; mode=display">
   \mathcal{L}_{D}\left(\mathbf{z}_{\gamma}\right)=\sum\left|\mathbf{f}(\mathbf{x})-\mathbf{f}\left(G\left(\mathbf{z}_{\gamma}\right)\right)\right|</script><p>   其中$f(*)$为判别器的中间层的输出.</p>
<p>综上,  寻找最优的$z$所用的损失函数为:</p>
<script type="math/tex; mode=display">
\mathcal{L}\left(\mathbf{z}_{\gamma}\right)=(1-\lambda) \cdot \mathcal{L}_{R}\left(\mathbf{z}_{\gamma}\right)+\lambda \cdot \mathcal{L}_{D}\left(\mathbf{z}_{\gamma}\right)</script><p>其中$\lambda$为权重, 本文设定为0.1 </p>
<h4 id="异常检测"><a href="#异常检测" class="headerlink" title="异常检测"></a>异常检测</h4><p>定义异常分数, 利用以上的损失函数:</p>
<script type="math/tex; mode=display">
A(\mathbf{x})=(1-\lambda) \cdot R(\mathbf{x})+\lambda \cdot D(\mathbf{x})
\\
=(1-\lambda) \cdot \mathcal{L}_{R}\left(\mathbf{z}_{\Gamma}\right)+\lambda \cdot \mathcal{L}_{D}\left(\mathbf{z}_{\Gamma}\right)</script><h4 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h4><p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/20201027202802.png" alt="image-20201027112720144"></p>
<p>第一,二列为训练样本, 第三列为测试样本.  第一行为输入样本, 第二行为对应的生成样本, 第三行中的红色部分为异常分数较高的区域, 最后一行中的绿色区域为异常区域.</p>
<p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/20201027204822.png" alt="image-20201027204822072"></p>
<p><strong>图a</strong>: 不同的模型的检测结果</p>
<p>AnoGAN:$A(\mathbf{x})=(1-\lambda) \cdot R(\mathbf{x})+\lambda \cdot D(\mathbf{x})$</p>
<p>$GAN_R$:$\hat{A}(\mathbf{x})=(1-\lambda) \cdot R(\mathbf{x})+\lambda \cdot \hat{D}(\mathbf{x})$</p>
<p>$P_D$:  直接的D(x), 不经过生成器. </p>
<p><strong>图b</strong>: 不同的部分的异常检测结果.</p>
<p><strong>图c</strong>:Residual loss A(x) =$\sum\left|\mathbf{x}-G\left(\mathbf{z}_{\gamma}\right)\right|$ 的分布</p>
<p><strong>图d</strong>:Discrimination loss A(x) =$\sum\left|\mathbf{f}(\mathbf{x})-\mathbf{f}\left(G\left(\mathbf{z}_{\gamma}\right)\right)\right|$ 的分布</p>
<p>其中蓝色为训练集, 绿色为测试集, 红色为异常样本.</p>
<p>综上,  能够检测出异常的部分主要是$R(X)=\sum\left|\mathbf{x}-G\left(\mathbf{z}_{\gamma}\right)\right|$,   </p>
<p>$D(X)=\sum\left|\mathbf{f}(\mathbf{x})-\mathbf{f}\left(G\left(\mathbf{z}_{\gamma}\right)\right)\right|$能够稍微提升检测结果.</p>
<h5 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h5><p>由于在训练的时候, 只使用了正常样本,</p>
<p>对于生成器来说,  给定异常样本x, 重构出来的会很像是正常样本.</p>
<p>对于判别器来说, 由于没有使用异常真实样本来训练,  不能将异常真实样本判定为真实样本. 只有正常真实样本, 才能判定为真实样本. </p>
<h2 id="f-anoGan"><a href="#f-anoGan" class="headerlink" title="f-anoGan"></a>f-anoGan</h2><p><strong>Paper</strong>：<em>f-AnoGAN: Fast unsupervised anomaly detection with generative adversarial networks</em></p>
<p>2019, Medical Image Analysis </p>
<h4 id="anoGan的缺点"><a href="#anoGan的缺点" class="headerlink" title="anoGan的缺点"></a>anoGan的缺点</h4><p>在检测的时候, 为了找到输入样本x对应的隐变量$z_\Gamma$, 需要经过500次迭代. 为了加速检测, 提出了f-anoGan</p>
<h4 id="新的网络结构"><a href="#新的网络结构" class="headerlink" title="新的网络结构"></a>新的网络结构</h4><p>原来的结构:</p>
<p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/20201027211838.png" alt="image-20201027211838605"></p>
<p>为了在检测的时候, 快速找到输入样本x对应的隐变量$z_\Gamma$, 在训练好生成器G和判别器D之后, 固定G和D的参数, 加入编码器E:</p>
<p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/20201027211946.png" alt="image-20201027211946806"></p>
<p>训练编码器E, 是的输入的样本x经过编码器E之后, 直接得到对应的隐变量z.</p>
]]></content>
      <categories>
        <category>zhj</category>
      </categories>
      <tags>
        <tag>异常检测</tag>
      </tags>
  </entry>
  <entry>
    <title>zhj 【KDD2016】FRAUDER Bounding Graph Fraud in the face of camouflage</title>
    <url>/2021/03/31/ZhangHongjun/%E3%80%902016KDD%E3%80%91FRAUDAR_Bounding%20Graph%20Fraud%20in%20the%20Face%20of%20Camouflage/</url>
    <content><![CDATA[<h3 id="任务场景"><a href="#任务场景" class="headerlink" title="任务场景"></a>任务场景</h3><p>在社交媒体中，有非常多的二部图。比如推特中，有关注者和被关注者两种节点，关注关系形成一个二部图；在大众点评中，有用户和商家两种节点，用户对商家的点评关系形成一个二部图；在淘宝里，用户购买商品，也形成一个二部图。</p>
<p><center class="half"><br>    <img img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/image-20220226160804505.png" alt="image-20220226160804505" width="150"/><br>    <img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/image-20220226165517763.png" width="500" /></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Fraudar可以解决哪些问题呢？（二部图的问题）</span><br><span class="line">\1. 用户在电商平台，购买商品（刷单）</span><br><span class="line">\2. 用户评论电影，美食，游戏评分（刷评分）</span><br><span class="line">\3. 推特，博客关注信息（购买粉丝）</span><br></pre></td></tr></table></figure>
<p>为了在二部图中检测出上述的欺诈行为，以往的方法（在此篇论文发表的2016年以前）是检测二部图中的稠密子图。以购买粉丝为例，购买者会突然增加许多粉丝，在二部图中，购买者这个节点的边突然增多（稠密子图）。</p>
<a id="more"></a>
<h3 id="解决的问题"><a href="#解决的问题" class="headerlink" title="解决的问题"></a>解决的问题</h3><p>欺诈者会想办法伪装自己的欺诈行为。以大众点评为例，某个商家向欺诈者购买了大量好评。欺诈者通过操控大量的账户，给商家好评，从而提高该商家的人气。为了不那么容易被检测出来，欺诈者会伪装自己的欺诈行为。本文提出的方案针对3种伪装方法：</p>
<ol>
<li>随机伪装。除了给目标商家好评，也随机给其他商家好评。</li>
<li>有偏的伪装。除了给目标商家好评，也随机给其他比较热门的商家好评。</li>
<li>劫持用户。通过劫持正常用户的账号，给目标商家好评。</li>
</ol>
<p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/image-20220226165801736.png" alt="image-20220226165801736"></p>
<h3 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h3><p>首先明确抗伪装的定义， 定义$g$为一个子图的密集程度指标（越密集越可疑），抗伪装的要求是：即使欺诈者做了一些伪装，这个指标$g$不会因此下降。</p>
<p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/image-20220226170724326.png" alt="image-20220226170724326"></p>
<p>看看作者设计的解决方案。作者设计的子图异常指标$g$（稠密程度）如下（左侧公式，右侧例子），其中$\mathcal{V}$是点集，$\mathcal{E}$是边集, $\mathcal{S}$是一个子图。</p>
<p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/image-20220226172725831.png" alt="image-20220226172725831"></p>
<p>这个指标满足几个欺诈检测中对异常指标的要求：</p>
<ol>
<li>子图规模相同的情况下，包含高危节点的子图更可疑。</li>
<li>子图的边增加，将会增加该子图的可疑性。</li>
<li>当点和边的权重相同时（并且在同样边的密度下），大图比小图更可疑（相同密度，越大越可疑）</li>
<li>如果总的可疑度相同，小图比大图更可疑（密度越大越可疑）</li>
</ol>
<p>算法流程：</p>
<p>是一个贪心算法。令$\mathcal{X}$是所有节点， 每次寻找一个节点$i$,使得下面这条式子最大：$\Delta_{i}=f(\mathcal{X} \backslash{i})-f(\mathcal{X})$</p>
<p>直观理解：每次选出一个节点，去除这个节点后，剩余的节点构成的子图的异常指标$f$最大。</p>
<p>遍历完成之后，取其中的一个子图作为异常子图，这个子图使得异常指标$g(S)=\frac{f_{S}}{|S|}$最大。</p>
<h5 id="这个算法是如何对抗伪装的？"><a href="#这个算法是如何对抗伪装的？" class="headerlink" title="这个算法是如何对抗伪装的？"></a>这个算法是如何对抗伪装的？</h5><p>回顾异常计算指标：</p>
<script type="math/tex; mode=display">
\begin{aligned}
f(\mathcal{S}) &=f_{\mathcal{V}}(\mathcal{S})+f_{\mathcal{E}}(\mathcal{S}) \\
&=\sum_{i \in \mathcal{S}} a_{i}+\sum_{i, j \in \mathcal{S} \wedge(i, j) \in \mathcal{E}} c_{i j}
\end{aligned}</script><p>其中$a<em>i$是节点的权重，$c</em>{i, j}$边的权重。通过调整$c_{i, j}$来抗伪装。</p>
<p>即通过令边权重$c_{i j}=\frac{1}{log (d_j+c)}$来达到抗伪装的目的， 其中$d_j$是商品节点$j$的度。这样调整权重的含义时，一个商品的度越高，它的边的权重越低。</p>
<h5 id="为什么这个权重-c-i-j-是抗伪装的？"><a href="#为什么这个权重-c-i-j-是抗伪装的？" class="headerlink" title="为什么这个权重$c_{i,j}$是抗伪装的？"></a>为什么这个权重$c_{i,j}$是抗伪装的？</h5><h5 id=""><a href="#" class="headerlink" title=""></a><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/image-20220227154756119.png" alt="image-20220227154756119"></h5><h3 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h3><p><strong>0. 本文使用的数据集</strong></p>
<p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/image-20220227160318769.png" alt="image-20220227160318769" style="zoom: 67%;" /></p>
<p><strong>1. 在生成数据中的实验。</strong> </p>
<p>在亚马逊的关于评论的图中，提取2000个用户和2000个商品的子图。往这个子图中注入欺诈块。</p>
<p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/image-20220227160011064.png" alt="image-20220227160011064"></p>
<p><strong>2. 在真实数据中的实验。</strong> </p>
<p>数据是推特的”关注者-被关注者“图。2009年采集数据，包含了4170万用户和14.7亿用户。在这张图上，Fraudar检测到4031关注者和4313被关注者的子图。</p>
<p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/image-20220227162143737.png" alt="image-20220227162143737" style="zoom:50%;" /></p>
<p>总结：通过迭代图中所有节点，检测出异常稠密的子图，这个子图就是有欺诈行为嫌疑的群体。</p>
<p>优点：</p>
<ol>
<li>是一个无监督的方法。</li>
<li>针对的是通过操纵大量用户进行欺诈的行为。</li>
</ol>
<p>不足之处：</p>
<ol>
<li>没有从时序的角度对用户和商品进行建模。用户和商品如果跟欺诈有关，会有特定的行为模式。</li>
<li>没有考虑用户、商品、和连边的内部特征。用户的个人特征、商品的特征、连边（评论）的特征也可以用来提高欺诈检测效果。这里可以引入GNN来实现这个目的。</li>
<li>不适用于检测个别用户的欺诈行为。</li>
</ol>
<p>附：本文中使用的数据集调研</p>
]]></content>
      <categories>
        <category>zhj</category>
      </categories>
      <tags>
        <tag>反欺诈</tag>
        <tag>风控</tag>
      </tags>
  </entry>
  <entry>
    <title>zhj 【NIPS2020】Supervised Contrastive Learning</title>
    <url>/2021/03/31/ZhangHongjun/%E3%80%902020NIPS%E3%80%91Supervised%20Contrastive%20Learning/</url>
    <content><![CDATA[<h2 id="Supervised-Contrastive-Learning"><a href="#Supervised-Contrastive-Learning" class="headerlink" title="Supervised Contrastive Learning"></a><strong>Supervised Contrastive Learning</strong></h2><p>关键词：对比学习；自监督；</p>
<p><strong>Abstract</strong></p>
<p>对比学习在自我监督表征学习中的应用近年来得到了迅速的发展，在深度图像模型的无监督训练中取得了很好的效果。现代批量对比方法包含或显著优于传统的对比损失，如三元组、最大边际和N对损失。在这项工作中，我们将自我监督的批对比方法扩展到完全监督的设置，使我们能够有效地利用标签信息。属于同一类的点簇在嵌入空间中被拉到一起，同时将来自不同类的样本簇分开。我们分析了监督对比（SupCon）损失的两种可能形式，确定了损失的最佳表现公式。在ResNet-200上，我们在ImageNet数据集上实现了81.4%的top-1准确率，比该体系结构报告的最佳数字高出0.8%。<br>我们在其他数据集和两个ResNet变量上显示了一致的优于交叉熵的性能。这种损失显示了对自然损坏的健壮性的好处，并且对于超参数设置（如优化器和数据处理）更为稳定。</p>
<a id="more"></a>
<h2 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1 Introduction"></a><strong>1 Introduction</strong></h2><p>交叉熵损失是深度分类模型监督学习中应用最广泛的损失函数。许多研究探索了这种损失的缺点，如对噪声标签缺乏鲁棒性[64，46]，以及边缘差的可能性[10，31]，导致泛化性能降低。然而，在实践中，大多数建议的替代方案并没有更好地适用于大规模数据集，如ImageNet[7]，这一点可以通过继续使用交叉熵来实现最新的结果来证明.</p>
<p>近年来，对比学习工作的重新兴起导致了自我监督表征学习的重大进展[55，18，38，48，22，3，15]。这些作品的共同思想是：在嵌入空间中把一个锚和一个“正”样本拉在一起，把锚从许多“负”样本中推开。由于没有可用的标签，正对通常由样本的数据扩充组成，负对由锚定和从minibatch中随机选择的样本组成。这在图2（左）中描绘。在[38，48]中，不同数据视图之间的对比损失与互信息最大化之间存在联系。</p>
<p>在这项工作中，我们提出了一个监督学习的损失，建立在对比自我监督文献的基础上，利用标签信息。来自同一类的规范化嵌入比来自不同类的嵌入更紧密地联系在一起。我们在这项工作中的技术创新之处在于，除了许多负面因素外，还考虑了每个锚定的许多正面因素（与只使用一个正面因素的自我监督对比学习相反）。这些积极因素是从与锚定相同类别的样本中提取的，而不是像在自监督学习中那样作为锚定的数据扩充。虽然这是自我监督设置的简单扩展，但如何正确设置损失函数并不明显，我们分析了两种选择。</p>
<p>我们的损失可以看作是triple loss[53]和N-pair loss[45]的推广.</p>
<p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/image-20210329111039811.png" alt="image-20210329111039811"></p>
<p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/image-20210331110557625.png" alt="image-20210331110557625"></p>
<p>这是第一个对比损失一贯表现优于交叉熵的大规模分类问题。此外，它提供了一个统一的损失函数，可用于自监督或监督学习。</p>
<p>我们的主要贡献总结如下:</p>
<ol>
<li>我们提出了一个新的扩展对比损失函数，每个锚点有多个正样本，从而适应对比学习的全监督设置。从分析和经验上，我们证明了原始的扩展的性能比我们提出的版本差得多。</li>
<li>我们表明，我们的损失为许多数据集提供了一致的提高，在前1的准确性。它也更为鲁棒。</li>
<li>我们的经验表明，我们的损失比交叉熵对一系列超参数不那么敏感。</li>
</ol>
<h2 id="2-Related-Work"><a href="#2-Related-Work" class="headerlink" title="2 Related Work"></a><strong>2 Related Work</strong></h2><p><strong>交叉熵损失函数的缺点：</strong></p>
<p>许多论文研究了交叉熵损失的其他缺点，如对噪声标签的敏感性[64，46]，存在对抗性样本[10，36]，以及较差的边缘[2]。虽然已经提出了替代损失函数，但实践中最有效的想法是改变参考标签分布的方法：如标签平滑[47,35]；数据增强方法：如Mixup[61]和CutMix[60]，以及知识提取[21]。</p>
<h2 id="3-Method"><a href="#3-Method" class="headerlink" title="3 Method"></a><strong>3 Method</strong></h2><p>我们的方法在结构上与CMC和simCLR中用于自监督对比学习的方法相似，但对监督分类进行了修改。给定一批输入数据，我们首先应用两次数据增强，得到该批数据的两个副本。两个拷贝通过编码器网络向前传播以获得2048维的规范化嵌入。在训练过程中，这种表示通过投影网络进一步传播，投影网络在推理时被丢弃。<br>根据投影网络的输出计算监督对比损失。为了使用训练好的模型进行分类，我们使用交叉熵损失在冻结表示的基础上训练了一个线性分类器。</p>
<p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/image-20210331111544441.png" alt="image-20210331111544441"></p>
<p><strong>3.1 Representation Learning Framework</strong></p>
<p>我们框架的主要组成部分是：</p>
<ul>
<li><p>数据扩充模块，Aug（·）。. 对于每个输入样本x，我们生成两个随机的增强数据x=Aug（x），每个增强数据表示不同的数据视图，并包含原始样本中的一些信息子集。第4节给出了增强的细节。</p>
</li>
<li><p>编码器网络，Enc（·），它把x映射到一个表示向量，r=Enc（x）。两个增强样本分别输入到同一个编码器，产生一对表示向量。r中被归一化为单位超球（在本文所有的实验中设置维度为2048）。与[42,52]的研究结果一致，我们的分析和实验表明，这种归一化提高了top-1的准确率。</p>
</li>
<li>投影网络，P roj（·），，将r映射到向量z=P roj（r）。我们将P roj（·）实例化为具有大小为2048的单个隐藏层和大小为DP=128的输出向量的多层感知器[14]，或者仅具有大小为DP=128的单个线性层；我们将最优P-roj（·）结构的研究留给以后的工作。我们再次将这个网络的输出标准化到单位超球面上，这样就可以使用内积来测量投影空间中的距离。在自我监督对比学习[48,3]中，我们在对比训练结束时抛弃了P-roj（·）。因此，我们的推理时间模型包含的参数数目与使用相同编码器Enc（·）的交叉熵模型完全相同。==这里的投影头，可以是MLP，也可以是Linear。simclr认为MLP的投影头比Linear的效果更好。另外，注意在投影头之前和之后，都对隐变量做了一次标准化。==</li>
</ul>
<p><strong>3.2 Contrastive Loss Functions</strong></p>
<p>在这个框架下，我们现在来看看对比损失家族，从自我监督领域开始，分析使之适应监督领域的选择，表明一个公式是优越的。</p>
<p><strong>3.2.1 Self-Supervised Contrastive Loss</strong></p>
<p>传统的自监督损失函数：</p>
<script type="math/tex; mode=display">
\mathcal{L}^{\text {self }}=\sum_{i \in I} \mathcal{L}_{i}^{\text {self }}=-\sum_{i \in I} \log \frac{\exp \left(\boldsymbol{z}_{i} \cdot \boldsymbol{z}_{j(i)} / \tau\right)}{\sum_{a \in A(i)} \exp \left(\boldsymbol{z}_{i} \cdot \boldsymbol{z}_{a} / \tau\right)}\tag1</script><p>注意，对于每个锚i，有1个正对和2n2个负对。==分母共有2n -1项（正项和负项）==。</p>
<p><strong>3.2.2 Supervised Contrastive Losses</strong></p>
<p>对于有监督学习，等式1中的对比损失无法处理由于标签的存在，多个样本已知属于同一类的情况。然而，推广到任意数量的正数，会导致在多个可能的函数之间进行选择。方程式。2和3给出了两种最直接的方法来概括公式1，以考虑有监督信息。</p>
<script type="math/tex; mode=display">
\mathcal{L}_{\text {out }}^{s u p}=\sum_{i \in I} \mathcal{L}_{\text {out }, i}^{s u p}=\sum_{i \in I} \frac{-1}{|P(i)|} \sum_{p \in P(i)} \log \frac{\exp \left(\boldsymbol{z}_{i} \cdot \boldsymbol{z}_{p} / \tau\right)}{\sum_{a \in A(i)} \exp \left(\boldsymbol{z}_{i} \cdot \boldsymbol{z}_{a} / \tau\right)}\tag2</script><script type="math/tex; mode=display">
\mathcal{L}_{i n}^{s u p}=\sum_{i \in I} \mathcal{L}_{i n, i}^{s u p}=\sum_{i \in I}-\log \left\{\frac{1}{|P(i)|} \sum_{p \in P(i)} \frac{\exp \left(\boldsymbol{z}_{i} \cdot \boldsymbol{z}_{p} / \tau\right)}{\sum_{a \in A(i)} \exp \left(\boldsymbol{z}_{i} \cdot \boldsymbol{z}_{a} / \tau\right)}\right\}\tag3</script><p>这两种损失都具有以下理想特性：</p>
<ul>
<li><p><strong>任意数量的正例对的推广。</strong>. Eqs的主要结构变化。公式1上的2和3是，现在，对于任何锚定，多视图批次中的所有阳性（即，基于增强的样本以及具有相同标签的任何剩余样本）都与分子有关。对于随机生成的批，其大小相对于类的数量而言较大，将出现多个附加项（平均而言，N/C，其中C是类的数量）。监督损失鼓励编码器对来自同一类的所有条目提供紧密对齐的表示，从而产生比由等式1生成的表示空间更健壮的表示空间聚类，这一点在Sec 4的实验中得到了支持。</p>
</li>
<li><p><strong>对比能力随着负面因素的增加而增加</strong>。其中，通过添加更多负性示例来提高信号和噪声（负）之间的辨别能力。这种特性对于自监督对比学习的表征学习具有重要意义，许多论文表现出随着否定数的增加而提高的表现</p>
</li>
<li><strong>执行难正/负挖掘的内在能力</strong>。当与标准化表示一起使用时，公式1中的损失会导致梯度结构，从而产生隐式硬正/负挖掘。难正/负样本（即，继续对比锚定对编码器有很大好处）的梯度贡献较大，而容易正/负样本（即，继续对比锚定对编码器只有微弱好处）的梯度贡献较小。此外，对于难正样本，效果随着负样本数量的增加（渐进地）增加。方程式。2和3都保留了这个有用的性质，并将其推广到所有的正样本。这种隐含的属性允许对比损失避开显式难样本发掘的需要，这是许多损失的一个微妙但关键的部分，例如三重态损失。</li>
</ul>
<p>然而，这两种损失公式并不相等。因为log是凹函数，所以Jensen不等式[23]表示L sup in≤Lsup out。因此，人们会期望L sup out是更好的监督损失函数（因为它的上限是L sup in）。这一结论也得到了理论上的支持。</p>
<p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/image-20210326104452766.png" alt="image-20210326104452766" style="zoom: 50%;" /></p>
<p>在这篇文章的其余部分，我们只考虑了$\mathcal{L}_{\text {out }}^{\text {sup }}$。</p>
<h2 id="4-Experiments"><a href="#4-Experiments" class="headerlink" title="4 Experiments"></a><strong>4 Experiments</strong></h2><p>我们通过在包括CIFAR-10和CIFAR-100[27]和Ima  geNet[7]在内的许多常见图像分类基准上测量分类精度，来评估SupCon损失（L sup out，公式2）。我们还测试了ImageNet模型对常见图像损坏的鲁棒性[19]，并展示了性能如何随超参数和减少数据的变化而变化。对于编码器网络（Enc（·）），我们试验了三种常用的编码器架构：ResNet-50、ResNet-101和ResNet-200[17]、最终池层（DE=2048）的规范化激活被用作表示向量。我们试验了Aug（·）数据增强模块的四种不同实现：自动增强[5]；随机增强[6]；SimAugment[3]和Stacked RandAugment[49]（请参阅补充说明中的SimAugment和Stacked randagment实现的详细信息）。对于SupCon和交叉熵，AutoAugment都优于ResNet-50上的所有其他数据增强策略。对于这两种损失函数，叠加RandAugment对ResNet-200的性能最好。我们在附录中提供了更多细节</p>
<p><strong>4.1 Classifification Accuracy</strong></p>
<p>表2显示，SupCon在CIFAR-10、CIFAR-100和ImageNet数据集上的推广优于交叉熵、边缘分类器（使用标签）和无监督对比学习技术。表3显示了针对ImageNet的ResNet-50和ResNet-200（我们使用ResNet-v1[17]）的结果。我们在ResNet-50上通过AutoAugment实现了78.7%的最新精度。</p>
<p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/image-20210331112321937.png" alt="image-20210331112321937"></p>
<p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/image-20210331112333082.png" alt="image-20210331112333082"></p>
<p>Evaluation protocol（Data-Efficient Image Recognition with Contrastive Predictive Coding）</p>
<ul>
<li>Linear classification 线性分类是评价无监督图像表现质量的标准基准。在这种情况下，分类网络hψ被限制为一个池，然后是一个线性层，θ以外的参数保持不变。标记的数据集是整个ImageNet数据集，监督的损失超过标准交叉熵。我们使用与无监督学习阶段相同的数据扩充进行训练，在测试时不使用任何数据扩充，并使用单个作物进行评估</li>
<li>Efficient classification 有效的分类直接测试CPC表示是否能够从很少的标签进行泛化。对于这个任务，分类器rhψ是一个任意深度的神经网络</li>
<li>Transfer  learning 迁移到其他数据集上。</li>
</ul>
<hr>
<p>一些想法：</p>
<p>多视图对比学习CMC也可以使用这个损失函数，从而将多个正样本考虑进去。</p>
<p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/image-20210329111415460.png" alt="image-20210329111415460" style="zoom: 67%;" /></p>
]]></content>
      <categories>
        <category>zhj</category>
      </categories>
      <tags>
        <tag>自监督</tag>
        <tag>对比学习</tag>
      </tags>
  </entry>
  <entry>
    <title>zhj 【CVPR2021】Understanding the Behaviour of Contrastive Loss</title>
    <url>/2021/07/21/ZhangHongjun/%E3%80%902021CVPR%E3%80%91Understanding%20the%20Behaviour%20of%20Contrastive%20Loss/</url>
    <content><![CDATA[<p><strong>Abstract</strong></p>
<p>无监督的对比学习取得了成功，而对比损失的机制很少被研究。本文专注于探究无监督损失的行为。本文将证明对比损失是一个具有难样本感知能力的损失函数，温度τ控制难样本的惩罚强度。以往的研究表明，均匀性是对比学习的一个重要特征。我们建立了均匀性和温度τ之间的关系。本文将证明，均匀性有助于对比学习学习可分离的特征，但过分追求均匀性会使对比损失对语义相似的样本无法容忍，这可能会破坏潜在的语义结构，不利于形成对下游任务有用的特征。究其原因，是由于实例判别目标函数的内在缺陷。具体来说，实例判别目标函数试图将所有不同的实例分开，忽略样本之间的潜在关系。将语义一致的样本分开对于获取一般下游任务的先验信息没有积极的作用。一个设计良好的对比损失应该对语义相似性样本有一定程度的容忍度。因此，我们发现对比损失会遇到一个均匀性-容忍性的困境，而温度的良好选择可以协调这两个特性，既有利于学习可分离特征，又有利于对语义相似样本的容忍，从而提高特征质量和下游性能。</p>
<a id="more"></a>
<p><strong>Introduction</strong></p>
<p>对比学习是一种无监督的方法，将原始的数据映射到超球面上。它尝试通过具有相同语义的正样本对互相拉近，让具有不同语义的负样本对互相远离，使得神经网络学习到不同视图之间共同的语义信息。在下图中，(a)图里具有相同语义的样本聚集，不同语义的样本远离，是一个比较好的表示。</p>
<p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/image-20210721094149256.png" alt="image-20210721094149256"></p>
<p>对比损失函数与softmax函数有许多相似之处，</p>
<p>softmax+交叉熵(多分类问题中常见)：</p>
<script type="math/tex; mode=display">
L_{i}=-\log \left(\frac{e^{f_{y_{i}}}}{\sum_{j} e^{j}}\right)</script><p>对比损失：</p>
<script type="math/tex; mode=display">
\mathcal{L}\left(x_{i}\right)=-\log \left[\frac{\exp \left(s_{i, i} / \tau\right)}{\sum_{k \neq i} \exp \left(s_{i, k} / \tau\right)+\exp \left(s_{i, i} / \tau\right)}\right]</script><p>本文发现对比损失是一个负样本难程度感知损失函数，它自动地集中于优化难负样本，并根据它们的难程度给予惩罚。温度对难负样本的惩罚强度起控制作用。具体地说，小的温度T下的对比损失在最难的负样本上作用更强，使得每个样本的局部结构更为清晰，整体分布更为均匀。另一方面，大的温度T下的对比损失对难负样本不太敏感，随着温度的升高至正无穷，难程度感知特性消失，难程度感知特性对基于softmax的对比损失的成功具有重要意义。 基于以上观察，本文提出显式难负采样策略，它虽然简单但是效果很好。</p>
<p>本文将对比学习的温度系数T和表示的均匀性联系起来。将温度T作为可调节的参数，我们发现虽然均匀性是对比模型的性能的关键指标，但过度追求均匀性可能会破坏潜在的语义结构。这是由无监督对比损失的固有缺陷引起的。具体而言，大多数对比的学习方法旨在通过将同一个样本经过不同的数据增强之后得到的两个view视作正样本对，这样做的缺点就是不能将其他具有相同语义的样本当做正样本。对于这种对比学习方法来说，上图（a）和（b）的对比损失是相同的。推开具有相同语义的样本不利于产生有用的特征表示。</p>
<p>如果对比损失具有非常小的温度T，则损失函数将对最近的样本非常大的惩罚，而这个样本很有可能与锚样本具有相同的语义。</p>
<p>我们认识到在无监督的对比学习中存在着一个一致性-容忍性的困境。一方面，我们希望特征分布足够均匀，以便更易于分离。另一方面，我们希望对比损失能更接近语义相似的样本。一个好的对比损失应该是一个折衷方案，以适当地满足这两个属性。因此需要合适的温度T。</p>
<p>总体而言，贡献可归纳如下：</p>
<ul>
<li>我们分析了对比损失的行为，表明对比损失是一种难程度感知的损失函数。</li>
<li>通过梯度分析，我们表明温度T是控制难负样本惩罚强度的关键参数。</li>
<li>我们表明，在对比学习中存在均匀性-容忍性困境，良好选择的温度T可以协调者两个性质，并且可以提高特征表示的质量。</li>
</ul>
<p><strong>2. Related Work</strong></p>
<p>对比学习框架： CPC，CMC，SimCLR， MoCo….</p>
<p>分析对比学习属性的论文：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1. A theoretical analysis of contrastive unsupervised representation learning.</span><br><span class="line">2. Demystifying contrastive self-supervised learning: Invariances, augmentations and dataset biases.</span><br><span class="line">3. What makes for good views for contrastive learning.</span><br><span class="line">4. On mutual information in contrastive learning for visual representations.</span><br><span class="line">5. Understanding contrastive representation learning through alignment and uniformity on the hypersphere.</span><br></pre></td></tr></table></figure>
<p>与上述论文不同，我们主要专注于对比损失的固有特性。我们强调温度τ的重要性，并使用它来分析对比学习中一些有趣的现象。</p>
<p><strong>3. Hardness-aware Property</strong></p>
<p>接下来，我们将从梯度分析开始解释对比损失的性质。给定未标记的训练集$X=\left{x<em>{1}, \ldots, x</em>{N}\right}$，制定了对比损失：</p>
<script type="math/tex; mode=display">
\mathcal{L}\left(x_{i}\right)=-\log \left[\frac{\exp \left(s_{i, i} / \tau\right)}{\sum_{k \neq i} \exp \left(s_{i, k} / \tau\right)+\exp \left(s_{i, i} / \tau\right)}\right]\tag1</script><p>其中$s<em>{i, j}$表示样本i和样本j在超球面的余弦距离。$s</em>{i, j}\in[-1,1]$, 越大表示样本i,j越近。为了方便，本文定义了</p>
<script type="math/tex; mode=display">
P_{i, j}=\frac{\exp \left(s_{i, j} / \tau\right)}{\sum_{k \neq i} \exp \left(s_{i, k} / \tau\right)+\exp \left(s_{i, i} / \tau\right)}\tag2</script><p>这个损失函数的目标是正样本对靠近，负样本对远离， 因此，使用如下更简单损失函数同样可以达到这个目的：</p>
<script type="math/tex; mode=display">
\mathcal{L}_{\text {simple }}\left(x_{i}\right)=-s_{i, i}+\lambda \sum_{i \neq j} s_{i, j}\tag3</script><p>但是，作者发现损失函数(3)的效果不如损失函数(1). 接下来，作者分析他们的不同。</p>
<p><strong>3.1. Gradients Analysis.</strong></p>
<p>作者对正样本对$s<em>{i,i}$和负样本$s</em>{i,j}$对分析梯度。分析表明，正样本对梯度的大小等于负样本对梯度的总和。温度T控制负梯度的分布。较小的温度T倾向于将梯度集中在锚点的最接近的样本。</p>
<script type="math/tex; mode=display">
\frac{\partial \mathcal{L}\left(x_{i}\right)}{\partial s_{i, i}}=-\frac{1}{\tau} \sum_{k \neq i} P_{i, k}, \quad \frac{\partial \mathcal{L}\left(x_{i}\right)}{\partial s_{i, j}}=\frac{1}{\tau} P_{i, j}\tag4</script><p>从式子（4）有一下观察：</p>
<p>1）对负样本对的梯度与$\exp \left(s_{i, j} / \tau\right)$成正相关，当T越小，对负样本的梯度越大。这一点与损失函数(3)对负样本对的梯度不同，它对所有负样本对的梯度是一样的。</p>
<p>2）相对于正样本的梯度幅度等于相对于所有负样本的梯度之和。也就是$\left(\sum<em>{k \neq i}\left|\frac{\partial L\left(x</em>{i}\right)}{\partial s<em>{i, k}}\right|\right) /\left|\frac{\partial L\left(x</em>{i}\right)}{\partial s_{i, i}}\right|=1$</p>
<p><strong>3.2. The Role of temperature</strong></p>
<p>这里定义了$r<em>{i}\left(s</em>{i, j}\right)=\left|\frac{\partial L\left(x<em>{i}\right)}{\partial s</em>{i, j}}\right| /\left|\frac{\partial L\left(x<em>{i}\right)}{\partial s</em>{i, i}}\right|$，表示了对负样本对梯度的相对值。</p>
<script type="math/tex; mode=display">
r_{i}\left(s_{i, j}\right)=\frac{\exp \left(s_{i, j} / \tau\right)}{\sum_{k \neq i} \exp \left(s_{i, k} / \tau\right)}, \quad i \neq j\tag5</script><p>在不同温度T和不同的$s<em>{i,j}$下，$r</em>{i}\left(s_{i, j}\right)$的值如下：</p>
<p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/image-20210721111953056.png" alt="image-20210721111953056"></p>
<p>从上图可以看出，随着温度T的降低，相对梯度惩罚更集中在高相似性区域上（$s_{i,j}≈1$），随着温度的增加，相对惩罚分布趋于更均匀，这倾向于使所有负样本样本具有相同的惩罚程度。此外，随着温度降低，有效的惩罚区间变窄。极小的温度会导致对比损失仅集中在最接近的一两种样本上，这将严重影响效果。</p>
<p>针对以上观察，作者提出了针对难负样本的损失函数：</p>
<script type="math/tex; mode=display">
\mathcal{L}_{\text {hard }}\left(x_{i}\right)=-\log \frac{\exp \left(s_{i, i} / \tau\right)}{\sum_{s_{i, k} \geqslant s_{\alpha}^{(i)}} \exp \left(s_{i, k} / \tau\right)+\exp \left(s_{i, i} / \tau\right)}\tag9</script><p>上式与原来的损失函数不同之处，是分母的负样本集里，只有难负样本，即$s<em>{i, k} \geqslant s</em>{\alpha}^{(i)}$的负样本K。</p>
<h4 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h4><p><img src="https://gitee.com/kris_poul/imagebed/raw/master/imgbed/image-20210721112642664.png" alt="image-20210721112642664"></p>
<p>取不同的温度$\tau \in {0.07, 0.3, 0.7, 1.0}$, </p>
<p>Contrastive是原始的对比损失（1）：</p>
<script type="math/tex; mode=display">
\mathcal{L}\left(x_{i}\right)=-\log \left[\frac{\exp \left(s_{i, i} / \tau\right)}{\sum_{k \neq i} \exp \left(s_{i, k} / \tau\right)+\exp \left(s_{i, i} / \tau\right)}\right]\tag1</script><p>simple 是式子（3）：</p>
<script type="math/tex; mode=display">
\mathcal{L}_{\text {simple }}\left(x_{i}\right)=-s_{i, i}+\lambda \sum_{i \neq j} s_{i, j}\tag3</script><p>HardContrastive是式子（9）：</p>
<script type="math/tex; mode=display">
\mathcal{L}_{\text {hard }}\left(x_{i}\right)=-\log \frac{\exp \left(s_{i, i} / \tau\right)}{\sum_{s_{i, k} \geqslant s_{\alpha}^{(i)}} \exp \left(s_{i, k} / \tau\right)+\exp \left(s_{i, i} / \tau\right)}\tag9</script><p>Hardsimple是只使用难负样本的简单形式。</p>
<p>对于α的设置：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>数据集</th>
<th>CIFAR10</th>
<th>CIFAR100</th>
<th>SVHN</th>
<th>ImageNet100</th>
</tr>
</thead>
<tbody>
<tr>
<td><em>α</em></td>
<td>0.0819</td>
<td>0.0819</td>
<td>0.0315</td>
<td>0.034</td>
</tr>
</tbody>
</table>
</div>
<p>总结:本文从梯度的角度分析对比损失函数，探究了温度系数T在对比学习中起到的作用。</p>
]]></content>
      <categories>
        <category>zhj</category>
      </categories>
      <tags>
        <tag>自监督</tag>
        <tag>对比学习</tag>
      </tags>
  </entry>
</search>
